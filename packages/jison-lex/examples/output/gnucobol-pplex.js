

/* lexer generated by jison-lex 0.7.0-220 */

/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a direct reference!
 *
 *               This "shared context" object was passed to the lexer by way of
 *               the `lexer.setInput(str, yy)` API before you may use it.
 *
 *               This "shared context" object is passed to the lexer action code in `performAction()`
 *               so userland code in the lexer actions may communicate with the outside world
 *               and/or other lexer rules' actions in more or less complex ways.
 *
 *  }
 *
 *  Lexer.prototype: {
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    yy:        The overall "shared context" object reference.
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance.
 *                               `yy_` is an alias for `this` lexer instance reference used internally.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *                             Note:
 *                             The extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file are passed to the lexer via this object
 *                             reference as member variables.
 *
 *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   let infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   let retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function(),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the **parser** or the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *    cleanupAfterLex: function(),
 *               Helper function.
 *
 *               This helper API is invoked when the **parse process** has completed: it is the responsibility
 *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
 *
 *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *    setInput: function(input, [yy]),
 *
 *
 *    input: function(),
 *
 *
 *    unput: function(str),
 *
 *
 *    more: function(),
 *
 *
 *    reject: function(),
 *
 *
 *    less: function(n),
 *
 *
 *    pastInput: function(n),
 *
 *
 *    upcomingInput: function(n),
 *
 *
 *    showPosition: function(),
 *
 *
 *    test_match: function(regex_match_array, rule_index),
 *
 *
 *    next: function(),
 *
 *
 *    begin: function(condition),
 *
 *
 *    pushState: function(condition),
 *
 *
 *    popState: function(),
 *
 *
 *    topState: function(),
 *
 *
 *    _currentRules: function(),
 *
 *
 *    stateStackSize: function(),
 *
 *
 *    performAction: function(yy, yy_, yyrulenumber, YY_START),
 *
 *
 *    rules: [...],
 *
 *
 *    conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */



const fs = require('fs');
const path = require('path');




const lexer = (function () {
    "use strict";

    

    /**
 * See also:
 * 
 * - https://github.com/onury/custom-error-test
 * - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error
 * 
 * We now provide an ES6 derived Error class. An updated ES5-compatible class
 * is available too, for those who might need it, as this is complex stuff to
 * get right (see first link above).
 *
 * @public
 * @constructor
 * @nocollapse
 */


/*---ES5---

//
// JS CustomError implementation — The One (Adapted for JISON)
// This is the closest we can get to ES2015 `extends Error` implementation.
// @version 2017-01-05
// @author
//     Onur Yıldırım (https://github.com/onury)
//     Matt Browne (https://github.com/mbrowne)
// @see
//     https://github.com/onury/custom-error-test
//     http://stackoverflow.com/a/35881508/112731
//     https://gist.github.com/mbrowne/4af54767dcb3d529648f5a8aa11d6348
//     http://stackoverflow.com/a/41338601/112731
//
function JisonLexerError(message, hash) {
    if (message == null) message = '???';

    let stacktrace;
    if (hash && hash.exception instanceof Error) {
        const ex2 = hash.exception;
        message = message + ' :: ' + ex2.message;
        stacktrace = ex2.stack;
    }

    let err;
    if (Object.setPrototypeOf) {
        err = new Error(message);
        Object.setPrototypeOf(err, CustomError.prototype);
    } else {
        err = this;
    }

    Object.defineProperty(err, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonLexerError'
    });

    err.hash = hash;

    if (!Object.setPrototypeOf) {
        Object.defineProperty(err, 'message', {
            enumerable: false,
            writable: true,
            value: message
        });
        if (!stacktrace) {
            if (typeof Error.captureStackTrace === 'function') { // V8
                Error.captureStackTrace(this, JisonLexerError);
            } else {
                stacktrace = (new Error(message)).stack;
            }
        }
    }

    if (stacktrace) {
        Object.defineProperty(err, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }

    return err;
}
if (Object.setPrototypeOf) {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
} else {
    JisonLexerError.prototype = Object.create(Error.prototype, {
        constructor: { value: JisonLexerError }
    });
}

---ES5---*/

//---ES6---//

class JisonLexerError extends Error {
  constructor(message, hash, ...params) {
    if (message == null) message = '???';

    let stacktrace;
    if (hash && hash.exception instanceof Error) {
        const ex2 = hash.exception;
        message = message + ' :: ' + ex2.message;
        stacktrace = ex2.stack;
    }

    // Pass remaining arguments (including vendor specific ones) to parent constructor
    super(message, ...params);

    if (!stacktrace) {
        // Maintains proper stack trace for where our error was thrown (only available on V8)
        if (typeof Error.captureStackTrace === 'function') { // V8
            Error.captureStackTrace(this, JisonLexerError);
        } else {
            stacktrace = (new Error(message)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }

    this.name = 'JisonLexerError';
    this.hash = hash;
  }
}

//---ES6---//

    

    
const lexer = {

// Code Generator Information Report
// ---------------------------------
//
// Options:
//
//   backtracking: .................... false
//   location.ranges: ................. false
//   location line+column tracking: ... true
//
//
// Forwarded Parser Analysis flags:
//
//   uses yyleng: ..................... 
//   uses yylineno: ................... 
//   uses yytext: ..................... 
//   uses yylloc: ..................... 
//   uses lexer values: ...............  / 
//   location tracking: ............... 
//   location assignment: ............. 
//
//
// Lexer Analysis flags:
//
//   uses yyleng: ..................... ???
//   uses yylineno: ................... ???
//   uses yytext: ..................... ???
//   uses yylloc: ..................... ???
//   uses ParseError API: ............. ???
//   uses yyerror: .................... ???
//   uses location tracking & editing:  ???
//   uses more() API: ................. ???
//   uses unput() API: ................ ???
//   uses reject() API: ............... ???
//   uses less() API: ................. ???
//   uses display APIs pastInput(), upcomingInput(), showPosition():
//        ............................. ???
//   uses describeYYLLOC() API: ....... ???
//
// --------- END OF REPORT -----------


EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup

    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use

    done: false,                                /// INTERNAL USE ONLY
    _backtrack: false,                          /// INTERNAL USE ONLY
    _input: '',                                 /// INTERNAL USE ONLY
    _more: false,                               /// INTERNAL USE ONLY
    _signaled_error_token: false,               /// INTERNAL USE ONLY
    _clear_state: 0,                            /// INTERNAL USE ONLY; 0: clear to do, 1: clear done for lex()/next(); -1: clear done for inut()/unput()/...

    conditionStack: [],                         /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`

    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far. (**WARNING:** this value MAY be negative if you `unput()` more text than you have already lexed. This type of behaviour is generally observed for one kind of 'lexer/parser hack' where custom token-illiciting characters are pushed in front of the input stream to help simulate multiple-START-points in the parser. When this happens, `base_position` will be adjusted to help track the original input's starting point in the `_input` buffer.)
    base_position: 0,                           /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: index to the original starting point of the input; always ZERO(0) unless `unput()` has pushed content before the input: see the `offset` **WARNING** just above.
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction
    CRLF_Re: /\r\n?|\n/,                        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: regex used to split lines while tracking the lexer cursor position.

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
     *
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
        msg = '' + msg;

        // heuristic to determine if the error message already contains a (partial) source code dump
        // as produced by either `showPosition()` or `prettyPrintRange()`:
        if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
        }
        if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
                const pretty_src = this.prettyPrintRange(this.yylloc);

                if (!/\n\s*$/.test(msg)) {
                    msg += '\n';
                }
                msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
            } else if (typeof this.showPosition === 'function') {
                const pos_str = this.showPosition();
                if (pos_str) {
                    if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
                        msg += '\n' + pos_str;
                    } else {
                        msg += pos_str;
                    }
                }
            }
        }
        
        /** @constructor */
        const pei = {
            errStr: msg,
            recoverable: !!recoverable,
            text: this.match,           // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...
            token: null,
            line: this.yylineno,
            loc: this.copy_yylloc(this.yylloc),
            yy: this.yy,
            // lexer: this,             // OBSOLETED member since 0.7.0: will cause reference cycles if not treated very carefully, hence has memory leak risks!

            // flags to help userland code to easily recognize what sort of error they're getting fed this time:
            isLexerError: true,                // identifies this as a *lexer* error (contrasting with a *parser* error, which would have `isParserError: true`)

            yyErrorInvoked: false,             // `true` when error is caused by call to `yyerror()`
            isLexerBacktrackingNotSupportedError: false,
            isLexerInternalError: false,

            // additional attributes which will be set up in various error scenarios:
            extra_error_attributes: null,      // array of extra arguments passed to parseError = args;
            lexerHasAlreadyForwardedCursorBy1: false,

            // OBSOLETED since 0.7.0: parser and lexer error `hash` and `yy` objects are no longer carrying cyclic references, hence no more memory leak risks here.
            // 
            // /**
            //  * and make sure the error info doesn't stay due to potential
            //  * ref cycle via userland code manipulations.
            //  * These would otherwise all be memory leak opportunities!
            //  *
            //  * Note that only array and object references are nuked as those
            //  * constitute the set of elements which can produce a cyclic ref.
            //  * The rest of the members is kept intact as they are harmless.
            //  *
            //  * @public
            //  * @this {LexErrorInfo}
            //  */
            // destroy: function destructLexErrorInfo() {
            //     // remove cyclic references added to error info:
            //     // info.yy = null;
            //     // info.lexer = null;
            //     // ...
            //     const rec = !!this.recoverable;
            //     for (let key in this) {
            //         if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
            //             this[key] = undefined;
            //         }
            //     }
            //     this.recoverable = rec;
            // }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     *
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
        if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
        }
        if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
                return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
                return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            }
        }
        throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
     *
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str, ...args) {
        let lineno_msg = 'Lexical error';
        if (this.yylloc) {
            lineno_msg += ' on line ' + (this.yylineno + 1);
        }
        const p = this.constructLexErrorInfo(lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

        // Add any extra args to the hash under the name `extra_error_attributes`:
        if (args.length) {
            p.extra_error_attributes = args;
        }
        p.yyErrorInvoked = true;   // so parseError() user code can easily recognize it is invoked from any yyerror() in the spec action code chunks

        return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     *
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex() {
        // prevent lingering circular references from causing memory leaks:
        this.setInput('', {});

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        for (let i = this.__error_infos.length - 1; i >= 0; i--) {
            let el = this.__error_infos[i];
            if (el && typeof el.destroy === 'function') {
                el.destroy();
            }
        }
        this.__error_infos.length = 0;

        return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     *
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        // - DO NOT reset `this.matched`
        this.matches = false;

        this._more = false;
        this._backtrack = false;

        const col = this.yylloc.last_column;
        this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,

            range: [ this.offset, this.offset ]
        };
    },

    /**
     * resets the lexer, sets new input
     *
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
        this.yy = yy || this.yy || {};

        // also check if we've fully initialized the lexer instance,
        // including expansion work to be done to go from a loaded
        // lexer to a usable lexer:
        if (!this.__decompressed) {
            // step 1: decompress the regex list:
            let rules = this.rules;
            for (let i = 0, len = rules.length; i < len; i++) {
                let rule_re = rules[i];

                // compression: is the RE an xref to another RE slot in the rules[] table?
                if (typeof rule_re === 'number') {
                    rules[i] = rules[rule_re];
                }
            }

            // step 2: unfold the conditions[] set to make these ready for use:
            let conditions = this.conditions;
            for (let k in conditions) {
                let spec = conditions[k];

                let rule_ids = spec.rules;

                let len = rule_ids.length;
                let rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
                let rule_new_ids = new Array(len + 1);

                for (let i = 0; i < len; i++) {
                    let idx = rule_ids[i];
                    let rule_re = rules[idx];
                    rule_regexes[i + 1] = rule_re;
                    rule_new_ids[i + 1] = idx;
                }

                spec.rules = rule_new_ids;
                spec.__rule_regexes = rule_regexes;
                spec.__rule_count = len;
            }

            this.__decompressed = true;
        }

        if (input && typeof input !== 'string') {
            input = '' + input;
        }
        this._input = input || '';
        this._clear_state = -1;
        this._signaled_error_token = false;
        this.done = false;
        this.yylineno = 0;
        this.matched = '';
        this.conditionStack = [ 'INITIAL' ];
        this.__currentRuleSet__ = null;
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [ 0, 0 ]
        };
        this.offset = 0;
        this.base_position = 0;
        // apply these bits of `this.clear()` as well:
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        this.matches = false;

        this._more = false;
        this._backtrack = false;

        return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse,
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the `unput()` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current `yyloc` cursor location or any history.
     *
     * Use this API to help implement C-preprocessor-like
     * `#include` statements, etc.
     *
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The `cpsArg` argument value is passed to the callback
     * as-is.
     *
     * `callback` interface:
     * `function callback(input, cpsArg)`
     *
     * - `input` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - `cpsArg` is `cpsArg` passed into this API.
     *
     * The `this` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API.
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the `"" + retval`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html
     * -- that way any returned object's `toValue()` and `toString()`
     * methods will be invoked in a proper/desirable order.)
     *
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
        const rv = callback.call(this, this._input, cpsArg);
        if (typeof rv !== 'string') {
            if (rv) {
                this._input = '' + rv;
            }
            // else: keep `this._input` as is.
        } else {
            this._input = rv;
        }
        return this;
    },

    /**
     * consumes and returns one char from the input
     *
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
        if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
        }
        if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
        }
        let ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        // Count the linenumber up when we hit the LF (or a stand-alone CR).
        // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
        // and we advance immediately past the LF as well, returning both together as if
        // it was all a single 'character' only.
        let slice_len = 1;
        let lines = false;
        if (ch === '\n') {
            lines = true;
        } else if (ch === '\r') {
            lines = true;
            const ch2 = this._input[1];
            if (ch2 === '\n') {
                slice_len++;
                ch += ch2;
                this.yytext += ch2;
                this.yyleng++;
                this.offset++;
                this.match += ch2;
                this.matched += ch2;
                this.yylloc.range[1]++;
            }
        }
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
        } else {
            this.yylloc.last_column++;
        }
        this.yylloc.range[1]++;

        this._input = this._input.slice(slice_len);
        return ch;
    },

    /**
     * consumes and returns N chars from the input
     *
     * @public
     * @this {RegExpLexer}
     */
    consume: function lexer_consume(n) {
        if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
        }
        if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
        }
        let str = this._input.substring(0, n);
        let len = str.length;
        this.yytext += str;
        this.yyleng += len;
        this.offset += len;
        this.match += str;
        this.matched += str;
        // Count the linenumber up when we hit the LF (or a stand-alone CR).
        // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
        // and we advance immediately past the LF as well, returning both together as if
        // it was all a single 'character' only.
        let slice_len = len;
        let lines_arr = str.split(this.CRLF_Re);
        let line_count = lines_arr.length - 1;
        let lines = false;
        const ch = this._input[n - 1];
        if (ch === '\n') {
            lines = true;
        } else if (ch === '\r') {
            lines = true;
            const ch2 = this._input[n];
            if (ch2 === '\n') {
                slice_len++;
                str += ch2;
                this.yytext += ch2;
                this.yyleng++;
                this.offset++;
                this.match += ch2;
                this.matched += ch2;
                this.yylloc.range[1]++;
            }
        }
        this.yylineno += line_count;
        this.yylloc.last_line += line_count;
        if (lines) {
            this.yylloc.last_column = 0;
        } else {
            this.yylloc.last_column = lines_arr[line_count].length;
        }
        this.yylloc.range[1] += len;

        this._input = this._input.slice(slice_len);
        return str;
    },

    /**
     * unshifts one char (or an entire string) into the input
     *
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
        let len = ch.length;
        let lines = ch.split(this.CRLF_Re);

        if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
        }

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        this.yyleng = this.yytext.length;
        this.offset -= len;
        // **WARNING:**
        // The `offset` value MAY be negative if you `unput()` more text than you have already lexed.
        // This type of behaviour is generally observed for one kind of 'lexer/parser hack'
        // where custom token-illiciting characters are pushed in front of the input stream to help
        // simulate multiple-START-points in the parser.
        // When this happens, `base_position` will be adjusted to help track the original input's
        // starting point in the `_input` buffer.
        if (-this.offset > this.base_position) {
            this.base_position = -this.offset;
        }
        this.match = this.match.substr(0, this.match.length - len);
        this.matched = this.matched.substr(0, this.matched.length - len);

        if (lines.length > 1) {
            this.yylineno -= lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the `pre_lines[]` array's
            // last index slot; we don't mind when other previously
            // matched lines end up in the array too.
            let pre = this.match;
            let pre_lines = pre.split(this.CRLF_Re);
            if (pre_lines.length === 1) {
                pre = this.matched;
                pre_lines = pre.split(this.CRLF_Re);
            }
            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
        } else {
            this.yylloc.last_column -= len;
        }

        this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;

        this.done = false;
        return this;
    },

    /**
     * return the upcoming input *which has not been lexed yet*.
     * This can, for example, be used for custom look-ahead inspection code
     * in your lexer.
     *
     * The entire pending input string is returned.
     *
     * > ### NOTE ###
     * >
     * > When augmenting error reports and alike, you might want to
     * > look at the `upcomingInput()` API instead, which offers more
     * > features for limited input extraction and which includes the
     * > part of the input which has been lexed by the last token a.k.a.
     * > the *currently lexed* input.
     * >
     *
     * @public
     * @this {RegExpLexer}
     */
    lookAhead: function lexer_lookAhead() {
        return this._input || '';
    },

    /**
     * cache matched text and append it on next action
     *
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
        this._more = true;
        return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     *
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            // when the `parseError()` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // `.lex()` run.
            let lineno_msg = 'Lexical error';
            if (this.yylloc) {
                lineno_msg += ' on line ' + (this.yylineno + 1);
            }
            const p = this.constructLexErrorInfo(lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).', false);
            p.isLexerBacktrackingNotSupportedError = true;            // when this is true, you 'know' the produced error token will be queued.
            this._signaled_error_token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
        }
        return this;
    },

    /**
     * retain first n characters of the match
     *
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
        return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     *
     * Limit the returned string length to `maxSize` (default: 20).
     *
     * Limit the returned string to the `maxLines` number of lines of
     * input (default: 1).
     *
     * A negative `maxSize` limit value equals *unlimited*, i.e.
     * produce the entire input that has already been lexed.
     *
     * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
     * to the `maxSize` specified number of characters *only*.
     *
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
        let past = this.matched.substring(0, this.matched.length - this.match.length);
        if (maxSize < 0) {
            maxSize = Infinity;
        } else if (!maxSize) {
            maxSize = 20;
        }
        if (maxLines < 0) {
            maxLines = Infinity;          // can't ever have more input lines than this!
        } else if (!maxLines) {
            maxLines = 1;
        }
        // `substr` anticipation: treat \r\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        past = past.substr(-maxSize * 2 - 2);
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        let a = past.split(this.CRLF_Re);
        a = a.slice(-maxLines);
        past = a.join('\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis prefix...
        if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
        }
        return past;
    },

    /**
     * return (part of the) upcoming input *including* the input
     * matched by the last token (see also the NOTE below).
     * This can be used to augment error messages, for example.
     *
     * Limit the returned string length to `maxSize` (default: 20).
     *
     * Limit the returned string to the `maxLines` number of lines of input (default: 1).
     *
     * A negative `maxSize` limit value equals *unlimited*, i.e.
     * produce the entire input that is yet to be lexed.
     *
     * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
     * to the `maxSize` specified number of characters *only*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block.
     * >
     * > When you want access to the 'upcoming input' in that you want access
     * > to the input *which has not been lexed yet* for look-ahead
     * > inspection or likewise purposes, please consider using the
     * > `lookAhead()` API instead.
     * >
     *
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
        let next = this.match;
        let source = this._input || '';
        if (maxSize < 0) {
            maxSize = next.length + source.length;
        } else if (!maxSize) {
            maxSize = 20;
        }

        if (maxLines < 0) {
            maxLines = maxSize;          // can't ever have more input lines than this!
        } else if (!maxLines) {
            maxLines = 1;
        }
        // `substring` anticipation: treat \r\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        if (next.length < maxSize * 2 + 2) {
            next += source.substring(0, maxSize * 2 + 2 - next.length);  // substring is faster on Chrome/V8
        }
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        let a = next.split(this.CRLF_Re, maxLines + 1);     // stop splitting once we have reached just beyond the reuired number of lines.
        a = a.slice(0, maxLines);
        next = a.join('\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis postfix...
        if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
        }
        return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     *
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
        const pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
        let c = new Array(pre.length + 1).join('-');
        return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the `preceding` and `following` locations, IFF those are available,
     * and reconstruct the `actual` location info from those.
     * If this fails, the heuristic is to take the `current` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     *
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
        let loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [ 0, 0 ]
        };
        if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
                loc.range[0] = actual.range[0] | 0;
                loc.range[1] = actual.range[1] | 0;
            }
        }
        if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
                loc.first_line = preceding.last_line | 0;
                loc.first_column = preceding.last_column | 0;

                if (preceding.range) {
                    loc.range[0] = actual.range[1] | 0;
                }
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
                loc.last_line = following.first_line | 0;
                loc.last_column = following.first_column | 0;

                if (following.range) {
                    loc.range[1] = actual.range[0] | 0;
                }
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
                loc.first_line = current.first_line | 0;
                loc.first_column = current.first_column | 0;

                if (current.range) {
                    loc.range[0] = current.range[0] | 0;
                }
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
                loc.last_line = current.last_line | 0;
                loc.last_column = current.last_column | 0;

                if (current.range) {
                    loc.range[1] = current.range[1] | 0;
                }
            }
        }
        // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
        // or plan D heuristics to produce a 'sensible' last_line value:
        if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
                loc.first_line = this.yylloc.first_line;
                loc.last_line = this.yylloc.last_line;
                loc.first_column = this.yylloc.first_column;
                loc.last_column = this.yylloc.last_column;

                loc.range[0] = this.yylloc.range[0];
                loc.range[1] = this.yylloc.range[1];
            } else {
                loc.last_line = this.yylloc.last_line;
                loc.last_column = this.yylloc.last_column;

                loc.range[1] = this.yylloc.range[1];
            }
        }
        if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;

            loc.range[1] = loc.range[0];
        }
        if (loc.first_column < 0) {
            loc.first_column = 0;
        }
        if (loc.last_column < 0) {
            loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
        }
        return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced
     * by the given location info range, plus a few lines of context.
     *
     * This function pretty-prints the indicated section of the input, with line numbers
     * and everything!
     *
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     *
     * - `loc` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by `^`
     *   characters below each character in the entire input range.
     *
     * - `context_loc` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by `loc`. This can help provide context for the displayed
     *   error, etc.
     *
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     *
     * - `context_loc2` is another *optional* location info object, which serves
     *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     *
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     *
     * Special Notes:
     *
     * - when the `loc`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   `...continued...` message will be printed between them.
     *
     *   This serves the purpose of not printing a huge amount of text when the `loc`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     *
     * - this function can display lines of input which whave not yet been lexed.
     *   `prettyPrintRange()` can access the entire input!
     *
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
        loc = this.deriveLocationInfo(loc, context_loc, context_loc2);

        const CONTEXT = 3;
        const CONTEXT_TAIL = 1;
        const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
        let input = this.matched + (this._input || '');
        let lines = input.split('\n');
        let l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
        let l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
        let lineno_display_width = (1 + Math.log10(l1 | 1) | 0);
        let ws_prefix = new Array(lineno_display_width).join(' ');
        let nonempty_line_indexes = [ [], [], [] ];
        let rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            let lno = index + l0;
            let lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            let rv = lno_pfx + ': ' + line;
            let errpfx = (new Array(lineno_display_width + 1)).join('^');
            let offset = 2 + 1;
            let len = 0;

            if (lno === loc.first_line) {
                offset += loc.first_column;

                len = Math.max(
                    2,
                    ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
                );
            } else if (lno === loc.last_line) {
                len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
                len = Math.max(2, line.length + 1);
            }

            let nli;
            if (len) {
                let lead = new Array(offset).join('.');
                let mark = new Array(len).join('^');
                rv += '\n' + errpfx + lead + mark;

                nli = 1;
            } else if (lno < loc.first_line) {
                nli = 0;
            } else if (lno > loc.last_line) {
                nli = 2;
            }

            if (line.trim().length > 0) {
                nonempty_line_indexes[nli].push(index);
            }

            rv = rv.replace(/\t/g, ' ');
            return rv;
        });

        // now make sure we don't print an overly large amount of lead/error/tail area: limit it
        // to the top and bottom line count:
        for (let i = 0; i <= 2; i++) {
            let line_arr = nonempty_line_indexes[i];
            if (line_arr.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
                let clip_start = line_arr[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
                let clip_end = line_arr[line_arr.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;

                let intermediate_line = (new Array(lineno_display_width + 1)).join(' ') +     '  (...continued...)';
                if (i === 1) {
                    intermediate_line += '\n' + (new Array(lineno_display_width + 1)).join('-') + '  (---------------)';
                }
                rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
            }
        }

        return rv.join('\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input `yylloc` location object.
     *
     * Set `display_range_too` to TRUE to include the string character index position(s)
     * in the description if the `yylloc.range` is available.
     *
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
        let l1 = yylloc.first_line;
        let l2 = yylloc.last_line;
        let c1 = yylloc.first_column;
        let c2 = yylloc.last_column;
        let dl = l2 - l1;
        let dc = c2 - c1;
        let rv;
        if (dl === 0) {
            rv = 'line ' + l1 + ', ';
            if (dc <= 1) {
                rv += 'column ' + c1;
            } else {
                rv += 'columns ' + c1 + ' .. ' + c2;
            }
        } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
        }
        if (yylloc.range && display_range_too) {
            let r1 = yylloc.range[0];
            let r2 = yylloc.range[1] - 1;
            if (r2 <= r1) {
                rv += ' {String Offset: ' + r1 + '}';
            } else {
                rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
        }
        return rv;
    },

    /**
     * Take a snapshot of the given `loc` location tracking object, e.g. `this.yylloc`.
     * 
     * Technically, this means this function returns a cloned instance of the given `loc`.
     * @param  {YYlloc} loc     location tracking object
     * @return {YYlloc}     
     */
    copy_yylloc: function leexer_copy_yylloc(loc) {
        if (loc) {
            let rv = Object.assign({}, loc);
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            rv.range = rv.range.slice();
            return rv;
        }
        return null;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     *
     * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
     * contains the actually matched text string.
     *
     * Also move the input cursor forward and update the match collectors:
     *
     * - `yytext`
     * - `yyleng`
     * - `match`
     * - `matches`
     * - `yylloc`
     * - `offset`
     *
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
        let backup;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.yylloc.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column,

                    range: this.yylloc.range.slice()
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                //_signaled_error_token: this._signaled_error_token,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(),
                done: this.done
            };
        }

        let match_str = match[0];
        let match_str_len = match_str.length;

        let lines = match_str.split(this.CRLF_Re);
        if (lines.length > 1) {
            this.yylineno += lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;
            this.yylloc.last_column = lines[lines.length - 1].length;
        } else {
            this.yylloc.last_column += match_str_len;
        }

        this.yytext += match_str;
        this.match += match_str;
        this.matched += match_str;
        this.matches = match;
        this.yyleng = this.yytext.length;
        this.yylloc.range[1] += match_str_len;

        // previous lex rules MAY have invoked the `more()` API rather than producing a token:
        // those rules will already have moved this `offset` forward matching their match lengths,
        // hence we must only add our own match length now:
        this.offset += match_str_len;
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match_str_len);

        // calling this method:
        //
        //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
        let token = this.performAction.call(this, this.yy, indexed_rule, this.conditionStack[this.conditionStack.length - 1] /* = YY_START */);
        // otherwise, when the action codes are all simple return token statements:
        //token = this.simpleCaseActionClusters[indexed_rule];

        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (let k in backup) {
                this[k] = backup[k];
            }
            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
        } else if (this._signaled_error_token) {
            // produce one 'error' token as `.parseError()` in `reject()`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;
            this._signaled_error_token = false;
            return token;
        }
        return false;
    },

    /**
     * return next match in input
     *
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
        if (this.done) {
            this.clear();
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        if (!this._more) {
            if (!this._clear_state) {
                this._clear_state = 1;
            }
            this.clear();
        }
        let spec = this.__currentRuleSet__;
        if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();
            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
                let lineno_msg = '';
                if (this.yylloc) {
                    lineno_msg = ' on line ' + (this.yylineno + 1);
                }
                const p = this.constructLexErrorInfo('Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!', false);
                p.isLexerInternalError = true;
                // produce one 'error' token until this situation has been resolved, most probably by parse termination!
                return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            }
        }

        {
            let rule_ids = spec.rules;
            let regexes = spec.__rule_regexes;
            let len = spec.__rule_count;
            let match;
            let index;

            // Note: the arrays are 1-based, while `len` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (let i = 1; i <= len; i++) {
                let tempMatch = this._input.match(regexes[i]);
                if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                    match = tempMatch;
                    index = i;
                    if (this.options.backtrack_lexer) {
                        let token = this.test_match(tempMatch, rule_ids[i]);
                        if (token !== false) {
                            return token;
                        } else if (this._backtrack) {
                            match = undefined;
                            continue; // rule action called reject() implying a rule MISmatch.
                        } else {
                            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                            return false;
                        }
                    } else if (!this.options.flex) {
                        break;
                    }
                }
            }

            if (match) {
                let token = this.test_match(match, rule_ids[index]);
                if (token !== false) {
                    return token;
                }
                // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                return false;
            }
        }

        if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
        }

        {
            let lineno_msg = 'Lexical error';
            if (this.yylloc) {
                lineno_msg += ' on line ' + (this.yylineno + 1);
            }
            const p = this.constructLexErrorInfo(lineno_msg + ': Unrecognized text.', this.options.lexerErrorsAreRecoverable);

            let pendingInput = this._input;
            let activeCondition = this.topState();
            let conditionStackDepth = this.conditionStack.length;

            // when this flag is set in your parseError() `hash`, you 'know' you cannot manipute `yytext` to be anything but 
            // a string value, unless
            // - you either get to experience a lexer crash once it invokes .input() with your manipulated `yytext` object,
            // - or you must forward the lex cursor yourself by invoking `yy.input()` or equivalent, *before* you go and
            //   tweak that `yytext`.
            p.lexerHasAlreadyForwardedCursorBy1 = (!this.matches);

            // Simplify use of (advanced) custom parseError() handlers: every time we encounter an error,
            // which HAS NOT consumed any input yet (thus causing an infinite lexer loop unless we take special action),
            // we FIRST consume ONE character of input, BEFORE we call parseError().
            // 
            // This implies that the parseError() now can call `unput(this.yytext)` if it wants to only change lexer
            // state via popState/pushState, but otherwise this would make for a cleaner parseError() implementation
            // as there's no conditional check for `hash.lexerHasAlreadyForwardedCursorBy1` needed in there any more.
            // 
            // Since that flag is new as of jison-gho 0.7.0, as is this new consume1+parseError() behaviour, only
            // sophisticated userland parseError() methods will need to be reviewed.
            // Haven't found any of those in the (Open Source) wild today, so this should be safe to change...

            // *** CONSUME 1 ***:
                        
            //if (token === this.ERROR) {
            //    ^^^^^^^^^^^^^^^^^^^^ WARNING: no matter what token the error handler produced, 
            //                         it MUST move the cursor forward or you'ld end up in 
            //                         an infinite lex loop, unless one or more of the following 
            //                         conditions was changed, so as to change the internal lexer 
            //                         state and thus enable it to produce a different token:
            //                         
                // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
                // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
                // has not consumed/modified any pending input or changed state in the error handler:
                if (!this.matches &&
                    // and make sure the input has been modified/consumed ...
                    pendingInput === this._input &&
                    // ...or the lexer state has been modified significantly enough
                    // to merit a non-consuming error handling action right now.
                    activeCondition === this.topState() &&
                    conditionStackDepth === this.conditionStack.length
                ) {
                    this.input();
                }
            //}

            // *** PARSE-ERROR ***:
            // 
            // Note:
            // userland code in there may `unput()` what was done, after checking the `hash.lexerHasAlreadyForwardedCursorBy1` flag.
            // Caveat emptor! :: When you simply `unput()` the `yytext` without at least changing the lexer condition state 
            // via popState/pushState, you WILL end up with an infinite lexer loop. 
            // 
            // This kernel code has been coded to prevent this dangerous situation unless you specifically seek it out
            // in your custom parseError handler.
                        
            return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
        }
    },

    /**
     * return next match that has a token
     *
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
        let r;

        //this._clear_state = 0;

        if (!this._more) {
            if (!this._clear_state) {
                this._clear_state = 1;
            }
            this.clear();
        }

        // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
        if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
        }
        if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
        }
        if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
        }

        while (!r) {
            r = this.next();
        }

        if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
        }
        if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
        }
        if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
        }

        if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);
            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);

            this._clear_state = 0;
        }

        return r;
    },

    /**
     * return next match that has a token. Identical to the `lex()` API but does not invoke any of the
     * `pre_lex()` nor any of the `post_lex()` callbacks.
     *
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
        let r;

        //this._clear_state = 0;

        while (!r) {
            r = this.next();
        }

        if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);
            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);

            this._clear_state = 0;
        }

        return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     *
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
        const rv = {
            fastLex: !(
                typeof this.pre_lex === 'function' ||
                typeof this.options.pre_lex === 'function' ||
                (this.yy && typeof this.yy.pre_lex === 'function') ||
                (this.yy && typeof this.yy.post_lex === 'function') ||
                typeof this.options.post_lex === 'function' ||
                typeof this.post_lex === 'function'
            ) && typeof this.fastLex === 'function'
        };
        return rv;
    },


    /**
     * backwards compatible alias for `pushState()`;
     * the latter is symmetrical with `popState()` and we advise to use
     * those APIs in any modern lexer code, rather than `begin()`.
     *
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
        return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     *
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
        this.conditionStack.push(condition);
        this.__currentRuleSet__ = null;
        return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     *
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
        const n = this.conditionStack.length - 1;
        if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
        }
        return this.conditionStack[0];
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     *
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        }
        return 'INITIAL';
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     *
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
        const n = this.conditionStack.length - 1;
        let state;
        if (n >= 0) {
            state = this.conditionStack[n];
        } else {
            state = 'INITIAL';
        }
        return this.conditions[state] || this.conditions.INITIAL;
    },

    /**
     * return the number of states currently on the stack
     *
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
        return this.conditionStack.length;
    },
    options: {
  trackPosition: true,
  caseInsensitive: true,
  _8bit: true,
  neverInteractive: true,
  prefix: "pp",
  stack: true
},
    JisonLexerError: JisonLexerError,
    performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
            const yy_ = this;

            /* Local variables */
static size_t			newline_count = 0;
static size_t			within_comment = 0;
static size_t			inside_bracket = 0;
static size_t			consecutive_quotation = 0;
static size_t			need_continuation = 0;
static size_t			buffer_overflow = 0;
static size_t			comment_allowed;
static unsigned int		plex_skip_input = 0;
static unsigned int		plex_nest_depth = 0;
static int			quotation_mark = 0;
static int			listing_line = 0;
static int			requires_listing_line;
static int			requires_new_line = 0


const YYSTATE = YY_START;
switch(yyrulenumber) {
case 0 : 
/*! Conditions:: * */ 
/*! Rule::       \*>.* */ 
 /* 2002+: inline comment */ 
break;
case 1 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?DEFINE */ 
 /* 2002+: definition of compiler constants display message during compilation */
	/* Define here to preempt next debug rule below */
	BEGIN DEFINE_DIRECTIVE_STATE;
	return DEFINE_DIRECTIVE 
break;
case 2 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?DISPLAY[ ]+ */ 
 /* OpenCOBOL/GnuCOBOL 1.0 extension: display message during compilation */
	BEGIN DISPLAY_DIRECTIVE_STATE 
break;
case 3 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>D */ 
 /* 2002 (only) floating debug line */
	/* Remove line if debugging lines not activated */
	/* Otherwise ignore the directive part of the line */
	(void) cb_verify (cb_debugging_mode, _("debugging indicator"));
	if (!cb_flag_debugging_line) {
		skip_to_eol ();
	} 
break;
case 4 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?PAGE */ 
 /* 2002+: listing directive for page eject with optional comment
	   Note: processed in cobc.c */
	skip_to_eol () 
break;
case 5 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?LISTING */ 
 /* 2002+: listing directive for (de-)activating the listing,
	   ON implied for empty value
	   Note: further checks in ppparse.y, processed in cobc.c */
	BEGIN ON_OFF_DIRECTIVE_STATE;
	return LISTING_DIRECTIVE 
break;
case 6 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?SOURCE */ 
 /* 2002+: directive for setting source format */
	BEGIN SOURCE_DIRECTIVE_STATE;
	return SOURCE_DIRECTIVE 
break;
case 7 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?SET */ 
 /* OpenCOBOL/GnuCOBOL 2.0 extension: MF SET directive in 2002+ style format */
	BEGIN SET_DIRECTIVE_STATE;
	return SET_DIRECTIVE 
break;
case 8 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?TURN */ 
 /* 2002+: directive for (de-)activating exception checks */
	BEGIN TURN_DIRECTIVE_STATE;
	return TURN_DIRECTIVE 
break;
case 9 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?IF */ 
 /* 2002+: conditional compilation */
	BEGIN IF_DIRECTIVE_STATE;
	return IF_DIRECTIVE 
break;
case 10 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?ELIF|^[ ]*>>[ ]?ELSE-IF */ 
 /* OpenCOBOL extension: conditional compilation combined ELSE IF,
	   2002+ style format */
	BEGIN IF_DIRECTIVE_STATE;
	return ELIF_DIRECTIVE 
break;
case 11 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?ELSE */ 
 /* 2002+: conditional compilation */
	BEGIN ELSE_DIRECTIVE_STATE;
	return ELSE_DIRECTIVE 
break;
case 12 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?END-IF */ 
 /* 2002+: conditional compilation */
	BEGIN ENDIF_DIRECTIVE_STATE;
	return ENDIF_DIRECTIVE 
break;
case 13 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?LEAP-SECOND */ 
 /* 2002+: more then 60 seconds per minute (currently always set to off),
	          OFF implied for empty value */
	BEGIN ON_OFF_DIRECTIVE_STATE;
	return LEAP_SECOND_DIRECTIVE 
break;
case 14 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]?CALL-CONVENTION */ 
 /* 2002+: convention for CALL/CANCEL */
	BEGIN CALL_DIRECTIVE_STATE;
	return CALL_DIRECTIVE 
break;
case 15 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]*\n */ 
 /* empty 2002+ style directive */
	cb_plex_warning (COBC_WARN_FILLER, newline_count,
			_("ignoring empty directive"));
	unput ('\n') 
break;
case 16 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>>[ ]*[_0-9A-Z-]+ */ 
 /* unknown 2002+ style directive */
	char	*s;

	s = strchr (yy_.yytext, '>');
	cb_plex_warning (COBC_WARN_FILLER, newline_count,
			_("ignoring invalid directive: '%s'"), s);
	skip_to_eol () 
break;
case 17 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*>> */ 
 /* unknown 2002+ style directive */
	cb_plex_warning (COBC_WARN_FILLER, newline_count,
			_("ignoring invalid directive"));
	skip_to_eol () 
break;
case 18 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$DISPLAY[ ]+VCS[ ]+=[ ]+ */ 
 /* MF extension: include @(#)text\0 in the object file */
	/* we just add a warning for now, maybe implement it later */
	CB_PENDING (_("VCS directive"));
	skip_to_eol () 
break;
case 19 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$DISPLAY[ ]+ */ 
 /* MF extension: display message during compilation */
	msg[0] = 0;
	BEGIN DISPLAY_DIRECTIVE_STATE 
break;
case 20 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$SET */ 
 /* MF extension: SET directive */
	BEGIN SET_DIRECTIVE_STATE;
	return SET_DIRECTIVE 
break;
case 21 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$IF */ 
 /* MF extension: conditional compilation */
	BEGIN IF_DIRECTIVE_STATE;
	return IF_DIRECTIVE 
break;
case 22 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$ELIF|^[ ]*\$ELSE-IF */ 
 /* OpenCOBOL/GnuCOBOL 2.0 extension: conditional compilation combined ELSE IF,
	   MF style format */
	BEGIN IF_DIRECTIVE_STATE;
	return ELIF_DIRECTIVE 
break;
case 23 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$ELSE */ 
 /* MF extension: conditional compilation */
	BEGIN ELSE_DIRECTIVE_STATE;
	return ELSE_DIRECTIVE 
break;
case 24 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$END */ 
 /* MF extension: conditional compilation */
	BEGIN ENDIF_DIRECTIVE_STATE;
	return ENDIF_DIRECTIVE 
break;
case 25 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$[_0-9A-Z-]+ */ 
 /* unknown MF style directive */
	char	*s;

	s = strchr (yy_.yytext, '$');
	cb_plex_warning (COBC_WARN_FILLER, newline_count,
			_("ignoring invalid directive: '%s'"), s);
	skip_to_eol () 
break;
case 26 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^......\$ */ 
 /* Allow $ in column 7 for acucomment in fixed format */
	if (cb_source_format == CB_FORMAT_FREE) {
		cb_plex_warning (COBC_WARN_FILLER, newline_count,
			_("spurious '$' detected - ignored"));
		skip_to_eol ();
	} 
break;
case 27 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\$ */ 
 cb_plex_warning (COBC_WARN_FILLER, newline_count,
		_("spurious '$' detected - ignored"));
	skip_to_eol () 
break;
case 28 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       PROCESS */ 
 cb_plex_warning (COBC_WARN_FILLER, newline_count,
		_("PROCESS statement ignored"));
	skip_to_eol () 
break;
case 29 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       COPY */ 
 yy_push_state (COPY_STATE);
	if (cb_src_list_file) {
		get_new_listing_file ();
	}
	return COPY 
break;
case 30 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       INCLUDE */ 
 /* Note: ++INCLUDE/-INC (include only the data records,
	   must be specified in column 8/1) are not implemented yet */
	yy_push_state (COPY_STATE);
	if (cb_src_list_file) {
		get_new_listing_file ();
	}
	return COPY 
break;
case 31 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       REPLACE */ 
 yy_push_state (COPY_STATE);
	return REPLACE 
break;
case 32 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*\*CONTROL|^[ ]*\*CBL */ 
 BEGIN CONTROL_STATEMENT_STATE;
	return CONTROL_STATEMENT 
break;
case 33 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ID[ ,;]+DIVISION|IDENTIFICATION[ ,;]+DIVISION */ 
 /* Allow comment sentences/paragraphs */
	comment_allowed = 1;
	ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 34 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       PROGRAM-ID */ 
 /* Allow comment sentences/paragraphs */
	comment_allowed = 1;
	ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 35 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       DIVISION */ 
 /* Disallow comment sentences/paragraphs */
	comment_allowed = 0;
	ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 36 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       SECTION */ 
 /* Disallow comment sentences/paragraphs */
	comment_allowed = 0;
	ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 37 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*EJECT([ ]*\.)?|^[ ]*SKIP1([ ]*\.)?|^[ ]*SKIP2([ ]*\.)?|^[ ]*SKIP3([ ]*\.)? */ 
 /* These words can either be a listing-directive statement,
	   a reserved word, or a user-defined word...
	   some implementations (dis-)allow the (optional) "."
	   some start column 8+ some column 12+
	   We ignore the detailed rules and just do the parsing. */
	if (cb_verify (cb_listing_statements, yy_.yytext)) {
		/* handle as listing-directive statement */
		skip_to_eol();
		return LISTING_STATEMENT;
	} else if (cb_listing_statements == CB_SKIP) {
		/* handle later (normal reserved / user defined word) */
		ECHO;
		check_listing (yy_.yytext, 0);
	} else {
		/* Ignore */
	} 
break;
case 38 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       ^[ ]*TITLE */ 
 /* This word can either be a listing-directive statement,
	   a reserved word, or a user-defined word...
	   some implementations (dis-)allow the (optional) "."
	   some start column 8+ some column 12+,
	   most limit the literal length (we cut in cobc.c)
	   We ignore the detailed rules and just do the parsing. */
	if (cb_verify (cb_title_statement, yy_.yytext)) {
		/* handle as listing-directive statement */
		BEGIN ALNUM_LITERAL_STATE;
		return TITLE_STATEMENT;
	} else if (cb_title_statement == CB_SKIP) {
		/* handle later (normal reserved / user defined word) */
		ECHO;
		check_listing (yy_.yytext, 0);
	} else {
		/* Ignore */
	} 
break;
case 39 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       WITH[ ,;]+DEBUGGING[ ,;]+MODE|DEBUGGING[ ,;]+MODE */ 
 /* Pick up early - Also activates debugging lines */
	cb_verify (cb_debugging_mode, "DEBUGGING MODE");
	cb_flag_debugging_line = 1;
	ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 40 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       [,;]?\n */ 
 ppecho ("\n", 0, 1);
	cb_source_line++ 
break;
case 41 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       [;]?[ ]+ */ 
 ppecho (" ", 1U, 1) 
break;
case 42 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       [,]?[ ]+ */ 
 if (inside_bracket) {
		ppecho (", ", 0, 2);
	} else {
		ppecho (" ", 1U, 1);
	} 
break;
case 43 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       \( */ 
 inside_bracket++;
	ppecho ("(", 0, 1) 
break;
case 44 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       \) */ 
 if (inside_bracket) {
		inside_bracket--;
	}
	ppecho (")", 0, 1) 
break;
case 45 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       {WORD}|{NUMRIC_LITERAL}|{ALNUM_LITERAL}|. */ 
 ppecho (yy_.yytext, 0, (int)yy_.yyleng) 
break;
case 46 : 
/*! Conditions:: CALL_DIRECTIVE_STATE SOURCE_DIRECTIVE_STATE DEFINE_DIRECTIVE_STATE ON_OFF_DIRECTIVE_STATE SET_DIRECTIVE_STATE TURN_DIRECTIVE_STATE IF_DIRECTIVE_STATE ELSE_DIRECTIVE_STATE ENDIF_DIRECTIVE_STATE ALNUM_LITERAL_STATE CONTROL_STATEMENT_STATE */ 
/*! Rule::       \n */ 
 BEGIN INITIAL;
	unput ('\n');
	return TERMINATOR;
  }
  [ ,;]+		{ /* ignore */ }
  "." {
	return DOT 
break;
case 47 : 
/*! Conditions:: DISPLAY_DIRECTIVE_STATE */ 
/*! Rule::       \n */ 
 BEGIN INITIAL;
	display_finish() 
break;
case 48 : 
/*! Conditions:: DISPLAY_DIRECTIVE_STATE */ 
/*! Rule::       {ALNUM_LITERAL} */ 
 yy_.yytext[yy_.yyleng - 1] = 0;
	strncat (msg, yy_.yytext + 1, (size_t)(PPLEX_BUFF_LEN - 1)) 
break;
case 49 : 
/*! Conditions:: DISPLAY_DIRECTIVE_STATE */ 
/*! Rule::       [x21-\xFF]|[ #A-Z0-9\x80-\xFF]+ */ 
 strncat (msg, yy_.yytext, (size_t)(PPLEX_BUFF_LEN - 1)) 
break;
case 50 : 
/*! Conditions:: ON_OFF_DIRECTIVE_STATE */ 
/*! Rule::       ON */ 
 return ON; }
  "OFF"			{ return OFF 
break;
case 51 : 
/*! Conditions:: SOURCE_DIRECTIVE_STATE */ 
/*! Rule::       FORMAT */ 
 return FORMAT; }
  "IS"			{ return IS; }
  "FIXED"		{ return FIXED; }
  "FREE"		{ return FREE; }
  "VARIABLE"		{ return VARIABLE 
break;
case 52 : 
/*! Conditions:: CALL_DIRECTIVE_STATE */ 
/*! Rule::       COBOL */ 
 return COBOL; }
  "EXTERN"		{ return TOK_EXTERN; }
  "STDCALL"		{ return STDCALL; }
  "STATIC"		{ return STATIC 
break;
case 53 : 
/*! Conditions:: CONTROL_STATEMENT_STATE */ 
/*! Rule::       SOURCE */ 
 return SOURCE; }
  "NOSOURCE"	{ return NOSOURCE; }
  "LIST"		{ return LIST; }
  "NOLIST"		{ return NOLIST; }
  "MAP"			{ return MAP; }
  "NOMAP"		{ return NOMAP 
break;
case 54 : 
/*! Conditions:: DEFINE_DIRECTIVE_STATE */ 
/*! Rule::       CONSTANT */ 
 return CONSTANT;
  }
  "AS"			{
	return AS;
  }
  "OFF"			{
	return OFF;
  }
  "OVERRIDE"		{
	return OVERRIDE;
  }
  "PARAMETER"		{
	return PARAMETER;
  }
  {NUMRIC_LITERAL} |
  {ALNUM_LITERAL}	{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return LITERAL;
  }
  {WORD}		{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return VARIABLE_NAME 
break;
case 55 : 
/*! Conditions:: SET_DIRECTIVE_STATE */ 
/*! Rule::       CONSTANT */ 
 return CONSTANT;
  }
  "SOURCEFORMAT"	{
	return SOURCEFORMAT;
  }
  "FOLDCOPYNAME" |
  "FOLD-COPY-NAME"	{
	return FOLDCOPYNAME;
  }
  "NOFOLDCOPYNAME" |
  "NOFOLD-COPY-NAME"	{
	return NOFOLDCOPYNAME;
  }
  /*"AS"			{ - not available with MF compilers -
	return AS;
  }*/
  "OVERRIDE"		{
	  /* not valid, only in for error checking as it would
	     result in a variable name otherwise */
	  return OVERRIDE;
  }
  {DEFNUM_LITERAL} |
  {ALNUM_LITERAL}	{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return LITERAL;
  }
  {SET_PAREN_LIT}	{
	yy_.yytext[yy_.yyleng - 1] = 0;
	pplval.s = cobc_plex_strdup (yy_.yytext + 1);
	return LITERAL;
  }
  {WORD}		{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return VARIABLE_NAME 
break;
case 56 : 
/*! Conditions:: TURN_DIRECTIVE_STATE */ 
/*! Rule::       ON */ 
 return ON;
  }
  "OFF"			{
	return OFF;
  }
  "WITH"		{
	return WITH;
  }
  "LOCATION"		{
	return LOCATION;
  }
  "CHECKING"		{
	return CHECKING;
  }
  {DEFNUM_LITERAL} |
  {ALNUM_LITERAL}	{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return LITERAL;
  }
  {SET_PAREN_LIT}	{
	yy_.yytext[yy_.yyleng - 1] = 0;
	pplval.s = cobc_plex_strdup (yy_.yytext + 1);
	return LITERAL;
  }
  {WORD}		{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return VARIABLE_NAME 
break;
case 57 : 
/*! Conditions:: CALL_DIRECTIVE_STATE SOURCE_DIRECTIVE_STATE ON_OFF_DIRECTIVE_STATE ELSE_DIRECTIVE_STATE ENDIF_DIRECTIVE_STATE */ 
/*! Rule::       {NUMRIC_LITERAL}|{ALNUM_LITERAL} */ 
 return LITERAL;
  }
  {WORD}		{
	return GARBAGE 
break;
case 58 : 
/*! Conditions:: IF_DIRECTIVE_STATE */ 
/*! Rule::       IS */ 
 return IS; }
  "NOT"			{ return NOT; }
  "EQUAL"		{ return EQUAL; }
  "TO"			{ return TO; }
  "OR"			{ return OR; }
  "GREATER"		{ return GREATER; }
  "LESS"		{ return LESS; }
  "THAN"		{ return THAN; }
  "DEFINED"		{ return DEFINED; }
  "SET"			{ return SET; }
  ">="			{ return GE; }
  ">"			{ return GT; }
  "<="			{ return LE; }
  "<>"			{ return NE; }
  "<"			{ return LT; }
  "="			{ return EQ; }
  {NUMRIC_LITERAL} |
  {ALNUM_LITERAL}	{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return LITERAL;
  }
  {WORD}		{
	pplval.s = cobc_plex_strdup (yy_.yytext);
	return VARIABLE_NAME 
break;
case 59 : 
/*! Conditions:: ALNUM_LITERAL_STATE */ 
/*! Rule::       {ALNUM_LITERAL} */ 
 return LITERAL 
break;
case 60 : 
/*! Conditions:: COPY_STATE */ 
/*! Rule::       [,;]?\n */ 
 ECHO;
	check_listing (yy_.yytext, 0);
	cb_source_line++;
  }
  [,;]?[ ]+		{ /* ignore */ }
  \. 			{
	  yy_pop_state ();
	  return DOT;
  }
  "=="			{ yy_push_state (PSEUDO_STATE); return EQEQ; }
  "("			{ return '('; }
  ")"			{ return ')'; }
  "BY"			{ return BY; }
  "IN"			{ return IN; }
  "OF"			{ return OF; }
  "OFF"			{ return OFF; }
  "SUPPRESS"		{ return SUPPRESS; }
  "PRINTING"		{ return PRINTING; }
  "REPLACING"		{ return REPLACING; }
  "LEADING"		{ return LEADING; }
  "TRAILING"		{ return TRAILING; }
  "ALSO"		{ return ALSO; }
  "LAST"		{ return LAST; }
  {WORD} |
  {NUMRIC_LITERAL} |
  {ALNUM_LITERAL} |
  .			{ pplval.s = cobc_plex_strdup (yy_.yytext); return TOKEN 
break;
case 61 : 
/*! Conditions:: PSEUDO_STATE */ 
/*! Rule::       [,;]?\n */ 
 ECHO;
	check_listing (yy_.yytext, 0);
	cb_source_line++ 
break;
case 62 : 
/*! Conditions:: PSEUDO_STATE */ 
/*! Rule::       [,;]?[ ]+ */ 
 pplval.s = cobc_plex_strdup (" ");
	return TOKEN 
break;
case 63 : 
/*! Conditions:: PSEUDO_STATE */ 
/*! Rule::       == */ 
 yy_pop_state ();
	return EQEQ 
break;
case 64 : 
/*! Conditions:: PSEUDO_STATE */ 
/*! Rule::       {WORD}|{NUMRIC_LITERAL}|{ALNUM_LITERAL}|. */ 
 pplval.s = cobc_plex_strdup (yy_.yytext);
	return TOKEN 
break;
case 65 : 
/*! Conditions:: INITIAL */ 
/*! Rule::       $ */ 
 struct copy_info *current_copy_info = copy_stack;

	yy_delete_buffer (YY_CURRENT_BUFFER);

	/* Terminate at the end of all input */
	if (current_copy_info->next == NULL) {
		/* Check dangling IF/ELSE */
		for (; plex_nest_depth > 0; --plex_nest_depth) {
			cb_source_line = plex_cond_stack[plex_nest_depth].line;
			cb_error (_("IF/ELIF/ELSE directive without matching END-IF"));
		}
		plex_nest_depth = 0;
		cobc_free (current_copy_info->dname);
		cobc_free (current_copy_info);
		listing_line = 0;
		requires_listing_line = 1;
		requires_new_line = 0;
		need_continuation = 0;
		buffer_overflow = 0;
		within_comment = 0;
		newline_count = 0;
		inside_bracket = 0;
		comment_allowed = 1;
		current_replace_list = NULL;
		base_replace_list = NULL;
		save_current_replace = NULL;
		text_queue = NULL;
		copy_stack = NULL;
		quotation_mark = 0;
		consecutive_quotation = 0;
		yyterminate ();
	}

	/* Close the current file */
	fclose (ppin);
	ppin = NULL;

	if (current_copy_info->containing_files) {
		cb_current_file = current_copy_info->containing_files;
	}

	/* Switch to previous buffer */
	switch_to_buffer (current_copy_info->line, current_copy_info->file,
			  current_copy_info->buffer);

	/* Restore variables */
	current_replace_list = current_copy_info->replacing;
	quotation_mark = current_copy_info->quotation_mark;
	cb_source_format = current_copy_info->source_format;

	copy_stack = current_copy_info->next;
	cobc_free (current_copy_info->dname);
	cobc_free (current_copy_info) 
break;
}
        },
    simpleCaseActionClusters: {

},
    rules: [
        /*  0: */  /^(?:\*>.*)/i,
/*  1: */  /^(?:^[ ]*>>[ ]?DEFINE)/i,
/*  2: */  /^(?:^[ ]*>>[ ]?DISPLAY[ ]+)/i,
/*  3: */  /^(?:^[ ]*>>D)/i,
/*  4: */  /^(?:^[ ]*>>[ ]?PAGE)/i,
/*  5: */  /^(?:^[ ]*>>[ ]?LISTING)/i,
/*  6: */  /^(?:^[ ]*>>[ ]?SOURCE)/i,
/*  7: */  /^(?:^[ ]*>>[ ]?SET)/i,
/*  8: */  /^(?:^[ ]*>>[ ]?TURN)/i,
/*  9: */  /^(?:^[ ]*>>[ ]?IF)/i,
/* 10: */  /^(?:^[ ]*>>[ ]?ELIF|^[ ]*>>[ ]?ELSE-IF)/i,
/* 11: */  /^(?:^[ ]*>>[ ]?ELSE)/i,
/* 12: */  /^(?:^[ ]*>>[ ]?END-IF)/i,
/* 13: */  /^(?:^[ ]*>>[ ]?LEAP-SECOND)/i,
/* 14: */  /^(?:^[ ]*>>[ ]?CALL-CONVENTION)/i,
/* 15: */  /^(?:^[ ]*>>[ ]*\n)/i,
/* 16: */  /^(?:^[ ]*>>[ ]*[_0-9A-Z-]+)/i,
/* 17: */  /^(?:^[ ]*>>)/i,
/* 18: */  /^(?:^[ ]*\$DISPLAY[ ]+VCS[ ]+=[ ]+)/i,
/* 19: */  /^(?:^[ ]*\$DISPLAY[ ]+)/i,
/* 20: */  /^(?:^[ ]*\$SET)/i,
/* 21: */  /^(?:^[ ]*\$IF)/i,
/* 22: */  /^(?:^[ ]*\$ELIF|^[ ]*\$ELSE-IF)/i,
/* 23: */  /^(?:^[ ]*\$ELSE)/i,
/* 24: */  /^(?:^[ ]*\$END)/i,
/* 25: */  /^(?:^[ ]*\$[_0-9A-Z-]+)/i,
/* 26: */  /^(?:^......\$)/i,
/* 27: */  /^(?:^[ ]*\$)/i,
/* 28: */  /^(?:PROCESS)/i,
/* 29: */  /^(?:COPY)/i,
/* 30: */  /^(?:INCLUDE)/i,
/* 31: */  /^(?:REPLACE)/i,
/* 32: */  /^(?:^[ ]*\*CONTROL|^[ ]*\*CBL)/i,
/* 33: */  /^(?:ID[ ,;]+DIVISION|IDENTIFICATION[ ,;]+DIVISION)/i,
/* 34: */  /^(?:PROGRAM-ID)/i,
/* 35: */  /^(?:DIVISION)/i,
/* 36: */  /^(?:SECTION)/i,
/* 37: */  /^(?:^[ ]*EJECT([ ]*\.)?|^[ ]*SKIP1([ ]*\.)?|^[ ]*SKIP2([ ]*\.)?|^[ ]*SKIP3([ ]*\.)?)/i,
/* 38: */  /^(?:^[ ]*TITLE)/i,
/* 39: */  /^(?:WITH[ ,;]+DEBUGGING[ ,;]+MODE|DEBUGGING[ ,;]+MODE)/i,
/* 40: */  /^(?:[,;]?\n)/i,
/* 41: */  /^(?:[;]?[ ]+)/i,
/* 42: */  /^(?:[,]?[ ]+)/i,
/* 43: */  /^(?:\()/i,
/* 44: */  /^(?:\))/i,
/* 45: */  /^(?:([_0-9A-Z\x80-\xFF-]+)|([+-]?[0-9,.]*[0-9])|("[^\"\n]*"|'[^\'\n]*')|.)/i,
/* 46: */  /^(?:\n)/i,
/* 47: */  /^(?:\n)/i,
/* 48: */  /^(?:("[^\"\n]*"|'[^\'\n]*'))/i,
/* 49: */  /^(?:[x21-\xFF]|[ #A-Z0-9\x80-\xFF]+)/i,
/* 50: */  /^(?:ON)/i,
/* 51: */  /^(?:FORMAT)/i,
/* 52: */  /^(?:COBOL)/i,
/* 53: */  /^(?:SOURCE)/i,
/* 54: */  /^(?:CONSTANT)/i,
/* 55: */  /^(?:CONSTANT)/i,
/* 56: */  /^(?:ON)/i,
/* 57: */  /^(?:([+-]?[0-9,.]*[0-9])|("[^\"\n]*"|'[^\'\n]*'))/i,
/* 58: */  /^(?:IS)/i,
/* 59: */  /^(?:("[^\"\n]*"|'[^\'\n]*'))/i,
/* 60: */  /^(?:[,;]?\n)/i,
/* 61: */  /^(?:[,;]?\n)/i,
/* 62: */  /^(?:[,;]?[ ]+)/i,
/* 63: */  /^(?:==)/i,
/* 64: */  /^(?:([_0-9A-Z\x80-\xFF-]+)|([+-]?[0-9,.]*[0-9])|("[^\"\n]*"|'[^\'\n]*')|.)/i,
/* 65: */  /^(?:$)/i
    ],
    conditions: {
  "CALL_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      52,
      57
    ],
    inclusive: false
  },
  "COPY_STATE": {
    rules: [
      0,
      60
    ],
    inclusive: false
  },
  "PSEUDO_STATE": {
    rules: [
      0,
      61,
      62,
      63,
      64
    ],
    inclusive: false
  },
  "SOURCE_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      51,
      57
    ],
    inclusive: false
  },
  "DEFINE_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      54
    ],
    inclusive: false
  },
  "ON_OFF_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      50,
      57
    ],
    inclusive: false
  },
  "SET_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      55
    ],
    inclusive: false
  },
  "TURN_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      56
    ],
    inclusive: false
  },
  "IF_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      58
    ],
    inclusive: false
  },
  "ELSE_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      57
    ],
    inclusive: false
  },
  "ENDIF_DIRECTIVE_STATE": {
    rules: [
      0,
      46,
      57
    ],
    inclusive: false
  },
  "ALNUM_LITERAL_STATE": {
    rules: [
      0,
      46,
      59
    ],
    inclusive: false
  },
  "CONTROL_STATEMENT_STATE": {
    rules: [
      0,
      46,
      53
    ],
    inclusive: false
  },
  "DISPLAY_DIRECTIVE_STATE": {
    rules: [
      0,
      47,
      48,
      49
    ],
    inclusive: false
  },
  "INITIAL": {
    rules: [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      65
    ],
    inclusive: true
  }
}
};


    

    



/* Global functions */

void
pp_set_replace_list (struct cb_replace_list *list, const cob_u32_t is_pushpop)
{
	/* Handle REPLACE verb */
	if (!list) {
		/* REPLACE [LAST] OFF */
		if (!is_pushpop) {
			base_replace_list = NULL;
			return;
		}
		if (!base_replace_list) {
			return;
		}
		base_replace_list = base_replace_list->prev;
		return;
	}
	/* REPLACE [ALSO] ... */
	if (base_replace_list && is_pushpop) {
		list->last->next = base_replace_list;
		list->prev = base_replace_list;
	} else {
		list->prev = NULL;
	}
	base_replace_list = list;
	if (cb_src_list_file) {
		set_print_replace_list (list);
	}
}

int
ppopen (const char *name, struct cb_replace_list *replacing_list)
{
	struct copy_info	*current_copy_info;
	char			*s;
	char			*dname;

	unsigned char		bom[4];

	if (ppin) {
		for (; newline_count > 0; newline_count--) {
			ungetc ('\n', ppin);
		}
	}

	/* Open copy/source file, or use stdin */
	if (strcmp(name, COB_DASH) == 0) {
		ppin = stdin;
	} else {
#ifdef	__OS400__
		ppin = fopen (name, "r");
#else
		ppin = fopen (name, "rb");
#endif
	}

	if (!ppin) {
		cb_error ("%s: %s", name, cb_get_strerror ());
		return -1;
	}

	/* Check for BOM - *not* for input from stdin as rewind() clears the input
	  buffer if used on stdin and output in console has normally no BOM at all */
	if (strcmp (name, COB_DASH) != 0) {
		if (fread (bom, 3, 1, ppin) == 1) {
			if (bom[0] != 0xEF || bom[1] != 0xBB || bom[2] != 0xBF) {
				rewind (ppin);
			}
		} else {
			rewind (ppin);
		}
	}

	/* Save name for listing */
	if (cb_current_file && !cb_current_file->name) {
		cb_current_file->name = cobc_strdup (name);
	}

	/* Preserve the current buffer */
	current_copy_info = cobc_malloc (sizeof (struct copy_info));
	current_copy_info->file = cb_source_file;
	current_copy_info->buffer = YY_CURRENT_BUFFER;

	/* Save variables */
	current_copy_info->replacing = current_replace_list;
	current_copy_info->line = cb_source_line;
	current_copy_info->quotation_mark = quotation_mark;
	current_copy_info->source_format = cb_source_format;

	current_copy_info->next = copy_stack;
	current_copy_info->containing_files = old_list_file;
	copy_stack = current_copy_info;

	if (cb_current_file) {
		cb_current_file->copy_line = cb_source_line;
	}

	/* Set replacing list */
	if (replacing_list) {
		if (current_replace_list) {
			replacing_list->last->next = current_replace_list;
			replacing_list->last = current_replace_list->last;
		}
		current_replace_list = replacing_list;
		if (cb_src_list_file) {
			set_print_replace_list (replacing_list);
		}
	}

	dname = cobc_strdup (name);
	current_copy_info->dname = dname;
	for (s = dname; *s; ++s) {
		if (*s == '\\') {
			*s = '/';
		}
	}

	/* Switch to new buffer */
	switch_to_buffer (1, dname, yy_create_buffer (ppin, YY_BUF_SIZE));
	return 0;
}

int
ppcopy (const char *name, const char *lib, struct cb_replace_list *replace_list)
{
	struct cb_text_list	*il;
	struct cb_text_list	*el;
	const char		*s;

	if (cb_current_file) {
		cb_current_file->copy_line = cb_source_line;
	}

	/* Locate and open COPY file */
	if (lib) {
		snprintf (plexbuff1, (size_t)COB_SMALL_MAX, "%s/%s", lib, name);
		plexbuff1[COB_SMALL_MAX] = 0;
		s = plexbuff1;
	} else {
		s = name;
	}

	/* Find the file */
	if (access (s, R_OK) == 0) {
		return ppopen (s, replace_list);
	}

	for (el = cb_extension_list; el; el = el->next) {
		snprintf (plexbuff2, (size_t)COB_SMALL_MAX, "%s%s", s, el->text);
		plexbuff2[COB_SMALL_MAX] = 0;
		if (access (plexbuff2, R_OK) == 0) {
			return ppopen (plexbuff2, replace_list);
		}
	}

	if (*s != '/') {
		for (il = cb_include_list; il; il = il->next) {
			for (el = cb_extension_list; el; el = el->next) {
				snprintf (plexbuff2, (size_t)COB_SMALL_MAX,
					  "%s/%s%s", il->text, name, el->text);
				plexbuff2[COB_SMALL_MAX] = 0;
				if (access (plexbuff2, R_OK) == 0) {
					return ppopen (plexbuff2, replace_list);
				}
			}
		}
	}

	/* On COPY, open error restore old file */
	cb_current_file = old_list_file;
	fprintf (yyout, "#line %d \"%s\"\n", cb_source_line, cb_source_file);

	cb_error ("%s: %s", s, cb_get_strerror ());
	return -1;
}

void
ppparse_error (const char *err_msg)
{
	cb_plex_error (newline_count, "%s", err_msg);
}

void
plex_clear_vars (void)
{
	/* Reset variables */
	plex_skip_input = 0;
	plex_nest_depth = 0;
	memset (plex_cond_stack, 0, sizeof(plex_cond_stack));
	requires_listing_line = 1;
	comment_allowed = 1;
}

void
plex_clear_all (void)
{
	if (plexbuff1) {
		cobc_free (plexbuff1);
		plexbuff1 = NULL;
	}
	if (plexbuff2) {
		cobc_free (plexbuff2);
		plexbuff2 = NULL;
	}
}

void
plex_call_destroy (void)
{
	(void)pplex_destroy ();
}

void
plex_action_directive (const unsigned int cmdtype, const unsigned int is_true)
{
	unsigned int	n;

	/* Action IF/ELSE/END-IF/ELIF */
	switch (cmdtype) {
	case PLEX_ACT_IF:
		/* Push stack - First occurrence is dummy */
		if (++plex_nest_depth >= PLEX_COND_DEPTH) {
			/* LCOV_EXCL_START */
			cobc_err_msg (_("directive nest depth exceeded: %d"),
					PLEX_COND_DEPTH);
			COBC_ABORT ();
			/* LCOV_EXCL_STOP */
		}
		plex_cond_stack[plex_nest_depth].cmd = 1U;
		/* Intersection with previous - first is always 0 */
		n = plex_cond_stack[plex_nest_depth - 1].skip | !is_true;
		plex_cond_stack[plex_nest_depth].skip = n;
		plex_cond_stack[plex_nest_depth].cond = is_true;
		plex_cond_stack[plex_nest_depth].line = cb_source_line;
		plex_skip_input = n;
		return;
	case PLEX_ACT_ELSE:
		/* Must have an associated IF/ELIF */
		if (!plex_nest_depth ||
		    plex_cond_stack[plex_nest_depth].cmd != 1) {
			cb_plex_error (newline_count,
				_("ELSE directive without matching IF/ELIF"));
			return;
		}
		plex_cond_stack[plex_nest_depth].cmd = 2U;
		/* Reverse any IF/ELIF condition */
		n = plex_cond_stack[plex_nest_depth].cond;
		plex_cond_stack[plex_nest_depth].skip = n;
		plex_cond_stack[plex_nest_depth].line = cb_source_line;
		/* Intersection with previous */
		plex_skip_input = plex_cond_stack[plex_nest_depth - 1].skip | n;
		return;
	case PLEX_ACT_END:
		/* Must have an associated IF/ELIF/ELSE */
		if (!plex_nest_depth ||
		    !plex_cond_stack[plex_nest_depth].cmd) {
			cb_plex_error (newline_count,
				_("END-IF directive without matching IF/ELIF/ELSE"));
			return;
		}
		plex_cond_stack[plex_nest_depth].cmd = 0;
		plex_cond_stack[plex_nest_depth].skip = 0;
		plex_cond_stack[plex_nest_depth].cond = 0;
		plex_cond_stack[plex_nest_depth].line = 0;
		/* Pop stack - set skip to previous */
		plex_nest_depth--;
		plex_skip_input = plex_cond_stack[plex_nest_depth].skip;
		return;
	case PLEX_ACT_ELIF:
		/* Must have an associated IF/ELIF */
		if (!plex_nest_depth ||
		    plex_cond_stack[plex_nest_depth].cmd != 1) {
			cb_plex_error (newline_count,
				_("ELIF directive without matching IF/ELIF"));
			return;
		}
		plex_cond_stack[plex_nest_depth].line = cb_source_line;
		if (plex_cond_stack[plex_nest_depth].cond) {
			/* Previous IF or one of previous ELIF was true */
			/* Set to skip */
			n = 1U;
		} else if (is_true) {
			/* Condition is true */
			plex_cond_stack[plex_nest_depth].cond = 1U;
			n = 0;
		} else {
			/* Set to skip */
			n = 1U;
		}
		plex_cond_stack[plex_nest_depth].skip = n;
		/* Intersection with previous */
		plex_skip_input = plex_cond_stack[plex_nest_depth - 1].skip | n;
		return;
	default:
		/* LCOV_EXCL_START */
		cobc_err_msg (_("invalid internal case: %u"),
				cmdtype);
		COBC_ABORT ();
		/* LCOV_EXCL_STOP */
	}
}

/* Local functions */

static void
get_new_listing_file (void)
{
	struct list_files	*newfile = cobc_malloc (sizeof (struct list_files));

	if (!cb_current_file->copy_head) {
		cb_current_file->copy_head = newfile;
	}
	if (cb_current_file->copy_tail) {
		cb_current_file->copy_tail->next = newfile;
	}
	cb_current_file->copy_tail = newfile;

	memset (newfile, 0, sizeof (struct list_files));
	newfile->copy_line = cb_source_line;
	newfile->source_format = cb_source_format;
	old_list_file = cb_current_file;
	cb_current_file = newfile;
}

static void
set_print_replace_list (struct cb_replace_list *list)
{
	struct cb_replace_list		*r;
	const struct cb_text_list	*l;
	struct list_replace		*repl;
	int 				length;

	for (r = list; r; r = r->next) {
		repl = cobc_malloc (sizeof (struct list_replace));
		memset (repl, 0, sizeof (struct list_replace));
		repl->firstline = r->line_num;
		repl->lead_trail = r->lead_trail;
		repl->lastline = cb_source_line;

		for (l = r->old_text, length = 0; l; l = l->next) {
			length += (int)strlen (l->text);
		}
		repl->from = cobc_malloc (length + 2);
		memset (repl->from, 0, length + 2);
		for (l = r->old_text; l; l = l->next) {
			strcat (repl->from, l->text);
		}

		for (l = r->new_text, length = 0; l; l = l->next) {
			length += (int)strlen (l->text);
		}
		repl->to = cobc_malloc (length + 2);
		memset (repl->to, 0, length + 2);
		for (l = r->new_text; l; l = l->next) {
			strcat (repl->to, l->text);
		}

		if (cb_current_file->replace_tail) {
			cb_current_file->replace_tail->next = repl;
		}
		if (!cb_current_file->replace_head) {
			cb_current_file->replace_head = repl;
		}
		cb_current_file->replace_tail = repl;
	}
}

static void
switch_to_buffer (const int line, const char *file, const YY_BUFFER_STATE buffer)
{
	/* Reset file/line */
	cb_source_line = line;
	cb_source_file = cobc_plex_strdup (file);
	fprintf (yyout, "#line %d \"%s\"\n", line, file);
	/* Switch buffer */
	yy_switch_to_buffer (buffer);
}

static int
is_condition_directive_clause (const char *buff)
{
	while (buff && !isalpha (*buff)) {
		++buff;
	}

	return buff && (strncmp (buff, "END", 3) == 0
			|| strncmp (buff, "IF", 2) == 0
			|| strncmp (buff, "ELSE", 4) == 0
			|| strncmp (buff, "ELIF", 4) == 0
			|| strncmp (buff, "EVALUATE", 8) == 0
			|| strncmp (buff, "WHEN", 4) == 0);
}

static int
is_cobol_word_char (const char c)
{
	return c == '-' || c == '_' || isalnum (c);
}

static int
ppinput (char *buff, const size_t max_size)
{
	char	*bp;
	size_t	gotcr;
	size_t	line_overflow;
	size_t	continuation;
	int	ipchar;
	int	i;
	int	n;
	int	coln;
	struct list_skip *skip;
	const char	*paragraph_name;

	/* Read line(s) */

	continuation = 0;
start:
	if (unlikely (buffer_overflow ||
		     (newline_count + PPLEX_BUFF_LEN) >= max_size)) {
		if (need_continuation || continuation) {
			cb_plex_error (newline_count,
					_("buffer overrun - too many continuation lines"));
#if 0		/* CHECKME: does anything breaks if we don't fake EOF here? */
			return YY_NULL; /* fake eof (no further processing) */
#endif
		}
		if (newline_count < max_size) {
			memset (buff, '\n', newline_count);
			buff[newline_count] = 0;
			ipchar = (int)newline_count;
			newline_count = 0;
			buffer_overflow = 0;
			return ipchar;
		}
		buffer_overflow = 1;
		ipchar = max_size - 1;
		memset (buff, '\n', (size_t)ipchar);
		buff[ipchar] = 0;
		newline_count -= ipchar;
		return ipchar;
	}
	gotcr = 0;
	line_overflow = 0;
	ipchar = 0;
	for (n = 0; ipchar != '\n';) {
		if (unlikely (n == PPLEX_BUFF_LEN)) {
			if (line_overflow != 2) {
				line_overflow = 1;
			}
		}
		ipchar = getc (ppin);
		if (unlikely (ipchar == EOF)) {
			if (n > 0) {
				/* No end of line at end of file */
				break;
			}
			if (newline_count == 0) {
				return YY_NULL;
			}
			memset (buff, '\n', newline_count);
			buff[newline_count] = 0;
			ipchar = (int)newline_count;
			newline_count = 0;
			return ipchar;
		}
#ifndef	COB_EBCDIC_MACHINE
		if (unlikely (ipchar == 0x1A && !n)) {
			continue;
		}
#endif
		if (unlikely (gotcr)) {
			gotcr = 0;
			if (ipchar != '\n') {
				if (likely (line_overflow == 0)) {
					buff[n++] = '\r';
				} else {
					line_overflow = 2;
				}
			}
		}
		if (unlikely (ipchar == '\r')) {
			gotcr = 1;
			continue;
		}
		if (unlikely (ipchar == '\t')) {
			if (likely (line_overflow == 0)) {
				buff[n++] = ' ';
				while (n % cb_tab_width != 0) {
					buff[n++] = ' ';
				}
				if (unlikely (n > PPLEX_BUFF_LEN)) {
					n = PPLEX_BUFF_LEN;
				}
			}
			continue;
		}
		if (likely (line_overflow == 0)) {
			buff[n++] = (char)ipchar;
		} else if ((char)ipchar != ' ' && (char)ipchar != '\n') {
			line_overflow = 2;
		}
	}

	if (buff[n - 1] != '\n') {
		/* FIXME: cb_source_line is one too low when CB_FORMAT_FREE is used
		   [but only during ppinput() in pplex.l ?] - Workaround for now:
		   Temporary newline_count + 1
		*/
		if (cb_source_format == CB_FORMAT_FREE) {
			if (line_overflow == 0) {
				cb_plex_warning (COBC_WARN_FILLER, newline_count + 1,
						 _("line not terminated by a newline"));
			} else if (line_overflow == 2) {
				cb_plex_warning (COBC_WARN_FILLER, newline_count + 1,
						 _("source text exceeds %d bytes, will be truncated"), PPLEX_BUFF_LEN);
			}
		} else {
			if (line_overflow == 0) {
				cb_plex_warning (COBC_WARN_FILLER, newline_count,
						 _("line not terminated by a newline"));
			} else if (line_overflow == 2) {
				cb_plex_warning (COBC_WARN_FILLER, newline_count,
						 _("source text exceeds %d bytes, will be truncated"), PPLEX_BUFF_LEN);
			}
		}
		buff[n++] = '\n';
	}
	buff[n] = 0;

	if (cb_source_format == CB_FORMAT_FREE) {
		bp = buff;
	} else {
		if (n < 8) {
			/* Line too short */
			newline_count++;
			goto start;
		}

		if (cb_flag_mfcomment) {
			if (buff[0] == '*' || buff[0] == '/') {
				newline_count++;
				goto start;
			}
		}

		/* Check if text is longer than cb_text_column */
		if (cb_source_format == CB_FORMAT_FIXED
		    && n > cb_text_column + 1) {
			/* Show warning if it is not whitespace
			   (postponed after checking for comments by setting
			    line_overflow to first column that leads to
				"source text too long")
			*/
			if (cb_warn_column_overflow && line_overflow == 0) {
				for (coln = cb_text_column; coln < n; ++coln) {
					if (buff[coln] != ' ' && buff[coln] != '\n') {
						line_overflow = coln;
						break;
					}
				}
			} else {
				line_overflow = 0;
			}
			/* Remove it */
			buff[cb_text_column] = '\n';
			buff[cb_text_column + 1] = 0;
			n = cb_text_column + 1;
		} else {
			line_overflow = 0;
		}

		memset (buff, ' ', (size_t)6);
		/* Note we allow directive lines to start at column 7 */
		bp = &buff[6];

		/* Special case: acucomment must be checked here as we'd pass comments
		   as directives otherwise */
		if (cb_flag_acucomment && buff[6] == '$') {
			buff[6] = '*';
		}
	}

	/* Check for directives/floating comment at first non-space of line */
	ipchar = 0;
	for (; *bp; bp++) {
		if (*bp != ' ') {
			if ((*bp == '$' && bp[1] != ' ') || (*bp == '>' && bp[1] == '>')) {
				/* Directive */
				ipchar = 1;
			} else if ((*bp == '*' && bp[1] == '>')
			           || (cb_flag_acucomment && *bp == '|')) {
				/* Float comment */
				newline_count++;
				goto start;
			}
			break;
		}
	}
	if (ipchar && (!plex_skip_input
		       || is_condition_directive_clause (bp))) {
		/* Directive - pass complete line with NL to ppparse */
		if (newline_count) {
			/* Move including NL and NULL byte */
			memmove (buff + newline_count, buff, (size_t)(n + 1));
			memset (buff, '\n', newline_count);
			n += newline_count;
			newline_count = 0;
		}
		return n;
	}

	if (plex_skip_input) {
		/* Skipping input */
		newline_count++;
		if (cb_src_list_file) {
			skip = cobc_malloc (sizeof (struct list_skip));
			memset (skip, 0, sizeof (struct list_skip));
			skip->skipline = cb_source_line + (int)newline_count;

			if (cb_current_file->skip_tail) {
				cb_current_file->skip_tail->next = skip;
			}
			cb_current_file->skip_tail = skip;

			if (!cb_current_file->skip_head) {
				cb_current_file->skip_head = skip;
			}
		}
		goto start;
	}

	/*
	  Check that line isn't start of ID DIVISION comment paragraph.
	*/
	if (comment_allowed) {
		if (!strncasecmp (bp, "AUTHOR", 6)) {
			paragraph_name = "AUTHOR";
		} else if (!strncasecmp (bp, "DATE-WRITTEN", 12)) {
			paragraph_name = "DATE-WRITTEN";
		} else if (!strncasecmp (bp, "DATE-MODIFIED", 13)) {
			paragraph_name = "DATE-MODIFIED";
		} else if (!strncasecmp (bp, "DATE-COMPILED", 13)) {
			paragraph_name = "DATE-COMPILED";
		} else if (!strncasecmp (bp, "INSTALLATION", 12)) {
			paragraph_name = "INSTALLATION";
		} else if (!strncasecmp (bp, "REMARKS", 7)) {
			paragraph_name = "REMARKS";
		} else if (!strncasecmp (bp, "SECURITY", 8)) {
			paragraph_name = "SECURITY";
		} else {
			paragraph_name = NULL;
		}

		if (paragraph_name
		    && !is_cobol_word_char (bp[strlen (paragraph_name)])) {
			cb_plex_verify (newline_count, cb_comment_paragraphs,
					paragraph_name);
			/* Skip comments until the end of line. */
			within_comment = 1;
			++newline_count;
			goto start;
		}
	}

	/* Return when free format (no floating comments removed!) */
	if (cb_source_format == CB_FORMAT_FREE) {
		within_comment = 0;
		if (newline_count) {
			memmove (buff + newline_count, buff, (size_t)(n + 1));
			memset (buff, '\n', newline_count);
			n += newline_count;
			newline_count = 0;
		}
		return n;
	}

	/* Fixed format */

	/* Check the indicator (column 7) */
	switch (buff[6]) {
	case ' ':
		break;
	case '-':
		if (unlikely (within_comment)) {
			cb_plex_error (newline_count,
					_("invalid continuation in comment entry"));
			newline_count++;
			goto start;
		} else if (!need_continuation) {
			cb_plex_verify (newline_count, cb_word_continuation,
					_("continuation of COBOL words"));
		}
		continuation = 1;
		break;
	case 'd':
	case 'D':
		/* Debugging line */
		(void) cb_verify (cb_debugging_mode, _("debugging indicator"));
		if (cb_flag_debugging_line) {
			break;
		}
		newline_count++;
		goto start;
	case '*':
	case '/':
		/* Comment line */
		newline_count++;
		goto start;
	default:
		/* Invalid indicator */
		cb_plex_error (newline_count,
				_("invalid indicator '%c' at column 7"), buff[6]);
		newline_count++;
		/* Treat as comment line instead of aborting compilation */
		goto start;
	}

	/* Skip comments that follow after AUTHORS, etc. */
	if (unlikely (within_comment)) {
		/* Check all of "Area A" */
		for (ipchar = 7; ipchar < (n - 1) && ipchar < 11; ++ipchar) {
			if (buff[ipchar] != ' ') {
				ipchar = 0;
				break;
			}
		}
		if (ipchar) {
			newline_count++;
			goto start;
		}
		within_comment = 0;
	}

	/* Skip blank lines */
	for (i = 7; buff[i] == ' '; ++i) {
		;
	}

	if (buff[i] == '\n') {
		newline_count++;
		goto start;
	}

	buff[6] = ' ';
	bp = buff + 7;

	if (unlikely (continuation)) {
		/* Line continuation */
		need_continuation = 0;
		for (; *bp == ' '; ++bp) {
			;
		}
		/* Validate concatenation */
		if (consecutive_quotation) {
			if (bp[0] == quotation_mark && bp[1] == quotation_mark) {
				bp++;
			} else {
				cb_plex_error (newline_count,
						_("invalid line continuation"));
				return YY_NULL;
			}
			quotation_mark = 0;
			consecutive_quotation = 0;
		} else if (quotation_mark) {
			/* Literal concatenation */
			if (*bp == quotation_mark) {
				bp++;
			} else {
				cb_plex_error (newline_count,
						_("invalid line continuation"));
				return YY_NULL;
			}
		}
	} else {
		/* Normal line */
		if (need_continuation) {
			cb_plex_error (newline_count,
					_("continuation character expected"));
			need_continuation = 0;
		}
		quotation_mark = 0;
		consecutive_quotation = 0;
	}

	/* Check if string literal is to be continued */
	for (i = bp - buff; buff[i] != '\n'; ++i) {
		/* Pick up floating comment and force loop exit */
		if (!quotation_mark && ((buff[i] == '*' && buff[i + 1] == '>') ||
			                    (cb_flag_acucomment && buff[i] == '|') ) ) {
			/* remove indicator "source text too long" if the column
			   leading to the indicator comes after the floating comment
			*/
			if (i < cb_text_column) {
				line_overflow = 0;
			}
			/* Set to null, 'i' is predecremented further below */
			buff[i] = 0;
			break;
		} else if (buff[i] == '\'' || buff[i] == '"') {
			if (quotation_mark == 0) {
				/* Literal start */
				quotation_mark = buff[i];
			} else if (quotation_mark == buff[i]) {
				if (i == cb_text_column - 1) {
					/* Consecutive quotation */
					consecutive_quotation = 1;
				} else {
					/* Literal end */
					quotation_mark = 0;
				}
			}
		}
	}

	if (unlikely (quotation_mark)) {
		/* Expecting continuation */
		if (!consecutive_quotation) {
			need_continuation = 1;
		}
		for (; i < cb_text_column;) {
			buff[i++] = ' ';
		}
		buff[i] = 0;
	} else {
		/* Truncate trailing spaces, including the newline */
		for (i--; i >= 0 && buff[i] == ' '; i--) {
			;
		}
		if (i < 0) {
			/* Empty line after removing floating comment */
			newline_count++;
			goto start;
		}
		if (buff[i] == '\'' || buff[i] == '\"') {
			buff[++i] = ' ';
		}
		buff[i + 1] = 0;
	}

	/* Show warning if text is longer than cb_text_column
	   and not whitespace (postponed here) */
	if (line_overflow != 0) {
		cb_plex_warning (COBC_WARN_FILLER, newline_count,
				 _("source text after program-text area (column %d)"),
				cb_text_column);
	}

	if (unlikely (continuation)) {
		gotcr = strlen (bp);
		memmove (buff, bp, gotcr + 1);
		newline_count++;
	} else {
		/* Insert newlines at the start of the buffer */
		gotcr = strlen (buff);
		if (newline_count != 0) {
			memmove (buff + newline_count, buff, gotcr + 1);
			memset (buff, '\n', newline_count);
			gotcr += newline_count;
		}
		newline_count = 1;
	}
	return (int)gotcr;
}

static struct cb_text_list *
pp_text_list_add (struct cb_text_list *list, const char *text,
		  const size_t size)
{
	struct cb_text_list	*p;
	void			*tp;

	p = cobc_plex_malloc (sizeof (struct cb_text_list));
	tp = cobc_plex_malloc (size + 1);
	memcpy (tp, text, size);
	p->text = tp;
	if (!list) {
		p->last = p;
		return p;
	}
	list->last->next = p;
	list->last = p;
	return list;
}

static void
ppecho (const char *text, const cob_u32_t alt_space, const int textlen)
{
	struct cb_replace_list		*r;
	struct cb_replace_list		*save_ptr;
	const struct cb_text_list	*lno;
	struct cb_text_list		*queue;
	struct cb_text_list		*save_queue;
	const char			*s;
	char				*temp_ptr;
	size_t				size;
	size_t				size2;

	/* Check for replacement text before outputting */
	if (alt_space) {
		s = yytext;
	} else {
		s = text;
	}

	if (text_queue == NULL && (text[0] == ' ' || text[0] == '\n')) {
		/* No replacement */
		fwrite (text, (size_t)textlen, (size_t)1, ppout);
		if (cb_listing_file) {
			check_listing (s, 0);
		}
		return;
	}
	if (!current_replace_list && !base_replace_list) {
		/* Ouput queue */
		for (; text_queue; text_queue = text_queue->next) {
			fputs (text_queue->text, ppout);
		}
		fwrite (text, (size_t)textlen, (size_t)1, ppout);
		if (cb_listing_file) {
			check_listing (s, 0);
		}
		return;
	}
	if (!current_replace_list) {
		current_replace_list = base_replace_list;
		save_ptr = NULL;
	} else {
		current_replace_list->last->next = base_replace_list;
		save_ptr = current_replace_list->last;
	}

	/* Do replacement */
	text_queue = pp_text_list_add (text_queue, text, (size_t)textlen);

	save_queue = NULL;
	size = 0;
	size2 = 0;
	for (r = current_replace_list; r; r = r->next) {
		queue = text_queue;
		/* The LEADING/TRAILING code looks peculiar as we use */
		/* variables after breaking out of the loop BUT */
		/* ppparse.y guarantees that we have only one token */
		/* and therefore only one iteration of this loop */
		for (lno = r->old_text; lno; lno = lno->next) {
			if (lno->text[0] == ' ' || lno->text[0] == '\n') {
				continue;
			}
			while (queue && (queue->text[0] == ' ' ||
			       queue->text[0] == '\n')) {
				queue = queue->next;
			}
			if (queue == NULL) {
				/* Partial match */
				if (!save_ptr) {
					current_replace_list = NULL;
				} else {
					save_ptr->next = NULL;
				}
				return;
			}
			if (r->lead_trail == CB_REPLACE_LEADING) {
				/* Check leading text */
				size = strlen (lno->text);
				if (strncasecmp (lno->text, queue->text, size)) {
					/* No match */
					break;
				}
				save_queue = queue;
			} else if (r->lead_trail == CB_REPLACE_TRAILING) {
				/* Check trailing text */
				size = strlen (lno->text);
				size2 = strlen (queue->text);
				if (size2 < size) {
					/* No match */
					break;
				}
				size2 -= size;
				if (strncasecmp (lno->text, queue->text + size2, size)) {
					/* No match */
					break;
				}
				save_queue = queue;
			} else if (strcasecmp (lno->text, queue->text)) {
				/* No match */
				break;
			}
			queue = queue->next;
		}
		if (lno == NULL) {
			/* Match */
			if (r->lead_trail == CB_REPLACE_TRAILING
				&& save_queue /* <- silence warnings */) {
				/* Non-matched part of original text */
				fprintf (ppout, "%*.*s", (int)size2, (int)size2,
					 save_queue->text);
				if (cb_listing_file) {
					temp_ptr = cobc_strdup (save_queue->text);
					*(temp_ptr + size2) = 0;
					check_listing (temp_ptr, 0);
					cobc_free (temp_ptr);
				}
			}
			for (lno = r->new_text; lno; lno = lno->next) {
				fputs (lno->text, ppout);
				if (cb_listing_file) {
					check_listing (lno->text, 0);
				}
			}
			if (r->lead_trail == CB_REPLACE_LEADING
				&& save_queue /* <- silence warnings */) {
				/* Non-matched part of original text */
				fputs (save_queue->text + size, ppout);
				if (cb_listing_file) {
					check_listing (save_queue->text + size, 0);
				}
			}
			text_queue = queue;
			continue;
		}
	}

	/* No match */
	for (; text_queue; text_queue = text_queue->next) {
		fputs (text_queue->text, ppout);
		if (cb_listing_file) {
			check_listing (text_queue->text, 0);
		}
	}
	if (!save_ptr) {
		current_replace_list = NULL;
	} else {
		save_ptr->next = NULL;
	}
}

static void
skip_to_eol (void)
{
	int	c;

	/* Skip bytes to end of line */
	while ((c = input ()) != EOF) {
		if (c == '\n') {
			break;
		}
	}
	if (c != EOF) {
		unput (c);
	}
}

static void
display_finish (void) {
	int msglen;
	if (!plex_skip_input) {
		msglen = strlen (msg) - 1;
		while (msglen != 0 && msg[msglen] == ' ') {
			msg[msglen--] = 0;
		}
		puts (msg);
		msg[0] = 0;
	}
	unput ('\n');
}

static void
check_listing (const char *text, const unsigned int comment)
{
	const char	*s;
	char		c;

	/* Check for listing */
	if (!cb_listing_file) {
		/* Nothing to do */
		return;
	}
	if (!text) {
		return;
	}
	if (cobc_gen_listing == 2) {
		/* LCOV_EXCL_START */
		/* Passed to cobxref */
		fputs (text, cb_listing_file);
		return;
		/* LCOV_EXCL_STOP */
	}
	if (comment) {
		c = '*';
	} else {
		c = ' ';
	}

	if (requires_listing_line) {
		if (requires_new_line) {
			requires_new_line = 0;
			putc ('\n', cb_listing_file);
		}
		fprintf (cb_listing_file, "%6d%c", ++listing_line, c);
	}

	if (requires_listing_line && cb_source_format != CB_FORMAT_FREE &&
	    strlen (text) > 6) {
		s = &text[6];
	} else {
		s = text;
	}
	fputs (s, cb_listing_file);
	if (strchr (text, '\n')) {
		requires_listing_line = 1;
	} else {
		requires_listing_line = 0;
	}
}

    return lexer;
})();

if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
    exports.lexer = lexer;
    exports.lex = function () {
        return lexer.lex.apply(lexer, arguments);
    };
}


if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
    exports.main = // Note: this function will be invoked with argv[0] being the app JS, i.e.
//
//         __jison_default_main__(process.argv.slice(1));
//
// which is the same convention as for C programs, shell scripts, etc.
// NodeJS differs from those in that the first argument *always* is the
// node executable itself, even when this script was invoked *without*
// the node prefix, e.g.
//
//         ./lexer.js --help
//
function __jisonlexer_default_main__(argv) {
    // When the lexer comes with its own `main` function, then use that one:
    if (typeof exports.lexer.main === 'function') {
        return exports.lexer.main(argv);
    }

    // don't dump more than 4 EOF tokens at the end of the stream:
    const maxEOFTokenCount = 4;
    // don't dump more than 20 error tokens in the output stream:
    const maxERRORTokenCount = 20;
    // maximum number of tokens in the output stream:
    const maxTokenCount = 10000;

    if (!argv[1] || argv[1] == '--help' || argv[1] == '-h') {
        console.log(`
Usage:
  ${path.basename(argv[0])} INFILE [OUTFILE]

Input
-----

Reads input from INFILE (which may be specified as '-' to specify STDIN for
use in piped commands, e.g.

  cat "example input" | ${path.basename(argv[0])} -

The input is lexed into a token stream, which is written to the OUTFILE as
an array of JSON nodes.

Output
------

When the OUTFILE is not specified, its path & name are derived off the INFILE,
appending the '.lexed.json' suffix. Hence

  ${path.basename(argv[0])} path/foo.bar

will have its token stream written to the 'path/foo.bar.lexed.json' file.

Errors
------

A (fatal) failure during lexing (i.e. an exception thrown) will be logged as
a special fatal error token:

  {
      id: -1,  // this signals a fatal failure
      token: null,
      fail: 1,
      msg: <the extended error exception type, message and stacktrace as STRING>
  }

Application Exit Codes
----------------------

This particular error situation will produce the same exit code as a successful
lexing: exitcode 0 (zero: SUCCESS)

However, any failure to read/write the files will be reported as errors with
exitcode 1 (one: FAILURE)

Limits
------

- The lexer output (token stream) is limited to ${maxTokenCount} tokens.
- The token stream will end with at most ${maxEOFTokenCount} EOF tokens.
- The token stream will end when at most ${maxERRORTokenCount} ERROR tokens have been
  produced by the lexer.
`);
        process.exit(1);
    }

    function customMainParseError(str, hash, ExceptionClass) {
        console.error("parseError: ", str);
        return this.ERROR;
    }

    function main_work_function(input) {
        const lexer = exports.lexer;

        let yy = {
            // if a custom parseError has already been defined, we DO NOT override that one:
            parseError: (lexer.yy && lexer.yy.parseError) || (lexer.yy && lexer.yy.parser && lexer.yy.parser.parseError) || customMainParseError
        };

        let tokens = [];
        
        let countEOFs = 0;
        let countERRORs = 0;
        let countFATALs = 0;

        try {
            lexer.setInput(input, yy);

            for (i = 0; i < maxTokenCount; i++) {
                let tok = lexer.lex();
                tokens.push({
                    id: tok,
                    token: (tok === 1 ? 'EOF' : tok),    // lexer.describeSymbol(tok),
                    yytext: lexer.yytext,
                    yylloc: lexer.yylloc
                });
                if (tok === lexer.EOF) {
                    // and make sure EOF stays EOF, i.e. continued invocation of `lex()` will only
                    // produce more EOF tokens at the same location:
                    countEOFs++;
                    if (countEOFs >= maxEOFTokenCount) {
                        break;
                    }
                }
                else if (tok === lexer.ERROR) {
                    countERRORs++;
                    if (countERRORs >= maxERRORTokenCount) {
                        break;
                    }
                }
            }
        } catch (ex) {
            countFATALs++;
            // save the error:
            let stk = '' + ex.stack;
            stk = stk.replace(/\t/g, '  ')
            .replace(/  at (.+?)\(.*?[\\/]([^\\/\s]+)\)/g, '  at $1($2)');
            let msg = 'ERROR:' + ex.name + '::' + ex.message + '::' + stk;
            tokens.push({
                id: -1,
                token: null,
                fail: 1,
                err: msg,
            });
        }

        // write a summary node at the end of the stream:
        tokens.push({
            id: -2,
            token: null,
            summary: {
                totalTokenCount: tokens.length,
                EOFTokenCount: countEOFs,
                ERRORTokenCount: countERRORs,
                fatalExceptionCount: countFATALs
            }
        });
        return tokens;
    }

    //const [ , ...args ] = argv;
    let must_read_from_stdin = (argv[1] === '-');
    let input_path = (!must_read_from_stdin ? path.normalize(argv[1]) : '(stdin)');
    let must_write_to_stdout = (argv[2] === '-');
    let output_path = (!must_write_to_stdout ? (path.normalize(argv[2] || (must_read_from_stdin ? input_path : 'stdin') + '.lexed.json')) : '(stdout)');
    const print_summary_and_write_to_output = (tokens) => {
        let summary = tokens[tokens.length - 1].summary;

        console.log(`
////////////////////////////////////////////////////////////////////////////                    
// Lexer output: 
//
// - total # tokens read:                         ${summary.totalTokenCount} 
// - # of EOF totkens:                            ${summary.EOFTokenCount} 
// - # of ERROR tokens produced by the lexer:     ${summary.ERRORTokenCount}
// - # of fatal crashes, i.e. lexer exceptions:   ${summary.fatalExceptionCount}
////////////////////////////////////////////////////////////////////////////
`);

        let dst = JSON.stringify(tokens, null, 2);
        if (!must_write_to_stdout) {
            fs.writeFileSync(output_path, dst, 'utf8');
        } else {
            console.log(dst);                
        }
    };

    if (!must_read_from_stdin) {
        try {
            const input = fs.readFileSync(input_path, 'utf8');
            let tokens = main_work_function(input);

            print_summary_and_write_to_output(tokens);

            process.exit(0); // SUCCESS!
        } catch (ex2) {
            console.error("Failure:\n", ex2, `

Input filepath:  ${input_path}
Output filepath: ${output_path}               
            `);
            process.exit(1);   // FAIL
        }
    } else {
        if (process.stdin.isTTY) {
            console.error(`
Error: 
You specified to read from STDIN without piping anything into the application.

Manual entry from the console is not supported.
            `);
            process.exit(1);
        } else {
            // Accepting piped content. E.g.:
            // echo "pass in this string as input" | ./example-script
            const stdin = process.openStdin();
            let data = '';
            stdin.setEncoding(encoding);

            stdin.on('readable', function () {
                let chunk;
                while (chunk = stdin.read()) {
                    data += chunk;
                }
            });

            stdin.on('end', function () {
                // There MAY be a trailing \n from the user hitting enter. Send it along.
                //data = data.replace(/\n$/, '')
                try {
                    let tokens = main_work_function(data);

                    print_summary_and_write_to_output(tokens);

                    process.exit(0);   // SUCCESS!
                } catch (ex2) {
                    console.error("Failure:\n", ex2, `

Input filepath:  ${input_path}
Output filepath: ${output_path}               
                    `);
                    process.exit(1);   // FAIL
                }
            });
        }
    }
};

    // IFF this is the main module executed by NodeJS,
    // then run 'main()' immediately:
    if (typeof module !== 'undefined' && require.main === module) {
      exports.main(process.argv.slice(1));
    }
}

