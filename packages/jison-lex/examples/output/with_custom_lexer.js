/* lexer generated by jison-lex 0.7.0-220 */

/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a direct reference!
 *
 *               This "shared context" object was passed to the lexer by way of
 *               the `lexer.setInput(str, yy)` API before you may use it.
 *
 *               This "shared context" object is passed to the lexer action code in `performAction()`
 *               so userland code in the lexer actions may communicate with the outside world
 *               and/or other lexer rules' actions in more or less complex ways.
 *
 *  }
 *
 *  Lexer.prototype: {
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    yy:        The overall "shared context" object reference.
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance.
 *                               `yy_` is an alias for `this` lexer instance reference used internally.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *                             Note:
 *                             The extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file are passed to the lexer via this object
 *                             reference as member variables.
 *
 *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   let infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   let retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function(),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the **parser** or the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *    cleanupAfterLex: function(),
 *               Helper function.
 *
 *               This helper API is invoked when the **parse process** has completed: it is the responsibility
 *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
 *
 *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *    setInput: function(input, [yy]),
 *
 *
 *    input: function(),
 *
 *
 *    unput: function(str),
 *
 *
 *    more: function(),
 *
 *
 *    reject: function(),
 *
 *
 *    less: function(n),
 *
 *
 *    pastInput: function(n),
 *
 *
 *    upcomingInput: function(n),
 *
 *
 *    showPosition: function(),
 *
 *
 *    test_match: function(regex_match_array, rule_index),
 *
 *
 *    next: function(),
 *
 *
 *    begin: function(condition),
 *
 *
 *    pushState: function(condition),
 *
 *
 *    popState: function(),
 *
 *
 *    topState: function(),
 *
 *
 *    _currentRules: function(),
 *
 *
 *    stateStackSize: function(),
 *
 *
 *    performAction: function(yy, yy_, yyrulenumber, YY_START),
 *
 *
 *    rules: [...],
 *
 *
 *    conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */



const fs = require('fs');

const path = require('path');

const lexer = function() {
  'use strict';

  /**
   * See also:
   * 
   * - https://github.com/onury/custom-error-test
   * - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error
   * 
   * We now provide an ES6 derived Error class. An updated ES5-compatible class
   * is available too, for those who might need it, as this is complex stuff to
   * get right (see first link above).
   *
   * @public
   * @constructor
   * @nocollapse
   */


  /*---ES5---

  //
  // JS CustomError implementation — The One (Adapted for JISON)
  // This is the closest we can get to ES2015 `extends Error` implementation.
  // @version 2017-01-05
  // @author
  //     Onur Yıldırım (https://github.com/onury)
  //     Matt Browne (https://github.com/mbrowne)
  // @see
  //     https://github.com/onury/custom-error-test
  //     http://stackoverflow.com/a/35881508/112731
  //     https://gist.github.com/mbrowne/4af54767dcb3d529648f5a8aa11d6348
  //     http://stackoverflow.com/a/41338601/112731
  //
  function JisonLexerError(message, hash) {
      if (message == null) message = '???';

      let stacktrace;
      if (hash && hash.exception instanceof Error) {
          const ex2 = hash.exception;
          message = message + ' :: ' + ex2.message;
          stacktrace = ex2.stack;
      }

      let err;
      if (Object.setPrototypeOf) {
          err = new Error(message);
          Object.setPrototypeOf(err, CustomError.prototype);
      } else {
          err = this;
      }

      Object.defineProperty(err, 'name', {
          enumerable: false,
          writable: false,
          value: 'JisonLexerError'
      });

      err.hash = hash;

      if (!Object.setPrototypeOf) {
          Object.defineProperty(err, 'message', {
              enumerable: false,
              writable: true,
              value: message
          });
          if (!stacktrace) {
              if (typeof Error.captureStackTrace === 'function') { // V8
                  Error.captureStackTrace(this, JisonLexerError);
              } else {
                  stacktrace = (new Error(message)).stack;
              }
          }
      }

      if (stacktrace) {
          Object.defineProperty(err, 'stack', {
              enumerable: false,
              writable: false,
              value: stacktrace
          });
      }

      return err;
  }
  if (Object.setPrototypeOf) {
      Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
  } else {
      JisonLexerError.prototype = Object.create(Error.prototype, {
          constructor: { value: JisonLexerError }
      });
  }

  ---ES5---*/

  //---ES6---//

  class JisonLexerError extends Error {
    constructor(message, hash, ...params) {
      if (message == null)
        message = '???';

      let stacktrace;

      if (hash && hash.exception instanceof Error) {
        const ex2 = hash.exception;
        message = message + ' :: ' + ex2.message;
        stacktrace = ex2.stack;
      }

      // Pass remaining arguments (including vendor specific ones) to parent constructor
      super(message, ...params);

      if (!stacktrace) {
        // Maintains proper stack trace for where our error was thrown (only available on V8)
        if (typeof Error.captureStackTrace === 'function') {
          // V8
          Error.captureStackTrace(this, JisonLexerError);
        } else {
          stacktrace = new Error(message).stack;
        }
      }

      if (stacktrace) {
        Object.defineProperty(this, 'stack', {
          enumerable: false,
          writable: false,
          value: stacktrace
        });
      }

      this.name = 'JisonLexerError';
      this.hash = hash;
    }
  }

  //---ES6---//




  // When you set up a custom lexer, this is the minimum example for one:
  // 
  // your lexer class/object must provide these interface methods and constants at least:
  //
  // - setInput(string)
  // - lex() -> token
  // - EOF = 1
  // - ERROR = 2
  //
  // and your lexer must have a `options` member set up as a hash table, i.e. JS object:
  //
  // - options: {}
  //
  // Your lexer must be named `lexer` as shown below.

  var input = '';

  var input_offset = 0;

  var lexer = {
    EOF: 1,
    ERROR: 2,
    options: {},

    lex: function() {
      if (input.length > input_offset) {
        return input[input_offset++];
      } else {
        return this.EOF;
      }
    },

    setInput: function(inp) {
      input = inp;
      input_offset = 0;
    }
  };

  // Included by Jison: includes/with-includes.main.js:

  lexer.main = function(args) {
    if (!args[1]) {
      console.log('Usage: ' + args[0] + ' FILE');
      process.exit(1);
    }

    var tty = require('tty');

    if (tty.isatty(process.stdout.fd)) {
      console.log('not redirected');
    } else {
      console.log('redirected');
    }

    var input_chunks = [];

    function process_one_line(source) {
      try {
        var rv = lexer.parse(source);
        process.stdout.write(JSON.stringify(rv, null, 2) + '\n');
      } catch (ex) {
        process.stdout.write(
          'Lexing error:\n' + JSON.stringify(ex, null, 2) + '\nfor input:\n' + source + '\n'
        );
      }
    }

    function act() {
      // see if we got an entire line's worth from stdin already?
      var source = input_chunks.join('').split('\n');

      while (source.length > 1) {
        process_one_line(source[0]);
        source.shift();
      }

      input_chunks = source;
    }

    if (args[1] === '-') {
      // read from stdin, echo output to stdout
      process.stdin.setEncoding('utf8');

      process.stdin.on('readable', function() {
        var chunk = process.stdin.read();

        //console.log("chunk:", JSON.stringify(chunk, null, 2));
        if (chunk !== null) {
          input_chunks.push(chunk);
          act();
        }
      });

      process.stdin.on('end', function() {
        input_chunks.push('\n');
        act();
        process.exit(0);
      });
    } else {
      try {
        var source = require('fs').readFileSync(require('path').normalize(args[1]), 'utf8');
        var rv = lexer.parse(source);
        process.stdout.write(JSON.stringify(rv, null, 2));
        return +rv || 0;
      } catch (ex) {
        process.stdout.write(
          'Lexing error:\n' + JSON.stringify(ex, null, 2) + '\nfor input file:\n' + args[1]
        );

        return 66;
      }
    }
  };

  // End Of Include by Jison: includes/with-includes.main.js

  return lexer;
}();

if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
  exports.lexer = lexer;

  exports.lex = function() {
    return lexer.lex.apply(lexer, arguments);
  };
}

if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
  // Note: this function will be invoked with argv[0] being the app JS, i.e.
  exports.main = //
  //         __jison_default_main__(process.argv.slice(1));
  //
  // which is the same convention as for C programs, shell scripts, etc.
  // NodeJS differs from those in that the first argument *always* is the
  // node executable itself, even when this script was invoked *without*
  // the node prefix, e.g.
  //
  //         ./lexer.js --help
  //
  function __jisonlexer_default_main__(argv) {
    // When the lexer comes with its own `main` function, then use that one:
    if (typeof exports.lexer.main === 'function') {
      return exports.lexer.main(argv);
    }

    // don't dump more than 4 EOF tokens at the end of the stream:
    const maxEOFTokenCount = 4;

    // don't dump more than 20 error tokens in the output stream:
    const maxERRORTokenCount = 20;

    // maximum number of tokens in the output stream:
    const maxTokenCount = 10000;

    if (!argv[1] || argv[1] == '--help' || argv[1] == '-h') {
      console.log(`
Usage:
  ${path.basename(argv[0])} INFILE [OUTFILE]

Input
-----

Reads input from INFILE (which may be specified as '-' to specify STDIN for
use in piped commands, e.g.

  cat "example input" | ${path.basename(argv[0])} -

The input is lexed into a token stream, which is written to the OUTFILE as
an array of JSON nodes.

Output
------

When the OUTFILE is not specified, its path & name are derived off the INFILE,
appending the '.lexed.json' suffix. Hence

  ${path.basename(argv[0])} path/foo.bar

will have its token stream written to the 'path/foo.bar.lexed.json' file.

Errors
------

A (fatal) failure during lexing (i.e. an exception thrown) will be logged as
a special fatal error token:

  {
      id: -1,  // this signals a fatal failure
      token: null,
      fail: 1,
      msg: <the extended error exception type, message and stacktrace as STRING>
  }

Application Exit Codes
----------------------

This particular error situation will produce the same exit code as a successful
lexing: exitcode 0 (zero: SUCCESS)

However, any failure to read/write the files will be reported as errors with
exitcode 1 (one: FAILURE)

Limits
------

- The lexer output (token stream) is limited to ${maxTokenCount} tokens.
- The token stream will end with at most ${maxEOFTokenCount} EOF tokens.
- The token stream will end when at most ${maxERRORTokenCount} ERROR tokens have been
  produced by the lexer.
`);

      process.exit(1);
    }

    function customMainParseError(str, hash, ExceptionClass) {
      console.error('parseError: ', str);
      return this.ERROR;
    }

    function main_work_function(input) {
      const lexer = exports.lexer;

      let yy = {
        // if a custom parseError has already been defined, we DO NOT override that one:
        parseError: lexer.yy && lexer.yy.parseError || lexer.yy && lexer.yy.parser && lexer.yy.parser.parseError || customMainParseError
      };

      let tokens = [];
      let countEOFs = 0;
      let countERRORs = 0;
      let countFATALs = 0;

      try {
        lexer.setInput(input, yy);

        for (i = 0; i < maxTokenCount; i++) {
          let tok = lexer.lex();

          tokens.push({
            id: tok,

            // lexer.describeSymbol(tok),
            token: tok === 1 ? 'EOF' : tok,

            yytext: lexer.yytext,
            yylloc: lexer.yylloc
          });

          if (tok === lexer.EOF) {
            // and make sure EOF stays EOF, i.e. continued invocation of `lex()` will only
            // produce more EOF tokens at the same location:
            countEOFs++;

            if (countEOFs >= maxEOFTokenCount) {
              break;
            }
          } else if (tok === lexer.ERROR) {
            countERRORs++;

            if (countERRORs >= maxERRORTokenCount) {
              break;
            }
          }
        }
      } catch (ex) {
        countFATALs++;

        // save the error:
        let stk = '' + ex.stack;

        stk = stk.replace(/\t/g, '  ').replace(/  at (.+?)\(.*?[\\/]([^\\/\s]+)\)/g, '  at $1($2)');
        let msg = 'ERROR:' + ex.name + '::' + ex.message + '::' + stk;

        tokens.push({
          id: -1,
          token: null,
          fail: 1,
          err: msg
        });
      }

      // write a summary node at the end of the stream:
      tokens.push({
        id: -2,
        token: null,

        summary: {
          totalTokenCount: tokens.length,
          EOFTokenCount: countEOFs,
          ERRORTokenCount: countERRORs,
          fatalExceptionCount: countFATALs
        }
      });

      return tokens;
    }

    //const [ , ...args ] = argv;
    let must_read_from_stdin = argv[1] === '-';

    let input_path = !must_read_from_stdin ? path.normalize(argv[1]) : '(stdin)';
    let must_write_to_stdout = argv[2] === '-';
    let output_path = !must_write_to_stdout ? path.normalize(argv[2] || (must_read_from_stdin ? input_path : 'stdin') + '.lexed.json') : '(stdout)';

    const print_summary_and_write_to_output = (tokens) => {
      let summary = tokens[tokens.length - 1].summary;

      console.log(`
////////////////////////////////////////////////////////////////////////////                    
// Lexer output: 
//
// - total # tokens read:                         ${summary.totalTokenCount} 
// - # of EOF totkens:                            ${summary.EOFTokenCount} 
// - # of ERROR tokens produced by the lexer:     ${summary.ERRORTokenCount}
// - # of fatal crashes, i.e. lexer exceptions:   ${summary.fatalExceptionCount}
////////////////////////////////////////////////////////////////////////////
`);

      let dst = JSON.stringify(tokens, null, 2);

      if (!must_write_to_stdout) {
        fs.writeFileSync(output_path, dst, 'utf8');
      } else {
        console.log(dst);
      }
    };

    if (!must_read_from_stdin) {
      try {
        const input = fs.readFileSync(input_path, 'utf8');
        let tokens = main_work_function(input);
        print_summary_and_write_to_output(tokens);
        process.exit(0); // SUCCESS!
      } catch (ex2) {
        console.error('Failure:\n', ex2, `

Input filepath:  ${input_path}
Output filepath: ${output_path}               
            `);

        process.exit(1);   // FAIL
      }
    } else {
      if (process.stdin.isTTY) {
        console.error(`
Error: 
You specified to read from STDIN without piping anything into the application.

Manual entry from the console is not supported.
            `);

        process.exit(1);
      } else {
        // Accepting piped content. E.g.:
        // echo "pass in this string as input" | ./example-script
        const stdin = process.openStdin();

        let data = '';
        stdin.setEncoding(encoding);

        stdin.on('readable', function() {
          let chunk;

          while (chunk = stdin.read()) {
            data += chunk;
          }
        });

        stdin.on('end', function() {
          // There MAY be a trailing \n from the user hitting enter. Send it along.
          //data = data.replace(/\n$/, '')
          try {
            let tokens = main_work_function(data);
            print_summary_and_write_to_output(tokens);
            process.exit(0);   // SUCCESS!
          } catch (ex2) {
            console.error('Failure:\n', ex2, `

Input filepath:  ${input_path}
Output filepath: ${output_path}               
                    `);

            process.exit(1);   // FAIL
          }
        });
      }
    }
  };

  // IFF this is the main module executed by NodeJS,
  // then run 'main()' immediately:
  if (typeof module !== 'undefined' && require.main === module) {
    exports.main(process.argv.slice(1));
  }
}