
//=============================================================================
//                     JISON-LEX OPTIONS:

{
  lexerActionsUseYYLENG: '???',
  lexerActionsUseYYLINENO: '???',
  lexerActionsUseYYTEXT: '???',
  lexerActionsUseYYLOC: '???',
  lexerActionsUseParseError: '???',
  lexerActionsUseYYERROR: '???',
  lexerActionsUseLocationTracking: '???',
  lexerActionsUseMore: '???',
  lexerActionsUseUnput: '???',
  lexerActionsUseReject: '???',
  lexerActionsUseLess: '???',
  lexerActionsUseDisplayAPIs: '???',
  lexerActionsUseDescribeYYLOC: '???',
  lex_rule_dictionary: {
    rules: [
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return '('",
        rule: '\\(',
      },
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return ')'",
        rule: '\\)',
      },
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return 'A'",
        rule: '.',
      },
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return 'BEGIN'",
        rule: '\\(',
        start_condition: [
          'alt',
        ],
      },
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return 'END'",
        rule: '\\)',
        start_condition: [
          'alt',
        ],
      },
      {
        ast: {
          source: '[IDEM: srcCode]',
          augmentedSource: '[LINE-SHIFTED SOURCE]',
          ast: '[recast AST]',
          fault: false,
        },
        fault: false,
        srcCode: "return 'B'",
        rule: '.',
        start_condition: [
          'alt',
        ],
      },
    ],
    moduleInclude: `// Included by Jison: includes/benchmark.js:

/**
 * Provide a generic performance timer, which strives to produce highest possible accuracy time measurements.
 * 
 * methods:
 * 
 * - \`start()\` (re)starts the timer and 'marks' the current time for ID="start". 
 *   \`.start()\` also CLEARS ALL .mark_delta() timers!
 *
 * - \`mark(ID)\` calculates the elapsed time for the current timer in MILLISECONDS (floating point) 
 *   since \`.start()\`. \`.mark_delta()\` then updates the 'start/mark time' for the given ID.
 *
 *   ID *may* be NULL, in which case \`.mark()\` will not update any 'start/mark time'.
 *    
 * - \`mark_delta(ID, START_ID)\` calculates the elapsed time for the current timer in MILLISECONDS (floating point) since 
 *   the last call to \`.mark_delta()\` or \`.mark()\` with the same ID. \`.mark_delta()\` then updates the 
 *   'start/mark time' for the given ID.
 *
 *   When the optional START_ID is specified, the delta is calculated against the last marked time 
 *   for that START_ID.
 *
 *   When the ID is NULL or not specified, then the default ID of "start" will be assumed.
 *   
 *   This results in consecutive calls to \`.mark_delta()\` with the same ID to produce 
 *   each of the time intervals between the calls, while consecutive calls to
 *   \`.mark()\` with he same ID would produce an increase each time instead as the time 
 *   between the \`.mark()\` call and the original \`.start()\` increases.
 * 
 * Notes:
 * 
 * - when you invoke \`.mark()\` or \`.mark_delta()\` without having called .start() before, 
 *   then the timer is started at the mark.
 * 
 * - \`.start()\` will erase all stored 'start/mark times' which may have been
 *   set by \`.mark()\` or \`.mark_delta()\` before -- you may call \`.start()\` multiple times for
 *   the same timer instance, after all.
 * 
 * - you are responsible to manage the IDs for \`.mark()\` and \`.mark_delta()\`. The ID MUST NOT be "start" 
 *   as ID = "start" identifies the .start() timer.
 * 
 * References for the internal implementation:
 * 
 *    - http://updates.html5rocks.com/2012/08/When-milliseconds-are-not-enough-performance-now
 *    - http://ejohn.org/blog/accuracy-of-javascript-time/
 *
 * @class 
 * @constructor
 */
function PerformanceTimer() {
  /* @private */ var start_time = false;
  var obj = {
  };
  // feature detect:
  /* @private */ var f, tv;
  /* @private */ var p = (typeof window !== 'undefined' && window.performance);
  if (p && p.timing.navigationStart && p.now) {
    f = function () {
      return p.now();
    };
  } else if (p && typeof p.webkitNow === 'function') {
    f = function () {
      return p.webkitNow();
    };
  } else {
    p = (typeof process !== 'undefined' && process.hrtime);
    if (typeof p === 'function') {
      tv = p();
      if (tv && tv.length === 2) {
        f = function () {
          var rv = p();
          return rv[0] * 1e3 + rv[1] * 1e-6;
        };
      } 
    } 
    if (!f) {
      f = function () {
        return Date.now();
      };
      try {
        f();
      } catch (ex) {
        f = function () {
          return +new Date();
        };
      }
    }
  }

  obj.start = function () {
    start_time = {
      start: f()
    };
    return obj;
  };
  
  obj.mark = function (id, start_id) {
    if (start_time === false) this.start();
    var end_time = f();
    var begin_time = start_time[start_id || id || "start"];
    if (!begin_time) {
      begin_time = end_time;
    }
    var rv = end_time - begin_time;
    if (id) {
      start_time[id] = end_time;
    }
    return rv;
  };
  
  obj.mark_delta = function (id) {
    if (start_time === false) this.start();
    id = id || "start";
    var end_time = f();
    var begin_time = start_time[id];
    if (!begin_time) {
      begin_time = end_time;
    }
    var rv = end_time - begin_time;
    start_time[id] = end_time;
    return rv;
  };
  
  obj.reset_mark = function (id) {
    id = id || "start";
    start_time[id] = null;
    return obj;
  };

  obj.get_mark = function (id) {
    id = id || "start";
    return start_time[id];
  };

  obj.mark_sample_and_hold = function (id) {
    if (start_time === false) this.start();
    id = id || "start";
    // sample ...
    var end_time = f();
    var begin_time = start_time[id];
    if (!begin_time) {
      begin_time = end_time;
      // ... and hold
      start_time[id] = begin_time;
    }
    var rv = end_time - begin_time;
    return rv;
  };

  return obj;
}

var perf = PerformanceTimer();



// round to the number of decimal digits:
function r(v, n) {
    var m = Math.pow(10, n | 0);
    v *= m;
    v = Math.round(v);
    return v / m;
}

// run the benchmark on function \`f\` for at least 5 seconds.
function bench(f, n, minimum_run_time, setup_f, destroy_f) {
    var factor = 50;
    var run = 1;         // factor of 50 !  
    n |= 0;
    n /= run;
    n |= 0;
    n = Math.max(n, 1); // --> minimum number of tests: 1*run*factor
    
    minimum_run_time |= 0;
    if (!minimum_run_time) {
        // default: 5 seconds minimum run time:
        minimum_run_time = 5000 * 1.01 /* overhead compensation */;     
    }
    minimum_run_time = Math.max(minimum_run_time, 1000);    // absolute minimum run time: 1 second

    perf.mark('monitor');

    if (setup_f) {
        setup_f(f, n, minimum_run_time);
    }

    // measure a short run and determine the run count based on this result:
    perf.mark('bench');
    // 50 x f(): that seems a sort of 'sweet spot' for NodeJS v5, at least for some benchmarks...
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    var sample1 = perf.mark('bench');
    var fmultiplier = 250 / sample1;
    var multiplier = Math.max(1, (fmultiplier + 0.5) | 0);
    run = Math.max(run, multiplier);
    console.log("run multiplier: ", run);

    // get the number of tests internal to the test function: 1 or more
    var internal_cnt = f();
    if (typeof internal_cnt === 'number' && (internal_cnt | 0) === internal_cnt) {
        factor *= internal_cnt;
    }

    var last_report = 500;
    var ts = [];
    for (var i = 0; i < n; i++) {
        perf.mark('bench');
        for (var j = 0; j < run; j++) {
            // 50 x f(): that seems a sort of 'sweet spot' for NodeJS v5, at least for some benchmarks...
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
        }
        ts.push(perf.mark('bench'));
        var consumed = perf.mark_sample_and_hold('monitor');
        //console.log('consumed', consumed, ts[ts.length - 1], i);
        if (last_report <= consumed) {
            console.log('#' + (ts.length * factor));
            last_report = consumed + 1000;
        }
        if (consumed < minimum_run_time || ts.length < 10) {
            // stay in the loop until 5 seconds have expired or at least 10 rounds have been executed!
            i = Math.min(i, n - 2);
        }
    }

    if (destroy_f) {
        destroy_f(f, n, minimum_run_time);
    }

    var consumed = perf.mark_sample_and_hold('monitor');
    
    var sum = 0;
    for (var i = 0, cnt = ts.length; i < cnt; i++) {
        sum += ts[i];
    }
    var avg = sum / cnt;

    var dev = 0;
    var peak = 0;
    for (var i = 0; i < cnt; i++) {
        var delta = Math.abs(ts[i] - avg);
        dev += delta;
        peak = Math.max(peak, delta);
    }
    dev /= cnt;
    var sample_size = run * factor;
    console.log(["Time: total: ", r(sum, 0) + 'ms',
        ", sample_count: ", cnt,
        ", # runs: ", cnt * sample_size,
        ", # runs/sec: ", r(cnt * sample_size * 1000 / sum, 1),
        ", average: ", r(avg / sample_size, 4) + 'ms',
        ", deviation: ", r(100 * dev / avg, 2) + '%',
        ", peak_deviation: ", r(100 * peak / avg, 2) + '%',
        ", total overhead: ", r(consumed - sum, 0) + 'ms'].join('')
    );
}

// End Of Include by Jison: includes/benchmark.js




// rephrase for display: error info objects which have been pushed onto the vstack:
function get_filtered_value_stack(vstack) {
    var rv = [];
    for (var i = 0, len = vstack.length; i < len; i++) {
        var o = vstack[i];
        if (o && o.errStr) {
            o = '#ERRORINFO#: ' + o.errStr;
        }
        rv.push(o);
    }
    return rv;
}

function get_reduced_error_info_obj(hash) {
    if (!hash || !hash.errStr) {
        return null;
    }
    return {
        text: hash.text,
        token: hash.token,
        token_id: hash.token_id,
        expected: hash.expected,
        matched: (hash.lexer && hash.lexer.matched) || '(-nada-)',
        lexerConditionStack: (hash.lexer && hash.lexer.conditionStack) || '(???)',
        remaining_input: (hash.lexer && hash.lexer._input) || '(-nada-)',
        recoverable: hash.recoverable,
        state_stack: hash.state_stack,
        value_stack: get_filtered_value_stack(hash.value_stack)
    };    
}

function compiledRunner(args) {
    var inp = 'xxx(x(x)x)xxx';
    console.log('input = ', inp);


    // set up a custom parseError handler.
    //
    // Note that this one has an extra feature: it tweaks the \`yytext\` value to propagate 
    // the error info into the parser error rules as \`$error\`: 
    parser.parseError = function altParseError(msg, hash) {
        if (hash && hash.exception) {
            msg = hash.exception.message;
            //console.log('ex:', hash.exception, hash.exception.stack);
        }
        console.log("### ERROR: " + msg, get_reduced_error_info_obj(hash));
        if (hash && hash.lexer) {
            hash.lexer.yytext = hash;
        };
    };

    parser.lexer.options.post_lex = function (tok) {
        parser.trace('lexer produces one token: ', tok, parser.describeSymbol(tok));
    };

    parser.options.debug = false;     

    function execute() {
        parser.parse(inp);
    }

    if (0) {
        execute();
    } else {
        // nuke the console output via trace() and output minimal progress while we run the benchmark:
        parser.trace = function nada_trace() {};
        // make sure to disable debug output at all, so we only get the conditional check as cost when \`%debug\` is enabled for this grammar
        parser.options.debug = false;     

        // track number of calls for minimal/FAST status update while benchmarking... 
        var logcount = 0;
        parser.post_parse = function (tok) {
            logcount++;
        };

        bench(execute, 0, 10e3, null, function () {
            console.log('run #', logcount);
        });
    }

    return 0;
}`,
    macros: {},
    startConditions: {
      alt: 1,
    },
    codeSections: [],
    importDecls: [],
    unknownDecls: [],
    options: {
      ranges: true,
    },
  },
  codeSections: [],
  importDecls: [],
  unknownDecls: [],
  options: {
    moduleType: 'commonjs',
    debug: false,
    enableDebugLogs: false,
    json: true,
    noMain: true,
    moduleMain: null,
    moduleMainImports: null,
    dumpSourceCodeOnFailure: false,
    throwErrorOnCompileFailure: true,
    doNotTestCompile: false,
    defaultModuleName: 'lexer',
    xregexp: false,
    lexerErrorsAreRecoverable: false,
    flex: false,
    backtrack_lexer: false,
    ranges: true,
    trackPosition: true,
    caseInsensitive: false,
    exportSourceCode: {
      enabled: false,
    },
    exportAST: false,
    prettyCfg: true,
  },
  conditions: {
    alt: {
      rules: [
        3,
        4,
        5,
      ],
      inclusive: false,
    },
    INITIAL: {
      rules: [
        0,
        1,
        2,
      ],
      inclusive: true,
    },
  },
  performAction: `function lexer__performAction(yy, yyrulenumber, YY_START) {
            const yy_ = this;

            
const YYSTATE = YY_START;
switch(yyrulenumber) {
default:
  return this.simpleCaseActionClusters[yyrulenumber];
}
        }`,
  caseHelperInclude: `{

  /*! Conditions:: INITIAL */ 
  /*! Rule::       \\( */ 
   0 : '(',
  /*! Conditions:: INITIAL */ 
  /*! Rule::       \\) */ 
   1 : ')',
  /*! Conditions:: INITIAL */ 
  /*! Rule::       . */ 
   2 : 'A',
  /*! Conditions:: alt */ 
  /*! Rule::       \\( */ 
   3 : 'BEGIN',
  /*! Conditions:: alt */ 
  /*! Rule::       \\) */ 
   4 : 'END',
  /*! Conditions:: alt */ 
  /*! Rule::       . */ 
   5 : 'B'
}`,
  rules: [
    {
      re: '/^(?:\\()/',
      source: '^(?:\\()',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:\\()',
        flags: '',
        isNative: true,
      },
    },
    {
      re: '/^(?:\\))/',
      source: '^(?:\\))',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:\\))',
        flags: '',
        isNative: true,
      },
    },
    {
      re: '/^(?:.)/',
      source: '^(?:.)',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:.)',
        flags: '',
        isNative: true,
      },
    },
    {
      re: '/^(?:\\()/',
      source: '^(?:\\()',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:\\()',
        flags: '',
        isNative: true,
      },
    },
    {
      re: '/^(?:\\))/',
      source: '^(?:\\))',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:\\))',
        flags: '',
        isNative: true,
      },
    },
    {
      re: '/^(?:.)/',
      source: '^(?:.)',
      flags: '',
      xregexp: {
        captureNames: null,
        source: '^(?:.)',
        flags: '',
        isNative: true,
      },
    },
  ],
  macros: {},
  regular_rule_count: 0,
  simple_rule_count: 6,
  conditionStack: [
    'INITIAL',
  ],
  actionInclude: '',
  moduleInclude: `



// Included by Jison: includes/benchmark.js:

/**
 * Provide a generic performance timer, which strives to produce highest possible accuracy time measurements.
 * 
 * methods:
 * 
 * - \`start()\` (re)starts the timer and 'marks' the current time for ID="start". 
 *   \`.start()\` also CLEARS ALL .mark_delta() timers!
 *
 * - \`mark(ID)\` calculates the elapsed time for the current timer in MILLISECONDS (floating point) 
 *   since \`.start()\`. \`.mark_delta()\` then updates the 'start/mark time' for the given ID.
 *
 *   ID *may* be NULL, in which case \`.mark()\` will not update any 'start/mark time'.
 *    
 * - \`mark_delta(ID, START_ID)\` calculates the elapsed time for the current timer in MILLISECONDS (floating point) since 
 *   the last call to \`.mark_delta()\` or \`.mark()\` with the same ID. \`.mark_delta()\` then updates the 
 *   'start/mark time' for the given ID.
 *
 *   When the optional START_ID is specified, the delta is calculated against the last marked time 
 *   for that START_ID.
 *
 *   When the ID is NULL or not specified, then the default ID of "start" will be assumed.
 *   
 *   This results in consecutive calls to \`.mark_delta()\` with the same ID to produce 
 *   each of the time intervals between the calls, while consecutive calls to
 *   \`.mark()\` with he same ID would produce an increase each time instead as the time 
 *   between the \`.mark()\` call and the original \`.start()\` increases.
 * 
 * Notes:
 * 
 * - when you invoke \`.mark()\` or \`.mark_delta()\` without having called .start() before, 
 *   then the timer is started at the mark.
 * 
 * - \`.start()\` will erase all stored 'start/mark times' which may have been
 *   set by \`.mark()\` or \`.mark_delta()\` before -- you may call \`.start()\` multiple times for
 *   the same timer instance, after all.
 * 
 * - you are responsible to manage the IDs for \`.mark()\` and \`.mark_delta()\`. The ID MUST NOT be "start" 
 *   as ID = "start" identifies the .start() timer.
 * 
 * References for the internal implementation:
 * 
 *    - http://updates.html5rocks.com/2012/08/When-milliseconds-are-not-enough-performance-now
 *    - http://ejohn.org/blog/accuracy-of-javascript-time/
 *
 * @class 
 * @constructor
 */
function PerformanceTimer() {
  /* @private */ var start_time = false;
  var obj = {
  };
  // feature detect:
  /* @private */ var f, tv;
  /* @private */ var p = (typeof window !== 'undefined' && window.performance);
  if (p && p.timing.navigationStart && p.now) {
    f = function () {
      return p.now();
    };
  } else if (p && typeof p.webkitNow === 'function') {
    f = function () {
      return p.webkitNow();
    };
  } else {
    p = (typeof process !== 'undefined' && process.hrtime);
    if (typeof p === 'function') {
      tv = p();
      if (tv && tv.length === 2) {
        f = function () {
          var rv = p();
          return rv[0] * 1e3 + rv[1] * 1e-6;
        };
      } 
    } 
    if (!f) {
      f = function () {
        return Date.now();
      };
      try {
        f();
      } catch (ex) {
        f = function () {
          return +new Date();
        };
      }
    }
  }

  obj.start = function () {
    start_time = {
      start: f()
    };
    return obj;
  };
  
  obj.mark = function (id, start_id) {
    if (start_time === false) this.start();
    var end_time = f();
    var begin_time = start_time[start_id || id || "start"];
    if (!begin_time) {
      begin_time = end_time;
    }
    var rv = end_time - begin_time;
    if (id) {
      start_time[id] = end_time;
    }
    return rv;
  };
  
  obj.mark_delta = function (id) {
    if (start_time === false) this.start();
    id = id || "start";
    var end_time = f();
    var begin_time = start_time[id];
    if (!begin_time) {
      begin_time = end_time;
    }
    var rv = end_time - begin_time;
    start_time[id] = end_time;
    return rv;
  };
  
  obj.reset_mark = function (id) {
    id = id || "start";
    start_time[id] = null;
    return obj;
  };

  obj.get_mark = function (id) {
    id = id || "start";
    return start_time[id];
  };

  obj.mark_sample_and_hold = function (id) {
    if (start_time === false) this.start();
    id = id || "start";
    // sample ...
    var end_time = f();
    var begin_time = start_time[id];
    if (!begin_time) {
      begin_time = end_time;
      // ... and hold
      start_time[id] = begin_time;
    }
    var rv = end_time - begin_time;
    return rv;
  };

  return obj;
}

var perf = PerformanceTimer();



// round to the number of decimal digits:
function r(v, n) {
    var m = Math.pow(10, n | 0);
    v *= m;
    v = Math.round(v);
    return v / m;
}

// run the benchmark on function \`f\` for at least 5 seconds.
function bench(f, n, minimum_run_time, setup_f, destroy_f) {
    var factor = 50;
    var run = 1;         // factor of 50 !  
    n |= 0;
    n /= run;
    n |= 0;
    n = Math.max(n, 1); // --> minimum number of tests: 1*run*factor
    
    minimum_run_time |= 0;
    if (!minimum_run_time) {
        // default: 5 seconds minimum run time:
        minimum_run_time = 5000 * 1.01 /* overhead compensation */;     
    }
    minimum_run_time = Math.max(minimum_run_time, 1000);    // absolute minimum run time: 1 second

    perf.mark('monitor');

    if (setup_f) {
        setup_f(f, n, minimum_run_time);
    }

    // measure a short run and determine the run count based on this result:
    perf.mark('bench');
    // 50 x f(): that seems a sort of 'sweet spot' for NodeJS v5, at least for some benchmarks...
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();
    f();

    var sample1 = perf.mark('bench');
    var fmultiplier = 250 / sample1;
    var multiplier = Math.max(1, (fmultiplier + 0.5) | 0);
    run = Math.max(run, multiplier);
    console.log("run multiplier: ", run);

    // get the number of tests internal to the test function: 1 or more
    var internal_cnt = f();
    if (typeof internal_cnt === 'number' && (internal_cnt | 0) === internal_cnt) {
        factor *= internal_cnt;
    }

    var last_report = 500;
    var ts = [];
    for (var i = 0; i < n; i++) {
        perf.mark('bench');
        for (var j = 0; j < run; j++) {
            // 50 x f(): that seems a sort of 'sweet spot' for NodeJS v5, at least for some benchmarks...
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();

            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
            f();
        }
        ts.push(perf.mark('bench'));
        var consumed = perf.mark_sample_and_hold('monitor');
        //console.log('consumed', consumed, ts[ts.length - 1], i);
        if (last_report <= consumed) {
            console.log('#' + (ts.length * factor));
            last_report = consumed + 1000;
        }
        if (consumed < minimum_run_time || ts.length < 10) {
            // stay in the loop until 5 seconds have expired or at least 10 rounds have been executed!
            i = Math.min(i, n - 2);
        }
    }

    if (destroy_f) {
        destroy_f(f, n, minimum_run_time);
    }

    var consumed = perf.mark_sample_and_hold('monitor');
    
    var sum = 0;
    for (var i = 0, cnt = ts.length; i < cnt; i++) {
        sum += ts[i];
    }
    var avg = sum / cnt;

    var dev = 0;
    var peak = 0;
    for (var i = 0; i < cnt; i++) {
        var delta = Math.abs(ts[i] - avg);
        dev += delta;
        peak = Math.max(peak, delta);
    }
    dev /= cnt;
    var sample_size = run * factor;
    console.log(["Time: total: ", r(sum, 0) + 'ms',
        ", sample_count: ", cnt,
        ", # runs: ", cnt * sample_size,
        ", # runs/sec: ", r(cnt * sample_size * 1000 / sum, 1),
        ", average: ", r(avg / sample_size, 4) + 'ms',
        ", deviation: ", r(100 * dev / avg, 2) + '%',
        ", peak_deviation: ", r(100 * peak / avg, 2) + '%',
        ", total overhead: ", r(consumed - sum, 0) + 'ms'].join('')
    );
}

// End Of Include by Jison: includes/benchmark.js




// rephrase for display: error info objects which have been pushed onto the vstack:
function get_filtered_value_stack(vstack) {
    var rv = [];
    for (var i = 0, len = vstack.length; i < len; i++) {
        var o = vstack[i];
        if (o && o.errStr) {
            o = '#ERRORINFO#: ' + o.errStr;
        }
        rv.push(o);
    }
    return rv;
}

function get_reduced_error_info_obj(hash) {
    if (!hash || !hash.errStr) {
        return null;
    }
    return {
        text: hash.text,
        token: hash.token,
        token_id: hash.token_id,
        expected: hash.expected,
        matched: (hash.lexer && hash.lexer.matched) || '(-nada-)',
        lexerConditionStack: (hash.lexer && hash.lexer.conditionStack) || '(???)',
        remaining_input: (hash.lexer && hash.lexer._input) || '(-nada-)',
        recoverable: hash.recoverable,
        state_stack: hash.state_stack,
        value_stack: get_filtered_value_stack(hash.value_stack)
    };    
}

function compiledRunner(args) {
    var inp = 'xxx(x(x)x)xxx';
    console.log('input = ', inp);


    // set up a custom parseError handler.
    //
    // Note that this one has an extra feature: it tweaks the \`yytext\` value to propagate 
    // the error info into the parser error rules as \`$error\`: 
    parser.parseError = function altParseError(msg, hash) {
        if (hash && hash.exception) {
            msg = hash.exception.message;
            //console.log('ex:', hash.exception, hash.exception.stack);
        }
        console.log("### ERROR: " + msg, get_reduced_error_info_obj(hash));
        if (hash && hash.lexer) {
            hash.lexer.yytext = hash;
        };
    };

    parser.lexer.options.post_lex = function (tok) {
        parser.trace('lexer produces one token: ', tok, parser.describeSymbol(tok));
    };

    parser.options.debug = false;     

    function execute() {
        parser.parse(inp);
    }

    if (0) {
        execute();
    } else {
        // nuke the console output via trace() and output minimal progress while we run the benchmark:
        parser.trace = function nada_trace() {};
        // make sure to disable debug output at all, so we only get the conditional check as cost when \`%debug\` is enabled for this grammar
        parser.options.debug = false;     

        // track number of calls for minimal/FAST status update while benchmarking... 
        var logcount = 0;
        parser.post_parse = function (tok) {
            logcount++;
        };

        bench(execute, 0, 10e3, null, function () {
            console.log('run #', logcount);
        });
    }

    return 0;
}`,
  __in_rules_failure_analysis_mode__: false,
  is_custom_lexer: false,
}