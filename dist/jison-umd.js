(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory(require('fs'), require('path'), require('@gerhobbelt/json5'), require('mkdirp'), require('@gerhobbelt/xregexp'), require('recast'), require('@babel/core'), require('assert'), require('ast-util')) :
    typeof define === 'function' && define.amd ? define(['fs', 'path', '@gerhobbelt/json5', 'mkdirp', '@gerhobbelt/xregexp', 'recast', '@babel/core', 'assert', 'ast-util'], factory) :
    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, global.jison = factory(global.fs, global.path$1, global.JSON5, global.mkdirp, global.XRegExp, global.recast, global.babel, global.assert$1, global.astUtils));
}(this, (function (fs, path$1, JSON5, mkdirp, XRegExp, recast, babel, assert$1, astUtils) { 'use strict';

    function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

    var fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);
    var path__default = /*#__PURE__*/_interopDefaultLegacy(path$1);
    var JSON5__default = /*#__PURE__*/_interopDefaultLegacy(JSON5);
    var mkdirp__default = /*#__PURE__*/_interopDefaultLegacy(mkdirp);
    var XRegExp__default = /*#__PURE__*/_interopDefaultLegacy(XRegExp);
    var recast__default = /*#__PURE__*/_interopDefaultLegacy(recast);
    var assert__default = /*#__PURE__*/_interopDefaultLegacy(assert$1);
    var astUtils__default = /*#__PURE__*/_interopDefaultLegacy(astUtils);

    // Return TRUE if `src` starts with `searchString`.
    function startsWith(src, searchString) {
        return src.substr(0, searchString.length) === searchString;
    }



    // tagged template string helper which removes the indentation common to all
    // non-empty lines: that indentation was added as part of the source code
    // formatting of this lexer spec file and must be removed to produce what
    // we were aiming for.
    //
    // Each template string starts with an optional empty line, which should be
    // removed entirely, followed by a first line of error reporting content text,
    // which should not be indented at all, i.e. the indentation of the first
    // non-empty line should be treated as the 'common' indentation and thus
    // should also be removed from all subsequent lines in the same template string.
    //
    // See also: https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Template_literals
    function rmCommonWS(strings, ...values) {
        // As `strings[]` is an array of strings, each potentially consisting
        // of multiple lines, followed by one(1) value, we have to split each
        // individual string into lines to keep that bit of information intact.
        //
        // We assume clean code style, hence no random mix of tabs and spaces, so every
        // line MUST have the same indent style as all others, so `length` of indent
        // should suffice, but the way we coded this is stricter checking as we look
        // for the *exact* indenting=leading whitespace in each line.
        let indent_str = null;
        let src = strings.map(function splitIntoLines(s) {
            let a = s.split('\n');

            indent_str = a.reduce(function analyzeLine(indent_str, line, index) {
                // only check indentation of parts which follow a NEWLINE:
                if (index !== 0) {
                    let m = /^(\s*)\S/.exec(line);
                    // only non-empty ~ content-carrying lines matter re common indent calculus:
                    if (m) {
                        if (indent_str == null) {
                            indent_str = m[1];
                        } else if (m[1].length < indent_str.length) {
                            indent_str = m[1];
                        }
                    }
                }
                return indent_str;
            }, indent_str);

            return a;
        });

        // Also note: due to the way we format the template strings in our sourcecode,
        // the last line in the entire template must be empty when it has ANY trailing
        // whitespace:
        {
            let a = src[src.length - 1];
            a[a.length - 1] = a[a.length - 1].replace(/\s+$/, '');
        }

        // Done removing common indentation.
        //
        // Process template string partials now, but only when there's
        // some actual UNindenting to do:
        if (indent_str) {
            for (let i = 0, len = src.length; i < len; i++) {
                let a = src[i];
                // only correct indentation at start of line, i.e. only check for
                // the indent after every NEWLINE ==> start at j=1 rather than j=0
                for (let j = 1, linecnt = a.length; j < linecnt; j++) {
                    if (startsWith(a[j], indent_str)) {
                        a[j] = a[j].substr(indent_str.length);
                    }
                }
            }
        }

        // now merge everything to construct the template result:
        {
            let rv = [];
            let i = 0;
            for (let len = values.length; i < len; i++) {
                rv.push(src[i].join('\n'));
                rv.push(values[i]);
            }
            // the last value is always followed by a last template string partial:
            rv.push(src[i].join('\n'));

            let sv = rv.join('');
            return sv;
        }
    }

    // Convert dashed option keys to Camel Case, e.g. `camelCase('camels-have-one-hump')` => `'camelsHaveOneHump'`
    /** @public */
    function camelCase(s) {
        // Convert first character to lowercase
        return s.replace(/^\w/, function (match) {
            return match.toLowerCase();
        })
        .replace(/-\w/g, function (match) {
            const c = match.charAt(1);
            const rv = c.toUpperCase();
            // do not mutate 'a-2' to 'a2':
            if (c === rv && c.match(/\d/)) {
                return match;
            }
            return rv;
        });
    }

    // https://www.ecma-international.org/ecma-262/6.0/#sec-reserved-words
    const reservedWords = ((list) => {
        let rv = new Set();
        for (let w of list) {
            //console.error('reserved word:', w);
            rv.add(w);
        }
        return rv;
    })([
        'await',
        'break',
        'case',
        'catch',
        'class',
        'const',
        'continue',
        'debugger',
        'default',
        'delete',
        'do',
        'else',
        'enum',
        'export',
        'extends',
        'finally',
        'for',
        'function',
        'if',
        'implements',
        'import',
        'in',
        'instanceof',
        'interface',
        'new',
        'package',
        'private',
        'protected',
        'public',
        'return',
        'super',
        'switch',
        'this',
        'throw',
        'try',
        'typeof',
        'var',
        'void',
        'while',
        'with',
        'yield'
    ]);

    // Convert dashed option keys and other inputs to Camel Cased legal JavaScript identifiers
    /** @public */
    function mkIdentifier(s) {
        s = '' + s;

        let rv = s
        // Convert dashed ids to Camel Case (though NOT lowercasing the initial letter though!),
        // e.g. `camelCase('camels-have-one-hump')` => `'camelsHaveOneHump'`
        .replace(/-\w/g, function (match) {
            let c = match.charAt(1);
            let rv = c.toUpperCase();
            // mutate 'a-2' to 'a_2':
            if (c === rv && c.match(/\d/)) {
                return '_' + match.substr(1);
            }
            return rv;
        })
        // cleanup: replace any non-suitable character series to a single underscore:
        .replace(/^([\d])/, '_$1')      // where leading numbers are prefixed by an underscore: '1' --> '_1'
        .replace(/^[^\w_]/, '_')
        // do not accept numerics at the leading position, despite those matching regex `\w`:
        .replace(/^\d/, '_')
        .replace(/[^\w\d_]/g, '_')
        // and only accept multiple (double, not triple) underscores at start or end of identifier name:
        .replace(/^__+/, '#')
        .replace(/__+$/, '#')
        .replace(/_+/g, '_')
        .replace(/#/g, '__');

        if (reservedWords.has(rv)) {
            rv = '_' + rv;
        }
        return rv;
    }

    // Check if the start of the given input matches a regex expression.
    // Return the length of the regex expression or -1 if none was found.
    /** @public */
    function scanRegExp(s) {
        s = '' + s;
        // code based on Esprima scanner: `Scanner.prototype.scanRegExpBody()`
        let index = 0;
        let length = s.length;
        let ch = s[index];
        //assert.assert(ch === '/', 'Regular expression literal must start with a slash');
        let str = s[index++];
        let classMarker = false;
        let terminated = false;
        while (index < length) {
            ch = s[index++];
            str += ch;
            if (ch === '\\') {
                ch = s[index++];
                // https://tc39.github.io/ecma262/#sec-literals-regular-expression-literals
                if (isLineTerminator(ch.charCodeAt(0))) {
                    break;             // UnterminatedRegExp
                }
                str += ch;
            } else if (isLineTerminator(ch.charCodeAt(0))) {
                break;                 // UnterminatedRegExp
            } else if (classMarker) {
                if (ch === ']') {
                    classMarker = false;
                }
            } else if (ch === '/') {
                terminated = true;
                break;
            } else if (ch === '[') {
                classMarker = true;
            }
        }
        if (!terminated) {
            return -1;                  // UnterminatedRegExp
        }
        return index;
    }


    // https://tc39.github.io/ecma262/#sec-line-terminators
    function isLineTerminator(cp) {
        return (cp === 0x0A) || (cp === 0x0D) || (cp === 0x2028) || (cp === 0x2029);
    }

    // Check if the given input can be a legal identifier-to-be-camelcased:
    // use this function to check if the way the identifier is written will
    // produce a sensible & comparable identifier name using the `mkIdentifier'
    // API - for humans that transformation should be obvious/trivial in
    // order to prevent confusion.
    /** @public */
    function isLegalIdentifierInput(s) {
        s = '' + s;
        // Convert dashed ids to Camel Case (though NOT lowercasing the initial letter though!),
        // e.g. `camelCase('camels-have-one-hump')` => `'camelsHaveOneHump'`
        let ref = s
        .replace(/-\w/g, function (match) {
            let c = match.charAt(1);
            let rv = c.toUpperCase();
            // mutate 'a-2' to 'a_2':
            if (c === rv && c.match(/\d/)) {
                return '_' + match.substr(1);
            }
            return rv;
        });
        let alt = mkIdentifier(s);
        return alt === ref;
    }

    // properly quote and escape the given input string
    function dquote$1(s) {
        let sq = (s.indexOf('\'') >= 0);
        let dq = (s.indexOf('"') >= 0);
        if (sq && dq) {
            s = s.replace(/"/g, '\\"');
            dq = false;
        }
        if (dq) {
            s = '\'' + s + '\'';
        } else {
            s = '"' + s + '"';
        }
        return s;
    }

    //



    function chkBugger(src) {
        src = String(src);
        if (src.match(/\bcov_\w+/)) {
            console.error('### ISTANBUL COVERAGE CODE DETECTED ###\n', src);
        }
    }




    // Helper function: pad number with leading zeroes
    function pad(n, p) {
        p = p || 2;
        let rv = '0000' + n;
        return rv.slice(-p);
    }


    function convertExceptionToObject(ex) {
        if (!ex) return ex;

        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error
        // 
        // - Copy enumerable properties (which may exist when this is a custom exception class derived off Error)
        let rv = Object.assign({}, ex);
        // - Set up the default fields which should ALWAYS be present:
        rv.message = ex.message;
        rv.name = ex.name;
        rv.stack = ex.stack; // this assignment stringifies the stack trace in ex.stack.
        // - Set the optional fields:
        if (ex.code !== undefined) rv.code = ex.code;
        if (ex.type !== undefined) rv.type = ex.type;
        if (ex.fileName !== undefined) rv.fileName = ex.fileName;
        if (ex.lineNumber !== undefined) rv.lineNumber = ex.lineNumber;
        if (ex.columnNumber !== undefined) rv.columnNumber = ex.columnNumber;
        if (Array.isArray(ex.errors)) {
            rv.errors = [];
            for (let se of ex.errors) {
                rv.errors.push(convertExceptionToObject(se));
            }
        }
        return rv;
    }


    function find_suitable_app_dump_path() {
        return process.cwd()
        .replace(/\\/g, '/')
        .replace(/\/node_modules\/.*$/, (m) => '/___nm___/')
        .replace(/(\/jison\/)(.*)$/, (m, p1, p2) => p1 + '___' + p2.split('/').map((d) => d.charAt(0).toUpperCase()).join('_'));
    }

    // attempt to dump in one of several locations: first winner is *it*!
    function dumpSourceToFile(sourcecode, errname, err_id, options, ex) {
        let dumpfile;
        options = options || {};

        try {
            const dumpPaths = [ (options.outfile ? path__default['default'].dirname(options.outfile) : null), options.inputPath, find_suitable_app_dump_path() ];
            let dumpName = path__default['default'].basename(options.inputFilename || options.moduleName || (options.outfile ? path__default['default'].dirname(options.outfile) : null) || options.defaultModuleName || errname)
            .replace(/\.[a-z]{1,5}$/i, '')          // remove extension .y, .yacc, .jison, ...whatever
            .replace(/[^a-z0-9_]/ig, '_')           // make sure it's legal in the destination filesystem: the least common denominator.
            .substr(0, 100);
            if (dumpName === '' || dumpName === '_') {
                dumpName = '__bugger__';
            }

            // generate a stacktrace for the dump no matter what:
            if (!ex) {
                try {
                    throw new Error("Not an error: only fetching stacktrace in sourcecode dump helper so you can see which code invoked this.");
                } catch (ex2) {
                    ex = ex2;
                }
            }

            err_id = err_id || 'XXX';
            err_id = err_id
            .replace(/[^a-z0-9_]/ig, '_')           // make sure it's legal in the destination filesystem: the least common denominator.
            .substr(0, 50);

            const ts = new Date();
            const tm = ts.getUTCFullYear() +
                '_' + pad(ts.getUTCMonth() + 1) +
                '_' + pad(ts.getUTCDate()) +
                'T' + pad(ts.getUTCHours()) +
                '' + pad(ts.getUTCMinutes()) +
                '' + pad(ts.getUTCSeconds()) +
                '.' + pad(ts.getUTCMilliseconds(), 3) +
                'Z';

            dumpName += '.fatal_' + err_id + '_dump_' + tm + '.js';

            for (let i = 0, l = dumpPaths.length; i < l; i++) {
                if (!dumpPaths[i]) {
                    continue;
                }

                try {
                    dumpfile = path__default['default'].normalize(path__default['default'].join(dumpPaths[i], dumpName));

                    const dump = {
                        errname,
                        err_id,
                        options,
                        ex: convertExceptionToObject(ex)
                    };
                    let d = JSON5__default['default'].stringify(dump, {
                        replacer: function remove_lexer_objrefs(key, value) {
                            if (value instanceof Error) {
                                return convertExceptionToObject(value);
                            }
                            return value;
                        },
                        space: 2,
                        circularRefHandler: (value, circusPos, stack, keyStack, key, err) => '[!circular ref!]',
                    });
                    // make sure each line is a comment line:
                    d = d.split('\n').map((l) => '// ' + l);
                    d = d.join('\n');

                    mkdirp__default['default'](path__default['default'].dirname(dumpfile));
                    fs__default['default'].writeFileSync(dumpfile, sourcecode + '\n\n\n' + d, 'utf8');
                    console.error('****** offending generated ' + errname + ' source code dumped into file: ', dumpfile);
                    break;          // abort loop once a dump action was successful!
                } catch (ex3) {
                    //console.error("generated " + errname + " source code fatal DUMPING error ATTEMPT: ", i, " = ", ex3.message, " -- while attempting to dump into file: ", dumpfile, "\n", ex3.stack);
                    if (i === l - 1) {
                        throw ex3;
                    }
                }
            }
        } catch (ex2) {
            console.error('generated ' + errname + ' source code fatal DUMPING error: ', ex2.message, ' -- while attempting to dump into file: ', dumpfile, '\n', ex2.stack);
        }

        // augment the exception info, when available:
        if (ex) {
            ex.offending_source_code = sourcecode;
            ex.offending_source_title = errname;
            ex.offending_source_dumpfile = dumpfile;
        }
    }




    //
    // `code_execution_rig` is a function which gets executed, while it is fed the `sourcecode` as a parameter.
    // When the `code_execution_rig` crashes, its failure is caught and (using the `options`) the sourcecode
    // is dumped to file for later diagnosis.
    //
    // Two options drive the internal behaviour:
    //
    // - options.dumpSourceCodeOnFailure        -- default: FALSE
    // - options.throwErrorOnCompileFailure     -- default: FALSE
    //
    // Dumpfile naming and path are determined through these options:
    //
    // - options.outfile
    // - options.inputPath
    // - options.inputFilename
    // - options.moduleName
    // - options.defaultModuleName
    //
    function exec_and_diagnose_this_stuff(sourcecode, code_execution_rig, options, title) {
        options = options || {};
        let errname = '' + (title || 'exec_test');
        let err_id = errname.replace(/[^a-z0-9_]/ig, '_');
        if (err_id.length === 0) {
            err_id = 'exec_crash';
        }
        const debug = options.debug || 0;

        if (debug) console.warn('generated ' + errname + ' code under EXEC TEST.');
        if (debug > 1) {
            console.warn(`
        ######################## source code ##########################
        ${sourcecode}
        ######################## source code ##########################
        `);
        }

        let p;
        try {
            // p = eval(sourcecode);
            if (typeof code_execution_rig !== 'function') {
                throw new Error('safe-code-exec-and-diag: code_execution_rig MUST be a JavaScript function');
            }
            chkBugger(sourcecode);
            p = code_execution_rig.call(this, sourcecode, options, errname, debug);
        } catch (ex) {
            if (debug > 1) console.log('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@');

            if (debug) console.log('generated ' + errname + ' source code fatal error: ', ex.message);

            if (debug > 1) console.log('exec-and-diagnose options:', options);

            if (debug > 1) console.log('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@');

            if (options.dumpSourceCodeOnFailure || 1) {
                dumpSourceToFile(sourcecode, errname, err_id, options, ex);
            }

            if (options.throwErrorOnCompileFailure) {
                throw ex;
            }
        }
        return p;
    }






    var exec = {
        exec: exec_and_diagnose_this_stuff,
        dump: dumpSourceToFile,
        convertExceptionToObject,
    };

    //



    assert__default['default'](recast__default['default']);
    //var types = recast.types;
    //assert(types);
    //var namedTypes = types.namedTypes;
    //assert(namedTypes);
    //var b = types.builders;
    //assert(b);
    //assert(astUtils);



    // WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
    //
    // This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
    const ID_REGEX_BASE = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';
    // regex set expression which can be used as part of a conditional check to find word/ID/token boundaries
    // as this lists all characters which are not allowed in an Identifier anywhere:
    const IN_ID_CHARSET = '\\p{Alphabetic}_\\p{Number}';




    // Determine which Unicode NonAsciiIdentifierStart characters
    // are unused in the given sourcecode and provide a mapping array
    // from given (JISON) start/end identifier character-sequences
    // to these.
    //
    // The purpose of this routine is to deliver a reversible
    // transform from JISON to plain JavaScript for any action
    // code chunks.
    //
    // This is the basic building block which helps us convert
    // jison variables such as `$id`, `$3`, `$-1` ('negative index' reference),
    // `@id`, `#id`, `#TOK#` to variable names which can be
    // parsed by a regular JavaScript parser such as esprima or babylon.
    function generateMapper4JisonGrammarIdentifiers(input) {
        // IMPORTANT: we only want the single char Unicodes in here
        // so we can do this transformation at 'Char'-word rather than 'Code'-codepoint level.

        //const IdentifierStart = unicode4IdStart.filter((e) => e.codePointAt(0) < 0xFFFF);

        // As we will be 'encoding' the Jison Special characters @ and # into the IDStart Unicode
        // range to make JavaScript parsers *not* barf a hairball on Jison action code chunks, we
        // must consider a few things while doing that:
        //
        // We CAN use an escape system where we replace a single character with multiple characters,
        // as JavaScript DOES NOT discern between single characters and multi-character strings: anything
        // between quotes is a string and there's no such thing as C/C++/C#'s `'c'` vs `"c"` which is
        // *character* 'c' vs *string* 'c'.
        //
        // As we can safely escape characters, all we need to do is find a character (or set of characters)
        // which are in the ID_Start range and are expected to be used rarely while clearly identifyable
        // by humans for ease of debugging of the escaped intermediate values.
        //
        // The escape scheme is simple and borrowed from ancient serial communication protocols and
        // the JavaScript string spec alike:
        //
        // - assume the escape character is A
        // - then if the original input stream includes an A, we output AA
        // - if the original input includes a character #, which must be escaped, it is encoded/output as A
        //
        // This is the same as the way the backslash escape in JavaScript strings works and has a minor issue:
        // sequences of AAA with an odd number of A's CAN occur in the output, which might be a little hard to read.
        // Those are, however, easily machine-decodable and that's what's most important here.
        //
        // To help with that AAA... issue AND because we need to escape multiple Jison markers, we choose to
        // a slightly tweaked approach: we are going to use a set of 2-char wide escape codes, where the
        // first character is fixed and the second character is chosen such that the escape code
        // DOES NOT occur in the original input -- unless someone would have intentionally fed nasty input
        // to the encoder as we will pick the 2 characters in the escape from 2 utterly different *human languages*:
        //
        // - the first character is ဩ which is highly visible and allows us to quickly search through a
        //   source to see if and where there are *any* Jison escapes.
        // - the second character is taken from the Unicode CANADIAN SYLLABICS range (0x1400-0x1670) as far as
        //   those are part of ID_Start (0x1401-0x166C or there-abouts) and, unless an attack is attempted at jison,
        //   we can be pretty sure that this 2-character sequence won't ever occur in real life: even when one
        //   writes such a escape in the comments to document this system, e.g. 'ဩᐅ', then there's still plenty
        //   alternatives for the second character left.
        // - the second character represents the escape type: $-n, $#, #n, @n, #ID#, etc. and each type will
        //   pick a different base shape from that CANADIAN SYLLABICS charset.
        // - note that the trailing '#' in Jison's '#TOKEN#' escape will be escaped as a different code to
        //   signal '#' as a token terminator there.
        // - meanwhile, only the initial character in the escape needs to be escaped if encountered in the
        //   original text: ဩ -> ဩဩ as the 2nd and 3rd character are only there to *augment* the escape.
        //   Any CANADIAN SYLLABICS in the original input don't need escaping, as these only have special meaning
        //   when prefixed with ဩ
        // - if the ဩ character is used often in the text, the alternative ℹ இ ண ஐ Ϟ ല ઊ characters MAY be considered
        //   for the initial escape code, hence we start with analyzing the entire source input to see which
        //   escapes we'll come up with this time.
        //
        // The basic shapes are:
        //
        // - 1401-141B:  ᐁ             1
        // - 142F-1448:  ᐯ             2
        // - 144C-1465:  ᑌ             3
        // - 146B-1482:  ᑫ             4
        // - 1489-14A0:  ᒉ             5
        // - 14A3-14BA:  ᒣ             6
        // - 14C0-14CF:  ᓀ
        // - 14D3-14E9:  ᓓ             7
        // - 14ED-1504:  ᓭ             8
        // - 1510-1524:  ᔐ             9
        // - 1526-153D:  ᔦ
        // - 1542-154F:  ᕂ
        // - 1553-155C:  ᕓ
        // - 155E-1569:  ᕞ
        // - 15B8-15C3:  ᖸ
        // - 15DC-15ED:  ᗜ            10
        // - 15F5-1600:  ᗵ
        // - 1614-1621:  ᘔ
        // - 1622-162D:  ᘢ
        //
        // ## JISON identifier formats ##
        //
        // - direct symbol references, e.g. `#NUMBER#` when there's a `%token NUMBER` for your grammar.
        //   These represent the token ID number.
        //
        //   -> (1+2) start-# + end-#
        //
        // - alias/token value references, e.g. `$token`, `$2`
        //
        //   -> $ is an accepted starter, so no encoding required
        //
        // - alias/token location reference, e.g. `@token`, `@2`
        //
        //   -> (6) single-@
        //
        // - alias/token id numbers, e.g. `#token`, `#2`
        //
        //   -> (3) single-#
        //
        // - alias/token stack indexes, e.g. `##token`, `##2`
        //
        //   -> (4) double-#
        //
        // - result value reference `$$`
        //
        //   -> $ is an accepted starter, so no encoding required
        //
        // - result location reference `@$`
        //
        //   -> (6) single-@
        //
        // - rule id number `#$`
        //
        //   -> (3) single-#
        //
        // - result stack index `##$`
        //
        //   -> (4) double-#
        //
        // - 'negative index' value references, e.g. `$-2`
        //
        //   -> (8) single-negative-$
        //
        // - 'negative index' location reference, e.g. `@-2`
        //
        //   -> (7) single-negative-@
        //
        // - 'negative index' stack indexes, e.g. `##-2`
        //
        //   -> (5) double-negative-#
        //

        // count the number of occurrences of ch in src:
        //
        // function countOccurrences(ch, src) {
        //     let cnt = 0;
        //     let offset = 0;
        //     for (;;) {
        //         let pos = src.indexOf(ch, offset);
        //         if (pos === -1) {
        //             return cnt;
        //         }
        //         cnt++;
        //         offset = pos + 1;
        //     }
        // }
        function countOccurrences(ch, src) {
            let i = ch.codePointAt(0);
            return hash[i] || 0;
        }

        // pick an infrequent occurring character from the given `set`.
        // Preferrably has ZERO occurrences in the given `input`, but otherwise
        // deliver the one with the least number of occurrences.
        function pickChar(set, input) {
            // strip out the spaces:
            set = set.replace(/\s+/g, '');

            assert__default['default'](set.length >= 1);
            let lsidx = 0;
            let lsfreq = Infinity;
            for (let i = 0, l = set.length; i < l; i++) {
                let ch = set[i];
                let freq = countOccurrences(ch);
                if (freq === 0) {
                    return ch;
                }
                if (freq < lsfreq) {
                    lsfreq = freq;
                    lsidx = i;
                }
            }
            return set[lsidx];
        }

        const escCharSet = 'ဩ ℹ இ ண ஐ Ϟ ല ઊ';

        // Currently we only need 7 rows of typeIdCharSets. The other rows are commented out but available for future use:
        const typeIdCharSets = [
            'ᐁ  ᐂ  ᐃ  ᐄ  ᐅ  ᐆ  ᐇ  ᐈ  ᐉ  ᐊ  ᐋ  ᐌ  ᐍ  ᐎ  ᐏ  ᐐ  ᐑ  ᐒ  ᐓ  ᐔ  ᐕ  ᐖ  ᐗ  ᐘ  ᐙ  ᐚ  ᐛ  ᐫ  ᐬ  ᐭ  ᐮ',
            //"ᐯ  ᐰ  ᐱ  ᐲ  ᐳ  ᐴ  ᐵ  ᐶ  ᐷ  ᐸ  ᐹ  ᐺ  ᐻ  ᐼ  ᐽ  ᐾ  ᐿ  ᑀ  ᑁ  ᑂ  ᑃ  ᑄ  ᑅ  ᑆ  ᑇ  ᑈ",
            'ᑌ  ᑍ  ᑎ  ᑏ  ᑐ  ᑑ  ᑒ  ᑓ  ᑔ  ᑕ  ᑖ  ᑗ  ᑘ  ᑙ  ᑚ  ᑛ  ᑜ  ᑝ  ᑞ  ᑟ  ᑠ  ᑡ  ᑢ  ᑣ  ᑤ  ᑥ  ᑧ  ᑨ  ᑩ  ᑪ',
            'ᑫ  ᑬ  ᑭ  ᑮ  ᑯ  ᑰ  ᑱ  ᑲ  ᑳ  ᑴ  ᑵ  ᑶ  ᑷ  ᑸ  ᑹ  ᑺ  ᑻ  ᑼ  ᑽ  ᑾ  ᑿ  ᒀ  ᒁ  ᒂ  ᒅ  ᒆ  ᒇ  ᒈ',
            //"ᒉ  ᒊ  ᒋ  ᒌ  ᒍ  ᒎ  ᒏ  ᒐ  ᒑ  ᒒ  ᒓ  ᒔ  ᒕ  ᒖ  ᒗ  ᒘ  ᒙ  ᒚ  ᒛ  ᒜ  ᒝ  ᒞ  ᒟ  ᒠ",
            //"ᒣ  ᒤ  ᒥ  ᒦ  ᒧ  ᒨ  ᒩ  ᒪ  ᒫ  ᒬ  ᒭ  ᒮ  ᒯ  ᒰ  ᒱ  ᒲ  ᒳ  ᒴ  ᒵ  ᒶ  ᒷ  ᒸ  ᒹ  ᒺ",
            //"ᓓ  ᓔ  ᓕ  ᓖ  ᓗ  ᓘ  ᓙ  ᓚ  ᓛ  ᓜ  ᓝ  ᓞ  ᓟ  ᓠ  ᓡ  ᓢ  ᓣ  ᓤ  ᓥ  ᓦ  ᓧ  ᓨ  ᓩ",
            //"ᓭ  ᓮ  ᓯ  ᓰ  ᓱ  ᓲ  ᓳ  ᓴ  ᓵ  ᓶ  ᓷ  ᓸ  ᓹ  ᓺ  ᓻ  ᓼ  ᓽ  ᓾ  ᓿ  ᔀ  ᔁ  ᔂ  ᔃ  ᔄ",
            //"ᔐ  ᔑ  ᔒ  ᔓ  ᔔ  ᔕ  ᔖ  ᔗ  ᔘ  ᔙ  ᔚ  ᔛ  ᔜ  ᔝ  ᔞ  ᔟ  ᔠ  ᔡ  ᔢ  ᔣ  ᔤ",
            'ᔦ  ᔧ  ᔨ  ᔩ  ᔪ  ᔫ  ᔬ  ᔭ  ᔮ  ᔯ  ᔰ  ᔱ  ᔲ  ᔳ  ᔴ  ᔵ  ᔶ  ᔷ  ᔸ  ᔹ  ᔺ  ᔻ  ᔼ  ᔽ',
            //"ᓀ  ᓁ  ᓂ  ᓃ  ᓄ  ᓅ  ᓆ  ᓇ  ᓈ  ᓉ  ᓊ  ᓋ  ᓌ  ᓍ  ᓎ  ᓏ",
            //"ᕂ  ᕃ  ᕄ  ᕅ  ᕆ  ᕇ  ᕈ  ᕉ  ᕊ  ᕋ  ᕌ  ᕍ  ᕎ  ᕏ",
            //"ᕞ  ᕟ  ᕠ  ᕡ  ᕢ  ᕣ  ᕤ  ᕥ  ᕦ  ᕧ  ᕨ  ᕩ",
            //"ᖸ  ᖹ  ᖺ  ᖻ  ᖼ  ᖽ  ᖾ  ᖿ  ᗀ  ᗁ  ᗂ  ᗃ",
            'ᗜ  ᗝ  ᗞ  ᗟ  ᗠ  ᗡ  ᗢ  ᗣ  ᗤ  ᗥ  ᗦ  ᗧ  ᗨ  ᗩ  ᗪ  ᗫ  ᗬ  ᗭ',
            //"ᗯ  ᗰ  ᗱ  ᗲ  ᗳ  ᗴ  ᗵ  ᗶ  ᗷ  ᗸ  ᗹ  ᗺ  ᗻ  ᗼ  ᗽ  ᗾ  ᗿ  ᘀ",
            'ᘔ  ᘕ  ᘖ  ᘗ  ᘘ  ᘙ  ᘚ  ᘛ  ᘜ  ᘝ  ᘞ  ᘟ  ᘠ  ᘡ',
            //"ᘢ  ᘣ  ᘤ  ᘥ  ᘦ  ᘧ  ᘨ  ᘩ  ᘪ  ᘫ  ᘬ  ᘭ  ᘴ  ᘵ  ᘶ  ᘷ  ᘸ  ᘹ",
            //"ᕓ  ᕔ  ᕕ  ᕖ  ᕗ  ᕘ  ᕙ  ᕚ  ᕛ  ᕜ",
            'ᗄ  ᗅ  ᗆ  ᗇ  ᗈ  ᗉ  ᗊ  ᗋ  ᗌ  ᗍ  ᗎ  ᗏ  ᗐ  ᗑ  ᗒ  ᗓ  ᗔ  ᗕ  ᗖ  ᗗ  ᗘ  ᗙ  ᗚ  ᗛ'
        ];

        //const I = 'ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩⅪⅫ';   // 1..12, but accepted as IdentifierStart in JavaScript :-)

        // Probable speed improvement: scan a single time through the (probably large) input source,
        // looking for all characters in parallel, instead of scanning N times through there:
        // construct a regex to dig out all potential occurrences and take it from there.
        let reStr = escCharSet + typeIdCharSets.join('');
        reStr = reStr.replace(/\s+/g, '');
        const re = new RegExp(`[${reStr}]`, 'g');
        var hash = new Array(0xD800);
        let m;
        while ((m = re.exec(input)) !== null) {
            let i = m[0].codePointAt();
            hash[i] = (hash[i] || 0) + 1;
        }

        //
        // The basic shapes are:
        //
        // - 1401-141B:  ᐁ             1
        // - 142F-1448:  ᐯ             2
        // - 144C-1465:  ᑌ             3
        // - 146B-1482:  ᑫ             4
        // - 1489-14A0:  ᒉ             5
        // - 14A3-14BA:  ᒣ             6
        // - 14C0-14CF:  ᓀ
        // - 14D3-14E9:  ᓓ             7
        // - 14ED-1504:  ᓭ             8
        // - 1510-1524:  ᔐ             9
        // - 1526-153D:  ᔦ
        // - 1542-154F:  ᕂ
        // - 1553-155C:  ᕓ
        // - 155E-1569:  ᕞ
        // - 15B8-15C3:  ᖸ
        // - 15DC-15ED:  ᗜ            10
        // - 15F5-1600:  ᗵ
        // - 1614-1621:  ᘔ
        // - 1622-162D:  ᘢ
        //
        // ## JISON identifier formats ##
        //
        // - direct symbol references, e.g. `#NUMBER#` when there's a `%token NUMBER` for your grammar.
        //   These represent the token ID number.
        //
        //   -> (1+2) start-# + end-#
        //
        // - alias/token value references, e.g. `$token`, `$2`
        //
        //   -> $ is an accepted starter, so no encoding required
        //
        // - alias/token location reference, e.g. `@token`, `@2`
        //
        //   -> (6) single-@
        //
        // - alias/token id numbers, e.g. `#token`, `#2`
        //
        //   -> (3) single-#
        //
        // - alias/token stack indexes, e.g. `##token`, `##2`
        //
        //   -> (4) double-#
        //
        // - result value reference `$$`
        //
        //   -> $ is an accepted starter, so no encoding required
        //
        // - result location reference `@$`
        //
        //   -> (6) single-@
        //
        // - rule id number `#$`
        //
        //   -> (3) single-#
        //
        // - result stack index `##$`
        //
        //   -> (4) double-#
        //
        // - 'negative index' value references, e.g. `$-2`
        //
        //   -> (8) single-negative-$
        //
        // - 'negative index' location reference, e.g. `@-2`
        //
        //   -> (7) single-negative-@
        //
        // - 'negative index' stack indexes, e.g. `##-2`
        //
        //   -> (5) double-negative-#
        //

        const escChar = pickChar(escCharSet);
        let typeIdChar = [];
        for (let i = 0, l = typeIdCharSets.length; i < l; i++) {
            typeIdChar[i] = pickChar(typeIdCharSets[i]);
        }

        // produce a function set for encoding and decoding content,
        // plus the basic strings to build regexes for matching the various jison
        // identifier types:
        return {
            // - direct symbol references, e.g. `#NUMBER#` when there's a `%token NUMBER` for your grammar.
            //   These represent the token ID number.
            //
            //   -> (1) start-#
            tokenDirectIdentifierStart: escChar + typeIdChar[0],
            tokenDirectIdentifierRe: new XRegExp__default['default'](`#(${ID_REGEX_BASE})#`, 'g'),

            // - alias/token value references, e.g. `$token`, `$2`
            //
            //   -> $ is an accepted starter, so no encoding required
            // - result value reference `$$`
            //
            //   -> $ is an accepted starter, so no encoding required
            tokenValueReferenceStart: '$',
            tokenValueReferenceRe: new XRegExp__default['default'](`$(${ID_REGEX_BASE})|$([0-9]+)`, 'g'),

            // - alias/token location reference, e.g. `@token`, `@2`
            //
            //   -> (6) single-@
            // - result location reference `@$`
            //
            //   -> (6) single-@
            tokenLocationStart: escChar + typeIdChar[1],
            tokenLocationRe: new XRegExp__default['default'](`@(${ID_REGEX_BASE})|@([0-9]+)`, 'g'),

            // - alias/token id numbers, e.g. `#token`, `#2`
            //
            //   -> (3) single-#
            // - rule id number `#$`
            //
            //   -> (3) single-#
            tokenIdentifierStart: escChar + typeIdChar[2],
            tokenIdentifierRe: new XRegExp__default['default'](`#(${ID_REGEX_BASE})|#([0-9]+)`, 'g'),

            // - alias/token stack indexes, e.g. `##token`, `##2`
            //
            //   -> (4) double-#
            // - result stack index `##$`
            //
            //   -> (4) double-#
            tokenStackIndexStart: escChar + typeIdChar[3],
            tokenStackIndexRe: new XRegExp__default['default'](`##(${ID_REGEX_BASE})|##([0-9]+)`, 'g'),

            // - 'negative index' value references, e.g. `$-2`
            //
            //   -> (8) single-negative-$
            tokenNegativeValueReferenceStart: escChar + typeIdChar[4],
            tokenValueReferenceRe: new XRegExp__default['default']('$-([0-9]+)', 'g'),

            // - 'negative index' location reference, e.g. `@-2`
            //
            //   -> (7) single-negative-@
            tokenNegativeLocationStart: escChar + typeIdChar[5],
            tokenNegativeLocationRe: new XRegExp__default['default']('@-([0-9]+)', 'g'),

            // - 'negative index' stack indexes, e.g. `##-2`
            //
            //   -> (5) double-negative-#
            tokenNegativeStackIndexStart: escChar + typeIdChar[6],
            tokenNegativeStackIndexRe: new XRegExp__default['default']('#-([0-9]+)', 'g'),

            // combined regex for encoding direction
            tokenDetect4EncodeRe: new XRegExp__default['default'](`([^$@#${IN_ID_CHARSET}])([$@#]|##)(${ID_REGEX_BASE}|[$]|-?[0-9]+)(#?)(?![$@#${IN_ID_CHARSET}])`, 'g'),

            // combined regex for decoding direction
            tokenDetect4DecodeRe: new XRegExp__default['default'](`([^$${IN_ID_CHARSET}])(${escChar}[${typeIdChar.slice(0, 7).join('')}])(${ID_REGEX_BASE}|[$]|[0-9]+)(?![$@#${IN_ID_CHARSET}])`, 'g'),

            encode: function encodeJisonTokens(src, locationOffsetSpec) {
                let re = this.tokenDetect4EncodeRe;

                // reset regex
                re.lastIndex = 0;

                // patch `src` for the lookbehind emulation in the main regex used:
                src = ' ' + src;

                // Perform the encoding, one token at a time via callback function.
                //
                // Note: all erroneous inputs are IGNORED as those MAY be part of a string
                // or comment, where they are perfectly legal.
                // This is a tad sub-optimal as we won't be able to report errors early
                // but otherwise we would be rejecting some potentially *legal* action code
                // and we DO NOT want to be pedantically strict while we are unable to parse
                // the input very precisely yet.
                src = src.replace(re, (m, p1, p2, p3, p4, offset) => {
                    // p1 is only serving as lookbehind emulation

                    switch (p2) {
                    case '$':
                        // no encoding required UNLESS it's a negative index; p4 MUST be empty
                        if (p4 !== '') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3} cannot be followed by ${p4}`, src, offset + p1.length + p2.length + p3.length);
                            }
                            return p1 + p2 + p3 + p4;
                        }
                        if (p3[0] === '-') {
                            return p1 + this.tokenNegativeValueReferenceStart + p3.substring(1);
                        }
                        return p1 + p2 + p3;

                    case '##':
                        // p4 MUST be empty
                        if (p4 !== '') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3} cannot be followed by ${p4}`, src, offset + p1.length + p2.length + p3.length);
                            }
                            return p1 + p2 + p3 + p4;
                        }
                        if (p3[0] === '-') {
                            return p1 + this.tokenNegativeStackIndexStart + p3.substring(1);
                        }
                        return p1 + this.tokenStackIndexStart + p3;

                    case '@':
                        // p4 MUST be empty
                        if (p4 !== '') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3} cannot be followed by ${p4}`, src, offset + p1.length + p2.length + p3.length);
                            }
                            return p1 + p2 + p3 + p4;
                        }
                        if (p3[0] === '-') {
                            return p1 + this.tokenNegativeLocationStart + p3.substring(1);
                        }
                        return p1 + this.tokenLocationStart + p3;

                    case '#':
                        // p4 MAY be non-empty; p3 CANNOT be a negative value or token ID
                        if (p3[0] === '-') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3 + p4} is an illegal negative reference type`, src, offset + p1.length + p2.length);
                            }
                            return p1 + p2 + p3 + p4;
                        }
                        if (p4 !== '') {
                            return p1 + this.tokenDirectIdentifierStart + p3;
                        }
                        return p1 + this.tokenIdentifierStart + p3;

                    // no default case needed as all possible matches are handled in the cases above.
                    }
                });

                // and remove the added prefix which was used for lookbehind emulation:
                return src.substring(1);
            },

            decode: function decodeJisonTokens(src, locationOffsetSpec) {
                let re = this.tokenDetect4DecodeRe;

                // reset regex
                re.lastIndex = 0;

                // patch `src` for the lookbehind emulation in the main regex used:
                src = ' ' + src;

                // Perform the encoding, one token at a time via callback function.
                //
                // Note: all erroneous inputs are IGNORED as those MAY be part of a string
                // or comment, where they are perfectly legal.
                // This is a tad sub-optimal as we won't be able to report errors early
                // but otherwise we would be rejecting some potentially *legal* action code
                // and we DO NOT want to be pedantically strict while we are unable to parse
                // the input very precisely yet.
                src = src.replace(re, (m, p1, p2, p3, offset) => {
                    // p1 is only serving as lookbehind emulation

                    switch (p2) {
                    case this.tokenNegativeValueReferenceStart:
                        return p1 + '$-' + p3;

                    case this.tokenNegativeStackIndexStart:
                        return p1 + '##-' + p3;

                    case this.tokenStackIndexStart:
                        return p1 + '##' + p3;

                    case this.tokenNegativeLocationStart:
                        return p1 + '@-' + p3;

                    case this.tokenLocationStart:
                        return p1 + '@' + p3;

                    case this.tokenDirectIdentifierStart:
                        // p3 CANNOT be a negative value or token ID
                        if (p3[0] === '-') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3 + p4} is an illegal negative reference type`, src, offset + p1.length + p2.length);
                            }
                            return p1 + p2 + p3;
                        }
                        return p1 + '#' + p3 + '#';

                    case this.tokenIdentifierStart:
                        // p3 CANNOT be a negative value or token ID
                        if (p3[0] === '-') {
                            if (locationOffsetSpec) {
                                locationOffsetSpec.reportLocation(`syntax error: ${p2 + p3 + p4} is an illegal negative reference type`, src, offset + p1.length + p2.length);
                            }
                            return p1 + p2 + p3;
                        }
                        return p1 + '#' + p3;

                    default:
                        if (locationOffsetSpec) {
                            locationOffsetSpec.reportLocation(`syntax error: unexpected jison token sentinel escape ${p2} at ${p2 + p3}`, src, offset + p1.length);
                        }
                        return p1 + p2 + p3;
                    }
                });

                // and remove the added prefix which was used for lookbehind emulation:
                return src.substring(1);
            }
        };
    }









    function parseCodeChunkToAST(src, options) {
        src = src
        .replace(/@/g, '\uFFDA')
        .replace(/#/g, '\uFFDB')
        ;
        const ast = recast__default['default'].parse(src);
        return ast;
    }


    function compileCodeToES5(src, options) {
        options = Object.assign({}, {
            ast: true,
            code: true,
            sourceMaps: true,
            comments: true,
            filename: 'compileCodeToES5.js',
            sourceFileName: 'compileCodeToES5.js',
            sourceRoot: '.',
            sourceType: 'module',

            babelrc: false,

            ignore: [
                'node_modules/**/*.js'
            ],
            compact: false,
            retainLines: false,
            presets: [
                [ '@babel/preset-env', {
                    targets: {
                        browsers: [ 'last 2 versions' ],
                        node: '8.0'
                    }
                } ]
            ]
        }, options);

        return babel.transformSync(src, options); // => { code, map, ast }
    }


    function prettyPrintAST(ast, options) {
        options = options || {};
        const defaultOptions = {
            tabWidth: 2,
            quote: 'single',
            arrowParensAlways: true,

            // Do not reuse whitespace (or anything else, for that matter)
            // when printing generically.
            reuseWhitespace: false
        };
        for (let key in defaultOptions) {
            if (options[key] === undefined) {
                options[key] = defaultOptions[key];
            }
        }

        let s = recast__default['default'].prettyPrint(ast, defaultOptions);
        let new_src = s.code;

        new_src = new_src
        .replace(/\r\n|\n|\r/g, '\n')    // platform dependent EOL fixup
        // backpatch possible jison variables extant in the prettified code:
        .replace(/\uFFDA/g, '@')
        .replace(/\uFFDB/g, '#')
        ;

        return new_src;
    }




    // validate the given JISON+JavaScript snippet: does it compile?
    //
    // Return either the parsed AST (object) or an error message (string).
    function checkActionBlock(src, yylloc, options) {
        // make sure reasonable line numbers, etc. are reported in any
        // potential parse errors by pushing the source code down:
        if (yylloc && yylloc.first_line > 0) {
            let cnt = yylloc.first_line;
            let lines = new Array(cnt);
            src = lines.join('\n') + src;
        }
        if (!src.trim()) {
            return false;
        }

        try {
            let rv = parseCodeChunkToAST(src, options);
            return false;
        } catch (ex) {
            return ex.message || 'code snippet cannot be parsed';
        }
    }



    // The rough-and-ready preprocessor for any action code block:
    // this one trims off any surplus whitespace and removes any
    // trailing semicolons and/or wrapping `{...}` braces,
    // when such is easily possible *without having to actually
    // **parse** the `src` code block in order to do this safely*.
    //
    // Returns the trimmed sourcecode which was provided via `src`.
    //
    // Note: the `startMarker` argument is special in that a lexer/parser
    // can feed us the delimiter which started the code block here:
    // when the starting delimiter actually is `{` we can safely
    // remove the outer `{...}` wrapper (which then *will* be present!),
    // while otherwise we may *not* do so as complex/specially-crafted
    // code will fail when it was wrapped in other delimiters, e.g.
    // action code specs like this one:
    //
    //              %{
    //                  {  // trimActionCode sees this one as outer-starting: WRONG
    //                      a: 1
    //                  };
    //                  {
    //                      b: 2
    //                  }  // trimActionCode sees this one as outer-ending: WRONG
    //              %}
    //
    // Of course the example would be 'ludicrous' action code but the
    // key point here is that users will certainly be able to come up with
    // convoluted code that is smarter than our simple regex-based
    // `{...}` trimmer in here!
    //
    function trimActionCode(src, startMarker) {
        let s = src.trim();
        // remove outermost set of braces UNLESS there's
        // a curly brace in there anywhere: in that case
        // we should leave it up to the sophisticated
        // code analyzer to simplify the code!
        //
        // This is a very rough check as it will also look
        // inside code comments, which should not have
        // any influence.
        //
        // Nevertheless: this is a *safe* transform as
        // long as the code doesn't end with a C++-style
        // comment which happens to contain that closing
        // curly brace at the end!
        //
        // Also DO strip off any trailing optional semicolon,
        // which might have ended up here due to lexer rules
        // like this one:
        //
        //     [a-z]+              -> 'TOKEN';
        //
        // We can safely ditch any trailing semicolon(s) as
        // our code generator reckons with JavaScript's
        // ASI rules (Automatic Semicolon Insertion).
        //
        //
        // TODO: make this is real code edit without that
        // last edge case as a fault condition.
        if (startMarker === '{') {
            // code is wrapped in `{...}` for sure: remove the wrapping braces.
            s = s.replace(/^\{([^]*?)\}$/, '$1').trim();
        } else {
            // code may not be wrapped or otherwise non-simple: only remove
            // wrapping braces when we can guarantee they're the only ones there,
            // i.e. only exist as outer wrapping.
            s = s.replace(/^\{([^}]*)\}$/, '$1').trim();
        }
        s = s.replace(/;+$/, '').trim();
        return s;
    }





    var parse2AST = {
        generateMapper4JisonGrammarIdentifiers,
        parseCodeChunkToAST,
        compileCodeToES5,
        prettyPrintAST,
        checkActionBlock,
        trimActionCode,

        ID_REGEX_BASE,
        IN_ID_CHARSET
    };

    function chkBugger$1(src) {
        src = String(src);
        if (src.match(/\bcov_\w+/)) {
            console.error('### ISTANBUL COVERAGE CODE DETECTED ###\n', src);
        }
    }


    /// HELPER FUNCTION: print the function in source code form, properly indented.
    /** @public */
    function printFunctionSourceCode(f) {
        const src = String(f);
        chkBugger$1(src);
        return src;
    }



    const funcRe = /^function[\s\r\n]*[^\(]*\(([^\)]*)\)[\s\r\n]*\{([^]*?)\}$/;
    const arrowFuncRe = /^(?:(?:\(([^\)]*)\))|(?:([^\(\)]+)))[\s\r\n]*=>[\s\r\n]*(?:(?:\{([^]*?)\})|(?:(([^\s\r\n\{)])[^]*?)))$/;

    /// HELPER FUNCTION: print the function **content** in source code form, properly indented,
    /// ergo: produce the code for inlining the function.
    ///
    /// Also supports ES6's Arrow Functions:
    ///
    /// ```
    /// function a(x) { return x; }        ==> 'return x;'
    /// function (x)  { return x; }        ==> 'return x;'
    /// (x) => { return x; }               ==> 'return x;'
    /// (x) => x;                          ==> 'return x;'
    /// (x) => do(1), do(2), x;            ==> 'return (do(1), do(2), x);'
    ///
    /** @public */
    function printFunctionSourceCodeContainer(f) {
        let action = printFunctionSourceCode(f).trim();
        let args;

        // Also cope with Arrow Functions (and inline those as well?).
        // See also https://github.com/zaach/jison-lex/issues/23
        let m = funcRe.exec(action);
        if (m) {
            args = m[1].trim();
            action = m[2].trim();
        } else {
            m = arrowFuncRe.exec(action);
            if (m) {
                if (m[2]) {
                    // non-bracketed arguments:
                    args = m[2].trim();
                } else {
                    // bracketed arguments: may be empty args list!
                    args = m[1].trim();
                }
                if (m[5]) {
                    // non-bracketed version: implicit `return` statement!
                    //
                    // Q: Must we make sure we have extra braces around the return value
                    // to prevent JavaScript from inserting implit EOS (End Of Statement)
                    // markers when parsing this, when there are newlines in the code?
                    // A: No, we don't have to as arrow functions rvalues suffer from this
                    // same problem, hence the arrow function's programmer must already
                    // have formatted the code correctly.
                    action = m[4].trim();
                    action = 'return ' + action + ';';
                } else {
                    action = m[3].trim();
                }
            } else {
                const e = new Error('Cannot extract code from function');
                e.subject = action;
                throw e;
            }
        }
        return {
            args: args,
            code: action
        };
    }







    var stringifier = {
        printFunctionSourceCode,
        printFunctionSourceCodeContainer
    };

    //
    //
    //
    function detectIstanbulGlobal() {
        const gcv = '__coverage__';
        const globalvar = new Function('return this')();
        const coverage = globalvar[gcv];
        return coverage || false;
    }

    //
    // Helper library for safe code execution/compilation
    //
    // MIT Licensed
    //
    //
    // This code is intended to help test and diagnose arbitrary regexes, answering questions like this:
    //
    // - is this a valid regex, i.e. does it compile?
    // - does it have captures, and if yes, how many?
    //

    //import XRegExp from '@gerhobbelt/xregexp';


    // validate the given regex.
    //
    // You can specify an (advanced or regular) regex class as a third parameter.
    // The default assumed is the standard JavaScript `RegExp` class.
    //
    // Return FALSE when there's no failure, otherwise return an `Error` info object.
    function checkRegExp(re_src, re_flags, XRegExp) {
        let re;

        // were we fed a RegExp object or a string?
        if (re_src
            && typeof re_src.source === 'string'
            && typeof re_src.flags === 'string'
            && typeof re_src.toString === 'function'
            && typeof re_src.test === 'function'
            && typeof re_src.exec === 'function'
        ) {
            // we're looking at a RegExp (or XRegExp) object, so we can trust the `.source` member
            // and the `.toString()` method to produce something that's compileable by XRegExp
            // at least...
            if (!re_flags || re_flags === re_src.flags) {
                // no change of flags: we assume it's okay as it's already contained
                // in an RegExp or XRegExp object
                return false;
            }
        }
        // we DO accept empty regexes: `''` but we DO NOT accept null/undefined
        if (re_src == null) {
            return new Error('invalid regular expression source: ' + re_src);
        }

        re_src = '' + re_src;
        if (re_flags == null) {
            re_flags = undefined;       // `new RegExp(..., flags)` will barf a hairball when `flags===null`
        } else {
            re_flags = '' + re_flags;
        }

        XRegExp = XRegExp || RegExp;

        try {
            re = new XRegExp(re_src, re_flags);
        } catch (ex) {
            return ex;
        }
        return false;
    }

    // provide some info about the given regex.
    //
    // You can specify an (advanced or regular) regex class as a third parameter.
    // The default assumed is the standard JavaScript `RegExp` class.
    //
    // Return FALSE when the input is not a legal regex.
    function getRegExpInfo(re_src, re_flags, XRegExp) {
        let re1, re2, m1, m2;

        // were we fed a RegExp object or a string?
        if (re_src
            && typeof re_src.source === 'string'
            && typeof re_src.flags === 'string'
            && typeof re_src.toString === 'function'
            && typeof re_src.test === 'function'
            && typeof re_src.exec === 'function'
        ) {
            // we're looking at a RegExp (or XRegExp) object, so we can trust the `.source` member
            // and the `.toString()` method to produce something that's compileable by XRegExp
            // at least...
            if (!re_flags || re_flags === re_src.flags) {
                // no change of flags: we assume it's okay as it's already contained
                // in an RegExp or XRegExp object
                re_flags = undefined;
            }
        } else if (re_src == null) {
            // we DO NOT accept null/undefined
            return false;
        } else {
            re_src = '' + re_src;

            if (re_flags == null) {
                re_flags = undefined;       // `new RegExp(..., flags)` will barf a hairball when `flags===null`
            } else {
                re_flags = '' + re_flags;
            }
        }

        XRegExp = XRegExp || RegExp;

        try {
            // A little trick to obtain the captures from a regex:
            // wrap it and append `(?:)` to ensure it matches
            // the empty string, then match it against it to
            // obtain the `match` array.
            re1 = new XRegExp(re_src, re_flags);
            re2 = new XRegExp('(?:' + re_src + ')|(?:)', re_flags);
            m1 = re1.exec('');
            m2 = re2.exec('');
            return {
                acceptsEmptyString: !!m1,
                captureCount: m2.length - 1
            };
        } catch (ex) {
            return false;
        }
    }








    var reHelpers = {
        checkRegExp: checkRegExp,
        getRegExpInfo: getRegExpInfo
    };

    let cycleref = [];
    let cyclerefpath = [];

    let linkref = [];
    let linkrefpath = [];

    let path = [];

    function shallow_copy(src) {
        if (typeof src === 'object') {
            if (src instanceof Array) {
                return src.slice();
            }

            let dst = {};
            if (src instanceof Error) {
                dst.name = src.name;
                dst.message = src.message;
                dst.stack = src.stack;
            }

            for (let k in src) {
                if (Object.prototype.hasOwnProperty.call(src, k)) {
                    dst[k] = src[k];
                }
            }
            return dst;
        }
        return src;
    }


    function shallow_copy_and_strip_depth(src, parentKey) {
        if (typeof src === 'object') {
            let dst;

            if (src instanceof Array) {
                dst = src.slice();
                for (let i = 0, len = dst.length; i < len; i++) {
                    path.push('[' + i + ']');
                    dst[i] = shallow_copy_and_strip_depth(dst[i], parentKey + '[' + i + ']');
                    path.pop();
                }
            } else {
                dst = {};
                if (src instanceof Error) {
                    dst.name = src.name;
                    dst.message = src.message;
                    dst.stack = src.stack;
                }

                for (let k in src) {
                    if (Object.prototype.hasOwnProperty.call(src, k)) {
                        let el = src[k];
                        if (el && typeof el === 'object') {
                            dst[k] = '[cyclic reference::attribute --> ' + parentKey + '.' + k + ']';
                        } else {
                            dst[k] = src[k];
                        }
                    }
                }
            }
            return dst;
        }
        return src;
    }


    // strip developer machine specific parts off any paths in a given stacktrace (string)
    // to ease cross-platform comparison of these stacktraces.
    function stripErrorStackPaths(msg) {
        // strip away devbox-specific paths in error stack traces in the output:
        // and any `nyc` profiler run added trailing cruft has to go too, e.g. ', <anonymous>:1489:27)':
        msg = msg
        .replace(/\bat ([^\r\n(\\\/]+?)\([^)]*?[\\\/]([a-z0-9_-]+\.js):([0-9]+:[0-9]+)\)(?:, <anonymous>:[0-9]+:[0-9]+\))?/gi, 'at $1(/$2:$3)')
        .replace(/\bat [^\r\n ]*?[\\\/]([a-z0-9_-]+\.js):([0-9]+:[0-9]+)/gi, 'at /$1:$2');

        return msg;
    }


    // strip off the line/position info from any stacktrace as a assert.deepEqual() on these
    // will otherwise FAIL due to us running this stuff through both regular `node` and 
    // the `nyc` profiler: the latter reformats the sourcecode-under-test, thus producing 
    // exceptions and stacktraces which point completely somewhere else and this would b0rk
    // our test rigs for the jison subpackages.
    function cleanStackTrace4Comparison(obj) {
        if (typeof obj === 'string') {
            // and any `nyc` profiler run added trailing cruft has to go too, e.g. ', <anonymous>:1489:27)':
            let msg = obj
            .replace(/\bat ([^\r\n(\\\/]+?)\([^)]*?[\\\/]([a-z0-9_-]+\.js):([0-9]+:[0-9]+)\)(?:, <anonymous>:[0-9]+:[0-9]+\))?/gi, 'at $1(/$2)')
            .replace(/\bat [^\r\n ]*?[\\\/]([a-z0-9_-]+\.js):([0-9]+:[0-9]+)/gi, 'at /$1');

            return msg;
        }

        if (obj) {
            if (obj.stack) {
                obj.stack = cleanStackTrace4Comparison(obj.stack);
            }
            let keys = Object.keys(obj);
            for (let i in keys) {
                let key = keys[i];
                let el = obj[key];
                cleanStackTrace4Comparison(el);
            }
        }
        return obj;
    }






    function trim_array_tail(arr) {
        if (arr instanceof Array) {
            for (var len = arr.length; len > 0; len--) {
                if (arr[len - 1] != null) {
                    break;
                }
            }
            arr.length = len;
        }
    }

    function treat_value_stack(v) {
        if (v instanceof Array) {
            let idx = cycleref.indexOf(v);
            if (idx >= 0) {
                v = '[cyclic reference to parent array --> ' + cyclerefpath[idx] + ']';
            } else {
                idx = linkref.indexOf(v);
                if (idx >= 0) {
                    v = '[reference to sibling array --> ' + linkrefpath[idx] + ', length = ' + v.length + ']';
                } else {
                    cycleref.push(v);
                    cyclerefpath.push(path.join('.'));
                    linkref.push(v);
                    linkrefpath.push(path.join('.'));

                    v = treat_error_infos_array(v);

                    cycleref.pop();
                    cyclerefpath.pop();
                }
            }
        } else if (v) {
            v = treat_object(v);
        }
        return v;
    }

    function treat_error_infos_array(arr) {
        let inf = arr.slice();
        trim_array_tail(inf);
        for (let key = 0, len = inf.length; key < len; key++) {
            let err = inf[key];
            if (err) {
                path.push('[' + key + ']');

                err = treat_object(err);

                if (typeof err === 'object') {
                    if (err.lexer) {
                        err.lexer = '[lexer]';
                    }
                    if (err.parser) {
                        err.parser = '[parser]';
                    }
                    trim_array_tail(err.symbol_stack);
                    trim_array_tail(err.state_stack);
                    trim_array_tail(err.location_stack);
                    if (err.value_stack) {
                        path.push('value_stack');
                        err.value_stack = treat_value_stack(err.value_stack);
                        path.pop();
                    }
                }

                inf[key] = err;

                path.pop();
            }
        }
        return inf;
    }

    function treat_lexer(l) {
        // shallow copy object:
        l = shallow_copy(l);
        delete l.simpleCaseActionClusters;
        delete l.rules;
        delete l.conditions;
        delete l.__currentRuleSet__;

        if (l.__error_infos) {
            path.push('__error_infos');
            l.__error_infos = treat_value_stack(l.__error_infos);
            path.pop();
        }

        return l;
    }

    function treat_parser(p) {
        // shallow copy object:
        p = shallow_copy(p);
        delete p.productions_;
        delete p.table;
        delete p.defaultActions;

        if (p.__error_infos) {
            path.push('__error_infos');
            p.__error_infos = treat_value_stack(p.__error_infos);
            path.pop();
        }

        if (p.__error_recovery_infos) {
            path.push('__error_recovery_infos');
            p.__error_recovery_infos = treat_value_stack(p.__error_recovery_infos);
            path.pop();
        }

        if (p.lexer) {
            path.push('lexer');
            p.lexer = treat_lexer(p.lexer);
            path.pop();
        }

        return p;
    }

    function treat_hash(h) {
        // shallow copy object:
        h = shallow_copy(h);

        if (h.parser) {
            path.push('parser');
            h.parser = treat_parser(h.parser);
            path.pop();
        }

        if (h.lexer) {
            path.push('lexer');
            h.lexer = treat_lexer(h.lexer);
            path.push();
        }

        return h;
    }

    function treat_error_report_info(e) {
        // shallow copy object:
        e = shallow_copy(e);

        if (e && e.hash) {
            path.push('hash');
            e.hash = treat_hash(e.hash);
            path.pop();
        }

        if (e.parser) {
            path.push('parser');
            e.parser = treat_parser(e.parser);
            path.pop();
        }

        if (e.lexer) {
            path.push('lexer');
            e.lexer = treat_lexer(e.lexer);
            path.pop();
        }

        if (e.__error_infos) {
            path.push('__error_infos');
            e.__error_infos = treat_value_stack(e.__error_infos);
            path.pop();
        }

        if (e.__error_recovery_infos) {
            path.push('__error_recovery_infos');
            e.__error_recovery_infos = treat_value_stack(e.__error_recovery_infos);
            path.pop();
        }

        trim_array_tail(e.symbol_stack);
        trim_array_tail(e.state_stack);
        trim_array_tail(e.location_stack);
        if (e.value_stack) {
            path.push('value_stack');
            e.value_stack = treat_value_stack(e.value_stack);
            path.pop();
        }

        return e;
    }

    function treat_object(e) {
        if (e && typeof e === 'object') {
            let idx = cycleref.indexOf(e);
            if (idx >= 0) {
                // cyclic reference, most probably an error instance.
                // we still want it to be READABLE in a way, though:
                e = shallow_copy_and_strip_depth(e, cyclerefpath[idx]);
            } else {
                idx = linkref.indexOf(e);
                if (idx >= 0) {
                    e = '[reference to sibling --> ' + linkrefpath[idx] + ']';
                } else {
                    cycleref.push(e);
                    cyclerefpath.push(path.join('.'));
                    linkref.push(e);
                    linkrefpath.push(path.join('.'));

                    e = treat_error_report_info(e);

                    cycleref.pop();
                    cyclerefpath.pop();
                }
            }
        }
        return e;
    }


    // strip off large chunks from the Error exception object before
    // it will be fed to a test log or other output.
    //
    // Internal use in the unit test rigs.
    function trimErrorForTestReporting(e) {
        cycleref.length = 0;
        cyclerefpath.length = 0;
        linkref.length = 0;
        linkrefpath.length = 0;
        path = [ '*' ];

        if (e) {
            e = treat_object(e);
        }

        cycleref.length = 0;
        cyclerefpath.length = 0;
        linkref.length = 0;
        linkrefpath.length = 0;
        path = [ '*' ];

        return e;
    }

    var helpers = {
        rmCommonWS,
        camelCase,
        mkIdentifier,
        isLegalIdentifierInput,
        scanRegExp,
        dquote: dquote$1,
        trimErrorForTestReporting,
        stripErrorStackPaths,
        cleanStackTrace4Comparison,

        checkRegExp: reHelpers.checkRegExp,
        getRegExpInfo: reHelpers.getRegExpInfo,

        exec: exec.exec,
        dump: exec.dump,
        convertExceptionToObject: exec.convertExceptionToObject,

        generateMapper4JisonGrammarIdentifiers: parse2AST.generateMapper4JisonGrammarIdentifiers,
        parseCodeChunkToAST: parse2AST.parseCodeChunkToAST,
        compileCodeToES5: parse2AST.compileCodeToES5,
        prettyPrintAST: parse2AST.prettyPrintAST,
        checkActionBlock: parse2AST.checkActionBlock,
        trimActionCode: parse2AST.trimActionCode,

        ID_REGEX_BASE: parse2AST.ID_REGEX_BASE,
        IN_ID_CHARSET: parse2AST.IN_ID_CHARSET,

        printFunctionSourceCode: stringifier.printFunctionSourceCode,
        printFunctionSourceCodeContainer: stringifier.printFunctionSourceCodeContainer,

        detectIstanbulGlobal
    };

    /*
     * Introduces a typal object to make classical/prototypal patterns easier
     * Plus some AOP sugar
     *
     * By Zachary Carter <zach@carter.name>
     * MIT Licensed
     */
    let mkIdentifier$1 = helpers.mkIdentifier;


    let create = Object.create || function (o) {
        function F() {}
        F.prototype = o;
        return new F();
    };
    let position = /^(before|after)/;

    // basic method layering
    // always returns original method's return value
    function layerMethod(pos, key, prop, fun) {
        if (pos === 'after') {
            return function () {
                let ret = prop.apply(this, arguments);
                let args = [].slice.call(arguments);
                args.splice(0, 0, ret);
                fun.apply(this, args);
                return ret;
            };
        } else if (pos === 'before') {
            return function () {
                fun.apply(this, arguments);
                let ret = prop.apply(this, arguments);
                return ret;
            };
        }
        return fun;
    }

    // mixes each argument's own properties into calling object,
    // overwriting them or layering them. i.e. an object method 'meth' is
    // layered by mixin methods 'beforemeth' or 'aftermeth'
    function typal_mix() {
        let i, o, k;
        for (i = 0; i < arguments.length; i++) {
            o = arguments[i];
            if (!o) continue;
            if (Object.prototype.hasOwnProperty.call(o, 'constructor')) {
                this.constructor = o.constructor;
            }
            if (Object.prototype.hasOwnProperty.call(o, 'toString')) {
                this.toString = o.toString;
            }
            for (k in o) {
                if (Object.prototype.hasOwnProperty.call(o, k)) {
                    let match = k.match(position);
                    let key = k.replace(position, '');
                    if (match && typeof this[key] === 'function') {
                        this[key] = layerMethod(match[0], key, this[key], o[k]);
                    } else {
                        this[k] = o[k];
                    }
                }
            }
        }
        return this;
    }

    // Same as typal_mix but also camelCases every object member and 'standardizes' the key set of every input
    // argument through a caLLback function.
    //
    // This is useful for processing options with dashes in their key, e.g. `token-stack` --> tokenStack.
    function typal_camel_mix(cb) {
        let i, o, k;

        // Convert first character to lowercase
        function lcase0(s) {
            return s.replace(/^\w/, function (match) {
                return match.toLowerCase();
            });
        }

        for (i = 1; i < arguments.length; i++) {
            o = arguments[i];
            if (!o) continue;
            if (Object.prototype.hasOwnProperty.call(o, 'constructor')) {
                this.constructor = o.constructor;
            }
            if (Object.prototype.hasOwnProperty.call(o, 'toString')) {
                this.toString = o.toString;
            }
            if (cb) {
                o = cb(o);
            }
            for (k in o) {
                if (Object.prototype.hasOwnProperty.call(o, k)) {
                    let nk = mkIdentifier$1(k);
                    let match = k.match(position);
                    let key = k.replace(position, '');
                    // This anticipates before/after members to be camelcased already, e.g.
                    // 'afterParse()' for layering 'parse()':
                    let alt_key = lcase0(key);
                    if (match && typeof this[key] === 'function') {
                        this[key] = layerMethod(match[0], key, this[key], o[k]);
                    } else if (match && typeof this[alt_key] === 'function') {
                        this[alt_key] = layerMethod(match[0], alt_key, this[alt_key], o[k]);
                    } else {
                        this[nk] = o[k];
                    }
                }
            }
        }
        return this;
    }

    let typal = {
        // extend object with own properties of each argument
        mix: typal_mix,

        camelMix: typal_camel_mix,

        // sugar for object begetting and mixing
        // - Object.create(typal).mix(etc, etc);
        // + typal.beget(etc, etc);
        beget: function typal_beget() {
            return arguments.length ? typal_mix.apply(create(this), arguments) : create(this);
        },

        // Creates a new Class function based on an object with a constructor method
        construct: function typal_construct() {
            let o = typal_mix.apply(create(this), arguments);
            let constructor = o.constructor;
            let Klass = o.constructor = function () { return constructor.apply(this, arguments); };
            Klass.prototype = o;
            Klass.mix = typal_mix; // allow for easy singleton property extension
            return Klass;
        },

        // no op
        constructor: function typal_constructor() { return this; }
    };

    // Set class to wrap arrays

    let setMixin = {
        constructor: function Set_constructor(set, raw) {
            this._items = [];
            if (set && set.constructor === Array) {
                this._items = raw ? set : set.slice(0);
            } else if (arguments.length) {
                this._items = [].slice.call(arguments, 0);
            }
        },
        concat: function concat(setB) {
            this._items.push.apply(this._items, setB._items || setB);
            return this;
        },
        eq: function eq(set) {
            return this._items.length === set._items.length && this.subset(set) && this.superset(set);
        },
        indexOf: function indexOf(item) {
            if (item && item.eq) {
                for (let k = 0; k < this._items.length; k++) {
                    if (item.eq(this._items[k])) {
                        return k;
                    }
                }
                return -1;
            }
            return this._items.indexOf(item);
        },
        intersection: function intersection(set) {
            return this.filter(function intersection_filter(elm) {
                return set.contains(elm);
            });
        },
        complement: function complement(set) {
            let that = this;
            return set.filter(function sub_complement(elm) {
                return !that.contains(elm);
            });
        },
        subset: function subset(set) {
            let cont = true;
            for (let i = 0; i < this._items.length && cont; i++) {
                cont = cont && set.contains(this._items[i]);
            }
            return cont;
        },
        superset: function superset(set) {
            return set.subset(this);
        },
        joinSet: function joinSet(set) {
            return this.concat(this.complement(set));
        },
        contains: function contains(item) {
            return this.indexOf(item) !== -1;
        },
        item: function item(v) {
            return this._items[v];
        },
        i: function i(v) {
            return this._items[v];
        },
        assign: function assign(index, value) {
            this._items[index] = value;
            return this;
        },
        first: function first() {
            return this._items[0];
        },
        last: function last() {
            return this._items[this._items.length - 1];
        },
        size: function size() {
            return this._items.length;
        },
        isEmpty: function isEmpty() {
            return this._items.length === 0;
        },
        copy: function copy() {
            return new Set$1(this._items);
        },
        toString: function toString() {
            return this._items.toString();
        }
    };

    'push shift unshift forEach some every join sort'.split(' ').forEach(function (e, i) {
        setMixin[e] = function () {
            return Array.prototype[e].apply(this._items, arguments);
        };
        //setMixin[e].name = e;
    });
    'filter slice map'.split(' ').forEach(function (e, i) {
        setMixin[e] = function () {
            return new Set$1(Array.prototype[e].apply(this._items, arguments), true);
        };
        //setMixin[e].name = e;
    });

    var Set$1 = typal.construct(setMixin);

    // See also:
    // http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
    // but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
    // with userland code which might access the derived class in a 'classic' way.
    function JisonParserError(msg, hash) {
        Object.defineProperty(this, 'name', {
            enumerable: false,
            writable: false,
            value: 'JisonParserError'
        });

        if (msg == null) msg = '???';

        Object.defineProperty(this, 'message', {
            enumerable: false,
            writable: true,
            value: msg
        });

        this.hash = hash;

        let stacktrace;
        if (hash && hash.exception instanceof Error) {
            let ex2 = hash.exception;
            this.message = ex2.message || msg;
            stacktrace = ex2.stack;
        }
        if (!stacktrace) {
            if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
                Error.captureStackTrace(this, this.constructor);
            } else {
                stacktrace = (new Error(msg)).stack;
            }
        }
        if (stacktrace) {
            Object.defineProperty(this, 'stack', {
                enumerable: false,
                writable: false,
                value: stacktrace
            });
        }
    }

    if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonParserError.prototype, Error.prototype);
    } else {
        JisonParserError.prototype = Object.create(Error.prototype);
    }
    JisonParserError.prototype.constructor = JisonParserError;
    JisonParserError.prototype.name = 'JisonParserError';




            // helper: reconstruct the productions[] table
            function bp(s) {
                let rv = [];
                let p = s.pop;
                let r = s.rule;
                for (let i = 0, l = p.length; i < l; i++) {
                    rv.push([
                        p[i],
                        r[i]
                    ]);
                }
                return rv;
            }
        


            // helper: reconstruct the defaultActions[] table
            function bda(s) {
                let rv = {};
                let d = s.idx;
                let g = s.goto;
                for (let i = 0, l = d.length; i < l; i++) {
                    let j = d[i];
                    rv[j] = g[i];
                }
                return rv;
            }
        


            // helper: reconstruct the 'goto' table
            function bt(s) {
                let rv = [];
                let d = s.len;
                let y = s.symbol;
                let t = s.type;
                let a = s.state;
                let m = s.mode;
                let g = s.goto;
                for (let i = 0, l = d.length; i < l; i++) {
                    let n = d[i];
                    let q = {};
                    for (let j = 0; j < n; j++) {
                        let z = y.shift();
                        switch (t.shift()) {
                        case 2:
                            q[z] = [
                                m.shift(),
                                g.shift()
                            ];
                            break;

                        case 0:
                            q[z] = a.shift();
                            break;

                        default:
                            // type === 1: accept
                            q[z] = [
                                3
                            ];
                        }
                    }
                    rv.push(q);
                }
                return rv;
            }
        


            // helper: runlength encoding with increment step: code, length: step (default step = 0)
            // `this` references an array
            function s(c, l, a) {
                a = a || 0;
                for (let i = 0; i < l; i++) {
                    this.push(c);
                    c += a;
                }
            }

            // helper: duplicate sequence from *relative* offset and length.
            // `this` references an array
            function c(i, l) {
                i = this.length - i;
                for (l += i; i < l; i++) {
                    this.push(this[i]);
                }
            }

            // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
            function u(a) {
                let rv = [];
                for (let i = 0, l = a.length; i < l; i++) {
                    let e = a[i];
                    // Is this entry a helper function?
                    if (typeof e === 'function') {
                        i++;
                        e.apply(rv, a[i]);
                    } else {
                        rv.push(e);
                    }
                }
                return rv;
            }
        

    let parser = {
        // Code Generator Information Report
        // ---------------------------------
        //
        // Options:
        //
        //   default action mode: ............. ["classic","merge"]
        //   test-compile action mode: ........ "parser:*,lexer:*"
        //   try..catch: ...................... true
        //   default resolve on conflict: ..... true
        //   on-demand look-ahead: ............ false
        //   error recovery token skip maximum: 3
        //   yyerror in parse actions is: ..... NOT recoverable,
        //   yyerror in lexer actions and other non-fatal lexer are:
        //   .................................. NOT recoverable,
        //   debug grammar/output: ............ false
        //   has partial LR conflict upgrade:   true
        //   rudimentary token-stack support:   false
        //   parser table compression mode: ... 2
        //   export debug tables: ............. false
        //   export *all* tables: ............. false
        //   module type: ..................... es
        //   parser engine type: .............. lalr
        //   output main() in the module: ..... true
        //   has user-specified main(): ....... false
        //   has user-specified require()/import modules for main():
        //   .................................. false
        //   number of expected conflicts: .... 0
        //
        //
        // Parser Analysis flags:
        //
        //   no significant actions (parser is a language matcher only):
        //   .................................. false
        //   uses yyleng: ..................... false
        //   uses yylineno: ................... false
        //   uses yytext: ..................... false
        //   uses yylloc: ..................... false
        //   uses ParseError API: ............. false
        //   uses YYERROR: .................... true
        //   uses YYRECOVERING: ............... false
        //   uses YYERROK: .................... false
        //   uses YYCLEARIN: .................. false
        //   tracks rule values: .............. true
        //   assigns rule values: ............. true
        //   uses location tracking: .......... true
        //   assigns location: ................ true
        //   uses yystack: .................... false
        //   uses yysstack: ................... false
        //   uses yysp: ....................... true
        //   uses yyrulelength: ............... false
        //   uses yyMergeLocationInfo API: .... true
        //   has error recovery: .............. true
        //   has error reporting: ............. true
        //
        // --------- END OF REPORT -----------

    trace: function no_op_trace() { },
    JisonParserError: JisonParserError,
    yy: {},
    options: {
      type: "lalr",
      hasPartialLrUpgradeOnConflict: true,
      errorRecoveryTokenDiscardCount: 3,
      ebnf: true
    },
    symbols_: {
      "$": 16,
      "$accept": 0,
      "$end": 1,
      "%%": 33,
      "(": 8,
      ")": 9,
      "*": 11,
      "+": 10,
      ",": 17,
      ".": 14,
      "/": 13,
      "/!": 41,
      "<": 3,
      "=": 18,
      ">": 6,
      "?": 12,
      "ACTION_BODY": 35,
      "ACTION_END": 23,
      "ACTION_START": 25,
      "ACTION_START_AT_SOL": 22,
      "ARROW_ACTION_START": 34,
      "BRACKET_MISSING": 37,
      "BRACKET_SURPLUS": 38,
      "CHARACTER_LIT": 50,
      "CODE": 29,
      "DUMMY3": 51,
      "EOF": 1,
      "ESCAPED_CHAR": 43,
      "IMPORT": 28,
      "INCLUDE": 30,
      "INCLUDE_PLACEMENT_ERROR": 36,
      "MACRO_END": 20,
      "MACRO_NAME": 19,
      "NAME_BRACE": 44,
      "OPTIONS": 27,
      "OPTIONS_END": 21,
      "OPTION_STRING": 52,
      "OPTION_VALUE": 53,
      "RANGE_REGEX": 48,
      "REGEX_SET": 47,
      "REGEX_SET_END": 46,
      "REGEX_SET_START": 45,
      "REGEX_SPECIAL_CHAR": 42,
      "SPECIAL_GROUP": 40,
      "START_EXC": 32,
      "START_INC": 31,
      "STRING_LIT": 49,
      "TRAILING_CODE_CHUNK": 54,
      "UNKNOWN_DECL": 26,
      "UNTERMINATED_ACTION_BLOCK": 24,
      "UNTERMINATED_STRING_ERROR": 39,
      "^": 15,
      "action": 73,
      "any_group_regex": 81,
      "definition": 59,
      "definitions": 58,
      "epilogue": 90,
      "epilogue_chunk": 92,
      "epilogue_chunks": 91,
      "error": 2,
      "import_keyword": 61,
      "include_keyword": 63,
      "include_macro_code": 93,
      "init": 57,
      "init_code_keyword": 62,
      "lex": 55,
      "literal_string": 85,
      "name_expansion": 80,
      "nonempty_regex_list": 77,
      "option": 87,
      "option_keyword": 60,
      "option_list": 86,
      "option_name": 88,
      "option_value": 89,
      "range_regex": 84,
      "regex": 75,
      "regex_base": 79,
      "regex_concat": 78,
      "regex_list": 76,
      "regex_set": 82,
      "regex_set_atom": 83,
      "rule": 72,
      "rule_block": 71,
      "rules": 69,
      "rules_and_epilogue": 56,
      "scoped_rules_collective": 70,
      "start_conditions": 74,
      "start_conditions_marker": 66,
      "start_epilogue_marker": 68,
      "start_exclusive_keyword": 65,
      "start_inclusive_keyword": 64,
      "start_productions_marker": 67,
      "{": 4,
      "|": 7,
      "}": 5
    },
    terminals_: {
      1: "EOF",
      2: "error",
      3: "<",
      4: "{",
      5: "}",
      6: ">",
      7: "|",
      8: "(",
      9: ")",
      10: "+",
      11: "*",
      12: "?",
      13: "/",
      14: ".",
      15: "^",
      16: "$",
      17: ",",
      18: "=",
      19: "MACRO_NAME",
      20: "MACRO_END",
      21: "OPTIONS_END",
      22: "ACTION_START_AT_SOL",
      23: "ACTION_END",
      24: "UNTERMINATED_ACTION_BLOCK",
      25: "ACTION_START",
      26: "UNKNOWN_DECL",
      27: "OPTIONS",
      28: "IMPORT",
      29: "CODE",
      30: "INCLUDE",
      31: "START_INC",
      32: "START_EXC",
      33: "%%",
      34: "ARROW_ACTION_START",
      35: "ACTION_BODY",
      36: "INCLUDE_PLACEMENT_ERROR",
      37: "BRACKET_MISSING",
      38: "BRACKET_SURPLUS",
      39: "UNTERMINATED_STRING_ERROR",
      40: "SPECIAL_GROUP",
      41: "/!",
      42: "REGEX_SPECIAL_CHAR",
      43: "ESCAPED_CHAR",
      44: "NAME_BRACE",
      45: "REGEX_SET_START",
      46: "REGEX_SET_END",
      47: "REGEX_SET",
      48: "RANGE_REGEX",
      49: "STRING_LIT",
      50: "CHARACTER_LIT",
      51: "DUMMY3",
      52: "OPTION_STRING",
      53: "OPTION_VALUE",
      54: "TRAILING_CODE_CHUNK"
    },
    terminal_descriptions_: {
      44: "macro name in '{...}' curly braces"
    },
    TERROR: 2,
        EOF: 1,

        // internals: defined here so the object *structure* doesn't get modified by parse() et al,
        // thus helping JIT compilers like Chrome V8.
        originalQuoteName: null,
        originalParseError: null,
        cleanupAfterParse: null,
        constructParseErrorInfo: null,
        yyMergeLocationInfo: null,
        copy_yytext: null,
        copy_yylloc: null,

        __reentrant_call_depth: 0,      // INTERNAL USE ONLY
        __error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
        __error_recovery_infos: [],     // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

        // APIs which will be set up depending on user action code analysis:
        //yyRecovering: 0,
        //yyErrOk: 0,
        //yyClearIn: 0,

        // Helper APIs
        // -----------

        // Helper function which can be overridden by user code later on: put suitable quotes around
        // literal IDs in a description string.
        quoteName: function parser_quoteName(id_str) {
            return '"' + id_str + '"';
        },

        // Return the name of the given symbol (terminal or non-terminal) as a string, when available.
        //
        // Return NULL when the symbol is unknown to the parser.
        getSymbolName: function parser_getSymbolName(symbol) {
            if (this.terminals_[symbol]) {
                return this.terminals_[symbol];
            }

            // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
            //
            // An example of this may be where a rule's action code contains a call like this:
            //
            //      parser.getSymbolName(#$)
            //
            // to obtain a human-readable name of the current grammar rule.
            const s = this.symbols_;
            for (let key in s) {
                if (s[key] === symbol) {
                    return key;
                }
            }
            return null;
        },

        // Return a more-or-less human-readable description of the given symbol, when available,
        // or the symbol itself, serving as its own 'description' for lack of something better to serve up.
        //
        // Return NULL when the symbol is unknown to the parser.
        describeSymbol: function parser_describeSymbol(symbol) {
            if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
                return this.terminal_descriptions_[symbol];
            } else if (symbol === this.EOF) {
                return 'end of input';
            }

            let id = this.getSymbolName(symbol);
            if (id) {
                return this.quoteName(id);
            }
            return null;
        },

        // Produce a (more or less) human-readable list of expected tokens at the point of failure.
        //
        // The produced list may contain token or token set descriptions instead of the tokens
        // themselves to help turning this output into something that easier to read by humans
        // unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
        // expected terminals and nonterminals is produced.
        //
        // The returned list (array) will not contain any duplicate entries.
        collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
            const TERROR = this.TERROR;
            let tokenset = [];
            let check = {};

            // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
            // If so, use that one instead of the less palatable token set.
            if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
                return [
                    this.state_descriptions_[state]
                ];
            }
            for (let p in this.table[state]) {
                p = +p;
                if (p !== TERROR) {
                    let d = do_not_describe ? p : this.describeSymbol(p);
                    if (d && !check[d]) {
                        tokenset.push(d);
                        check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
                    }
                }
            }
            return tokenset;
        },
    productions_: bp({
      pop: u([
      55,
      s,
      [56, 5],
      57,
      58,
      58,
      s,
      [59, 20],
      s,
      [60, 10, 1],
      s,
      [69, 12],
      s,
      [70, 5],
      71,
      71,
      s,
      [72, 7],
      s,
      [73, 7],
      74,
      74,
      75,
      76,
      76,
      s,
      [77, 5],
      78,
      78,
      s,
      [79, 18],
      80,
      81,
      81,
      82,
      82,
      83,
      83,
      84,
      85,
      85,
      s,
      [86, 3],
      s,
      [87, 4],
      88,
      88,
      89,
      89,
      s,
      [90, 3],
      s,
      [91, 3],
      s,
      [92, 4],
      93,
      93
    ]),
      rule: u([
      4,
      3,
      3,
      2,
      2,
      0,
      0,
      2,
      0,
      3,
      2,
      3,
      2,
      c,
      [4, 3],
      1,
      2,
      c,
      [6, 3],
      1,
      3,
      3,
      6,
      5,
      5,
      3,
      s,
      [1, 10],
      2,
      2,
      4,
      2,
      c,
      [41, 4],
      s,
      [2, 4],
      0,
      2,
      4,
      c,
      [53, 4],
      0,
      s,
      [4, 3],
      s,
      [3, 3],
      s,
      [2, 7],
      0,
      4,
      c,
      [46, 3],
      c,
      [68, 3],
      2,
      c,
      [44, 3],
      c,
      [62, 3],
      c,
      [24, 7],
      c,
      [12, 3],
      s,
      [1, 7],
      c,
      [17, 3],
      c,
      [9, 7],
      c,
      [8, 3],
      c,
      [13, 8],
      c,
      [35, 5],
      c,
      [17, 5],
      2
    ])
    }),
    performAction: function parser__PerformAction(yyloc, yystate /* action[1] */, yysp, yyvstack, yylstack) {

              /* this == yyval */

              // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
              let yy = this.yy;
              let yyparser = yy.parser;
              let yylexer = yy.lexer;

              const OPTION_DOES_NOT_ACCEPT_VALUE = 0x0001;
        const OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES = 0x0002;
        const OPTION_ALSO_ACCEPTS_STAR_AS_IDENTIFIER_NAME = 0x0004;
        const OPTION_DOES_NOT_ACCEPT_MULTIPLE_OPTIONS = 0x0008;
        const OPTION_DOES_NOT_ACCEPT_COMMA_SEPARATED_OPTIONS = 0x0010;

              switch (yystate) {
    case 0:
        /*! Production::    $accept : lex $end */

        // default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yylstack[yysp - 1];
        // END of default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,LT,LA,-,-)
        break;

    case 1:
        /*! Production::    lex : init definitions rules_and_epilogue EOF */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        this.$ = yyvstack[yysp - 1];
        for (let key in yyvstack[yysp - 2]) {
          this.$[key] = yyvstack[yysp - 2][key];
        }
        
        // if there are any options, add them all, otherwise set options to NULL:
        // can't check for 'empty object' by `if (yy.options) ...` so we do it this way:
        for (let key in yy.options) {
          this.$.options = yy.options;
          break;
        }
        
        if (yy.actionInclude) {
          let asrc = yy.actionInclude.join('\n\n');
          // Only a non-empty action code chunk should actually make it through:
          if (asrc.trim() !== '') {
            this.$.actionInclude = asrc;
          }
        }
        
        delete yy.options;
        delete yy.actionInclude;
        return this.$;
        }

    case 2:
        /*! Production::    rules_and_epilogue : start_productions_marker rules epilogue */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        if (yyvstack[yysp]) {
            this.$ = { rules: yyvstack[yysp - 1], moduleInclude: yyvstack[yysp] };
        } else {
            this.$ = { rules: yyvstack[yysp - 1] };
        }
        break;

    case 3:
        /*! Production::    rules_and_epilogue : start_productions_marker error epilogue */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        There's probably an error in one or more of your lexer regex rules.
        The lexer rule spec should have this structure:
    
                regex  action_code
    
        where 'regex' is a lex-style regex expression (see the
        jison and jison-lex documentation) which is intended to match a chunk
        of the input to lex, while the 'action_code' block is the JS code
        which will be invoked when the regex is matched. The 'action_code' block
        may be any (indented!) set of JS statements, optionally surrounded
        by '{...}' curly braces or otherwise enclosed in a '%{...%}' block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 4:
        /*! Production::    rules_and_epilogue : start_productions_marker rules */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = { rules: yyvstack[yysp] };
        break;

    case 5:
        /*! Production::    rules_and_epilogue : start_productions_marker error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        There's probably an error in one or more of your lexer regex rules.
        There's an error in your lexer regex rules section.
        Maybe you did not correctly separate the lexer sections with
        a '%%' on an otherwise empty line? Did you correctly
        delimit every rule's action code block?
        The lexer spec file should have this structure:
    
            definitions
            %%
            rules
            %%                  // <-- only needed if ...
            extra_module_code   // <-- ... epilogue is present.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 6:
        /*! Production::    rules_and_epilogue : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = { rules: [] };
        break;

    case 7:
        /*! Production::    init : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = undefined;
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.actionInclude = [];
        if (!yy.options) yy.options = {};
        yy.__options_flags__ = 0;
        yy.__options_category_description__ = '???';
        
        // Store the `%s` and `%x` condition states in `yy` to ensure the rules section of the
        // lex language parser can reach these and use them for validating whether the lexer
        // rules written by the user actually reference *known* condition states.
        yy.startConditions = {};            // hash table
        
        // The next attribute + API set is a 'lexer/parser hack' in the sense that
        // it assumes zero look-ahead at some points during the parse
        // when a parser rule production's action code pushes or pops a value
        // on/off the context description stack to help the lexer produce
        // better informing error messages in case of a subsequent lexer
        // fail.
        yy.__context_description__ = ['???CONTEXT???'];
        
        yy.pushContextDescription = function (str) {
            yy.__context_description__.push(str);
        };
        yy.popContextDescription = function () {
            if (yy.__context_description__.length > 1) {
                yy.__context_description__.pop();
            } else {
                yyparser.yyError('__context_description__ stack depleted! Contact a developer!');
            }
        };
        yy.getContextDescription = function () {
            return yy.__context_description__[yy.__context_description__.length - 1];
        };
        break;

    case 8:
        /*! Production::    definitions : definitions definition */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        this.$ = yyvstack[yysp - 1];
        if (yyvstack[yysp]) {
            switch (yyvstack[yysp].type) {
            case 'macro':
                this.$.macros[yyvstack[yysp].name] = yyvstack[yysp].body;
                break;
        
            case 'names':
                let condition_defs = yyvstack[yysp].names;
                for (let i = 0, len = condition_defs.length; i < len; i++) {
                    let name = condition_defs[i][0];
                    if (name in this.$.startConditions && this.$.startConditions[name] !== condition_defs[i][1]) {
                        yyparser.yyError(rmCommonWS$1`
                        You have specified the lexer condition state '${name}' as both
                        EXCLUSIVE ('%x') and INCLUSIVE ('%s'). Pick one, please, e.g.:
    
                            %x ${name}
                            %%
                            <${name}>LEXER_RULE_REGEX    return 'TOK';
    
                          Erroneous code:
                        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
                          Technical error report:
                        ${yyvstack[yysp].errStr}
                    `);
                    }
                    this.$.startConditions[name] = condition_defs[i][1];     // flag as 'exclusive'/'inclusive'
                }
        
                // and update the `yy.startConditions` hash table as well, so we have a full set
                // by the time this parser arrives at the lexer rules in the input-to-parse:
                yy.startConditions = this.$.startConditions;
                break;
        
            case 'unknown':
                this.$.unknownDecls.push(yyvstack[yysp].body);
                break;
        
            case 'imports':
                this.$.importDecls.push(yyvstack[yysp].body);
                break;
        
            case 'codeSection':
                this.$.codeSections.push(yyvstack[yysp].body);
                break;
        
            default:
                yyparser.yyError(rmCommonWS$1`
              Encountered an unsupported definition type: ${yyvstack[yysp].type}.
    
                Erroneous area:
              ${yylexer.prettyPrintRange(yylstack[yysp])}
            `);
                break;
            }
        }
        }
        break;

    case 9:
        /*! Production::    definitions : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
          macros: {},           // { hash table }
          startConditions: {},  // { hash table }
          codeSections: [],     // [ array of {qualifier,include} pairs ]
          importDecls: [],      // [ array of {name,path} pairs ]
          unknownDecls: []      // [ array of {name,value} pairs ]
        };
        break;

    case 10:
        /*! Production::    definition : MACRO_NAME regex MACRO_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        // Note: make sure we don't try re-define/override any XRegExp `\p{...}` or `\P{...}`
        // macros here:
        if (XRegExp__default['default']._getUnicodeProperty(yyvstack[yysp - 2])) {
            // Work-around so that you can use `\p{ascii}` for a XRegExp slug, a.k.a.
            // Unicode 'General Category' Property cf. http://unicode.org/reports/tr18/#Categories,
            // while using `\p{ASCII}` as a *macro expansion* of the `ASCII`
            // macro:
            if (yyvstack[yysp - 2].toUpperCase() !== yyvstack[yysp - 2]) {
                yyparser.yyError(rmCommonWS$1`
              Cannot use name "${$MACRO_NAME}" as a macro name
              as it clashes with the same XRegExp "\\p{..}" Unicode \'General Category\'
              Property name.
              Use all-uppercase macro names, e.g. name your macro
              "${$MACRO_NAME.toUpperCase()}" to work around this issue
              or give your offending macro a different name.
    
                Erroneous area:
              ${yylexer.prettyPrintRange(yylstack[yysp - 2])}
            `);
            }
        }
        
        this.$ = {
            type: 'macro',
            name: yyvstack[yysp - 2],
            body: yyvstack[yysp - 1]
        };
        break;

    case 11:
        /*! Production::    definition : MACRO_NAME error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        ill defined macro definition.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 12:
        /*! Production::    definition : start_inclusive_keyword option_list OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let lst = yyvstack[yysp - 1];
        for (let i = 0, len = lst.length; i < len; i++) {
            lst[i][1] = 0;     // flag as 'inclusive'
        }
        
        this.$ = {
            type: 'names',
            names: lst         // 'inclusive' conditions have value 0, 'exclusive' conditions have value 1
        };
        }
        break;

    case 13:
        /*! Production::    definition : start_inclusive_keyword error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        ill defined '%s' inclusive lexer condition set specification.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 14:
        /*! Production::    definition : start_exclusive_keyword option_list OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let lst = yyvstack[yysp - 1];
        for (let i = 0, len = lst.length; i < len; i++) {
            lst[i][1] = 1;     // flag as 'exclusive'
        }
        
        this.$ = {
            type: 'names',
            names: lst         // 'inclusive' conditions have value 0, 'exclusive' conditions have value 1
        };
        }
        break;

    case 15:
        /*! Production::    definition : start_exclusive_keyword error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        ill defined '%x' exclusive lexer condition set specification.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 16:
        /*! Production::    definition : ACTION_START_AT_SOL action ACTION_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp - 1], yyvstack[yysp - 2]);
        if (srcCode) {
            let rv = checkActionBlock$1(srcCode, yylstack[yysp - 1], yy);
            if (rv) {
                yyparser.yyError(rmCommonWS$1`
                The '%{...%}' lexer setup action code section does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
            `);
            }
            yy.actionInclude.push(srcCode);
        }
        this.$ = null;
        }
        break;

    case 17:
        /*! Production::    definition : UNTERMINATED_ACTION_BLOCK */
    case 132:
        /*! Production::    epilogue_chunk : UNTERMINATED_ACTION_BLOCK */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        // The issue has already been reported by the lexer. No need to repeat
        // ourselves with another error report from here.
        this.$ = null;
        break;

    case 18:
        /*! Production::    definition : ACTION_START_AT_SOL error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        There's very probably a problem with this '%{...%}' lexer setup action code section.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        this.$ = null;
        break;

    case 19:
        /*! Production::    definition : ACTION_START error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let start_marker = yyvstack[yysp - 1].trim();
        let marker_msg = (start_marker ? ' or similar, such as ' + start_marker : '');
        yyparser.yyError(rmCommonWS$1`
        The '%{...%}' lexer setup action code section MUST have its action
        block start marker (\`%{\`${marker_msg}) positioned
        at the start of a line to be accepted: *indented* action code blocks
        (such as this one) are always related to an immediately preceding lexer spec item,
        e.g. a lexer match rule expression (see 'lexer rules').
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        this.$ = null;
        }
        break;

    case 20:
        /*! Production::    definition : option_keyword option_list OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let lst = yyvstack[yysp - 1];
        for (let i = 0, len = lst.length; i < len; i++) {
            yy.options[lst[i][0]] = lst[i][1];
        }
        this.$ = null;
        }
        break;

    case 21:
        /*! Production::    definition : option_keyword error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        ill defined %options line.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 22:
        /*! Production::    definition : UNKNOWN_DECL */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
            type: 'unknown',
            body: yyvstack[yysp]
        };
        break;

    case 23:
        /*! Production::    definition : import_keyword option_list OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // check if there are two unvalued options: 'name path'
        let lst = yyvstack[yysp - 1];
        let len = lst.length;
        let body;
        if (len === 2 && lst[0][1] === true && lst[1][1] === true) {
            // `name path`:
            body = {
                name: lst[0][0],
                path: lst[1][0]
            };
        } else if (len <= 2) {
            yyparser.yyError(rmCommonWS$1`
            You did not specify a legal qualifier name and/or file path for the '%import' statement, which must have the format:
                %import qualifier_name file_path
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
        `);
        } else {
            yyparser.yyError(rmCommonWS$1`
            You did specify too many attributes for the '%import' statement, which must have the format:
                %import qualifier_name file_path
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
        `);
        }
        
        this.$ = {
            type: 'imports',
            body: body
        };
        }
        break;

    case 24:
        /*! Production::    definition : import_keyword error OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        %import name or source filename missing maybe?
    
        Note: each '%import' must be qualified by a name, e.g. 'required' before the import path itself:
            %import qualifier_name file_path
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 25:
        /*! Production::    definition : init_code_keyword option_list ACTION_START action ACTION_END OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 6/6,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 5, yysp);
        // END of default action (generated by JISON mode classic/merge :: 6/6,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // check there's only 1 option which is an identifier
        let lst = yyvstack[yysp - 4];
        let len = lst.length;
        let name;
        if (len === 1 && lst[0][1] === true) {
            // `name`:
            name = lst[0][0];
        } else if (len <= 1) {
            yyparser.yyError(rmCommonWS$1`
            You did not specify a legal qualifier name for the '%code' initialization code statement, which must have the format:
                %code qualifier_name %{...code...%}
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 4], yylstack[yysp - 5])}
        `);
        } else {
            yyparser.yyError(rmCommonWS$1`
            You did specify too many attributes for the '%code' initialization code statement, which must have the format:
                %code qualifier_name %{...code...%}
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 4], yylstack[yysp - 5])}
        `);
        }
        
        let srcCode = trimActionCode$1(yyvstack[yysp - 2], yyvstack[yysp - 3]);
        let rv = checkActionBlock$1(srcCode, yylstack[yysp - 2], yy);
        if (rv) {
            yyparser.yyError(rmCommonWS$1`
            The '%code ${name}' initialization code section does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp - 2], yylstack[yysp - 5])}
        `);
        }
        this.$ = {
            type: 'codeSection',
            body: {
              qualifier: name,
              include: srcCode
            }
        };
        }
        break;

    case 26:
        /*! Production::    definition : init_code_keyword option_list ACTION_START error OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 4];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
        // END of default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-)
        
        
        {
        let start_marker = yyvstack[yysp - 2].trim();
        let marker_msg = (start_marker ? ' or similar, such as ' + start_marker : '');
        let end_marker_msg = marker_msg.replace(/\{/g, '}');
        yyparser.yyError(rmCommonWS$1`
        The '%code ID %{...%\}' initialization code section must be properly 
        wrapped in block start markers (\`%{\`${marker_msg}) 
        and matching end markers (\`%}\`${end_marker_msg}). Expected format:
    
            %code qualifier_name {action code}
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 4])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        }
        break;

    case 27:
        /*! Production::    definition : init_code_keyword error ACTION_START error OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 4];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
        // END of default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Each '%code' initialization code section must be qualified by a name, 
        e.g. 'required' before the action code itself:
    
            %code qualifier_name {action code}
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 3], yylstack[yysp - 4])}
    
          Technical error report:
        ${yyvstack[yysp - 3].errStr}
    `);
        break;

    case 28:
        /*! Production::    definition : init_code_keyword error OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Each '%code' initialization code section must be qualified by a name, 
        e.g. 'required' before the action code itself.
    
        The '%code ID %{...%\}' initialization code section must be properly 
        wrapped in block start markers (e.g. \`%{\`) and matching end markers 
        (e.g. \`%}\`). Expected format:
    
            %code qualifier_name {action code}
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 29:
        /*! Production::    definition : error */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        illegal input in the lexer spec definitions section.
    
        This might be stuff incorrectly dangling off the previous
        '${yy.__options_category_description__}' definition statement, so please do check above
        when the mistake isn't immediately obvious from this error spot itself.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 30:
        /*! Production::    option_keyword : OPTIONS */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES;
        yy.__options_category_description__ = yyvstack[yysp];
        break;

    case 31:
        /*! Production::    import_keyword : IMPORT */
    case 33:
        /*! Production::    include_keyword : INCLUDE */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_DOES_NOT_ACCEPT_VALUE | OPTION_DOES_NOT_ACCEPT_COMMA_SEPARATED_OPTIONS;
        yy.__options_category_description__ = yyvstack[yysp];
        break;

    case 32:
        /*! Production::    init_code_keyword : CODE */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_DOES_NOT_ACCEPT_VALUE | OPTION_DOES_NOT_ACCEPT_MULTIPLE_OPTIONS | OPTION_DOES_NOT_ACCEPT_COMMA_SEPARATED_OPTIONS;
        yy.__options_category_description__ = yyvstack[yysp];
        break;

    case 34:
        /*! Production::    start_inclusive_keyword : START_INC */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_DOES_NOT_ACCEPT_VALUE | OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES;
        yy.__options_category_description__ = 'the inclusive lexer start conditions set (%s)';
        break;

    case 35:
        /*! Production::    start_exclusive_keyword : START_EXC */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_DOES_NOT_ACCEPT_VALUE | OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES;
        yy.__options_category_description__ = 'the exclusive lexer start conditions set (%x)';
        break;

    case 36:
        /*! Production::    start_conditions_marker : "<" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = OPTION_DOES_NOT_ACCEPT_VALUE | OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES | OPTION_ALSO_ACCEPTS_STAR_AS_IDENTIFIER_NAME;
        yy.__options_category_description__ = 'the <...> delimited set of lexer start conditions';
        break;

    case 37:
        /*! Production::    start_productions_marker : "%%" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = 0;
        yy.__options_category_description__ = 'the lexer rules definition section';
        break;

    case 38:
        /*! Production::    start_epilogue_marker : "%%" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        yy.__options_flags__ = 0;
        yy.__options_category_description__ = 'the lexer epilogue section';
        break;

    case 39:
        /*! Production::    rules : rules scoped_rules_collective */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1].concat(yyvstack[yysp]);
        break;

    case 40:
        /*! Production::    rules : rules rule */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1].concat([yyvstack[yysp]]);
        break;

    case 41:
        /*! Production::    rules : rules ACTION_START_AT_SOL action ACTION_END */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp - 1], yyvstack[yysp - 2]);
        if (srcCode) {
            let rv = checkActionBlock$1(srcCode, yylstack[yysp - 1], yy);
            if (rv) {
                yyparser.yyError(rmCommonWS$1`
                The '%{...%}' lexer setup action code section does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
            `);
            }
            yy.actionInclude.push(srcCode);
        }
        this.$ = yyvstack[yysp - 3];
        }
        break;

    case 42:
        /*! Production::    rules : rules UNTERMINATED_ACTION_BLOCK */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        // The issue has already been reported by the lexer. No need to repeat
        // ourselves with another error report from here.
        this.$ = yyvstack[yysp - 1];
        break;

    case 43:
        /*! Production::    rules : rules ACTION_START_AT_SOL error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let start_marker = yyvstack[yysp - 1].trim();
        yyparser.yyError(rmCommonWS$1`
        There's very probably a problem with this '%{...%}' lexer setup action code section.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        this.$ = yyvstack[yysp - 2];
        }
        break;

    case 44:
        /*! Production::    rules : rules ACTION_START error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let start_marker = yyvstack[yysp - 1].trim();
        // When the start_marker is not an explicit `%{`, `{` or similar, the error
        // is more probably due to indenting the rule regex, rather than an error
        // in writing the action code block:
        console.error("*** error! marker:", start_marker);
        if (start_marker.indexOf('{') >= 0) {
            let marker_msg = (start_marker ? ' or similar, such as ' + start_marker : '');
            yyparser.yyError(rmCommonWS$1`
            The '%{...%}' lexer setup action code section MUST have its action
            block start marker (\`%{\`${marker_msg}) positioned
            at the start of a line to be accepted: *indented* action code blocks
            (such as this one) are always related to an immediately preceding lexer spec item,
            e.g. a lexer match rule expression (see 'lexer rules').
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
              Technical error report:
            ${yyvstack[yysp].errStr}
        `);
        } else {
            yyparser.yyError(rmCommonWS$1`
            There's probably an error in one or more of your lexer regex rules.
            Did you perhaps indent the rule regex? Note that all rule regexes
            MUST start at the start of the line, i.e. text column 1. Indented text
            is perceived as JavaScript action code related to the last lexer
            rule regex.
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
    
              Technical error report:
            ${yyvstack[yysp].errStr}
        `);
        }
        this.$ = yyvstack[yysp - 2];
        }
        break;

    case 45:
        /*! Production::    rules : rules start_inclusive_keyword */
    case 46:
        /*! Production::    rules : rules start_exclusive_keyword */
    case 47:
        /*! Production::    rules : rules option_keyword */
    case 48:
        /*! Production::    rules : rules UNKNOWN_DECL */
    case 49:
        /*! Production::    rules : rules import_keyword */
    case 50:
        /*! Production::    rules : rules init_code_keyword */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        \`${yy.__options_category_description__}\` statements must be placed in
        the top section of the lexer spec file, above the first '%%'
        separator. You cannot specify any in the second section as has been
        done here.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp])}
    `);
        this.$ = yyvstack[yysp - 1];
        break;

    case 51:
        /*! Production::    rules : %epsilon */
    case 58:
        /*! Production::    rule_block : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [];
        break;

    case 52:
        /*! Production::    scoped_rules_collective : start_conditions rule */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        if (yyvstack[yysp - 1]) {
            yyvstack[yysp].unshift(yyvstack[yysp - 1]);
        }
        this.$ = [yyvstack[yysp]];
        break;

    case 53:
        /*! Production::    scoped_rules_collective : start_conditions "{" rule_block "}" */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        if (yyvstack[yysp - 3]) {
            yyvstack[yysp - 1].forEach(function (d) {
                d.unshift(yyvstack[yysp - 3]);
            });
        }
        this.$ = yyvstack[yysp - 1];
        break;

    case 54:
        /*! Production::    scoped_rules_collective : start_conditions "{" error "}" */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 3];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Seems you made a mistake while specifying one of the lexer rules inside
        the start condition
           <${yyvstack[yysp - 3].join(',')}> { rules... }
        block.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yyparser.mergeLocationInfo((yysp - 3), (yysp)), yylstack[yysp - 3])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 55:
        /*! Production::    scoped_rules_collective : start_conditions "{" error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Seems you did not correctly bracket a lexer rules set inside
        the start condition
          <${yyvstack[yysp - 2].join(',')}> { rules... }
        as a terminating curly brace '}' could not be found.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 56:
        /*! Production::    scoped_rules_collective : start_conditions error "}" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Seems you did not correctly bracket a lexer rules set inside
        the start condition
          <${yyvstack[yysp - 2].join(',')}> { rules... }
        as a terminating curly brace '}' could not be found.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 57:
        /*! Production::    rule_block : rule_block rule */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1]; this.$.push(yyvstack[yysp]);
        break;

    case 59:
        /*! Production::    rule : regex ACTION_START action ACTION_END */
    case 60:
        /*! Production::    rule : regex ACTION_START_AT_SOL action ACTION_END */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp - 1], yyvstack[yysp - 2]);
        let rv = checkActionBlock$1(srcCode, yylstack[yysp - 1], yy);
        if (rv) {
            yyparser.yyError(rmCommonWS$1`
            The lexer rule's action code section does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 3])}
        `);
        }
        this.$ = [yyvstack[yysp - 3], srcCode];
        }
        break;

    case 61:
        /*! Production::    rule : regex ARROW_ACTION_START action ACTION_END */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp - 1]);
        // add braces around ARROW_ACTION_CODE so that the action chunk test/compiler
        // will uncover any illegal action code following the arrow operator, e.g.
        // multiple statements separated by semicolon.
        //
        // Note/Optimization:
        // there's no need for braces in the generated expression when we can
        // already see the given action is an identifier string or something else
        // that's a sure simple thing for a JavaScript `return` statement to carry.
        // By doing this, we simplify the token return replacement code replacement
        // process which will be applied to the parsed lexer before its code
        // will be generated by JISON.
        if (/^[^\r\n;\/]+$/.test(srcCode)) {
            srcCode = 'return ' + srcCode;
        } else {
            srcCode = 'return (' + srcCode + '\n)';
        }
        
        let rv = checkActionBlock$1(srcCode, yylstack[yysp - 1], yy);
        if (rv) {
            yyparser.yyError(rmCommonWS$1`
            The lexer rule's 'arrow' action code section does not compile: ${rv}
    
            # NOTE that the arrow action automatically wraps the action code
            # in a \`return (...);\` statement to prevent hard-to-diagnose run-time
            # errors down the line.
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 3])}
        `);
        }
        
        this.$ = [yyvstack[yysp - 3], srcCode];
        }
        break;

    case 62:
        /*! Production::    rule : regex ARROW_ACTION_START error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
        yyparser.yyError(rmCommonWS$1`
        A lexer rule action arrow must be followed by a single JavaScript expression specifying the lexer token to produce, e.g.:
    
            /rule/   -> 'BUGGABOO'
    
        which is equivalent to:
    
            /rule/      %{ return 'BUGGABOO'; %}
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 63:
        /*! Production::    rule : regex ACTION_START error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        // TODO: REWRITE
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
        yyparser.yyError(rmCommonWS$1`
        A lexer rule regex action code must be properly terminated and must contain a JavaScript statement block (or anything that does parse as such), e.g.:
    
            /rule/      %{ invokeHooHaw(); return 'TOKEN'; %}
    
        NOTE: when you have very simple action code, wrapping it in '%{...}%' or equivalent is not required as long as you keep the code indented, e.g.:
    
            /rule/      invokeHooHaw();
                        return 'TOKEN';
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 64:
        /*! Production::    rule : regex ACTION_START_AT_SOL error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        // TODO: REWRITE
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
        yyparser.yyError(rmCommonWS$1`
        A lexer rule regex action code must be properly terminated and must contain a JavaScript statement block (or anything that does parse as such), e.g.:
    
            /rule/
            %{
                invokeHooHaw();
                return 'TOKEN';
            %}
    
        You may indent the initial '%{' to disambiguate this as being a rule action code block instead of a lexer init code block:
    
            /rule/
              %{
                invokeHooHaw();
                return 'TOKEN';
            %}
    
        You can also accomplish this by placing the '%{' on the same line as the regex:
    
            /rule/      %{
                invokeHooHaw();
                return 'TOKEN';
            %}
    
        NOTE: when you have very simple action code, wrapping it in '%{...}%' or equivalent is not required as long as you keep the code indented, e.g.:
    
            /rule/      invokeHooHaw();
                        return 'TOKEN';
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 65:
        /*! Production::    rule : regex error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 1], yyvstack[yysp]];
        yyparser.yyError(rmCommonWS$1`
        Lexer rule regex action code declaration error?
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 66:
        /*! Production::    action : action ACTION_BODY */
    case 83:
        /*! Production::    regex_concat : regex_concat regex_base */
    case 95:
        /*! Production::    regex_base : regex_base range_regex */
    case 106:
        /*! Production::    regex_set : regex_set regex_set_atom */
    case 127:
        /*! Production::    epilogue_chunks : epilogue_chunks epilogue_chunk */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 67:
        /*! Production::    action : action include_macro_code */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + '\n\n' + yyvstack[yysp] + '\n\n';
        break;

    case 68:
        /*! Production::    action : action INCLUDE_PLACEMENT_ERROR */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        You may place the '%include' instruction only at the start/front of a line.
    
          Its use is not permitted at this position:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 3])}
    `);
        break;

    case 69:
        /*! Production::    action : action BRACKET_MISSING */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Missing curly braces: seems you did not correctly bracket a lexer rule action block in curly braces: '{ ... }'.
    
          Offending action body:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 3])}
    `);
        break;

    case 70:
        /*! Production::    action : action BRACKET_SURPLUS */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Too many curly braces: seems you did not correctly bracket a lexer rule action block in curly braces: '{ ... }'.
    
          Offending action body:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 3])}
    `);
        break;

    case 71:
        /*! Production::    action : action UNTERMINATED_STRING_ERROR */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Unterminated string constant in lexer rule action block.
    
        When your action code is as intended, it may help to enclose
        your rule action block code in a '%{...%}' block.
    
          Offending action body:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 3])}
    `);
        break;

    case 72:
        /*! Production::    action : %epsilon */
    case 77:
        /*! Production::    regex_list : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '';
        break;

    case 73:
        /*! Production::    start_conditions : start_conditions_marker option_list OPTIONS_END ">" */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // rewrite + accept star '*' as name + check if we allow empty list?
        this.$ = yyvstack[yysp - 2].map(function (el) {
            let name = el[0];
        
            // Validate the given condition state: when it isn't known, print an error message
            // accordingly:
            if (name !== '*' && name !== 'INITIAL' && !(name in yy.startConditions)) {
                yyparser.yyError(rmCommonWS$1`
                You specified an unknown lexer condition state '${name}'.
                Is this a typo or did you forget to include this one in the '%s' and '%x'
                inclusive and exclusive condition state sets specifications at the top of
                the lexer spec?
    
                As a rough example, things should look something like this in your lexer
                spec file:
    
                    %s ${name}
                    %%
                    <${name}>LEXER_RULE_REGEX    return 'TOK';
    
                  Erroneous code:
                ${yylexer.prettyPrintRange(yylstack[yysp - 2], yylstack[yysp - 3], yylstack[yysp])}
            `);
            }
        
            return name;
        });
        
        // '<' '*' '>'
        //    { $$ = ['*']; }
        }
        break;

    case 74:
        /*! Production::    start_conditions : start_conditions_marker option_list error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        {
        // rewrite + accept star '*' as name + check if we allow empty list?
        let lst = yyvstack[yysp - 1].map(function (el) {
            return el[0];
        });
        
        yyparser.yyError(rmCommonWS$1`
        Seems you did not correctly terminate the start condition set
            <${lst.join(',')},???>
        with a terminating '>'
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        }
        break;

    case 75:
        /*! Production::    regex : nonempty_regex_list */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // Detect if the regex ends with a pure (Unicode) word;
        // we *do* consider escaped characters which are 'alphanumeric'
        // to be equivalent to their non-escaped version, hence these are
        // all valid 'words' for the 'easy keyword rules' option:
        //
        // - hello_kitty
        // - γεια_σου_γατούλα
        // - \u03B3\u03B5\u03B9\u03B1_\u03C3\u03BF\u03C5_\u03B3\u03B1\u03C4\u03BF\u03CD\u03BB\u03B1
        //
        // http://stackoverflow.com/questions/7885096/how-do-i-decode-a-string-with-escaped-unicode#12869914
        //
        // As we only check the *tail*, we also accept these as
        // 'easy keywords':
        //
        // - %options
        // - %foo-bar
        // - +++a:b:c1
        //
        // Note the dash in that last example: there the code will consider
        // `bar` to be the keyword, which is fine with us as we're only
        // interested in the trailing boundary and patching that one for
        // the `easy_keyword_rules` option.
        this.$ = yyvstack[yysp];
        if (yy.options.easy_keyword_rules) {
          // We need to 'protect' `eval` here as keywords are allowed
          // to contain double-quotes and other leading cruft.
          // `eval` *does* gobble some escapes (such as `\b`) but
          // we protect against that through a simple replace regex:
          // we're not interested in the special escapes' exact value
          // anyway.
          // It will also catch escaped escapes (`\\`), which are not
          // word characters either, so no need to worry about
          // `eval(str)` 'correctly' converting convoluted constructs
          // like '\\\\\\\\\\b' in here.
          this.$ = this.$
          .replace(/\\\\/g, '.')
          .replace(/"/g, '.')
          .replace(/\\c[A-Z]/g, '.')
          .replace(/\\[^xu0-7]/g, '.');
        
          try {
            // Convert Unicode escapes and other escapes to their literal characters
            // BEFORE we go and check whether this item is subject to the
            // `easy_keyword_rules` option.
            this.$ = JSON.parse('"' + this.$ + '"');
          }
          catch (ex) {
            yyparser.warn('easy-keyword-rule FAIL on eval: ', ex);
        
            // make the next keyword test fail:
            this.$ = '.';
          }
          // a 'keyword' starts with an alphanumeric character,
          // followed by zero or more alphanumerics or digits:
          let re = new XRegExp__default['default']('\\w[\\w\\d]*$');
          if (XRegExp__default['default'].match(this.$, re)) {
            this.$ = yyvstack[yysp] + "\\b";
          } else {
            this.$ = yyvstack[yysp];
          }
        }
        }
        break;

    case 76:
        /*! Production::    regex_list : nonempty_regex_list */
    case 82:
        /*! Production::    nonempty_regex_list : regex_concat */
    case 84:
        /*! Production::    regex_concat : regex_base */
    case 103:
        /*! Production::    name_expansion : NAME_BRACE */
    case 110:
        /*! Production::    range_regex : RANGE_REGEX */
    case 129:
        /*! Production::    epilogue_chunks : epilogue_chunk */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp];
        break;

    case 78:
        /*! Production::    nonempty_regex_list : nonempty_regex_list "|" regex_concat */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2] + '|' + yyvstack[yysp];
        break;

    case 79:
        /*! Production::    nonempty_regex_list : nonempty_regex_list "|" */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + '|';
        break;

    case 80:
        /*! Production::    nonempty_regex_list : "|" regex_concat */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '|' + yyvstack[yysp];
        break;

    case 81:
        /*! Production::    nonempty_regex_list : "|" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '|';
        break;

    case 85:
        /*! Production::    regex_base : "(" regex_list ")" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '(' + yyvstack[yysp - 1] + ')';
        break;

    case 86:
        /*! Production::    regex_base : SPECIAL_GROUP regex_list ")" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + ')';
        break;

    case 87:
        /*! Production::    regex_base : "(" regex_list error */
    case 88:
        /*! Production::    regex_base : SPECIAL_GROUP regex_list error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Seems you did not correctly bracket a lex rule regex part in '(...)' braces.
    
          Unterminated regex part:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 89:
        /*! Production::    regex_base : regex_base "+" */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + '+';
        break;

    case 90:
        /*! Production::    regex_base : regex_base "*" */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + '*';
        break;

    case 91:
        /*! Production::    regex_base : regex_base "?" */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + '?';
        break;

    case 92:
        /*! Production::    regex_base : "/" regex_base */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '(?=' + yyvstack[yysp] + ')';
        break;

    case 93:
        /*! Production::    regex_base : "/!" regex_base */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '(?!' + yyvstack[yysp] + ')';
        break;

    case 94:
        /*! Production::    regex_base : name_expansion */
    case 96:
        /*! Production::    regex_base : any_group_regex */
    case 100:
        /*! Production::    regex_base : REGEX_SPECIAL_CHAR */
    case 101:
        /*! Production::    regex_base : literal_string */
    case 107:
        /*! Production::    regex_set : regex_set_atom */
    case 108:
        /*! Production::    regex_set_atom : REGEX_SET */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        break;

    case 97:
        /*! Production::    regex_base : "." */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '.';
        break;

    case 98:
        /*! Production::    regex_base : "^" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '^';
        break;

    case 99:
        /*! Production::    regex_base : "$" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '$';
        break;

    case 102:
        /*! Production::    regex_base : ESCAPED_CHAR */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = encodeRegexLiteralStr(encodeUnicodeCodepoint(yyvstack[yysp]));
        break;

    case 104:
        /*! Production::    any_group_regex : REGEX_SET_START regex_set REGEX_SET_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 105:
        /*! Production::    any_group_regex : REGEX_SET_START regex_set error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        Seems you did not correctly bracket a lex rule regex set in '[...]' brackets.
    
          Unterminated regex set:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 109:
        /*! Production::    regex_set_atom : name_expansion */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        if (XRegExp__default['default']._getUnicodeProperty(yyvstack[yysp].replace(/[{}]/g, ''))
            && yyvstack[yysp].toUpperCase() !== yyvstack[yysp]
        ) {
            // treat this as part of an XRegExp `\p{...}` Unicode 'General Category' Property cf. http://unicode.org/reports/tr18/#Categories
            this.$ = yyvstack[yysp];
        } else {
            this.$ = yyvstack[yysp];
        }
        //yyparser.log("name expansion for: ", { name: $name_expansion, redux: $name_expansion.replace(/[{}]/g, ''), output: $$ });
        break;

    case 111:
        /*! Production::    literal_string : STRING_LIT */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let src = yyvstack[yysp];
        let s = src.substring(1, src.length - 1);
        let edge = src[0];
        this.$ = encodeRegexLiteralStr(s, edge);
        }
        break;

    case 112:
        /*! Production::    literal_string : CHARACTER_LIT */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let s = yyvstack[yysp];
        this.$ = encodeRegexLiteralStr(s);
        }
        break;

    case 113:
        /*! Production::    option_list : option_list "," option */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // validate that this is legal behaviour under the given circumstances, i.e. parser context:
        if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_MULTIPLE_OPTIONS) {
            yyparser.yyError(rmCommonWS$1`
            You may only specify one name/argument in a ${yy.__options_category_description__} statement.
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylexer.deriveLocationInfo(yylstack[yysp - 1], yylstack[yysp]), yylstack[yysp - 4])}
        `);
        }
        if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_COMMA_SEPARATED_OPTIONS) {
            let optlist = yyvstack[yysp - 2].map(function (opt) {
                return opt[0];
            });
            optlist.push(yyvstack[yysp][0]);
        
            yyparser.yyError(rmCommonWS$1`
            You may not separate entries in a ${yy.__options_category_description__} statement using commas.
            Use whitespace instead, e.g.:
    
                ${yyvstack[yysp - 4]} ${optlist.join(' ')} ...
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylexer.deriveLocationInfo(yylstack[yysp - 1], yylstack[yysp - 2]), yylstack[yysp - 4])}
        `);
        }
        this.$ = yyvstack[yysp - 2];
        this.$.push(yyvstack[yysp]);
        }
        break;

    case 114:
        /*! Production::    option_list : option_list option */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        // validate that this is legal behaviour under the given circumstances, i.e. parser context:
        if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_MULTIPLE_OPTIONS) {
            yyparser.yyError(rmCommonWS$1`
            You may only specify one name/argument in a ${yy.__options_category_description__} statement.
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylexer.deriveLocationInfo(yylstack[yysp]), yylstack[yysp - 3])}
        `);
        }
        this.$ = yyvstack[yysp - 1];
        this.$.push(yyvstack[yysp]);
        break;

    case 115:
        /*! Production::    option_list : option */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp]];
        break;

    case 116:
        /*! Production::    option : option_name */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp], true];
        break;

    case 117:
        /*! Production::    option : option_name "=" option_value */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        // validate that this is legal behaviour under the given circumstances, i.e. parser context:
        if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_VALUE) {
            yyparser.yyError(rmCommonWS$1`
            The entries in a ${yy.__options_category_description__} statement MUST NOT be assigned values, such as '${$option_name}=${$option_value}'.
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylexer.deriveLocationInfo(yylstack[yysp], yylstack[yysp - 2]), yylstack[yysp - 4])}
        `);
        }
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
        break;

    case 118:
        /*! Production::    option : option_name "=" error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$1`
        Internal error: option "${$option}" value assignment failure in a ${yy.__options_category_description__} statement.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 4])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 119:
        /*! Production::    option : DUMMY3 error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        {
        let with_value_msg = ' (with optional value assignment)';
        if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_VALUE) {
            with_value_msg = '';
        }
        yyparser.yyError(rmCommonWS$1`
        Expected a valid option name${with_value_msg} in a ${yy.__options_category_description__} statement.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 3])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        }
        break;

    case 120:
        /*! Production::    option_name : option_value */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // validate that this is legal input under the given circumstances, i.e. parser context:
        if (yy.__options_flags__ & OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES) {
            this.$ = mkIdentifier$2(yyvstack[yysp]);
            // check if the transformation is obvious & trivial to humans;
            // if not, report an error as we don't want confusion due to
            // typos and/or garbage input here producing something that
            // is usable from a machine perspective.
            if (!isLegalIdentifierInput$1(yyvstack[yysp])) {
                let with_value_msg = ' (with optional value assignment)';
                if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_VALUE) {
                    with_value_msg = '';
                }
                yyparser.yyError(rmCommonWS$1`
                Expected a valid name/argument${with_value_msg} in a ${yy.__options_category_description__} statement.
                Entries (names) must look like regular programming language
                identifiers, with the addition that option names MAY contain
                '-' dashes, e.g. 'example-option-1'.
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
            `);
            }
        } else {
            this.$ = yyvstack[yysp];
        }
        }
        break;

    case 121:
        /*! Production::    option_name : "*" */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        // validate that this is legal input under the given circumstances, i.e. parser context:
        if (!(yy.__options_flags__ & OPTION_EXPECTS_ONLY_IDENTIFIER_NAMES) || (yy.__options_flags__ & OPTION_ALSO_ACCEPTS_STAR_AS_IDENTIFIER_NAME)) {
            this.$ = yyvstack[yysp];
        } else {
            let with_value_msg = ' (with optional value assignment)';
            if (yy.__options_flags__ & OPTION_DOES_NOT_ACCEPT_VALUE) {
                with_value_msg = '';
            }
            yyparser.yyError(rmCommonWS$1`
            Expected a valid name/argument${with_value_msg} in a ${yy.__options_category_description__} statement.
            Entries (names) must look like regular programming language
            identifiers, with the addition that option names MAY contain
            '-' dashes, e.g. 'example-option-1'
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
        `);
        }
        }
        break;

    case 122:
        /*! Production::    option_value : OPTION_STRING */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = JSON5__default['default'].parse(yyvstack[yysp]);
        break;

    case 123:
        /*! Production::    option_value : OPTION_VALUE */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = parseValue(yyvstack[yysp]);
        break;

    case 124:
        /*! Production::    epilogue : start_epilogue_marker */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '';
        break;

    case 125:
        /*! Production::    epilogue : start_epilogue_marker epilogue_chunks */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp]);
        if (srcCode) {
            let rv = checkActionBlock$1(srcCode, yylstack[yysp], yy);
            if (rv) {
                yyparser.yyError(rmCommonWS$1`
                The '%%' lexer epilogue code does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
            `);
            }
        }
        this.$ = srcCode;
        }
        break;

    case 126:
        /*! Production::    epilogue : start_epilogue_marker error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        There's an error in your lexer epilogue code block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 128:
        /*! Production::    epilogue_chunks : epilogue_chunks error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$1`
        Module code declaration error?
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        this.$ = '';
        break;

    case 130:
        /*! Production::    epilogue_chunk : ACTION_START_AT_SOL action ACTION_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let srcCode = trimActionCode$1(yyvstack[yysp - 1], yyvstack[yysp - 2]);
        if (srcCode) {
            let rv = checkActionBlock$1(srcCode, yylstack[yysp - 1], yy);
            if (rv) {
                yyparser.yyError(rmCommonWS$1`
                The '%{...%}' lexer epilogue code chunk does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
            `);
            }
        }
        // Since the epilogue is concatenated as-is (see the `epilogue_chunks` rule above)
        // we append those protective double newlines right now, as the calling site
        // won't do it for us:
        this.$ = '\n\n' + srcCode + '\n\n';
        }
        break;

    case 131:
        /*! Production::    epilogue_chunk : ACTION_START_AT_SOL error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let start_marker = yyvstack[yysp - 1].trim();
        yyparser.yyError(rmCommonWS$1`
        There's very probably a problem with this '%{...%}' lexer setup action code section.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        this.$ = '';
        }
        break;

    case 133:
        /*! Production::    epilogue_chunk : TRAILING_CODE_CHUNK */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        // these code chunks are very probably incomplete, hence compile-testing
        // for these should be deferred until we've collected the entire epilogue.
        this.$ = yyvstack[yysp];
        break;

    case 134:
        /*! Production::    include_macro_code : include_keyword option_list OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,LU,LUbA):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,LU,LUbA)
        
        
        {
        // check if there is only 1 unvalued options: 'path'
        let lst = yyvstack[yysp - 1];
        let len = lst.length;
        let path;
        if (len === 1 && lst[0][1] === true) {
            // `path`:
            path = lst[0][0];
        } else if (len <= 1) {
            yyparser.yyError(rmCommonWS$1`
            You did not specify a legal file path for the '%include' statement, which must have the format:
                %include file_path
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
              Technical error report:
            ${$error.errStr}
        `);
        } else {
            yyparser.yyError(rmCommonWS$1`
            You did specify too many attributes for the '%include' statement, which must have the format:
                %include file_path
    
              Erroneous code:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
              Technical error report:
            ${$error.errStr}
        `);
        }
        
        // **Aside**: And no, we don't support nested '%include'!
        let fileContent = fs__default['default'].readFileSync(path, { encoding: 'utf-8' });
        
        let srcCode = trimActionCode$1(fileContent);
        if (srcCode) {
            let rv = checkActionBlock$1(srcCode, this._$, yy);
            if (rv) {
                yyparser.yyError(rmCommonWS$1`
                The source code included from file '${path}' does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(this._$)}
            `);
            }
        }
        
        this.$ = '\n// Included by Jison: ' + path + ':\n\n' + srcCode + '\n\n// End Of Include by Jison: ' + path + '\n\n';
        }
        break;

    case 135:
        /*! Production::    include_macro_code : include_keyword error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$1`
        %include MUST be followed by a valid file path.
    
          Erroneous path:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;
                
    }
    },
    table: bt({
      len: u([
      15,
      1,
      14,
      21,
      1,
      13,
      28,
      22,
      s,
      [9, 3],
      13,
      1,
      9,
      13,
      c,
      [6, 3],
      27,
      s,
      [31, 5],
      1,
      44,
      4,
      1,
      13,
      6,
      25,
      24,
      25,
      23,
      23,
      17,
      17,
      s,
      [24, 8],
      26,
      5,
      24,
      24,
      9,
      13,
      8,
      9,
      1,
      s,
      [9, 5],
      13,
      9,
      13,
      c,
      [3, 3],
      c,
      [13, 3],
      2,
      1,
      26,
      26,
      9,
      26,
      c,
      [5, 3],
      s,
      [26, 4],
      7,
      24,
      4,
      5,
      8,
      c,
      [60, 3],
      c,
      [59, 3],
      s,
      [24, 5],
      2,
      3,
      2,
      25,
      25,
      6,
      s,
      [4, 3],
      13,
      7,
      8,
      4,
      8,
      13,
      13,
      s,
      [7, 6],
      9,
      5,
      s,
      [13, 3],
      9,
      1,
      13,
      9,
      26,
      26,
      6,
      1,
      5,
      9,
      5,
      5,
      26,
      17,
      c,
      [85, 4],
      27,
      10,
      s,
      [24, 7],
      4,
      s,
      [8, 3],
      9,
      7,
      9,
      1,
      1,
      26,
      5,
      c,
      [30, 3],
      23,
      27,
      26,
      9,
      27,
      9,
      27,
      9,
      27,
      1,
      16,
      7,
      1,
      13,
      13,
      5,
      26,
      15,
      26,
      s,
      [27, 3],
      16,
      13
    ]),
      symbol: u([
      1,
      2,
      19,
      22,
      s,
      [24, 6, 1],
      31,
      32,
      33,
      55,
      57,
      1,
      c,
      [16, 13],
      58,
      c,
      [14, 13],
      56,
      s,
      [59, 4, 1],
      64,
      65,
      67,
      c,
      [36, 14],
      1,
      2,
      3,
      7,
      8,
      s,
      [13, 4, 1],
      c,
      [19, 10],
      s,
      [40, 6, 1],
      49,
      50,
      69,
      2,
      c,
      [26, 6],
      c,
      [16, 8],
      75,
      s,
      [77, 5, 1],
      85,
      2,
      11,
      51,
      52,
      53,
      s,
      [86, 4, 1],
      c,
      [9, 10],
      23,
      30,
      s,
      [35, 5, 1],
      73,
      c,
      [90, 13],
      2,
      c,
      [32, 9],
      c,
      [23, 14],
      c,
      [63, 17],
      c,
      [144, 40],
      c,
      [27, 5],
      11,
      c,
      [28, 22],
      c,
      [75, 3],
      c,
      [31, 125],
      1,
      c,
      [182, 25],
      c,
      [373, 5],
      s,
      [66, 5, 2],
      c,
      [320, 7],
      90,
      1,
      33,
      68,
      90,
      20,
      c,
      [276, 14],
      7,
      20,
      22,
      25,
      34,
      c,
      [367, 3],
      9,
      c,
      [68, 4],
      c,
      [12, 4],
      c,
      [62, 8],
      c,
      [370, 6],
      c,
      [25, 19],
      c,
      [24, 8],
      s,
      [10, 7, 1],
      c,
      [27, 10],
      48,
      49,
      50,
      84,
      c,
      [49, 8],
      c,
      [45, 8],
      s,
      [76, 6, 1],
      c,
      [72, 9],
      c,
      [23, 15],
      c,
      [485, 13],
      c,
      [17, 21],
      c,
      [105, 24],
      c,
      [24, 189],
      s,
      [46, 5, 1],
      44,
      47,
      80,
      82,
      83,
      c,
      [79, 48],
      11,
      17,
      21,
      c,
      [500, 3],
      c,
      [729, 18],
      17,
      21,
      25,
      c,
      [24, 3],
      c,
      [8, 3],
      18,
      c,
      [9, 6],
      c,
      [10, 10],
      c,
      [9, 26],
      c,
      [76, 22],
      c,
      [849, 7],
      63,
      93,
      c,
      [796, 15],
      c,
      [13, 11],
      c,
      [57, 22],
      c,
      [22, 9],
      21,
      11,
      17,
      c,
      [95, 4],
      c,
      [10, 4],
      25,
      c,
      [670, 27],
      c,
      [26, 26],
      c,
      [981, 10],
      c,
      [35, 26],
      c,
      [88, 52],
      c,
      [26, 105],
      2,
      22,
      24,
      54,
      91,
      92,
      2,
      4,
      c,
      [1221, 14],
      72,
      c,
      [1222, 8],
      c,
      [465, 3],
      c,
      [35, 5],
      c,
      [1158, 8],
      c,
      [8, 4],
      c,
      [1307, 14],
      c,
      [912, 78],
      c,
      [760, 117],
      9,
      2,
      7,
      9,
      c,
      [5, 4],
      c,
      [152, 47],
      84,
      2,
      44,
      46,
      47,
      80,
      83,
      c,
      [6, 4],
      c,
      [4, 8],
      c,
      [614, 14],
      c,
      [602, 6],
      c,
      [754, 9],
      52,
      53,
      c,
      [12, 9],
      c,
      [689, 26],
      c,
      [592, 7],
      c,
      [7, 35],
      c,
      [1571, 14],
      c,
      [82, 26],
      c,
      [430, 14],
      c,
      [688, 8],
      2,
      c,
      [842, 23],
      c,
      [580, 56],
      92,
      c,
      [534, 3],
      c,
      [7, 3],
      c,
      [1765, 11],
      c,
      [14, 3],
      c,
      [5, 6],
      c,
      [794, 26],
      5,
      c,
      [630, 14],
      71,
      5,
      c,
      [159, 10],
      c,
      [9, 17],
      s,
      [1, 4, 2],
      c,
      [72, 24],
      c,
      [976, 9],
      c,
      [628, 48],
      c,
      [24, 121],
      c,
      [560, 4],
      c,
      [1290, 10],
      c,
      [8, 13],
      c,
      [205, 9],
      c,
      [495, 14],
      63,
      93,
      21,
      21,
      c,
      [388, 31],
      c,
      [5, 5],
      c,
      [1301, 11],
      c,
      [14, 3],
      c,
      [354, 15],
      c,
      [984, 8],
      c,
      [333, 27],
      c,
      [100, 26],
      c,
      [549, 11],
      c,
      [62, 25],
      c,
      [36, 72],
      6,
      c,
      [1170, 16],
      c,
      [53, 7],
      21,
      c,
      [744, 28],
      c,
      [621, 29],
      c,
      [266, 15],
      c,
      [745, 28],
      c,
      [284, 27],
      c,
      [27, 52],
      c,
      [203, 16],
      c,
      [182, 13]
    ]),
      type: u([
      s,
      [2, 13],
      0,
      0,
      1,
      c,
      [16, 14],
      c,
      [30, 15],
      s,
      [0, 6],
      s,
      [2, 41],
      c,
      [42, 16],
      c,
      [64, 12],
      c,
      [9, 18],
      c,
      [49, 19],
      c,
      [32, 16],
      c,
      [22, 19],
      c,
      [145, 45],
      s,
      [2, 181],
      s,
      [0, 18],
      c,
      [20, 4],
      c,
      [62, 45],
      c,
      [25, 24],
      c,
      [441, 40],
      c,
      [442, 13],
      c,
      [23, 31],
      c,
      [17, 34],
      c,
      [416, 210],
      c,
      [57, 111],
      c,
      [76, 42],
      c,
      [98, 34],
      c,
      [57, 22],
      c,
      [22, 10],
      c,
      [165, 66],
      c,
      [509, 189],
      c,
      [756, 25],
      c,
      [740, 56],
      c,
      [912, 70],
      c,
      [286, 136],
      c,
      [25, 29],
      c,
      [275, 31],
      c,
      [240, 14],
      c,
      [227, 82],
      c,
      [1144, 56],
      c,
      [53, 22],
      c,
      [775, 59],
      c,
      [58, 15],
      c,
      [149, 63],
      c,
      [1837, 18],
      c,
      [81, 35],
      c,
      [628, 51],
      c,
      [1393, 171],
      c,
      [197, 47],
      c,
      [268, 26],
      c,
      [272, 64],
      c,
      [62, 36],
      c,
      [36, 72],
      s,
      [2, 226]
    ]),
      state: u([
      s,
      [1, 5, 1],
      13,
      15,
      16,
      8,
      9,
      6,
      s,
      [25, 4, 2],
      32,
      37,
      38,
      43,
      49,
      51,
      52,
      54,
      58,
      c,
      [4, 3],
      60,
      63,
      c,
      [5, 3],
      65,
      c,
      [4, 3],
      67,
      c,
      [4, 3],
      77,
      79,
      80,
      75,
      76,
      85,
      81,
      70,
      71,
      82,
      83,
      c,
      [38, 6],
      69,
      81,
      87,
      90,
      c,
      [8, 4],
      91,
      c,
      [4, 3],
      95,
      97,
      98,
      c,
      [20, 5],
      99,
      c,
      [7, 6],
      100,
      c,
      [4, 3],
      101,
      c,
      [4, 3],
      105,
      102,
      103,
      108,
      52,
      54,
      c,
      [3, 3],
      119,
      114,
      c,
      [8, 6],
      c,
      [3, 3],
      127,
      130,
      132,
      136,
      c,
      [66, 7],
      143,
      c,
      [87, 3],
      144,
      c,
      [67, 9],
      95,
      95,
      105,
      151,
      152,
      52,
      54,
      153,
      155,
      c,
      [22, 3],
      157,
      119,
      114,
      161,
      163,
      165,
      168,
      170,
      172,
      c,
      [49, 3],
      c,
      [29, 4],
      c,
      [67, 5],
      119,
      114,
      182,
      c,
      [57, 7],
      c,
      [12, 4],
      119,
      114
    ]),
      mode: u([
      s,
      [2, 27],
      s,
      [1, 13],
      c,
      [27, 15],
      c,
      [53, 38],
      c,
      [66, 27],
      c,
      [46, 12],
      c,
      [65, 23],
      s,
      [2, 197],
      c,
      [271, 26],
      c,
      [340, 23],
      c,
      [25, 4],
      c,
      [27, 6],
      c,
      [264, 10],
      c,
      [20, 20],
      c,
      [12, 5],
      c,
      [66, 18],
      c,
      [89, 5],
      c,
      [102, 14],
      s,
      [1, 38],
      s,
      [2, 218],
      c,
      [220, 50],
      c,
      [274, 30],
      c,
      [25, 6],
      c,
      [85, 37],
      c,
      [736, 26],
      c,
      [52, 52],
      c,
      [427, 61],
      c,
      [54, 34],
      c,
      [515, 158],
      c,
      [696, 29],
      c,
      [1120, 25],
      c,
      [845, 62],
      c,
      [689, 122],
      c,
      [1055, 8],
      c,
      [151, 24],
      c,
      [24, 20],
      c,
      [539, 29],
      c,
      [29, 12],
      c,
      [1006, 79],
      c,
      [660, 49],
      c,
      [45, 8],
      c,
      [793, 47],
      c,
      [131, 31],
      c,
      [439, 50],
      c,
      [44, 16],
      c,
      [125, 9],
      c,
      [161, 22],
      c,
      [663, 28],
      c,
      [599, 24],
      c,
      [1703, 174],
      c,
      [875, 16],
      c,
      [920, 43],
      c,
      [1192, 22],
      c,
      [260, 51],
      c,
      [123, 34],
      c,
      [34, 69],
      c,
      [1284, 181],
      s,
      [2, 51]
    ]),
      goto: u([
      s,
      [7, 13],
      s,
      [9, 13],
      6,
      17,
      7,
      10,
      11,
      12,
      14,
      21,
      22,
      23,
      19,
      20,
      18,
      24,
      s,
      [8, 13],
      51,
      26,
      s,
      [51, 25],
      28,
      30,
      33,
      35,
      39,
      40,
      41,
      34,
      36,
      42,
      s,
      [44, 5, 1],
      50,
      55,
      53,
      56,
      57,
      59,
      c,
      [5, 4],
      61,
      s,
      [72, 7],
      s,
      [17, 13],
      62,
      64,
      c,
      [27, 4],
      s,
      [22, 13],
      66,
      c,
      [18, 4],
      68,
      c,
      [5, 4],
      s,
      [29, 13],
      s,
      [37, 27],
      s,
      [34, 31],
      s,
      [35, 31],
      s,
      [30, 31],
      s,
      [31, 31],
      s,
      [32, 31],
      1,
      4,
      86,
      c,
      [272, 6],
      72,
      73,
      74,
      78,
      c,
      [330, 5],
      84,
      c,
      [282, 8],
      5,
      84,
      88,
      s,
      [11, 13],
      75,
      89,
      s,
      [75, 4],
      81,
      81,
      33,
      81,
      c,
      [48, 4],
      s,
      [81, 4],
      c,
      [42, 8],
      82,
      82,
      33,
      82,
      c,
      [20, 4],
      s,
      [82, 4],
      c,
      [20, 8],
      s,
      [84, 4],
      92,
      93,
      94,
      s,
      [84, 14],
      96,
      84,
      84,
      77,
      30,
      33,
      77,
      c,
      [384, 12],
      c,
      [16, 16],
      c,
      [413, 13],
      c,
      [13, 13],
      s,
      [94, 24],
      s,
      [96, 24],
      s,
      [97, 24],
      s,
      [98, 24],
      s,
      [99, 24],
      s,
      [100, 24],
      s,
      [101, 24],
      s,
      [102, 24],
      s,
      [103, 26],
      45,
      104,
      s,
      [111, 24],
      s,
      [112, 24],
      55,
      107,
      106,
      c,
      [640, 3],
      s,
      [13, 13],
      s,
      [115, 8],
      s,
      [116, 3],
      109,
      s,
      [116, 5],
      110,
      s,
      [120, 9],
      s,
      [121, 9],
      s,
      [122, 9],
      s,
      [123, 9],
      55,
      107,
      111,
      c,
      [73, 3],
      s,
      [15, 13],
      112,
      120,
      113,
      s,
      [115, 4, 1],
      s,
      [18, 13],
      s,
      [19, 13],
      55,
      107,
      121,
      c,
      [52, 3],
      s,
      [21, 13],
      55,
      107,
      122,
      c,
      [19, 3],
      c,
      [78, 3],
      124,
      c,
      [7, 3],
      126,
      125,
      2,
      s,
      [39, 26],
      s,
      [40, 26],
      128,
      s,
      [72, 7],
      s,
      [42, 26],
      129,
      s,
      [45, 26],
      s,
      [46, 26],
      s,
      [47, 26],
      s,
      [48, 26],
      s,
      [49, 26],
      s,
      [50, 26],
      124,
      131,
      133,
      134,
      135,
      138,
      137,
      c,
      [1118, 14],
      142,
      140,
      139,
      141,
      s,
      [38, 5],
      c,
      [1071, 4],
      s,
      [36, 4],
      3,
      s,
      [10, 13],
      79,
      79,
      33,
      79,
      c,
      [47, 4],
      s,
      [79, 4],
      c,
      [51, 8],
      80,
      80,
      33,
      80,
      c,
      [20, 4],
      s,
      [80, 4],
      c,
      [20, 8],
      s,
      [83, 4],
      c,
      [845, 3],
      s,
      [83, 14],
      96,
      83,
      83,
      s,
      [89, 24],
      s,
      [90, 24],
      s,
      [91, 24],
      s,
      [95, 24],
      s,
      [110, 24],
      146,
      145,
      76,
      89,
      76,
      148,
      147,
      s,
      [92, 5],
      93,
      94,
      s,
      [92, 14],
      96,
      c,
      [19, 3],
      s,
      [93, 3],
      c,
      [24, 3],
      s,
      [93, 14],
      96,
      93,
      93,
      150,
      45,
      149,
      104,
      s,
      [107, 4],
      s,
      [108, 4],
      s,
      [109, 4],
      s,
      [12, 13],
      c,
      [290, 4],
      s,
      [114, 8],
      154,
      56,
      57,
      s,
      [119, 8],
      s,
      [14, 13],
      s,
      [16, 13],
      s,
      [66, 7],
      s,
      [67, 7],
      s,
      [68, 7],
      s,
      [69, 7],
      s,
      [70, 7],
      s,
      [71, 7],
      156,
      c,
      [92, 4],
      s,
      [33, 5],
      s,
      [20, 13],
      s,
      [23, 13],
      s,
      [24, 13],
      158,
      s,
      [72, 7],
      159,
      s,
      [28, 13],
      160,
      c,
      [793, 6],
      s,
      [43, 26],
      s,
      [44, 26],
      125,
      162,
      c,
      [541, 3],
      126,
      s,
      [129, 5],
      164,
      s,
      [72, 7],
      s,
      [132, 5],
      s,
      [133, 5],
      s,
      [52, 26],
      166,
      s,
      [58, 15],
      167,
      169,
      s,
      [72, 7],
      171,
      s,
      [72, 7],
      173,
      s,
      [72, 7],
      s,
      [65, 27],
      175,
      55,
      107,
      174,
      c,
      [255, 3],
      78,
      78,
      33,
      78,
      c,
      [599, 4],
      s,
      [78, 4],
      c,
      [599, 8],
      s,
      [85, 24],
      s,
      [87, 24],
      s,
      [86, 24],
      s,
      [88, 24],
      s,
      [104, 24],
      s,
      [105, 24],
      s,
      [106, 4],
      s,
      [113, 8],
      s,
      [117, 8],
      s,
      [118, 8],
      55,
      107,
      176,
      c,
      [198, 3],
      s,
      [135, 7],
      177,
      c,
      [394, 6],
      178,
      179,
      s,
      [41, 26],
      s,
      [127, 5],
      s,
      [128, 5],
      180,
      c,
      [45, 6],
      s,
      [131, 5],
      181,
      c,
      [927, 14],
      55,
      55,
      183,
      s,
      [55, 24],
      s,
      [56, 26],
      184,
      c,
      [80, 6],
      s,
      [63, 27],
      185,
      c,
      [34, 6],
      s,
      [64, 27],
      186,
      c,
      [34, 6],
      s,
      [62, 27],
      187,
      s,
      [74, 16],
      s,
      [134, 7],
      188,
      s,
      [26, 13],
      s,
      [27, 13],
      s,
      [130, 5],
      s,
      [53, 26],
      s,
      [57, 15],
      s,
      [54, 26],
      s,
      [59, 27],
      s,
      [60, 27],
      s,
      [61, 27],
      s,
      [73, 16],
      s,
      [25, 13]
    ])
    }),
    defaultActions: bda({
      idx: u([
      0,
      2,
      5,
      11,
      14,
      s,
      [17, 8, 1],
      28,
      s,
      [37, 9, 1],
      47,
      48,
      50,
      51,
      s,
      [54, 4, 1],
      59,
      61,
      62,
      64,
      69,
      70,
      71,
      73,
      s,
      [75, 6, 1],
      84,
      86,
      87,
      88,
      s,
      [92, 5, 1],
      s,
      [103, 4, 1],
      108,
      s,
      [110, 9, 1],
      s,
      [120, 4, 1],
      126,
      128,
      129,
      131,
      132,
      134,
      135,
      136,
      142,
      s,
      [145, 10, 1],
      156,
      160,
      161,
      162,
      164,
      s,
      [167, 5, 2],
      176,
      s,
      [178, 11, 1]
    ]),
      goto: u([
      7,
      9,
      8,
      17,
      22,
      29,
      37,
      34,
      35,
      30,
      31,
      32,
      1,
      11,
      94,
      s,
      [96, 8, 1],
      111,
      112,
      13,
      115,
      s,
      [120, 4, 1],
      15,
      18,
      19,
      21,
      2,
      39,
      40,
      42,
      s,
      [45, 6, 1],
      38,
      36,
      3,
      10,
      89,
      90,
      91,
      95,
      110,
      107,
      108,
      109,
      12,
      114,
      119,
      14,
      16,
      s,
      [66, 6, 1],
      33,
      20,
      23,
      24,
      28,
      43,
      44,
      126,
      129,
      132,
      133,
      52,
      65,
      85,
      87,
      86,
      88,
      104,
      105,
      106,
      113,
      117,
      118,
      135,
      41,
      127,
      128,
      131,
      56,
      63,
      64,
      62,
      74,
      134,
      26,
      27,
      130,
      53,
      57,
      54,
      59,
      60,
      61,
      73,
      25
    ])
    }),
    parseError: function parseError(str, hash, ExceptionClass) {
        if (hash.recoverable) {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            hash.destroy();             // destroy... well, *almost*!
        } else {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            throw new ExceptionClass(str, hash);
        }
    },
    parse: function parse(input) {
        let self = this;
        let stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
        let sstack = new Array(128);        // state stack: stores states (column storage)

        let vstack = new Array(128);        // semantic value stack
        let lstack = new Array(128);        // location stack
        let table = this.table;
        let sp = 0;                         // 'stack pointer': index into the stacks
        let yyloc;

        let symbol = 0;
        let preErrorSymbol = 0;
        let lastEofErrorStateDepth = Infinity;
        let recoveringErrorInfo = null;
        let recovering = 0;                 // (only used when the grammar contains error recovery rules)
        const TERROR = this.TERROR;
        const EOF = this.EOF;
        const ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
        const NO_ACTION = [ 0, 189 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

        let lexer;
        if (this.__lexer__) {
            lexer = this.__lexer__;
        } else {
            lexer = this.__lexer__ = Object.create(this.lexer);
        }

        let sharedState_yy = {
            parseError: undefined,
            quoteName: undefined,
            lexer: undefined,
            parser: undefined,
            pre_parse: undefined,
            post_parse: undefined,
            pre_lex: undefined,
            post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly!
        };

        const ASSERT = (
            typeof assert !== 'function' ?
                function JisonAssert(cond, msg) {
                    if (!cond) {
                        throw new Error('assertion failed: ' + (msg || '***'));
                    }
                } :
                assert
        );

        this.yyGetSharedState = function yyGetSharedState() {
            return sharedState_yy;
        };


        this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
            return recoveringErrorInfo;
        };


        // shallow clone objects & arrays, straight copy of simple `src` values
        // e.g. `lexer.yytext` MAY be a complex value object,
        // rather than a simple string/value.
        //
        // https://jsperf.com/new-array-vs-splice-vs-slice/72
        // https://jsperf.com/instanceof-vs-typeof/20
        // benchmark:: http://127.0.0.1:8080/example/jsperf/#testfile=test0020-typeof-instanceof-isArray.json5
        // benchmark:: http://127.0.0.1:8080/example/jsperf/?333#testfile=test0021-shallow-clones.json5
        //
        function shallow_copy(src) {
            if (src && typeof src === 'object') {
                // non-Object-type objects, e.g. RegExp, Date, etc., can usually be shallow cloned
                // using their constructor:
                if (src.constructor !== Object) {
                    if (Array.isArray(src)) {
                        return src.slice();
                    }
                    let dst = new src.constructor(src);

                    // and make sure all custom attributes are added to the clone:
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
                // native objects must be cloned a different way:
                {
                    //return Object.assign({}, src);
                    let dst = {};
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
            }
            return src;
        }
        // add elements from `src` to `dst` when:
        // - either the element does not yet exist in `src`
        // - or exists in `src` but is NULL or UNDEFINED there, while its value is non-NULL in `dst`
        function shallow_copy_noclobber(dst, src) {
            const chk = Object.prototype.hasOwnProperty;
            for (let k in src) {
                if (!(k in dst)) {
                    if (chk.call(src, k)) {
                        dst[k] = src[k];
                    }
                } else if (src[k] != null && dst[k] == null && chk.call(src, k)) {
                    dst[k] = src[k];
                }
            }
        }
        function copy_yylloc_native(loc) {
            let rv = shallow_copy(loc);
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            if (rv) {
                rv.range = rv.range.slice();
            }
            return rv;
        }

        // copy state
        shallow_copy_noclobber(sharedState_yy, this.yy);

        sharedState_yy.lexer = lexer;
        sharedState_yy.parser = this;

        // allow userland code to override the yytext and yylloc copy/clone functions:
        this.copy_yytext = this.options.copy_yytext || sharedState_yy.copy_yytext || shallow_copy;
        this.copy_yylloc = this.options.copy_yylloc || sharedState_yy.copy_yylloc || copy_yylloc_native;





        // *Always* setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions as it is paramount
        // to have *their* closure match ours -- if we only set them up once,
        // any subsequent `parse()` runs will fail in very obscure ways when
        // these functions are invoked in the user action code block(s) as
        // their closure will still refer to the `parse()` instance which set
        // them up. Hence we MUST set them up at the start of every `parse()` run!
        if (this.yyError) {
            this.yyError = function yyError(str /*, ...args */) {








    let error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
                let expected = this.collect_expected_token_set(state);
                let hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
                // append to the old one?
                if (recoveringErrorInfo) {
                    let esp = recoveringErrorInfo.info_stack_pointer;

                    recoveringErrorInfo.symbol_stack[esp] = symbol;
                    let v = this.shallowCopyErrorInfo(hash);
                    v.yyError = true;
                    v.errorRuleDepth = error_rule_depth;
                    v.recovering = recovering;
                    // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                    recoveringErrorInfo.value_stack[esp] = v;
                    recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;
                } else {
                    recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                    recoveringErrorInfo.yyError = true;
                    recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                    recoveringErrorInfo.recovering = recovering;
                }


                // Add any extra args to the hash under the name `extra_error_attributes`:
                let args = Array.prototype.slice.call(arguments, 1);
                if (args.length) {
                    hash.extra_error_attributes = args;
                }

                return this.parseError(str, hash, this.JisonParserError);
            };
        }







        // Does the shared state override the default `parseError` that already comes with this instance?
        if (typeof sharedState_yy.parseError === 'function') {
            this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
                if (!ExceptionClass) {
                    ExceptionClass = this.JisonParserError;
                }
                return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
            };
        } else {
            this.parseError = this.originalParseError;
        }

        // Does the shared state override the default `quoteName` that already comes with this instance?
        if (typeof sharedState_yy.quoteName === 'function') {
            this.quoteName = function quoteNameAlt(id_str) {
                return sharedState_yy.quoteName.call(this, id_str);
            };
        } else {
            this.quoteName = this.originalQuoteName;
        }

        // set up the cleanup function; make it an API so that external code can re-use this one in case of
        // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
        // case this parse() API method doesn't come with a `finally { ... }` block any more!
        //
        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `sharedState`, etc. references will be *wrong*!
        this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
            let rv;

            if (invoke_post_methods) {
                let hash;

                if (sharedState_yy.post_parse || this.post_parse) {
                    // create an error hash info instance: we re-use this API in a **non-error situation**
                    // as this one delivers all parser internals ready for access by userland code.
                    hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
                }

                if (sharedState_yy.post_parse) {
                    rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }
                if (this.post_parse) {
                    rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }

                // cleanup:
                if (hash && hash.destroy) {
                    hash.destroy();
                }
            }

            if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

            // clean up the lingering lexer structures as well:
            if (lexer.cleanupAfterLex) {
                lexer.cleanupAfterLex(do_not_nuke_errorinfos);
            }

            // prevent lingering circular references from causing memory leaks:
            if (sharedState_yy) {
                sharedState_yy.lexer = undefined;
                sharedState_yy.parser = undefined;
                if (lexer.yy === sharedState_yy) {
                    lexer.yy = undefined;
                }
            }
            sharedState_yy = undefined;
            this.parseError = this.originalParseError;
            this.quoteName = this.originalQuoteName;

            // nuke the vstack[] array at least as that one will still reference obsoleted user values.
            // To be safe, we nuke the other internal stack columns as well...
            stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
            sstack.length = 0;
            lstack.length = 0;
            vstack.length = 0;
            sp = 0;

            // nuke the error hash info instances created during this run.
            // Userland code must COPY any data/references
            // in the error hash instance(s) it is more permanently interested in.
            if (!do_not_nuke_errorinfos) {
                for (let i = this.__error_infos.length - 1; i >= 0; i--) {
                    let el = this.__error_infos[i];
                    if (el && typeof el.destroy === 'function') {
                        el.destroy();
                    }
                }
                this.__error_infos.length = 0;


                for (let i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                    let el = this.__error_recovery_infos[i];
                    if (el && typeof el.destroy === 'function') {
                        el.destroy();
                    }
                }
                this.__error_recovery_infos.length = 0;

                // `recoveringErrorInfo` is also part of the `__error_recovery_infos` array,
                // hence has been destroyed already: no need to do that *twice*.
                if (recoveringErrorInfo) {
                    recoveringErrorInfo = undefined;
                }


            }

            return resultValue;
        };

        // merge yylloc info into a new yylloc instance.
        //
        // `first_index` and `last_index` MAY be UNDEFINED/NULL or these are indexes into the `lstack[]` location stack array.
        //
        // `first_yylloc` and `last_yylloc` MAY be UNDEFINED/NULL or explicit (custom or regular) `yylloc` instances, in which
        // case these override the corresponding first/last indexes.
        //
        // `dont_look_back` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
        // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
        // yylloc info.
        //
        // Note: epsilon rule's yylloc situation is detected by passing both `first_index` and `first_yylloc` as UNDEFINED/NULL.
        this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
            let i1 = first_index | 0;
            let i2 = last_index | 0;
            let l1 = first_yylloc;
            let l2 = last_yylloc;
            let rv;

            // rules:
            // - first/last yylloc entries override first/last indexes

            if (!l1) {
                if (first_index != null) {
                    for (let i = i1; i <= i2; i++) {
                        l1 = lstack[i];
                        if (l1) {
                            break;
                        }
                    }
                }
            }

            if (!l2) {
                if (last_index != null) {
                    for (let i = i2; i >= i1; i--) {
                        l2 = lstack[i];
                        if (l2) {
                            break;
                        }
                    }
                }
            }

            // - detect if an epsilon rule is being processed and act accordingly:
            if (!l1 && first_index == null) {
                // epsilon rule span merger. With optional look-ahead in l2.
                if (!dont_look_back) {
                    for (let i = (i1 || sp) - 1; i >= 0; i--) {
                        l1 = lstack[i];
                        if (l1) {
                            break;
                        }
                    }
                }
                if (!l1) {
                    if (!l2) {
                        // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                        // without look-ahead and no preceding terms and/or `dont_look_back` set:
                        // in that case we ca do nothing but return NULL/UNDEFINED:
                        return null;
                    }
                    // shallow-copy L2: after all, we MAY be looking
                    // at unconventional yylloc info objects...
                    rv = this.copy_yylloc(l2);
                    return rv;
                }
                // shallow-copy L1, then adjust first col/row 1 column past the end.
                rv = this.copy_yylloc(l1);
                rv.first_line = rv.last_line;
                rv.first_column = rv.last_column;
                rv.range[0] = rv.range[1];

                if (l2) {
                    // shallow-mixin L2, then adjust last col/row accordingly.
                    shallow_copy_noclobber(rv, l2);
                    rv.last_line = l2.last_line;
                    rv.last_column = l2.last_column;
                    rv.range[1] = l2.range[1];
                }
                return rv;
            }

            if (!l1) {
                l1 = l2;
                l2 = null;
            }
            if (!l1) {
                return null;
            }

            // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
            // at unconventional yylloc info objects...
            rv = this.copy_yylloc(l1);

            if (l2) {
                shallow_copy_noclobber(rv, l2);
                rv.last_line = l2.last_line;
                rv.last_column = l2.last_column;
                rv.range[1] = l2.range[1];
            }

            return rv;
        };

        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
        this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
            const pei = {
                errStr: msg,
                exception: ex,
                text: lexer.match,
                value: this.copy_yytext(lexer.yytext),
                token: this.describeSymbol(symbol) || symbol,
                token_id: symbol,
                line: lexer.yylineno,
                loc: this.copy_yylloc(lexer.yylloc),
                expected,
                recoverable,
                state,
                action,
                new_state: newState,
                symbol_stack: stack,
                state_stack: sstack,
                value_stack: vstack,
                location_stack: lstack,
                stack_pointer: sp,
                yy: sharedState_yy,
                lexer,
                parser: this,

                // and make sure the error info doesn't stay due to potential
                // ref cycle via userland code manipulations.
                // These would otherwise all be memory leak opportunities!
                //
                // Note that only array and object references are nuked as those
                // constitute the set of elements which can produce a cyclic ref.
                // The rest of the members is kept intact as they are harmless.
                destroy: function destructParseErrorInfo() {
                    // remove cyclic references added to error info:
                    // info.yy = null;
                    // info.lexer = null;
                    // info.value = null;
                    // info.value_stack = null;
                    // ...
                    const rec = !!this.recoverable;
                    for (let key in this) {
                        if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                            this[key] = undefined;
                        }
                    }
                    this.recoverable = rec;
                }
            };
            // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
            this.__error_infos.push(pei);
            return pei;
        };

        // clone some parts of the (possibly enhanced!) errorInfo object
        // to give them some persistence.
        this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
            let rv = shallow_copy(p);

            // remove the large parts which can only cause cyclic references
            // and are otherwise available from the parser kernel anyway.
            delete rv.sharedState_yy;
            delete rv.parser;
            delete rv.lexer;

            // lexer.yytext MAY be a complex value object, rather than a simple string/value:
            rv.value = this.copy_yytext(rv.value);

            // yylloc info:
            rv.loc = this.copy_yylloc(rv.loc);

            // the 'expected' set won't be modified, so no need to clone it:
            //rv.expected = rv.expected.slice();

            // symbol stack is a simple array:
            rv.symbol_stack = rv.symbol_stack.slice();
            // ditto for state stack:
            rv.state_stack = rv.state_stack.slice();
            // clone the yylloc's in the location stack?:
            rv.location_stack = rv.location_stack.map(this.copy_yylloc);
            // and the value stack may carry both simple and complex values:
            // shallow-copy the latter.
            rv.value_stack = rv.value_stack.map(this.copy_yytext);

            // and we don't bother with the sharedState_yy reference:
            //delete rv.yy;

            // now we prepare for tracking the COMBINE actions
            // in the error recovery code path:
            //
            // as we want to keep the maximum error info context, we
            // *scan* the state stack to find the first *empty* slot.
            // This position will surely be AT OR ABOVE the current
            // stack pointer, but we want to keep the 'used but discarded'
            // part of the parse stacks *intact* as those slots carry
            // error context that may be useful when you want to produce
            // very detailed error diagnostic reports.
            //
            // ### Purpose of each stack pointer:
            //
            // - stack_pointer: points at the top of the parse stack
            //                  **as it existed at the time of the error
            //                  occurrence, i.e. at the time the stack
            //                  snapshot was taken and copied into the
            //                  errorInfo object.**
            // - base_pointer:  the bottom of the **empty part** of the
            //                  stack, i.e. **the start of the rest of
            //                  the stack space /above/ the existing
            //                  parse stack. This section will be filled
            //                  by the error recovery process as it
            //                  travels the parse state machine to
            //                  arrive at the resolving error recovery rule.**
            // - info_stack_pointer:
            //                  this stack pointer points to the **top of
            //                  the error recovery tracking stack space**, i.e.
            //                  this stack pointer takes up the role of
            //                  the `stack_pointer` for the error recovery
            //                  process. Any mutations in the **parse stack**
            //                  are **copy-appended** to this part of the
            //                  stack space, keeping the bottom part of the
            //                  stack (the 'snapshot' part where the parse
            //                  state at the time of error occurrence was kept)
            //                  intact.
            // - root_failure_pointer:
            //                  copy of the `stack_pointer`...
            //
            {
                let i;
                for (i = rv.stack_pointer; rv.state_stack[i] != null; i++) {
                    // empty
                }
                rv.base_pointer = i;
                rv.info_stack_pointer = i;
            }

            rv.root_failure_pointer = rv.stack_pointer;

            // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
            this.__error_recovery_infos.push(rv);

            return rv;
        };

        function getNonTerminalFromCode(symbol) {
            let tokenName = self.getSymbolName(symbol);
            if (!tokenName) {
                tokenName = symbol;
            }
            return tokenName;
        }


        function stdLex() {
            let token = lexer.lex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        function fastLex() {
            let token = lexer.fastLex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        let lex = stdLex;


        let state, action, r, t;
        let yyval = {
            $: true,
            _$: undefined,
            yy: sharedState_yy
        };
        let p;
        let yyrulelen;
        let this_production;
        let newState;
        let retval = false;


        // Return the rule stack depth where the nearest error rule can be found.
        // Return -1 when no error recovery rule was found.
        function locateNearestErrorRecoveryRule(state) {
            let stack_probe = sp - 1;
            let depth = 0;

            // try to recover from error
            while (stack_probe >= 0) {
                // check for error recovery rule in this state








    const t = (table[state] && table[state][TERROR]) || NO_ACTION;
                if (t[0]) {
                    // We need to make sure we're not cycling forever:
                    // once we hit EOF, even when we `yyerrok()` an error, we must
                    // prevent the core from running forever,
                    // e.g. when parent rules are still expecting certain input to
                    // follow after this, for example when you handle an error inside a set
                    // of braces which are matched by a parent rule in your grammar.
                    //
                    // Hence we require that every error handling/recovery attempt
                    // *after we've hit EOF* has a diminishing state stack: this means
                    // we will ultimately have unwound the state stack entirely and thus
                    // terminate the parse in a controlled fashion even when we have
                    // very complex error/recovery code interplay in the core + user
                    // action code blocks:








    if (symbol === EOF) {
                        if (lastEofErrorStateDepth > sp - 1 - depth) {
                            lastEofErrorStateDepth = sp - 1 - depth;
                        } else {








    --stack_probe; // popStack(1): [symbol, action]
                            state = sstack[stack_probe];
                            ++depth;
                            continue;
                        }
                    }
                    return depth;
                }
                if (state === 0 /* $accept rule */ || stack_probe < 1) {








    return -1; // No suitable error recovery rule available.
                }
                --stack_probe; // popStack(1): [symbol, action]
                state = sstack[stack_probe];
                ++depth;
            }








    return -1; // No suitable error recovery rule available.
        }


        try {
            this.__reentrant_call_depth++;

            lexer.setInput(input, sharedState_yy);

            // NOTE: we *assume* no lexer pre/post handlers are set up *after*
            // this initial `setInput()` call: hence we can now check and decide
            // whether we'll go with the standard, slower, lex() API or the
            // `fast_lex()` one:
            if (typeof lexer.canIUse === 'function') {
                let lexerInfo = lexer.canIUse();
                if (lexerInfo.fastLex && typeof fastLex === 'function') {
                    lex = fastLex;
                }
            }

            yyloc = this.copy_yylloc(lexer.yylloc);
            lstack[sp] = yyloc;
            vstack[sp] = null;
            sstack[sp] = 0;
            stack[sp] = 0;
            ++sp;





            if (this.pre_parse) {
                this.pre_parse.call(this, sharedState_yy);
            }
            if (sharedState_yy.pre_parse) {
                sharedState_yy.pre_parse.call(this, sharedState_yy);
            }

            newState = sstack[sp - 1];
            for (;;) {
                // retrieve state number from top of stack
                state = newState;               // sstack[sp - 1];

                // use default actions if available
                if (this.defaultActions[state]) {
                    action = 2;
                    newState = this.defaultActions[state];
                } else {
                    // The single `==` condition below covers both these `===` comparisons in a single
                    // operation:
                    //
                    //     if (symbol === null || typeof symbol === 'undefined') ...
                    if (!symbol) {
                        symbol = lex();
                    }
                    // read action for current state and first input
                    t = (table[state] && table[state][symbol]) || NO_ACTION;
                    newState = t[1];
                    action = t[0];








    // handle parse error
                    if (!action) {
                        // first see if there's any chance at hitting an error recovery rule:
                        let error_rule_depth = locateNearestErrorRecoveryRule(state);
                        let errStr = null;
                        let errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                        let expected = this.collect_expected_token_set(state);

                        if (!recovering) {
                            // Report error
                            errStr = 'Parse error';
                            if (typeof lexer.yylineno === 'number') {
                                errStr += ' on line ' + (lexer.yylineno + 1);
                            }

                            if (typeof lexer.showPosition === 'function') {
                                errStr += ':\n' + lexer.showPosition(79 - 10, 10) + '\n';
                            } else {
                                errStr += ': ';
                            }
                            if (expected.length) {
                                errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                            } else {
                                errStr += 'Unexpected ' + errSymbolDescr;
                            }

                            p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                            // DO NOT cleanup the old one before we start the new error info track:
                            // the old one will *linger* on the error stack and stay alive until we
                            // invoke the parser's cleanup API!
                            recoveringErrorInfo = this.shallowCopyErrorInfo(p);








    r = this.parseError(p.errStr, p, this.JisonParserError);
                            if (typeof r !== 'undefined') {
                                retval = r;
                                break;
                            }

                            // Protect against overly blunt userland `parseError` code which *sets*
                            // the `recoverable` flag without properly checking first:
                            // we always terminate the parse when there's no recovery rule available anyhow!
                            if (!p.recoverable || error_rule_depth < 0) {
                                break;
                            } else {
                                // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                            }
                        }








    let esp = recoveringErrorInfo.info_stack_pointer;

                        // just recovered from another error
                        if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                            // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                            yyloc = this.copy_yylloc(lexer.yylloc);

                            // SHIFT current lookahead and grab another
                            recoveringErrorInfo.symbol_stack[esp] = symbol;

                            recoveringErrorInfo.location_stack[esp] = yyloc;
                            recoveringErrorInfo.state_stack[esp] = newState; // push state
                            ++esp;

                            preErrorSymbol = 0;
                            symbol = lex();








    }

                        // try to recover from error
                        if (error_rule_depth < 0) {
                            ASSERT(recovering > 0, 'Line 1048');
                            recoveringErrorInfo.info_stack_pointer = esp;

                            // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                            // while we are still busy recovering from another error:
                            let po = this.__error_infos[this.__error_infos.length - 1];

                            // Report error
                            if (typeof lexer.yylineno === 'number') {
                                errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                            } else {
                                errStr = 'Parsing halted while starting to recover from another error';
                            }

                            if (po) {
                                errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                            } else {
                                errStr += ': ';
                            }

                            if (typeof lexer.showPosition === 'function') {
                                errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                            }
                            if (expected.length) {
                                errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                            } else {
                                errStr += 'Unexpected ' + errSymbolDescr;
                            }

                            p = this.constructParseErrorInfo(errStr, null, expected, false);
                            if (po) {
                                p.extra_error_attributes = po;
                            }

                            r = this.parseError(p.errStr, p, this.JisonParserError);
                            if (typeof r !== 'undefined') {
                                retval = r;
                            }
                            break;
                        }

                        preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                        symbol = TERROR;            // insert generic error symbol as new lookahead

                        const EXTRA_STACK_SAMPLE_DEPTH = 3;

                        // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                        recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                        if (errStr) {
                            recoveringErrorInfo.value_stack[esp] = {
                                yytext: this.copy_yytext(lexer.yytext),
                                errorRuleDepth: error_rule_depth,
                                errStr,
                                errSymbolDescr,
                                expectedStr: expected,
                                stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                            };








    } else {
                            recoveringErrorInfo.value_stack[esp] = {
                                yytext: this.copy_yytext(lexer.yytext),
                                errorRuleDepth: error_rule_depth,
                                stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                            };
                        }
                        recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                        recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                        ++esp;
                        recoveringErrorInfo.info_stack_pointer = esp;

                        yyval.$ = recoveringErrorInfo;
                        yyval._$ = undefined;

                        yyrulelen = error_rule_depth;

                        let combineState = NO_ACTION[1];








    r = this.performAction.call(yyval, yyloc, combineState, sp - 1, vstack, lstack);

                        if (typeof r !== 'undefined') {
                            retval = r;
                            break;
                        }

                        // pop off stack
                        sp -= yyrulelen;

                        // and move the top entries + discarded part of the parse stacks onto the error info stack:
                        for (let idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                            recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                            recoveringErrorInfo.value_stack[esp] = vstack[idx];
                            recoveringErrorInfo.location_stack[esp] = lstack[idx];
                            recoveringErrorInfo.state_stack[esp] = sstack[idx];
                        }

                        recoveringErrorInfo.symbol_stack[esp] = TERROR;
                        recoveringErrorInfo.value_stack[esp] = this.copy_yytext(yyval.$);
                        recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(yyval._$);

                        // goto new state = table[STATE][NONTERMINAL]
                        newState = sstack[sp - 1];

                        if (this.defaultActions[newState]) {
                            recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                        } else {
                            t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                            recoveringErrorInfo.state_stack[esp] = t[1];
                        }

                        ++esp;
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // allow N (default: 3) real symbols to be shifted before reporting a new error
                        recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;










                        // Now duplicate the standard parse machine here, at least its initial
                        // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                        // as we wish to push something special then!
                        //
                        // Run the state machine in this copy of the parser state machine
                        // until we *either* consume the error symbol (and its related information)
                        // *or* we run into another error while recovering from this one
                        // *or* we execute a `reduce` action which outputs a final parse
                        // result (yes, that MAY happen!).
                        //
                        // We stay in this secondary parse loop until we have completed
                        // the *error recovery phase* as the main parse loop (further below)
                        // is optimized for regular parse operation and DOES NOT cope with
                        // error recovery *at all*.
                        //
                        // We call the secondary parse loop just below the "slow parse loop",
                        // while the main parse loop, which is an almost-duplicate of this one,
                        // yet optimized for regular parse operation, is called the "fast
                        // parse loop".
                        //
                        // Compare this to `bison` & (vanilla) `jison`, both of which have
                        // only a single parse loop, which handles everything. Our goal is
                        // to eke out every drop of performance in the main parse loop...

                        ASSERT(recoveringErrorInfo, 'Line 1204');
                        ASSERT(symbol === TERROR, 'Line 1205');
                        ASSERT(!action, 'Line 1206');
                        let errorSymbolFromParser = true;
                        for (;;) {
                            // retrieve state number from top of stack
                            state = newState;               // sstack[sp - 1];

                            // use default actions if available
                            if (this.defaultActions[state]) {
                                action = 2;
                                newState = this.defaultActions[state];
                            } else {
                                // The single `==` condition below covers both these `===` comparisons in a single
                                // operation:
                                //
                                //     if (symbol === null || typeof symbol === 'undefined') ...
                                if (!symbol) {
                                    symbol = lex();
                                    // **Warning: Edge Case**: the *lexer* may produce
                                    // TERROR tokens of its own volition: *those* TERROR
                                    // tokens should be treated like *regular tokens*
                                    // i.e. tokens which have a lexer-provided `yyvalue`
                                    // and `yylloc`:
                                    errorSymbolFromParser = false;
                                }
                                // read action for current state and first input
                                t = (table[state] && table[state][symbol]) || NO_ACTION;
                                newState = t[1];
                                action = t[0];








    // encountered another parse error? If so, break out to main loop
                                // and take it from there!
                                if (!action) {










                                    ASSERT(recoveringErrorInfo, 'Line 1248');

                                    // Prep state variables so that upon breaking out of
                                    // this "slow parse loop" and hitting the `continue;`
                                    // statement in the outer "fast parse loop" we redo
                                    // the exact same state table lookup as the one above
                                    // so that the outer=main loop will also correctly
                                    // detect the 'parse error' state (`!action`) we have
                                    // just encountered above.
                                    newState = state;
                                    break;
                                }
                            }








    switch (action) {
                            // catch misc. parse failures:
                            default:
                                // this shouldn't happen, unless resolve defaults are off
                                //
                                // SILENTLY SIGNAL that the outer "fast parse loop" should
                                // take care of this internal error condition:
                                // prevent useless code duplication now/here.
                                break;

                            // shift:
                            case 1:
                                stack[sp] = symbol;
                                // ### Note/Warning ###
                                //
                                // The *lexer* may also produce TERROR tokens on its own,
                                // so we specifically test for the TERROR we did set up
                                // in the error recovery logic further above!
                                if (symbol === TERROR && errorSymbolFromParser) {
                                    // Push a special value onto the stack when we're
                                    // shifting the `error` symbol that is related to the
                                    // error we're recovering from.
                                    ASSERT(recoveringErrorInfo, 'Line 1305');
                                    vstack[sp] = recoveringErrorInfo;
                                    lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                                } else {
                                    ASSERT(symbol !== 0, 'Line 1309');
                                    ASSERT(preErrorSymbol === 0, 'Line 1310');
                                    vstack[sp] = lexer.yytext;
                                    lstack[sp] = this.copy_yylloc(lexer.yylloc);
                                }
                                sstack[sp] = newState; // push state

                                ++sp;

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    let tokenName = this.getSymbolName(symbol || EOF);
                                    if (!tokenName) {
                                        tokenName = symbol;
                                    }

                                    Jison.parserDebugger.push({
                                        action: 'shift',
                                        text: lexer.yytext,
                                        terminal: tokenName,
                                        terminal_id: symbol
                                    });
                                }

                                symbol = 0;
                                // **Warning: Edge Case**: the *lexer* may have produced
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided `yyvalue`
                                // and `yylloc`:
                                errorSymbolFromParser = false;
                                if (!preErrorSymbol) { // normal execution / no error
                                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                                    yyloc = this.copy_yylloc(lexer.yylloc);

                                    if (recovering > 0) {
                                        recovering--;









                                    }
                                } else {
                                    // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                    ASSERT(recovering > 0, 'Line 1352');
                                    symbol = preErrorSymbol;
                                    preErrorSymbol = 0;









                                    // read action for current state and first input
                                    t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                    if (!t[0] || symbol === TERROR) {
                                        // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                        // (simple) stuff might have been missing before the token which caused the error we're
                                        // recovering from now...
                                        //
                                        // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                        // recovery, for then this we would we idling (cycling) on the error forever.
                                        // Yes, this does not take into account the possibility that the *lexer* may have
                                        // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!









                                        symbol = 0;
                                    }
                                }

                                // once we have pushed the special ERROR token value,
                                // we REMAIN in this inner, "slow parse loop" until
                                // the entire error recovery phase has completed.
                                //
                                // ### Note About Edge Case ###
                                //
                                // Userland action code MAY already have 'reset' the
                                // error recovery phase marker `recovering` to ZERO(0)
                                // while the error symbol hasn't been shifted onto
                                // the stack yet. Hence we only exit this "slow parse loop"
                                // when *both* conditions are met!
                                ASSERT(preErrorSymbol === 0, 'Line 1383');
                                if (recovering === 0) {
                                    break;
                                }
                                continue;

                            // reduce:
                            case 2:
                                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                                yyrulelen = this_production[1];








    r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                                    let debuggableProductions = [];
                                    for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                                        let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                                        debuggableProductions.push(debuggableProduction);
                                    }

                                    // find the current nonterminal name (- nolan)
                                    let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                                    let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                                    Jison.parserDebugger.push({
                                        action: 'reduce',
                                        nonterminal: currentNonterminal,
                                        nonterminal_id: currentNonterminalCode,
                                        prereduce: prereduceValue,
                                        result: r,
                                        productions: debuggableProductions,
                                        text: yyval.$
                                    });
                                }

                                if (typeof r !== 'undefined') {
                                    // signal end of error recovery loop AND end of outer parse loop
                                    action = 3;
                                    retval = r;

                                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                        Jison.parserDebugger.push({
                                            action: 'accept',
                                            text: retval
                                        });
                                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                                    }

                                    sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                    break;
                                }

                                // pop off stack
                                sp -= yyrulelen;

                                // don't overwrite the `symbol` variable: use a local var to speed things up:
                                {
                                    let ntsymbol = this_production[0];    // push nonterminal (reduce)
                                    stack[sp] = ntsymbol;
                                    vstack[sp] = yyval.$;
                                    lstack[sp] = yyval._$;
                                    // goto new state = table[STATE][NONTERMINAL]
                                    newState = table[sstack[sp - 1]][ntsymbol];
                                    sstack[sp] = newState;
                                    ++sp;









                                }
                                continue;

                            // accept:
                            case 3:
                                retval = true;
                                // Return the `$accept` rule's `$$` result, if available.
                                //
                                // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                                // default, action):
                                //
                                //     $accept: <startSymbol> $end
                                //                  %{ $$ = $1; @$ = @1; %}
                                //
                                // which, combined with the parse kernel's `$accept` state behaviour coded below,
                                // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                                // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                                //
                                // In code:
                                //
                                //                  %{
                                //                      @$ = @1;            // if location tracking support is included
                                //                      if (typeof $1 !== 'undefined')
                                //                          return $1;
                                //                      else
                                //                          return true;           // the default parse result if the rule actions don't produce anything
                                //                  %}
                                sp--;
                                if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                    retval = vstack[sp];
                                }

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    Jison.parserDebugger.push({
                                        action: 'accept',
                                        text: retval
                                    });
                                    console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                                }

                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                break;
                            }

                            // break out of loop: we accept or fail with error
                            break;
                        }

                        // should we also break out of the regular/outer parse loop,
                        // i.e. did the parser already produce a parse result in here?!
                        // *or* did we hit an unsupported parse state, to be handled
                        // in the `switch/default` code further below?
                        ASSERT(action !== 2, 'Line 1509');
                        if (!action || action === 1) {
                            continue;
                        }
                    }


                }








    switch (action) {
                // catch misc. parse failures:
                default:
                    // this shouldn't happen, unless resolve defaults are off
                    if (action instanceof Array) {
                        p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }
                    // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                    // or a buggy LUT (LookUp Table):
                    p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;

                // shift:
                case 1:
                    stack[sp] = symbol;
                    vstack[sp] = lexer.yytext;
                    lstack[sp] = this.copy_yylloc(lexer.yylloc);
                    sstack[sp] = newState; // push state

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let tokenName = this.getSymbolName(symbol || EOF);
                        if (!tokenName) {
                            tokenName = symbol;
                        }

                        Jison.parserDebugger.push({
                            action: 'shift',
                            text: lexer.yytext,
                            terminal: tokenName,
                            terminal_id: symbol
                        });
                    }

                    ++sp;

                    symbol = 0;

                    ASSERT(preErrorSymbol === 0, 'Line 1619');         // normal execution / no error
                    ASSERT(recovering === 0, 'Line 1620');             // normal execution / no error

                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                    yyloc = this.copy_yylloc(lexer.yylloc);
                    continue;

                // reduce:
                case 2:
                    ASSERT(preErrorSymbol === 0, 'Line 1631');         // normal execution / no error
                    ASSERT(recovering === 0, 'Line 1632');             // normal execution / no error

                    this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                    yyrulelen = this_production[1];








    r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                        let debuggableProductions = [];
                        for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                            let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                            debuggableProductions.push(debuggableProduction);
                        }

                        // find the current nonterminal name (- nolan)
                        let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                        let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                        Jison.parserDebugger.push({
                            action: 'reduce',
                            nonterminal: currentNonterminal,
                            nonterminal_id: currentNonterminalCode,
                            prereduce: prereduceValue,
                            result: r,
                            productions: debuggableProductions,
                            text: yyval.$
                        });
                    }

                    if (typeof r !== 'undefined') {
                        retval = r;

                        if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                            Jison.parserDebugger.push({
                                action: 'accept',
                                text: retval
                            });
                            console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                        }

                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // don't overwrite the `symbol` variable: use a local var to speed things up:
                    {
                        let ntsymbol = this_production[0];    // push nonterminal (reduce)
                        stack[sp] = ntsymbol;
                        vstack[sp] = yyval.$;
                        lstack[sp] = yyval._$;
                        // goto new state = table[STATE][NONTERMINAL]
                        newState = table[sstack[sp - 1]][ntsymbol];
                        sstack[sp] = newState;
                        ++sp;









                    }
                    continue;

                // accept:
                case 3:
                    if (sp !== -2) {
                        retval = true;
                        // Return the `$accept` rule's `$$` result, if available.
                        //
                        // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                        // default, action):
                        //
                        //     $accept: <startSymbol> $end
                        //                  %{ $$ = $1; @$ = @1; %}
                        //
                        // which, combined with the parse kernel's `$accept` state behaviour coded below,
                        // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                        // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                        //
                        // In code:
                        //
                        //                  %{
                        //                      @$ = @1;            // if location tracking support is included
                        //                      if (typeof $1 !== 'undefined')
                        //                          return $1;
                        //                      else
                        //                          return true;           // the default parse result if the rule actions don't produce anything
                        //                  %}
                        sp--;
                        if (typeof vstack[sp] !== 'undefined') {
                            retval = vstack[sp];
                        }
                    }

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        Jison.parserDebugger.push({
                            action: 'accept',
                            text: retval
                        });
                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                    }

                    break;
                }

                // break out of loop: we accept or fail with error
                break;
            }
        } catch (ex) {
            // report exceptions through the parseError callback too, but keep the exception intact
            // if it is a known parser or lexer error which has been thrown by parseError() already:
            if (ex instanceof this.JisonParserError) {
                throw ex;
            } else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
                throw ex;
            }

            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        } finally {
            retval = this.cleanupAfterParse(retval, true, true);
            this.__reentrant_call_depth--;

            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                Jison.parserDebugger.push({
                    action: 'return',
                    text: retval
                });
                console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
            }
        }   // /finally

        return retval;
    },
    yyError: 1
    };
    parser.originalParseError = parser.parseError;
    parser.originalQuoteName = parser.quoteName;
    /* lexer generated by jison-lex 0.6.2-220 */

    /*
     * Returns a Lexer object of the following structure:
     *
     *  Lexer: {
     *    yy: {}     The so-called "shared state" or rather the *source* of it;
     *               the real "shared state" `yy` passed around to
     *               the rule actions, etc. is a direct reference!
     *
     *               This "shared context" object was passed to the lexer by way of
     *               the `lexer.setInput(str, yy)` API before you may use it.
     *
     *               This "shared context" object is passed to the lexer action code in `performAction()`
     *               so userland code in the lexer actions may communicate with the outside world
     *               and/or other lexer rules' actions in more or less complex ways.
     *
     *  }
     *
     *  Lexer.prototype: {
     *    EOF: 1,
     *    ERROR: 2,
     *
     *    yy:        The overall "shared context" object reference.
     *
     *    JisonLexerError: function(msg, hash),
     *
     *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
     *
     *               The function parameters and `this` have the following value/meaning:
     *               - `this`    : reference to the `lexer` instance.
     *                               `yy_` is an alias for `this` lexer instance reference used internally.
     *
     *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
     *                             by way of the `lexer.setInput(str, yy)` API before.
     *
     *                             Note:
     *                             The extra arguments you specified in the `%parse-param` statement in your
     *                             **parser** grammar definition file are passed to the lexer via this object
     *                             reference as member variables.
     *
     *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
     *
     *               - `YY_START`: the current lexer "start condition" state.
     *
     *    parseError: function(str, hash, ExceptionClass),
     *
     *    constructLexErrorInfo: function(error_message, is_recoverable),
     *               Helper function.
     *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
     *               See it's use in this lexer kernel in many places; example usage:
     *
     *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
     *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
     *
     *    options: { ... lexer %options ... },
     *
     *    lex: function(),
     *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
     *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
     *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
     *
     *               WARNING:
     *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
     *               any attributes already added to `yy` by the **parser** or the jison run-time;
     *               when such a collision is detected an exception is thrown to prevent the generated run-time
     *               from silently accepting this confusing and potentially hazardous situation!
     *
     *    cleanupAfterLex: function(do_not_nuke_errorinfos),
     *               Helper function.
     *
     *               This helper API is invoked when the **parse process** has completed: it is the responsibility
     *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
     *
     *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
     *
     *    setInput: function(input, [yy]),
     *
     *
     *    input: function(),
     *
     *
     *    unput: function(str),
     *
     *
     *    more: function(),
     *
     *
     *    reject: function(),
     *
     *
     *    less: function(n),
     *
     *
     *    pastInput: function(n),
     *
     *
     *    upcomingInput: function(n),
     *
     *
     *    showPosition: function(),
     *
     *
     *    test_match: function(regex_match_array, rule_index),
     *
     *
     *    next: function(),
     *
     *
     *    begin: function(condition),
     *
     *
     *    pushState: function(condition),
     *
     *
     *    popState: function(),
     *
     *
     *    topState: function(),
     *
     *
     *    _currentRules: function(),
     *
     *
     *    stateStackSize: function(),
     *
     *
     *    performAction: function(yy, yy_, yyrulenumber, YY_START),
     *
     *
     *    rules: [...],
     *
     *
     *    conditions: {associative list: name ==> set},
     *  }
     *
     *
     *  token location info (`yylloc`): {
     *    first_line: n,
     *    last_line: n,
     *    first_column: n,
     *    last_column: n,
     *    range: [start_number, end_number]
     *               (where the numbers are indexes into the input string, zero-based)
     *  }
     *
     * ---
     *
     * The `parseError` function receives a 'hash' object with these members for lexer errors:
     *
     *  {
     *    text:        (matched text)
     *    token:       (the produced terminal token, if any)
     *    token_id:    (the produced terminal token numeric ID, if any)
     *    line:        (yylineno)
     *    loc:         (yylloc)
     *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
     *                  available for this particular error)
     *    yy:          (object: the current parser internal "shared state" `yy`
     *                  as is also available in the rule actions; this can be used,
     *                  for instance, for advanced error analysis and reporting)
     *    lexer:       (reference to the current lexer instance used by the parser)
     *  }
     *
     * while `this` will reference the current lexer instance.
     *
     * When `parseError` is invoked by the lexer, the default implementation will
     * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
     * it will try to invoke `yy.parseError()` instead. When that callback is also not
     * provided, a `JisonLexerError` exception will be thrown containing the error
     * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
     *
     * Note that the lexer's `JisonLexerError` error class is passed via the
     * `ExceptionClass` argument, which is invoked to construct the exception
     * instance to be thrown, so technically `parseError` will throw the object
     * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
     *
     * ---
     *
     * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
     * These options are available:
     *
     * (Options are permanent.)
     *
     *  yy: {
     *      parseError: function(str, hash, ExceptionClass)
     *                 optional: overrides the default `parseError` function.
     *  }
     *
     *  lexer.options: {
     *      pre_lex:  function()
     *                 optional: is invoked before the lexer is invoked to produce another token.
     *                 `this` refers to the Lexer object.
     *      post_lex: function(token) { return token; }
     *                 optional: is invoked when the lexer has produced a token `token`;
     *                 this function can override the returned token value by returning another.
     *                 When it does not return any (truthy) value, the lexer will return
     *                 the original `token`.
     *                 `this` refers to the Lexer object.
     *
     * WARNING: the next set of options are not meant to be changed. They echo the abilities of
     * the lexer as per when it was compiled!
     *
     *      ranges: boolean
     *                 optional: `true` ==> token location info will include a .range[] member.
     *      flex: boolean
     *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
     *                 exhaustively to find the longest match.
     *      backtrack_lexer: boolean
     *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
     *                 the lexer terminates the scan when a token is returned by the action code.
     *      xregexp: boolean
     *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
     *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
     *                 rule regexes have been written as standard JavaScript RegExp expressions.
     *  }
     */


    var lexer = function() {

      /**
       * See also:
       * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
       * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
       * with userland code which might access the derived class in a 'classic' way.
       *
       * @public
       * @constructor
       * @nocollapse
       */
      function JisonLexerError(msg, hash) {
        Object.defineProperty(this, 'name', {
          enumerable: false,
          writable: false,
          value: 'JisonLexerError'
        });

        if (msg == null)
          msg = '???';

        Object.defineProperty(this, 'message', {
          enumerable: false,
          writable: true,
          value: msg
        });

        this.hash = hash;
        let stacktrace;

        if (hash && hash.exception instanceof Error) {
          const ex2 = hash.exception;
          this.message = ex2.message || msg;
          stacktrace = ex2.stack;
        }

        if (!stacktrace) {
          if (Error.hasOwnProperty('captureStackTrace')) {
            // V8
            Error.captureStackTrace(this, this.constructor);
          } else {
            stacktrace = new Error(msg).stack;
          }
        }

        if (stacktrace) {
          Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
          });
        }
      }

      if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
      } else {
        JisonLexerError.prototype = Object.create(Error.prototype);
      }

      JisonLexerError.prototype.constructor = JisonLexerError;
      JisonLexerError.prototype.name = 'JisonLexerError';

      const lexer = {
        
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   backtracking: .................... false
    //   location.ranges: ................. true
    //   location line+column tracking: ... true
    //
    //
    // Forwarded Parser Analysis flags:
    //
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses lexer values: ............... true / true
    //   location tracking: ............... true
    //   location assignment: ............. true
    //
    //
    // Lexer Analysis flags:
    //
    //   uses yyleng: ..................... ???
    //   uses yylineno: ................... ???
    //   uses yytext: ..................... ???
    //   uses yylloc: ..................... ???
    //   uses ParseError API: ............. ???
    //   uses yyerror: .................... ???
    //   uses location tracking & editing:  ???
    //   uses more() API: ................. ???
    //   uses unput() API: ................ ???
    //   uses reject() API: ............... ???
    //   uses less() API: ................. ???
    //   uses display APIs pastInput(), upcomingInput(), showPosition():
    //        ............................. ???
    //   uses describeYYLLOC() API: ....... ???
    //
    // --------- END OF REPORT -----------


        EOF: 1,

        ERROR: 2,

        // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

        // options: {},                             /// <-- injected by the code generator

        // yy: ...,                                 /// <-- injected by setInput()

        /// INTERNAL USE ONLY: internal rule set cache for the current lexer state
        __currentRuleSet__: null,

        /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup
        __error_infos: [],

        /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use
        __decompressed: false,

        /// INTERNAL USE ONLY
        done: false,

        /// INTERNAL USE ONLY
        _backtrack: false,

        /// INTERNAL USE ONLY
        _input: '',

        /// INTERNAL USE ONLY
        _more: false,

        /// INTERNAL USE ONLY
        _signaled_error_token: false,

        /// INTERNAL USE ONLY; 0: clear to do, 1: clear done for lex()/next(); -1: clear done for inut()/unput()/...
        _clear_state: 0,

        /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`
        conditionStack: [],

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!
        match: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
        matched: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
        matches: false,

        /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.
        yytext: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far. (**WARNING:** this value MAY be negative if you `unput()` more text than you have already lexed. This type of behaviour is generally observed for one kind of 'lexer/parser hack' where custom token-illiciting characters are pushed in front of the input stream to help simulate multiple-START-points in the parser. When this happens, `base_position` will be adjusted to help track the original input's starting point in the `_input` buffer.)
        offset: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: index to the original starting point of the input; always ZERO(0) unless `unput()` has pushed content before the input: see the `offset` **WARNING** just above.
        base_position: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)
        yyleng: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
        yylineno: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction
        yylloc: null,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: regex used to split lines while tracking the lexer cursor position.
        CRLF_Re: /\r\n?|\n/,

        /**
             * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
             *
             * @public
             * @this {RegExpLexer}
             */
        constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
          msg = '' + msg;

          // heuristic to determine if the error message already contains a (partial) source code dump
          // as produced by either `showPosition()` or `prettyPrintRange()`:
          if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
          }

          if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
              const pretty_src = this.prettyPrintRange(this.yylloc);

              if (!/\n\s*$/.test(msg)) {
                msg += '\n';
              }

              msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
            } else if (typeof this.showPosition === 'function') {
              const pos_str = this.showPosition();

              if (pos_str) {
                if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
                  msg += '\n' + pos_str;
                } else {
                  msg += pos_str;
                }
              }
            }
          }

          /** @constructor */
          const pei = {
            errStr: msg,
            recoverable: !!recoverable,

            // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...
            text: this.match,

            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
                         * and make sure the error info doesn't stay due to potential
                         * ref cycle via userland code manipulations.
                         * These would otherwise all be memory leak opportunities!
                         *
                         * Note that only array and object references are nuked as those
                         * constitute the set of elements which can produce a cyclic ref.
                         * The rest of the members is kept intact as they are harmless.
                         *
                         * @public
                         * @this {LexErrorInfo}
                         */
            destroy: function destructLexErrorInfo() {
              // remove cyclic references added to error info:
              // info.yy = null;
              // info.lexer = null;
              // ...
              const rec = !!this.recoverable;

              for (let key in this) {
                if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                  this[key] = undefined;
                }
              }

              this.recoverable = rec;
            }
          };

          // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
          this.__error_infos.push(pei);

          return pei;
        },

        /**
             * handler which is invoked when a lexer error occurs.
             *
             * @public
             * @this {RegExpLexer}
             */
        parseError: function lexer_parseError(str, hash, ExceptionClass) {
          if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
          }

          if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
              return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
              return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            }
          }

          throw new ExceptionClass(str, hash);
        },

        /**
             * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
             *
             * @public
             * @this {RegExpLexer}
             */
        yyerror: function yyError(str /*, ...args */) {
          let lineno_msg = 'Lexical error';

          if (this.yylloc) {
            lineno_msg += ' on line ' + (this.yylineno + 1);
          }

          const p = this.constructLexErrorInfo(lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

          // Add any extra args to the hash under the name `extra_error_attributes`:
          let args = Array.prototype.slice.call(arguments, 1);

          if (args.length) {
            p.extra_error_attributes = args;
          }

          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        },

        /**
             * final cleanup function for when we have completed lexing the input;
             * make it an API so that external code can use this one once userland
             * code has decided it's time to destroy any lingering lexer error
             * hash object instances and the like: this function helps to clean
             * up these constructs, which *may* carry cyclic references which would
             * otherwise prevent the instances from being properly and timely
             * garbage-collected, i.e. this function helps prevent memory leaks!
             *
             * @public
             * @this {RegExpLexer}
             */
        cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
          // prevent lingering circular references from causing memory leaks:
          this.setInput('', {});

          // nuke the error hash info instances created during this run.
          // Userland code must COPY any data/references
          // in the error hash instance(s) it is more permanently interested in.
          if (!do_not_nuke_errorinfos) {
            for (let i = this.__error_infos.length - 1; i >= 0; i--) {
              let el = this.__error_infos[i];

              if (el && typeof el.destroy === 'function') {
                el.destroy();
              }
            }

            this.__error_infos.length = 0;
          }

          return this;
        },

        /**
             * clear the lexer token context; intended for internal use only
             *
             * @public
             * @this {RegExpLexer}
             */
        clear: function lexer_clear() {
          this.yytext = '';
          this.yyleng = 0;
          this.match = '';

          // - DO NOT reset `this.matched`
          this.matches = false;

          this._more = false;
          this._backtrack = false;
          const col = this.yylloc.last_column;

          this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,
            range: [this.offset, this.offset]
          };
        },

        /**
             * resets the lexer, sets new input
             *
             * @public
             * @this {RegExpLexer}
             */
        setInput: function lexer_setInput(input, yy) {
          this.yy = yy || this.yy || {};

          // also check if we've fully initialized the lexer instance,
          // including expansion work to be done to go from a loaded
          // lexer to a usable lexer:
          if (!this.__decompressed) {
            // step 1: decompress the regex list:
            let rules = this.rules;

            for (var i = 0, len = rules.length; i < len; i++) {
              var rule_re = rules[i];

              // compression: is the RE an xref to another RE slot in the rules[] table?
              if (typeof rule_re === 'number') {
                rules[i] = rules[rule_re];
              }
            }

            // step 2: unfold the conditions[] set to make these ready for use:
            let conditions = this.conditions;

            for (let k in conditions) {
              let spec = conditions[k];
              let rule_ids = spec.rules;
              var len = rule_ids.length;
              let rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
              let rule_new_ids = new Array(len + 1);

              for (var i = 0; i < len; i++) {
                let idx = rule_ids[i];
                var rule_re = rules[idx];
                rule_regexes[i + 1] = rule_re;
                rule_new_ids[i + 1] = idx;
              }

              spec.rules = rule_new_ids;
              spec.__rule_regexes = rule_regexes;
              spec.__rule_count = len;
            }

            this.__decompressed = true;
          }

          if (input && typeof input !== 'string') {
            input = '' + input;
          }

          this._input = input || '';
          this._clear_state = -1;
          this._signaled_error_token = false;
          this.done = false;
          this.yylineno = 0;
          this.matched = '';
          this.conditionStack = ['INITIAL'];
          this.__currentRuleSet__ = null;

          this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          this.offset = 0;
          this.base_position = 0;

          // apply these bits of `this.clear()` as well:
          this.yytext = '';

          this.yyleng = 0;
          this.match = '';
          this.matches = false;
          this._more = false;
          this._backtrack = false;
          return this;
        },

        /**
             * edit the remaining input via user-specified callback.
             * This can be used to forward-adjust the input-to-parse,
             * e.g. inserting macro expansions and alike in the
             * input which has yet to be lexed.
             * The behaviour of this API contrasts the `unput()` et al
             * APIs as those act on the *consumed* input, while this
             * one allows one to manipulate the future, without impacting
             * the current `yyloc` cursor location or any history.
             *
             * Use this API to help implement C-preprocessor-like
             * `#include` statements, etc.
             *
             * The provided callback must be synchronous and is
             * expected to return the edited input (string).
             *
             * The `cpsArg` argument value is passed to the callback
             * as-is.
             *
             * `callback` interface:
             * `function callback(input, cpsArg)`
             *
             * - `input` will carry the remaining-input-to-lex string
             *   from the lexer.
             * - `cpsArg` is `cpsArg` passed into this API.
             *
             * The `this` reference for the callback will be set to
             * reference this lexer instance so that userland code
             * in the callback can easily and quickly access any lexer
             * API.
             *
             * When the callback returns a non-string-type falsey value,
             * we assume the callback did not edit the input and we
             * will using the input as-is.
             *
             * When the callback returns a non-string-type value, it
             * is converted to a string for lexing via the `"" + retval`
             * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html
             * -- that way any returned object's `toValue()` and `toString()`
             * methods will be invoked in a proper/desirable order.)
             *
             * @public
             * @this {RegExpLexer}
             */
        editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
          const rv = callback.call(this, this._input, cpsArg);

          if (typeof rv !== 'string') {
            if (rv) {
              this._input = '' + rv;
            }
            // else: keep `this._input` as is.
          } else {
            this._input = rv;
          }

          return this;
        },

        /**
             * consumes and returns one char from the input
             *
             * @public
             * @this {RegExpLexer}
             */
        input: function lexer_input() {
          if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
          }

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          let ch = this._input[0];
          this.yytext += ch;
          this.yyleng++;
          this.offset++;
          this.match += ch;
          this.matched += ch;

          // Count the linenumber up when we hit the LF (or a stand-alone CR).
          // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
          // and we advance immediately past the LF as well, returning both together as if
          // it was all a single 'character' only.
          let slice_len = 1;

          let lines = false;

          if (ch === '\n') {
            lines = true;
          } else if (ch === '\r') {
            lines = true;
            const ch2 = this._input[1];

            if (ch2 === '\n') {
              slice_len++;
              ch += ch2;
              this.yytext += ch2;
              this.yyleng++;
              this.offset++;
              this.match += ch2;
              this.matched += ch2;
              this.yylloc.range[1]++;
            }
          }

          if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
          } else {
            this.yylloc.last_column++;
          }

          this.yylloc.range[1]++;
          this._input = this._input.slice(slice_len);
          return ch;
        },

        /**
             * unshifts one char (or an entire string) into the input
             *
             * @public
             * @this {RegExpLexer}
             */
        unput: function lexer_unput(ch) {
          let len = ch.length;
          let lines = ch.split(this.CRLF_Re);

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          this._input = ch + this._input;
          this.yytext = this.yytext.substr(0, this.yytext.length - len);
          this.yyleng = this.yytext.length;
          this.offset -= len;

          // **WARNING:**
          // The `offset` value MAY be negative if you `unput()` more text than you have already lexed.
          // This type of behaviour is generally observed for one kind of 'lexer/parser hack'
          // where custom token-illiciting characters are pushed in front of the input stream to help
          // simulate multiple-START-points in the parser.
          // When this happens, `base_position` will be adjusted to help track the original input's
          // starting point in the `_input` buffer.
          if (-this.offset > this.base_position) {
            this.base_position = -this.offset;
          }

          this.match = this.match.substr(0, this.match.length - len);
          this.matched = this.matched.substr(0, this.matched.length - len);

          if (lines.length > 1) {
            this.yylineno -= lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the `pre_lines[]` array's
            // last index slot; we don't mind when other previously
            // matched lines end up in the array too.
            let pre = this.match;

            let pre_lines = pre.split(this.CRLF_Re);

            if (pre_lines.length === 1) {
              pre = this.matched;
              pre_lines = pre.split(this.CRLF_Re);
            }

            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
          } else {
            this.yylloc.last_column -= len;
          }

          this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
          this.done = false;
          return this;
        },

        /**
             * return the upcoming input *which has not been lexed yet*.
             * This can, for example, be used for custom look-ahead inspection code
             * in your lexer.
             *
             * The entire pending input string is returned.
             *
             * > ### NOTE ###
             * >
             * > When augmenting error reports and alike, you might want to
             * > look at the `upcomingInput()` API instead, which offers more
             * > features for limited input extraction and which includes the
             * > part of the input which has been lexed by the last token a.k.a.
             * > the *currently lexed* input.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        lookAhead: function lexer_lookAhead() {
          return this._input || '';
        },

        /**
             * cache matched text and append it on next action
             *
             * @public
             * @this {RegExpLexer}
             */
        more: function lexer_more() {
          this._more = true;
          return this;
        },

        /**
             * signal the lexer that this rule fails to match the input, so the
             * next matching rule (regex) should be tested instead.
             *
             * @public
             * @this {RegExpLexer}
             */
        reject: function lexer_reject() {
          if (this.options.backtrack_lexer) {
            this._backtrack = true;
          } else {
            // when the `parseError()` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // `.lex()` run.
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
              false
            );

            this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
          }

          return this;
        },

        /**
             * retain first n characters of the match
             *
             * @public
             * @this {RegExpLexer}
             */
        less: function lexer_less(n) {
          return this.unput(this.match.slice(n));
        },

        /**
             * return (part of the) already matched input, i.e. for error
             * messages.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of
             * input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that has already been lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * @public
             * @this {RegExpLexer}
             */
        pastInput: function lexer_pastInput(maxSize, maxLines) {
          let past = this.matched.substring(0, this.matched.length - this.match.length);

          if (maxSize < 0) {
            maxSize = Infinity;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = Infinity;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substr` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          past = past.substr(-maxSize * 2 - 2);

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = past.split(this.CRLF_Re);

          a = a.slice(-maxLines);
          past = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis prefix...
          if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
          }

          return past;
        },

        /**
             * return (part of the) upcoming input *including* the input
             * matched by the last token (see also the NOTE below).
             * This can be used to augment error messages, for example.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that is yet to be lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * > ### NOTE ###
             * >
             * > *"upcoming input"* is defined as the whole of the both
             * > the *currently lexed* input, together with any remaining input
             * > following that. *"currently lexed"* input is the input
             * > already recognized by the lexer but not yet returned with
             * > the lexer token. This happens when you are invoking this API
             * > from inside any lexer rule action code block.
             * >
             * > When you want access to the 'upcoming input' in that you want access
             * > to the input *which has not been lexed yet* for look-ahead
             * > inspection or likewise purposes, please consider using the
             * > `lookAhead()` API instead.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
          let next = this.match;
          let source = this._input || '';

          if (maxSize < 0) {
            maxSize = next.length + source.length;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = maxSize;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substring` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          if (next.length < maxSize * 2 + 2) {
            next += source.substring(0, maxSize * 2 + 2 - next.length);  // substring is faster on Chrome/V8
          }

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = next.split(this.CRLF_Re, maxLines + 1);     // stop splitting once we have reached just beyond the reuired number of lines.

          a = a.slice(0, maxLines);
          next = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis postfix...
          if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
          }

          return next;
        },

        /**
             * return a string which displays the character position where the
             * lexing error occurred, i.e. for error messages
             *
             * @public
             * @this {RegExpLexer}
             */
        showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
          const pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
          let c = new Array(pre.length + 1).join('-');
          return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
        },

        /**
             * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
             * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
             * it MAY be NULL) and you MUST have a valid location info object anyway:
             * then we take the given context of the `preceding` and `following` locations, IFF those are available,
             * and reconstruct the `actual` location info from those.
             * If this fails, the heuristic is to take the `current` location, IFF available.
             * If this fails as well, we assume the sought location is at/around the current lexer position
             * and then produce that one as a response. DO NOTE that these heuristic/derived location info
             * values MAY be inaccurate!
             *
             * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
             * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
             *
             * @public
             * @this {RegExpLexer}
             */
        deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
          let loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
              loc.range[0] = actual.range[0] | 0;
              loc.range[1] = actual.range[1] | 0;
            }
          }

          if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
              loc.first_line = preceding.last_line | 0;
              loc.first_column = preceding.last_column | 0;

              if (preceding.range) {
                loc.range[0] = actual.range[1] | 0;
              }
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
              loc.last_line = following.first_line | 0;
              loc.last_column = following.first_column | 0;

              if (following.range) {
                loc.range[1] = actual.range[0] | 0;
              }
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
              loc.first_line = current.first_line | 0;
              loc.first_column = current.first_column | 0;

              if (current.range) {
                loc.range[0] = current.range[0] | 0;
              }
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
              loc.last_line = current.last_line | 0;
              loc.last_column = current.last_column | 0;

              if (current.range) {
                loc.range[1] = current.range[1] | 0;
              }
            }
          }

          // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
          // or plan D heuristics to produce a 'sensible' last_line value:
          if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
              loc.first_line = this.yylloc.first_line;
              loc.last_line = this.yylloc.last_line;
              loc.first_column = this.yylloc.first_column;
              loc.last_column = this.yylloc.last_column;
              loc.range[0] = this.yylloc.range[0];
              loc.range[1] = this.yylloc.range[1];
            } else {
              loc.last_line = this.yylloc.last_line;
              loc.last_column = this.yylloc.last_column;
              loc.range[1] = this.yylloc.range[1];
            }
          }

          if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;
            loc.range[1] = loc.range[0];
          }

          if (loc.first_column < 0) {
            loc.first_column = 0;
          }

          if (loc.last_column < 0) {
            loc.last_column = loc.first_column > 0 ? loc.first_column : 80;
          }

          return loc;
        },

        /**
             * return a string which displays the lines & columns of input which are referenced
             * by the given location info range, plus a few lines of context.
             *
             * This function pretty-prints the indicated section of the input, with line numbers
             * and everything!
             *
             * This function is very useful to provide highly readable error reports, while
             * the location range may be specified in various flexible ways:
             *
             * - `loc` is the location info object which references the area which should be
             *   displayed and 'marked up': these lines & columns of text are marked up by `^`
             *   characters below each character in the entire input range.
             *
             * - `context_loc` is the *optional* location info object which instructs this
             *   pretty-printer how much *leading* context should be displayed alongside
             *   the area referenced by `loc`. This can help provide context for the displayed
             *   error, etc.
             *
             *   When this location info is not provided, a default context of 3 lines is
             *   used.
             *
             * - `context_loc2` is another *optional* location info object, which serves
             *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
             *   context lines to display in the pretty-print output.
             *
             *   When this location info is not provided, a default context of 1 line only is
             *   used.
             *
             * Special Notes:
             *
             * - when the `loc`-indicated range is very large (about 5 lines or more), then
             *   only the first and last few lines of this block are printed while a
             *   `...continued...` message will be printed between them.
             *
             *   This serves the purpose of not printing a huge amount of text when the `loc`
             *   range happens to be huge: this way a manageable & readable output results
             *   for arbitrary large ranges.
             *
             * - this function can display lines of input which whave not yet been lexed.
             *   `prettyPrintRange()` can access the entire input!
             *
             * @public
             * @this {RegExpLexer}
             */
        prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
          loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
          const CONTEXT = 3;
          const CONTEXT_TAIL = 1;
          const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
          let input = this.matched + (this._input || '');
          let lines = input.split('\n');
          let l0 = Math.max(1, context_loc ? context_loc.first_line : loc.first_line - CONTEXT);
          let l1 = Math.max(1, context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL);
          let lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
          let ws_prefix = new Array(lineno_display_width).join(' ');
          let nonempty_line_indexes = [[], [], []];

          let rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            let lno = index + l0;
            let lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            let rv = lno_pfx + ': ' + line;
            let errpfx = new Array(lineno_display_width + 1).join('^');
            let offset = 2 + 1;
            let len = 0;

            if (lno === loc.first_line) {
              offset += loc.first_column;

              len = Math.max(
                2,
                (lno === loc.last_line ? loc.last_column : line.length) - loc.first_column + 1
              );
            } else if (lno === loc.last_line) {
              len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
              len = Math.max(2, line.length + 1);
            }

            let nli;

            if (len) {
              let lead = new Array(offset).join('.');
              let mark = new Array(len).join('^');
              rv += '\n' + errpfx + lead + mark;
              nli = 1;
            } else if (lno < loc.first_line) {
              nli = 0;
            } else if (lno > loc.last_line) {
              nli = 2;
            }

            if (line.trim().length > 0) {
              nonempty_line_indexes[nli].push(index);
            }

            rv = rv.replace(/\t/g, ' ');
            return rv;
          });

          // now make sure we don't print an overly large amount of lead/error/tail area: limit it
          // to the top and bottom line count:
          for (let i = 0; i <= 2; i++) {
            let line_arr = nonempty_line_indexes[i];

            if (line_arr.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
              let clip_start = line_arr[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
              let clip_end = line_arr[line_arr.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
              let intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';

              if (i === 1) {
                intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
              }

              rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
            }
          }

          return rv.join('\n');
        },

        /**
             * helper function, used to produce a human readable description as a string, given
             * the input `yylloc` location object.
             *
             * Set `display_range_too` to TRUE to include the string character index position(s)
             * in the description if the `yylloc.range` is available.
             *
             * @public
             * @this {RegExpLexer}
             */
        describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
          let l1 = yylloc.first_line;
          let l2 = yylloc.last_line;
          let c1 = yylloc.first_column;
          let c2 = yylloc.last_column;
          let dl = l2 - l1;
          let dc = c2 - c1;
          let rv;

          if (dl === 0) {
            rv = 'line ' + l1 + ', ';

            if (dc <= 1) {
              rv += 'column ' + c1;
            } else {
              rv += 'columns ' + c1 + ' .. ' + c2;
            }
          } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
          }

          if (yylloc.range && display_range_too) {
            let r1 = yylloc.range[0];
            let r2 = yylloc.range[1] - 1;

            if (r2 <= r1) {
              rv += ' {String Offset: ' + r1 + '}';
            } else {
              rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
          }

          return rv;
        },

        /**
             * test the lexed token: return FALSE when not a match, otherwise return token.
             *
             * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
             * contains the actually matched text string.
             *
             * Also move the input cursor forward and update the match collectors:
             *
             * - `yytext`
             * - `yyleng`
             * - `match`
             * - `matches`
             * - `yylloc`
             * - `offset`
             *
             * @public
             * @this {RegExpLexer}
             */
        test_match: function lexer_test_match(match, indexed_rule) {
          let backup;

          if (this.options.backtrack_lexer) {
            // save context
            backup = {
              yylineno: this.yylineno,

              yylloc: {
                first_line: this.yylloc.first_line,
                last_line: this.yylloc.last_line,
                first_column: this.yylloc.first_column,
                last_column: this.yylloc.last_column,
                range: this.yylloc.range.slice()
              },

              yytext: this.yytext,
              match: this.match,
              matches: this.matches,
              matched: this.matched,
              yyleng: this.yyleng,
              offset: this.offset,
              _more: this._more,
              _input: this._input,

              //_signaled_error_token: this._signaled_error_token,
              yy: this.yy,

              conditionStack: this.conditionStack.slice(),
              done: this.done
            };
          }

          let match_str = match[0];
          let match_str_len = match_str.length;
          let lines = match_str.split(this.CRLF_Re);

          if (lines.length > 1) {
            this.yylineno += lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;
            this.yylloc.last_column = lines[lines.length - 1].length;
          } else {
            this.yylloc.last_column += match_str_len;
          }

          this.yytext += match_str;
          this.match += match_str;
          this.matched += match_str;
          this.matches = match;
          this.yyleng = this.yytext.length;
          this.yylloc.range[1] += match_str_len;

          // previous lex rules MAY have invoked the `more()` API rather than producing a token:
          // those rules will already have moved this `offset` forward matching their match lengths,
          // hence we must only add our own match length now:
          this.offset += match_str_len;

          this._more = false;
          this._backtrack = false;
          this._input = this._input.slice(match_str_len);

          // calling this method:
          //
          //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
          let token = this.performAction.call(
            this,
            this.yy,
            indexed_rule,
            this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
          );

          // otherwise, when the action codes are all simple return token statements:
          //token = this.simpleCaseActionClusters[indexed_rule];

          if (this.done && this._input) {
            this.done = false;
          }

          if (token) {
            return token;
          } else if (this._backtrack) {
            // recover context
            for (let k in backup) {
              this[k] = backup[k];
            }

            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
          } else if (this._signaled_error_token) {
            // produce one 'error' token as `.parseError()` in `reject()`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;

            this._signaled_error_token = false;
            return token;
          }

          return false;
        },

        /**
             * return next match in input
             *
             * @public
             * @this {RegExpLexer}
             */
        next: function lexer_next() {
          if (this.done) {
            this.clear();
            return this.EOF;
          }

          if (!this._input) {
            this.done = true;
          }

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          let spec = this.__currentRuleSet__;

          if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();

            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
              let lineno_msg = '';

              if (this.yylloc) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
              }

              const p = this.constructLexErrorInfo(
                'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
                false
              );

              // produce one 'error' token until this situation has been resolved, most probably by parse termination!
              return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
            }
          }

          {
            let rule_ids = spec.rules;
            let regexes = spec.__rule_regexes;
            let len = spec.__rule_count;
            let match;
            let index;

            // Note: the arrays are 1-based, while `len` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (let i = 1; i <= len; i++) {
              let tempMatch = this._input.match(regexes[i]);

              if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;

                if (this.options.backtrack_lexer) {
                  let token = this.test_match(tempMatch, rule_ids[i]);

                  if (token !== false) {
                    return token;
                  } else if (this._backtrack) {
                    match = undefined;
                    continue; // rule action called reject() implying a rule MISmatch.
                  } else {
                    // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                    return false;
                  }
                } else if (!this.options.flex) {
                  break;
                }
              }
            }

            if (match) {
              let token = this.test_match(match, rule_ids[index]);

              if (token !== false) {
                return token;
              }

              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          }

          if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
          }

          {
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': Unrecognized text.',
              this.options.lexerErrorsAreRecoverable
            );

            let pendingInput = this._input;
            let activeCondition = this.topState();
            let conditionStackDepth = this.conditionStack.length;
            let token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

            if (token === this.ERROR) {
              // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
              // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
              // has not consumed/modified any pending input or changed state in the error handler:
              if (!this.matches && // and make sure the input has been modified/consumed ...
              pendingInput === this._input && // ...or the lexer state has been modified significantly enough
              // to merit a non-consuming error handling action right now.
              activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
                this.input();
              }
            }

            return token;
          }
        },

        /**
             * return next match that has a token
             *
             * @public
             * @this {RegExpLexer}
             */
        lex: function lexer_lex() {
          let r;

          //this._clear_state = 0;

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
          if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
          }

          if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
          }

          if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
          }

          while (!r) {
            r = this.next();
          }

          if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
          }

          if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
          }

          if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return next match that has a token. Identical to the `lex()` API but does not invoke any of the
             * `pre_lex()` nor any of the `post_lex()` callbacks.
             *
             * @public
             * @this {RegExpLexer}
             */
        fastLex: function lexer_fastLex() {
          let r;

          //this._clear_state = 0;

          while (!r) {
            r = this.next();
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return info about the lexer state that can help a parser or other lexer API user to use the
             * most efficient means available. This API is provided to aid run-time performance for larger
             * systems which employ this lexer.
             *
             * @public
             * @this {RegExpLexer}
             */
        canIUse: function lexer_canIUse() {
          const rv = {
            fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
          };

          return rv;
        },

        /**
             * backwards compatible alias for `pushState()`;
             * the latter is symmetrical with `popState()` and we advise to use
             * those APIs in any modern lexer code, rather than `begin()`.
             *
             * @public
             * @this {RegExpLexer}
             */
        begin: function lexer_begin(condition) {
          return this.pushState(condition);
        },

        /**
             * activates a new lexer condition state (pushes the new lexer
             * condition state onto the condition stack)
             *
             * @public
             * @this {RegExpLexer}
             */
        pushState: function lexer_pushState(condition) {
          this.conditionStack.push(condition);
          this.__currentRuleSet__ = null;
          return this;
        },

        /**
             * pop the previously active lexer condition state off the condition
             * stack
             *
             * @public
             * @this {RegExpLexer}
             */
        popState: function lexer_popState() {
          const n = this.conditionStack.length - 1;

          if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
          }

          return this.conditionStack[0];
        },

        /**
             * return the currently active lexer condition state; when an index
             * argument is provided it produces the N-th previous condition state,
             * if available
             *
             * @public
             * @this {RegExpLexer}
             */
        topState: function lexer_topState(n) {
          n = this.conditionStack.length - 1 - Math.abs(n || 0);

          if (n >= 0) {
            return this.conditionStack[n];
          }

          return 'INITIAL';
        },

        /**
             * (internal) determine the lexer rule set which is active for the
             * currently active lexer condition state
             *
             * @public
             * @this {RegExpLexer}
             */
        _currentRules: function lexer__currentRules() {
          const n = this.conditionStack.length - 1;
          let state;

          if (n >= 0) {
            state = this.conditionStack[n];
          } else {
            state = 'INITIAL';
          }

          return this.conditions[state] || this.conditions.INITIAL;
        },

        /**
             * return the number of states currently on the stack
             *
             * @public
             * @this {RegExpLexer}
             */
        stateStackSize: function lexer_stateStackSize() {
          return this.conditionStack.length;
        },

        options: {
          xregexp: true,
          ranges: true,
          trackPosition: true,
          easy_keyword_rules: true
        },

        JisonLexerError: JisonLexerError,

        performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
          var yy_ = this;

          switch (yyrulenumber) {
          case 0:
            /*! Conditions:: INITIAL macro options rules */
            /*! Rule::       \/\/[^\r\n]* */
            /* skip single-line comment */
            break;
          case 1:
            /*! Conditions:: INITIAL macro options rules */
            /*! Rule::       \/\*[^]*?\*\/ */
            /* skip multi-line comment */
            break;
          case 2:
            /*! Conditions:: action */
            /*! Rule::       %\{([^]*?)%\}(?!\}) */
            yy_.yytext = this.matches[1];

            yy.include_command_allowed = false;
            return 35;
          case 3:
            /*! Conditions:: action */
            /*! Rule::       %include\b */
            if (yy.include_command_allowed) {
              // This is an include instruction in place of (part of) an action:
              this.pushState('options');

              return 30;
            } else {
              // TODO
              yy_.yyerror(rmCommonWS`
                                                %include statements must occur on a line on their own and cannot occur inside an action code block.
                                                Its use is not permitted at this position.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

              return 36;
            }
          case 4:
            /*! Conditions:: action */
            /*! Rule::       \/\*[^]*?\*\/ */
            //yy.include_command_allowed = false; -- doesn't impact include-allowed state
            return 35;
          case 5:
            /*! Conditions:: action */
            /*! Rule::       \/\/.* */
            yy.include_command_allowed = false;

            return 35;
          case 6:
            /*! Conditions:: action */
            /*! Rule::       \| */
            if (yy.depth === 0) {
              this.popState();
              this.unput(yy_.yytext);

              // yy_.yytext = '';    --- ommitted as this is the side-effect of .unput(yy_.yytext) already!
              return 23;
            } else {
              return 35;
            }
          case 7:
            /*! Conditions:: action */
            /*! Rule::       %% */
            if (yy.depth === 0) {
              this.popState();
              this.unput(yy_.yytext);

              // yy_.yytext = '';    --- ommitted as this is the side-effect of .unput(yy_.yytext) already!
              return 23;
            } else {
              return 35;
            }
          case 8:
            /*! Conditions:: action */
            /*! Rule::       \/(?=\s) */
            return 35;       // most probably a `/` divide operator. 
          case 9:
            /*! Conditions:: action */
            /*! Rule::       \/.* */
            {
              yy.include_command_allowed = false;
              let l = scanRegExp(yy_.yytext);

              if (l > 0) {
                this.unput(yy_.yytext.substring(l));
                yy_.yytext = yy_.yytext.substring(0, l);
              } else {
                // assume it's a division operator:
                this.unput(yy_.yytext.substring(1));

                yy_.yytext = yy_.yytext[0];
              }

              return 35;
            }
          case 10:
            /*! Conditions:: action */
            /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}"|'{QUOTED_STRING_CONTENT}'|`{ES2017_STRING_CONTENT}` */
            yy.include_command_allowed = false;

            return 35;
          case 11:
            /*! Conditions:: action */
            /*! Rule::       [^/"'`%\{\}\/{BR}]+ */
            yy.include_command_allowed = false;

            return 35;
          case 12:
            /*! Conditions:: action */
            /*! Rule::       % */
            yy.include_command_allowed = false;

            return 35;
          case 13:
            /*! Conditions:: action */
            /*! Rule::       \{ */
            yy.depth++;

            yy.include_command_allowed = false;
            return 35;
          case 14:
            /*! Conditions:: action */
            /*! Rule::       \} */
            yy.include_command_allowed = false;

            if (yy.depth <= 0) {
              yy_.yyerror(rmCommonWS`
                                                too many closing curly braces in lexer rule action block.

                                                Note: the action code chunk may be too complex for jison to parse
                                                easily; we suggest you wrap the action code chunk in '%{...%}'
                                                to help jison grok more or less complex action code chunks.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

              return 38;
            } else {
              yy.depth--;
            }

            return 35;
          case 15:
            /*! Conditions:: action */
            /*! Rule::       (?:[\s\r\n]*?){BR}+{WS}+ */
            yy.include_command_allowed = true;

            return 35;           // keep empty lines as-is inside action code blocks. 
          case 17:
            /*! Conditions:: action */
            /*! Rule::       {BR} */
            if (yy.depth > 0) {
              yy.include_command_allowed = true;
              return 35;       // keep empty lines as-is inside action code blocks.
            } else {
              // end of action code chunk; allow parent mode to see this mode-terminating linebreak too.
              this.popState();

              this.unput(yy_.yytext);

              // yy_.yytext = '';    --- ommitted as this is the side-effect of .unput(yy_.yytext) already!
              return 23;
            }
          case 18:
            /*! Conditions:: action */
            /*! Rule::       $ */
            yy.include_command_allowed = false;

            if (yy.depth !== 0) {
              yy_.yyerror(rmCommonWS`
                                                missing ${yy.depth} closing curly braces in lexer rule action block.

                                                Note: the action code chunk may be too complex for jison to parse
                                                easily; we suggest you wrap the action code chunk in '%{...%}'
                                                to help jison grok more or less complex action code chunks.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

              return 37;
            }

            this.popState();
            yy_.yytext = '';
            return 23;
          case 19:
            /*! Conditions:: INITIAL rules code options */
            /*! Rule::       [%\{]\{+ */
            {
              yy.depth = 0;
              yy.include_command_allowed = false;
              this.pushState('action');

              // keep matched string in local variable as the `unput()` call at the end will also 'unput' `yy_.yytext`,
              // which for our purposes here is highly undesirable (see trimActionCode() use in the BNF parser spec).
              let marker = yy_.yytext;

              // check whether this `%{` marker was located at the start of the line:
              // if it is, we treat it as a different token to signal the grammar we've
              // got an action which stands on its own, i.e. is not a rule action, %code
              // section, etc...
              //let precedingStr = this.pastInput(1,2).replace(/[\r\n]/g, '\n');
              //let precedingStr = this.matched.substr(-this.match.length - 1, 1);
              let precedingStr = this.matched[this.matched.length - this.match.length - 1];

              let atSOL = !precedingStr /* @ Start Of File */ || precedingStr === '\n';

              // Make sure we've the proper lexer rule regex active for any possible `%{...%}`, `{{...}}` or what have we here?
              let endMarker = this.setupDelimitedActionChunkLexerRegex(marker);

              // Early sanity check for better error reporting:
              // we'd better make sure that end marker indeed does exist in the
              // remainder of the input! When it's not, we'll have the `action`
              // lexer state running past its due date as it'll then go and spit
              // out a 'too may closing braces' error report at some spot way
              // beyond the intended end of the action code chunk.
              //
              // Writing the wrong end marker is a common user mistake, we can
              // easily look ahead and check for it now and report a proper hint
              // to cover this failure mode in a more helpful manner.
              let remaining = this.lookAhead();

              let prevEnd = 0;
              let endMarkerIndex;

              for (; ; ) {
                endMarkerIndex = remaining.indexOf(endMarker, prevEnd);

                // check for both simple non-existence *and* non-match due to trailing braces,
                // e.g. in this input: `%{{...%}}}` -- note the 3rd curly closing brace.
                if (endMarkerIndex >= 0 && remaining[endMarkerIndex + endMarker.length] === '}') {
                  prevEnd = endMarkerIndex + endMarker.length;
                  continue;
                }

                if (endMarkerIndex < 0) {
                  yy_.yyerror(rmCommonWS`
                                                    Incorrectly terminated action code block. We're expecting the
                                                    '${endMarker}' end marker to go with the given start marker.
                                                    Regrettably, it does not exist in the remainder of the input.

                                                      Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

                  return 24;
                }

                break;
              }

              // Allow the start marker to be re-matched by the generated lexer rule regex:
              this.unput(marker);

              // Now RESET `yy_.yytext` to what it was originally, i.e. un-unput that lexer variable explicitly:
              yy_.yytext = marker;

              // and allow the next lexer round to match and execute the suitable lexer rule(s) to parse this incoming action code block.
              if (atSOL) {
                return 22;
              }

              return 25;
            }
          case 20:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       -> */
            yy.depth = 0;

            yy.include_command_allowed = false;
            this.pushState('action');
            return 34;
          case 21:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       → */
            yy.depth = 0;

            yy.include_command_allowed = false;
            this.pushState('action');
            return 34;
          case 22:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       => */
            yy.depth = 0;

            yy.include_command_allowed = false;
            this.pushState('action');
            return 34;
          case 23:
            /*! Conditions:: rules */
            /*! Rule::       {WS}+(?!(?:\{\{|\||%|->|=>|→|{WS}|{BR})) */
            {
              yy.depth = 0;
              yy.include_command_allowed = true;

              //console.error('*** ACTION start @ 355:', yy_.yytext);
              this.pushState('action');

              // Do a bit of magic that's useful for the parser when we
              // call `trimActionCode()` in there to perform a bit of
              // rough initial action code chunk cleanup:
              // when we start the action block -- hence *delimit* the
              // action block -- with a plain old '{' brace, we can
              // throw that one and its counterpart out safely without
              // damaging the action code in any way.
              //
              // In order to be able to detect that, we look ahead
              // now and see whether or rule's regex with the fancy
              // '/!' postcondition check actually hit a '{', which
              // is the only action code block starter we cannot
              // detect explicitly using any of the '%{.*?%}' lexer
              // rules you've seen further above.
              //
              // Thanks to this rule's regex, we DO know that the
              // first look-ahead character will be a non-whitespace
              // character, which would either be an action code block
              // delimiter *or* a comment starter. In the latter case
              // we just throw up our hands and leave code trimming
              // and analysis to the more advanced systems which
              // follow after `trimActionCode()` has passed once we
              // get to the parser productions which process this
              // upcoming action code block.
              let la = this.lookAhead();

              if (la[0] === '{') {
                yy_.yytext = '{';           // hint the parser
              }

              return 25;
            }
          case 24:
            /*! Conditions:: rules */
            /*! Rule::       %% */
            this.popState();

            this.pushState('code');
            return 33;
          case 25:
            /*! Conditions:: rules */
            /*! Rule::       $ */
            this.popState();

            this.pushState('code');
            return 33;
          case 30:
            /*! Conditions:: options */
            /*! Rule::       %%|\||; */
            this.popState();

            this.unput(yy_.yytext);
            return 21;
          case 31:
            /*! Conditions:: options */
            /*! Rule::       %include\b */
            yy.depth = 0;

            yy.include_command_allowed = true;
            this.pushState('action');

            // push the parsed '%include' back into the input-to-parse
            // to trigger the `<action>` state to re-parse it
            // and issue the desired follow-up token: 'INCLUDE':
            this.unput(yy_.yytext);

            return 25;
          case 32:
            /*! Conditions:: options */
            /*! Rule::       > */
            this.popState();

            this.unput(yy_.yytext);
            return 21;
          case 35:
            /*! Conditions:: options */
            /*! Rule::       <{ID}> */
            yy_.yytext = this.matches[1];

            return 'TOKEN_TYPE';
          case 37:
            /*! Conditions:: options */
            /*! Rule::       {BR}{WS}+(?=\S) */
            /* ignore */
            break;
          case 38:
            /*! Conditions:: options */
            /*! Rule::       {BR} */
            this.popState();

            this.unput(yy_.yytext);
            return 21;
          case 39:
            /*! Conditions:: options */
            /*! Rule::       {WS}+ */
            /* skip whitespace */
            break;
          case 40:
            /*! Conditions:: INITIAL */
            /*! Rule::       {ID} */
            this.pushState('macro');

            return 19;
          case 41:
            /*! Conditions:: macro */
            /*! Rule::       {BR}+ */
            this.popState();

            this.unput(yy_.yytext);
            return 20;
          case 42:
            /*! Conditions:: macro */
            /*! Rule::       $ */
            this.popState();

            this.unput(yy_.yytext);
            return 20;
          case 43:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       {BR}+ */
            /* skip newlines */
            break;
          case 44:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       {WS}+ */
            /* skip whitespace */
            break;
          case 48:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       {ANY_LITERAL_CHAR}+ */
            // accept any non-regex, non-lex, non-string-delim,
            // non-escape-starter, non-space character as-is
            return 50;
          case 49:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       \[ */
            this.pushState('set');

            return 45;
          case 64:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       < */
            this.pushState('options');

            return 3;
          case 66:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       \/! */
            return 41;                    // treated as `(?!atom)` 
          case 67:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       \/ */
            return 13;                     // treated as `(?=atom)` 
          case 69:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       \\(?:([0-7]{1,3})|c([A-Z])|x([0-9a-fA-F]{2})|u([0-9a-fA-F]{4})|u\{([0-9a-fA-F]{1,8})\}) */
            {
              let m = this.matches;
              yy_.yytext = NaN;

              if (m[1]) {
                // [1]: octal char: `\012` --> \x0A
                let v = parseInt(m[1], 8);

                yy_.yytext = v;
              } else if (m[2]) {
                // [2]: CONTROL char: `\cA` --> \u0001
                let v = m[2].charCodeAt(0) - 64;

                yy_.yytext = v;
              } else if (m[3]) {
                // [3]: hex char: `\x41` --> A
                let v = parseInt(m[3], 16);

                yy_.yytext = v;
              } else if (m[4]) {
                // [4]: unicode/UTS2 char: `\u03c0` --> PI
                let v = parseInt(m[4], 16);

                yy_.yytext = v;
              } else if (m[5]) {
                // [5]: unicode code point: `\u{00003c0}` --> PI
                let v = parseInt(m[5], 16);

                yy_.yytext = v;
              }

              return 43;
            }
          case 70:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       \\. */
            yy_.yytext = yy_.yytext.substring(1);

            return 50;
          case 73:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %option[s]? */
            this.pushState('options');

            return 27;
          case 74:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %s\b */
            this.pushState('options');

            return 31;
          case 75:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %x\b */
            this.pushState('options');

            return 32;
          case 76:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %code\b */
            this.pushState('options');

            return 29;
          case 77:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %import\b */
            this.pushState('options');

            return 28;
          case 80:
            /*! Conditions:: INITIAL rules code */
            /*! Rule::       %include\b */
            {
              yy.depth = 0;
              yy.include_command_allowed = true;

              // check whether this `%include` command was located at the start of the line:
              // if it is, we treat it as a different token to signal the grammar we've
              // got an action which stands on its own.
              let precedingStr = this.matched[this.matched.length - this.match.length - 1];

              let atSOL = !precedingStr /* @ Start Of File */ || precedingStr === '\n';
              this.pushState('action');

              // push the parsed '%include' back into the input-to-parse
              // to trigger the `<action>` state to re-parse it
              // and issue the desired follow-up token: 'INCLUDE':
              this.unput(yy_.yytext);

              // and allow the next lexer round to match and execute the suitable lexer rule(s) to parse this incoming action code block.
              if (atSOL) {
                return 22;
              }

              return 25;
            }
          case 81:
            /*! Conditions:: INITIAL rules code */
            /*! Rule::       %{NAME}([^\r\n]*) */
            /* ignore unrecognized decl */
            this.warn(rmCommonWS`
                                                ignoring unsupported lexer option ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

            yy_.yytext = {
              // {NAME}
              name: this.matches[1],

              // optional value/parameters
              value: this.matches[2].trim()
            };

            return 26;
          case 82:
            /*! Conditions:: rules macro INITIAL */
            /*! Rule::       %% */
            this.pushState('rules');

            return 33;
          case 90:
            /*! Conditions:: set */
            /*! Rule::       \] */
            this.popState();

            return 46;
          case 91:
            /*! Conditions:: code */
            /*! Rule::       (?:[^%{BR}][^{BR}]*{BR}+)+ */
            return 54;      // shortcut to grab a large bite at once when we're sure not to encounter any `%include` in there at start-of-line. 
          case 93:
            /*! Conditions:: code */
            /*! Rule::       [^{BR}]+ */
            return 54;      // the bit of CODE just before EOF... 
          case 94:
            /*! Conditions:: action */
            /*! Rule::       " */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 95:
            /*! Conditions:: action */
            /*! Rule::       ' */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 96:
            /*! Conditions:: action */
            /*! Rule::       ` */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 97:
            /*! Conditions:: options */
            /*! Rule::       " */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 98:
            /*! Conditions:: options */
            /*! Rule::       ' */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 99:
            /*! Conditions:: options */
            /*! Rule::       ` */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 39;
          case 100:
            /*! Conditions:: * */
            /*! Rule::       " */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 39;
            }
          case 101:
            /*! Conditions:: * */
            /*! Rule::       ' */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 39;
            }
          case 102:
            /*! Conditions:: * */
            /*! Rule::       ` */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 39;
            }
          case 103:
            /*! Conditions:: macro rules */
            /*! Rule::       . */
            {
              /* b0rk on bad characters */
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unsupported lexer input encountered while lexing
                                            ${rules} (i.e. jison lex regexes) in ${dquote(this.topState())} state.

                                                NOTE: When you want this input to be interpreted as a LITERAL part
                                                      of a lex rule regex, you MUST enclose it in double or
                                                      single quotes.

                                                      If not, then know that this input is not accepted as a valid
                                                      regex expression here in jison-lex ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 2;
            }
          case 104:
            /*! Conditions:: options */
            /*! Rule::       . */
            yy_.yyerror(rmCommonWS`
                                            unsupported lexer input: ${dquote(yy_.yytext)}
                                            while lexing in ${dquote(this.topState())} state.

                                            If this input was intentional, you might want to put quotes around
                                            it; any JavaScript string quoting style is accepted (single quotes,
                                            double quotes *or* backtick quotes a la ES6 string templates).

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 2;
          case 105:
            /*! Conditions:: * */
            /*! Rule::       . */
            yy_.yyerror(rmCommonWS`
                                            unsupported lexer input: ${dquote(yy_.yytext)}
                                            while lexing in ${dquote(this.topState())} state.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 2;
          default:
            return this.simpleCaseActionClusters[yyrulenumber];
          }
        },

        simpleCaseActionClusters: {
          /*! Conditions:: action */
          /*! Rule::       {WS}+ */
          16: 35,

          /*! Conditions:: options */
          /*! Rule::       = */
          26: 18,

          /*! Conditions:: options */
          /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
          27: 52,

          /*! Conditions:: options */
          /*! Rule::       '{QUOTED_STRING_CONTENT}' */
          28: 52,

          /*! Conditions:: options */
          /*! Rule::       `{ES2017_STRING_CONTENT}` */
          29: 52,

          /*! Conditions:: options */
          /*! Rule::       , */
          33: 17,

          /*! Conditions:: options */
          /*! Rule::       \* */
          34: 11,

          /*! Conditions:: options */
          /*! Rule::       {ANY_LITERAL_CHAR}+ */
          36: 53,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
          45: 49,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       '{QUOTED_STRING_CONTENT}' */
          46: 49,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       `{ES2017_STRING_CONTENT}` */
          47: 49,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \| */
          50: 7,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \(\?: */
          51: 40,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \(\?= */
          52: 40,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \(\?! */
          53: 40,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \(\?<= */
          54: 40,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \(\?<! */
          55: 40,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \( */
          56: 8,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \) */
          57: 9,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \+ */
          58: 10,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \* */
          59: 11,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \? */
          60: 12,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \^ */
          61: 15,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       , */
          62: 17,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       <<EOF>> */
          63: 16,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       > */
          65: 6,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \\(?:[sSbBwWdDpP]|[rfntv\\*+()${}|[\]\/.^?]) */
          68: 42,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \$ */
          71: 16,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \. */
          72: 14,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       %pointer\b */
          78: 'FLEX_POINTER_MODE',

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       %array\b */
          79: 'FLEX_ARRAY_MODE',

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \{\d+(,\s*\d+|,)?\} */
          83: 48,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \{{ID}\} */
          84: 44,

          /*! Conditions:: set options */
          /*! Rule::       \{{ID}\} */
          85: 44,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \{ */
          86: 4,

          /*! Conditions:: rules macro INITIAL */
          /*! Rule::       \} */
          87: 5,

          /*! Conditions:: set */
          /*! Rule::       (?:\\[^{BR}]|[^\]{])+ */
          88: 47,

          /*! Conditions:: set */
          /*! Rule::       \{ */
          89: 47,

          /*! Conditions:: code */
          /*! Rule::       [^{BR}]*{BR}+ */
          92: 54,

          /*! Conditions:: * */
          /*! Rule::       $ */
          106: 1
        },

        rules: [
          /*   0: */  /^(?:\/\/[^\r\n]*)/,
          /*   1: */  /^(?:\/\*[\s\S]*?\*\/)/,
          /*   2: */  /^(?:%\{([\s\S]*?)%\}(?!\}))/,
          /*   3: */  /^(?:%include\b)/,
          /*   4: */  /^(?:\/\*[\s\S]*?\*\/)/,
          /*   5: */  /^(?:\/\/.*)/,
          /*   6: */  /^(?:\|)/,
          /*   7: */  /^(?:%%)/,
          /*   8: */  /^(?:\/(?=\s))/,
          /*   9: */  /^(?:\/.*)/,
          /*  10: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)"|'((?:\\'|\\[^']|[^\n\r'\\])*)'|`((?:\\`|\\[^`]|[^\\`])*)`)/,
          /*  11: */  /^(?:[^\n\r"%'/`{}]+)/,
          /*  12: */  /^(?:%)/,
          /*  13: */  /^(?:\{)/,
          /*  14: */  /^(?:\})/,
          /*  15: */  /^(?:(?:\s*?)(\r\n|\n|\r)+([^\S\n\r])+)/,
          /*  16: */  /^(?:([^\S\n\r])+)/,
          /*  17: */  /^(?:(\r\n|\n|\r))/,
          /*  18: */  /^(?:$)/,
          /*  19: */  /^(?:[%{]\{+)/,
          /*  20: */  /^(?:->)/,
          /*  21: */  /^(?:→)/,
          /*  22: */  /^(?:=>)/,
          /*  23: */  /^(?:([^\S\n\r])+(?!(?:\{\{|\||%|->|=>|→|([^\S\n\r])|(\r\n|\n|\r))))/,
          /*  24: */  /^(?:%%)/,
          /*  25: */  /^(?:$)/,
          /*  26: */  /^(?:=)/,
          /*  27: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /*  28: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /*  29: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
          /*  30: */  /^(?:%%|\||;)/,
          /*  31: */  /^(?:%include\b)/,
          /*  32: */  /^(?:>)/,
          /*  33: */  /^(?:,)/,
          /*  34: */  /^(?:\*)/,
          /*  35: */  new XRegExp__default['default']('^(?:<([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)>)', ''),
          /*  36: */  /^(?:([^\s!"$%'-,./:-?\[-\^`{-}])+)/,
          /*  37: */  /^(?:(\r\n|\n|\r)([^\S\n\r])+(?=\S))/,
          /*  38: */  /^(?:(\r\n|\n|\r))/,
          /*  39: */  /^(?:([^\S\n\r])+)/,
          /*  40: */  new XRegExp__default['default']('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
          /*  41: */  /^(?:(\r\n|\n|\r)+)/,
          /*  42: */  /^(?:$)/,
          /*  43: */  /^(?:(\r\n|\n|\r)+)/,
          /*  44: */  /^(?:([^\S\n\r])+)/,
          /*  45: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /*  46: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /*  47: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
          /*  48: */  /^(?:([^\s!"$%'-,./:-?\[-\^`{-}])+)/,
          /*  49: */  /^(?:\[)/,
          /*  50: */  /^(?:\|)/,
          /*  51: */  /^(?:\(\?:)/,
          /*  52: */  /^(?:\(\?=)/,
          /*  53: */  /^(?:\(\?!)/,
          /*  54: */  /^(?:\(\?<=)/,
          /*  55: */  /^(?:\(\?<!)/,
          /*  56: */  /^(?:\()/,
          /*  57: */  /^(?:\))/,
          /*  58: */  /^(?:\+)/,
          /*  59: */  /^(?:\*)/,
          /*  60: */  /^(?:\?)/,
          /*  61: */  /^(?:\^)/,
          /*  62: */  /^(?:,)/,
          /*  63: */  /^(?:<<EOF>>)/,
          /*  64: */  /^(?:<)/,
          /*  65: */  /^(?:>)/,
          /*  66: */  /^(?:\/!)/,
          /*  67: */  /^(?:\/)/,
          /*  68: */  /^(?:\\(?:[BDPSWbdpsw]|[$(-+./?\[-\^fnrtv{-}]))/,
          /*  69: */  /^(?:\\(?:([0-7]{1,3})|c([A-Z])|x([\dA-Fa-f]{2})|u([\dA-Fa-f]{4})|u\{([\dA-Fa-f]{1,8})\}))/,
          /*  70: */  /^(?:\\.)/,
          /*  71: */  /^(?:\$)/,
          /*  72: */  /^(?:\.)/,
          /*  73: */  /^(?:%option[s]?)/,
          /*  74: */  /^(?:%s\b)/,
          /*  75: */  /^(?:%x\b)/,
          /*  76: */  /^(?:%code\b)/,
          /*  77: */  /^(?:%import\b)/,
          /*  78: */  /^(?:%pointer\b)/,
          /*  79: */  /^(?:%array\b)/,
          /*  80: */  /^(?:%include\b)/,
          /*  81: */  new XRegExp__default['default'](
            '^(?:%([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?)([^\\n\\r]*))',
            ''
          ),
          /*  82: */  /^(?:%%)/,
          /*  83: */  /^(?:\{\d+(,\s*\d+|,)?\})/,
          /*  84: */  new XRegExp__default['default']('^(?:\\{([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\})', ''),
          /*  85: */  new XRegExp__default['default']('^(?:\\{([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\})', ''),
          /*  86: */  /^(?:\{)/,
          /*  87: */  /^(?:\})/,
          /*  88: */  /^(?:(?:\\[^\n\r]|[^\]{])+)/,
          /*  89: */  /^(?:\{)/,
          /*  90: */  /^(?:\])/,
          /*  91: */  /^(?:(?:[^\n\r%][^\n\r]*(\r\n|\n|\r)+)+)/,
          /*  92: */  /^(?:[^\n\r]*(\r\n|\n|\r)+)/,
          /*  93: */  /^(?:[^\n\r]+)/,
          /*  94: */  /^(?:")/,
          /*  95: */  /^(?:')/,
          /*  96: */  /^(?:`)/,
          /*  97: */  /^(?:")/,
          /*  98: */  /^(?:')/,
          /*  99: */  /^(?:`)/,
          /* 100: */  /^(?:")/,
          /* 101: */  /^(?:')/,
          /* 102: */  /^(?:`)/,
          /* 103: */  /^(?:.)/,
          /* 104: */  /^(?:.)/,
          /* 105: */  /^(?:.)/,
          /* 106: */  /^(?:$)/
        ],

        conditions: {
          'rules': {
            rules: [
              0,
              1,
              19,
              20,
              21,
              22,
              23,
              24,
              25,
              43,
              44,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              74,
              75,
              76,
              77,
              78,
              79,
              80,
              81,
              82,
              83,
              84,
              86,
              87,
              100,
              101,
              102,
              103,
              105,
              106
            ],

            inclusive: true
          },

          'macro': {
            rules: [
              0,
              1,
              20,
              21,
              22,
              41,
              42,
              43,
              44,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              74,
              75,
              76,
              77,
              78,
              79,
              82,
              83,
              84,
              86,
              87,
              100,
              101,
              102,
              103,
              105,
              106
            ],

            inclusive: true
          },

          'code': {
            rules: [19, 80, 81, 91, 92, 93, 100, 101, 102, 105, 106],
            inclusive: false
          },

          'options': {
            rules: [
              0,
              1,
              19,
              26,
              27,
              28,
              29,
              30,
              31,
              32,
              33,
              34,
              35,
              36,
              37,
              38,
              39,
              85,
              97,
              98,
              99,
              100,
              101,
              102,
              104,
              105,
              106
            ],

            inclusive: false
          },

          'action': {
            rules: [
              2,
              3,
              4,
              5,
              6,
              7,
              8,
              9,
              10,
              11,
              12,
              13,
              14,
              15,
              16,
              17,
              18,
              94,
              95,
              96,
              100,
              101,
              102,
              105,
              106
            ],

            inclusive: false
          },

          'set': {
            rules: [85, 88, 89, 90, 100, 101, 102, 105, 106],
            inclusive: false
          },

          'INITIAL': {
            rules: [
              0,
              1,
              19,
              20,
              21,
              22,
              40,
              43,
              44,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              74,
              75,
              76,
              77,
              78,
              79,
              80,
              81,
              82,
              83,
              84,
              86,
              87,
              100,
              101,
              102,
              105,
              106
            ],

            inclusive: true
          }
        }
      };

      const rmCommonWS = helpers.rmCommonWS;
      const dquote = helpers.dquote;
      const scanRegExp = helpers.scanRegExp;

      // Calculate the end marker to match and produce a
      // lexer rule to match when the need arrises:
      lexer.setupDelimitedActionChunkLexerRegex = function lexer__setupDelimitedActionChunkLexerRegex(marker) {
        // Special: when we encounter `{` as the start of the action code block,
        // we DO NOT patch the `%{...%}` lexer rule as we will handle `{...}`
        // elsewhere in the lexer anyway: we cannot use a simple regex like
        // `/{[^]*?}/` to match an entire action code block after all!
        let doNotPatch = marker === '{';

        let action_end_marker = marker.replace(/\{/g, '}');

        if (!doNotPatch) {
          // Note: this bit comes straight from the lexer kernel!
          //
          // Get us the currently active set of lexer rules.
          // (This is why we push the 'action' lexer condition state above *before*
          // we commence and work on the ruleset itself.)
          let spec = this.__currentRuleSet__;

          if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();
          }

          let regexes = spec.__rule_regexes;
          let len = spec.__rule_count;
          let rules = spec.rules;
          let i;
          let action_chunk_regex;

          // Must we still locate the rule to patch or have we done
          // that already during a previous encounter?
          //
          // WARNING: our cache/patch must live beyond the current lexer+parser invocation:
          // our patching must remain detected indefinitely to ensure subsequent invocations
          // of the parser will still work as expected!
          // This implies that we CANNOT store anything in the `yy` context as that one
          // is short-lived: `yy` dies once the current parser.parse() has completed!
          // Hence we store our patch data in the lexer instance itself: in `spec`.
          //
          if (!spec.__action_chunk_rule_idx) {
            // **WARNING**: *(this bit, like so much else in here, comes straight from the lexer kernel)*
            //
            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
            let orig_re_str1 = '/^(?:%\\{([^]*?)%\\}(?!\\}))/';

            let orig_re_str2 = '/^(?:%\\{([\\s\\S]*?)%\\}(?!\\}))/';   // the XRegExp 'cross-platform' version of the same.

            // Note: the arrays are 1-based, while `len` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (i = 1; i <= len; i++) {
              let rule_re = regexes[i];
              let re_str = rule_re.toString();

              //console.error('test regexes:', {i, len, re1: re_str, match1: rule_re.toString() === orig_re_str1, match1: rule_re.toString() === orig_re_str2});
              if (re_str === orig_re_str1 || re_str === orig_re_str2) {
                spec.__action_chunk_rule_idx = i;
                break;
              }
            }

            if (!spec.__action_chunk_rule_idx) {
              //console.error('ruleset dump:', spec);
              throw new Error('INTERNAL DEV ERROR: cannot locate %{...%} rule regex!');
            }

            // As we haven't initialized yet, we're sure the rule cache doesn't exist either.
            // Make it happen:
            spec.__cached_action_chunk_rule = {};   // set up empty cache
          }

          i = spec.__action_chunk_rule_idx;

          // Must we build the lexer rule or did we already run this variant
          // through this lexer before? When the latter, fetch the cached version!
          action_chunk_regex = spec.__cached_action_chunk_rule[marker];

          if (!action_chunk_regex) {
            action_chunk_regex = spec.__cached_action_chunk_rule[marker] = new RegExp(
              '^(?:' + marker.replace(/\{/g, '\\{') + '([^]*?)' + action_end_marker.replace(/\}/g, '\\}') + '(?!\\}))'
            );
            //console.warn('encode new action block regex:', action_chunk_regex);
          }

          //console.error('new ACTION REGEX:', { i, action_chunk_regex });
          // and patch the lexer regex table for the current lexer condition state:
          regexes[i] = action_chunk_regex;
        }

        return action_end_marker;
      };

      lexer.warn = function l_warn() {
        if (this.yy && this.yy.parser && typeof this.yy.parser.warn === 'function') {
          return this.yy.parser.warn.apply(this, arguments);
        } else {
          console.warn.apply(console, arguments);
        }
      };

      lexer.log = function l_log() {
        if (this.yy && this.yy.parser && typeof this.yy.parser.log === 'function') {
          return this.yy.parser.log.apply(this, arguments);
        } else {
          console.log.apply(console, arguments);
        }
      };

      return lexer;
    }();
    parser.lexer = lexer;

    const rmCommonWS$1 = helpers.rmCommonWS;
    const checkActionBlock$1 = helpers.checkActionBlock;
    const mkIdentifier$2 = helpers.mkIdentifier;
    const isLegalIdentifierInput$1 = helpers.isLegalIdentifierInput;
    const trimActionCode$1 = helpers.trimActionCode;


    // see also:
    // - https://en.wikipedia.org/wiki/C0_and_C1_control_codes
    // - https://docs.microsoft.com/en-us/dotnet/standard/base-types/character-escapes-in-regular-expressions
    // - https://kangax.github.io/compat-table/es6/#test-RegExp_y_and_u_flags
    // - http://2ality.com/2015/07/regexp-es6.html
    // - http://www.regular-expressions.info/quickstart.html

    const charCvtTable = {
        // "\a": "\x07",
        // "\e": "\x1B",
        // "\b": "\x08",
        "\f": "\\f",
        "\n": "\\n",
        "\r": "\\r",
        "\t": "\\t",
        "\v": "\\v",
    };
    const escCvtTable = {
        "a": "\\x07",
        "e": "\\x1B",
        "b": "\\x08",
        "f": "\\f",
        "n": "\\n",
        "r": "\\r",
        "t": "\\t",
        "v": "\\v",
    };
    const codeCvtTable = {
        12: "\\f",
        10: "\\n",
        13: "\\r",
        9:  "\\t",
        11: "\\v",
    };

    // Note about 'b' in the regex below:
    // when inside a literal string, it's BACKSPACE, otherwise it's
    // the regex word edge condition `\b`. Here it's BACKSPACE.
    const codedCharRe = /(?:([sSBwWdDpP])|([*+()${}|[\]\/.^?])|([aberfntv])|([0-7]{1,3})|c([@A-Z])|x([0-9a-fA-F]{2})|u([0-9a-fA-F]{4})|u\{([0-9a-fA-F]{1,8})\}|())/g;

    function encodeCharCode(v) {
        if (v < 32) {
            let rv = codeCvtTable[v];
            if (rv) return rv;
            return '\\u' + ('0000' + v.toString(16)).substr(-4);
        } else {
            return String.fromCharCode(v);
        }
    }

    function encodeUnicodeCodepoint(v) {
        if (v < 32) {
            let rv = codeCvtTable[v];
            if (rv) return rv;
            return '\\u' + ('0000' + v.toString(16)).substr(-4);
        } else {
            return String.fromCodePoint(v);
        }
    }

    function encodeRegexLiteralStr(s, edge) {
        let rv = '';
        //console.warn("encodeRegexLiteralStr INPUT:", {s, edge});
        for (let i = 0, l = s.length; i < l; i++) {
            let c = s[i];
            switch (c) {
            case '\\':
                i++;
                if (i < l) {
                    c = s[i];
                    if (c === edge) {
                        rv += c;
                        continue;
                    }
                    let pos = '\'"`'.indexOf(c);
                    if (pos >= 0) {
                        rv += '\\\\' + c;
                        continue;
                    }
                    if (c === '\\') {
                        rv += '\\\\';
                        continue;
                    }
                    codedCharRe.lastIndex = i;
                    // we 'fake' the RegExp 'y'=sticky feature cross-platform by using 'g' flag instead
                    // plus an empty capture group at the end of the regex: when that one matches,
                    // we know we did not get a hit.
                    let m = codedCharRe.exec(s);
                    if (m && m[0]) {
                        if (m[1]) {
                            // [1]: regex operators, which occur in a literal string: `\s` --> \\s
                            rv += '\\\\' + m[1];
                            i += m[1].length - 1;
                            continue;
                        }
                        if (m[2]) {
                            // [2]: regex special characters, which occur in a literal string: `\[` --> \\\[
                            rv += '\\\\\\' + m[2];
                            i += m[2].length - 1;
                            continue;
                        }
                        if (m[3]) {
                            // [3]: special escape characters, which occur in a literal string: `\a` --> BELL
                            rv += escCvtTable[m[3]];
                            i += m[3].length - 1;
                            continue;
                        }
                        if (m[4]) {
                            // [4]: octal char: `\012` --> \x0A
                            let v = parseInt(m[4], 8);
                            rv += encodeCharCode(v);
                            i += m[4].length - 1;
                            continue;
                        }
                        if (m[5]) {
                            // [5]: CONTROL char: `\cA` --> \u0001
                            let v = m[5].charCodeAt(0) - 64;
                            rv += encodeCharCode(v);
                            i++;
                            continue;
                        }
                        if (m[6]) {
                            // [6]: hex char: `\x41` --> A
                            let v = parseInt(m[6], 16);
                            rv += encodeCharCode(v);
                            i += m[6].length;
                            continue;
                        }
                        if (m[7]) {
                            // [7]: unicode/UTS2 char: `\u03c0` --> PI
                            let v = parseInt(m[7], 16);
                            rv += encodeCharCode(v);
                            i += m[7].length;
                            continue;
                        }
                        if (m[8]) {
                            // [8]: unicode code point: `\u{00003c0}` --> PI
                            let v = parseInt(m[8], 16);
                            rv += encodeUnicodeCodepoint(v);
                            i += m[8].length;
                            continue;
                        }
                    }
                }
                // all the rest: simply treat the `\\` escape as a character on its own:
                rv += '\\\\';
                i--;
                continue;

            default:
                // escape regex operators:
                let pos = ".*+?^${}()|[]/\\".indexOf(c);
                if (pos >= 0) {
                    rv += '\\' + c;
                    continue;
                }
                let cc = charCvtTable[c];
                if (cc) {
                    rv += cc;
                    continue;
                }
                cc = c.charCodeAt(0);
                if (cc < 32) {
                    let rvp = codeCvtTable[v];
                    if (rvp) {
                        rv += rvp;
                    } else {
                        rv += '\\u' + ('0000' + cc.toString(16)).substr(-4);
                    }
                } else {
                    rv += c;
                }
                continue;
            }
        }
        s = rv;
        //console.warn("encodeRegexLiteralStr ROUND 3:", {s});
        return s;
    }


    // convert string value to number or boolean value, when possible
    // (and when this is more or less obviously the intent)
    // otherwise produce the string itself as value.
    function parseValue(v) {
        if (v === 'false') {
            return false;
        }
        if (v === 'true') {
            return true;
        }
        // http://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number
        // Note that the `v` check ensures that we do not convert `undefined`, `null` and `''` (empty string!)
        if (v && !isNaN(v)) {
            let rv = +v;
            if (isFinite(rv)) {
                return rv;
            }
        }
        return v;
    }


    parser.warn = function p_warn() {
        console.warn.apply(console, arguments);
    };

    parser.log = function p_log() {
        console.log.apply(console, arguments);
    };

    parser.pre_parse = function p_lex() {
        if (parser.yydebug) parser.log('pre_parse:', arguments);
    };

    parser.yy.pre_parse = function p_lex() {
        if (parser.yydebug) parser.log('pre_parse YY:', arguments);
    };

    parser.yy.post_lex = function p_lex() {
        if (parser.yydebug) parser.log('post_lex:', arguments);
    };


    function Parser() {
        this.yy = {};
    }
    Parser.prototype = parser;
    parser.Parser = Parser;

    function yyparse() {
        return parser.parse.apply(parser, arguments);
    }



    var lexParser = {
        parser,
        Parser,
        parse: yyparse,
        
    };

    //




    const XREGEXP_UNICODE_ESCAPE_RE = /^\{[A-Za-z0-9 \-\._]+\}/;              // Matches the XRegExp Unicode escape braced part, e.g. `{Number}`
    const CHR_RE = /^(?:[^\\]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})/;
    const SET_PART_RE = /^(?:[^\\\]]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})+/;
    const NOTHING_SPECIAL_RE = /^(?:[^\\\[\]\(\)\|^\{\}]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})+/;
    const SET_IS_SINGLE_PCODE_RE = /^\\[dDwWsS]$|^\\p\{[A-Za-z0-9 \-\._]+\}$/;

    const UNICODE_BASE_PLANE_MAX_CP = 65535;

    // The expanded regex sets which are equivalent to the given `\\{c}` escapes:
    //
    // `/\s/`:
    const WHITESPACE_SETSTR = ' \f\n\r\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff';
    // `/\d/`:
    const DIGIT_SETSTR = '0-9';
    // `/\w/`:
    const WORDCHAR_SETSTR = 'A-Za-z0-9_';





    // Helper for `bitarray2set()`: convert character code to a representation string suitable for use in a regex
    function i2c(i) {
        let c, x;

        switch (i) {
        case 10:
            return '\\n';

        case 13:
            return '\\r';

        case 9:
            return '\\t';

        case 8:
            return '\\b';

        case 12:
            return '\\f';

        case 11:
            return '\\v';

        case 45:        // ASCII/Unicode for '-' dash
            return '\\-';

        case 91:        // '['
            return '\\[';

        case 92:        // '\\'
            return '\\\\';

        case 93:        // ']'
            return '\\]';

        case 94:        // ']'
            return '\\^';
        }
        if (i < 32
                || i > 0xFFF0 /* Unicode Specials, also in UTF16 */
                || (i >= 0xD800 && i <= 0xDFFF) /* Unicode Supplementary Planes; we're TOAST in JavaScript as we're NOT UTF-16 but UCS-2! */
                || String.fromCharCode(i).match(/[\u2028\u2029]/) /* Code compilation via `new Function()` does not like to see these, or rather: treats them as just another form of CRLF, which breaks your generated regex code! */
        ) {
            // Detail about a detail:
            // U+2028 and U+2029 are part of the `\s` regex escape code (`\s` and `[\s]` match either of these) and when placed in a JavaScript
            // source file verbatim (without escaping it as a `\uNNNN` item) then JavaScript will interpret it as such and consequently report
            // a b0rked generated parser, as the generated code would include this regex right here.
            // Hence we MUST escape these buggers everywhere we go...
            x = i.toString(16);
            if (x.length >= 1 && i <= 0xFFFF) {
                c = '0000' + x;
                return '\\u' + c.substr(c.length - 4);
            }
            return '\\u{' + x + '}';
        }
        return String.fromCharCode(i);
    }


    // Helper collection for `bitarray2set()`: we have expanded all these cached `\\p{NAME}` regex sets when creating
    // this bitarray and now we should look at these expansions again to see if `bitarray2set()` can produce a
    // `\\p{NAME}` shorthand to represent [part of] the bitarray:
    let Pcodes_bitarray_cache = {};
    let Pcodes_bitarray_cache_test_order = [];

    // Helper collection for `bitarray2set()` for minifying special cases of result sets which can be represented by
    // a single regex 'escape', e.g. `\d` for digits 0-9.
    let EscCode_bitarray_output_refs;

    // now initialize the EscCodes_... table above:
    init_EscCode_lookup_table();

    function init_EscCode_lookup_table() {
        let s, bitarr, set2esc = {}, esc2bitarr = {};

        // patch global lookup tables for the time being, while we calculate their *real* content in this function:
        EscCode_bitarray_output_refs = {
            esc2bitarr: {},
            set2esc: {}
        };
        Pcodes_bitarray_cache_test_order = [];

        // `/\S':
        bitarr = [];
        set2bitarray(bitarr, '^' + WHITESPACE_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['S'] = bitarr;
        set2esc[s] = 'S';
        // set2esc['^' + s] = 's';
        Pcodes_bitarray_cache['\\S'] = bitarr;

        // `/\s':
        bitarr = [];
        set2bitarray(bitarr, WHITESPACE_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['s'] = bitarr;
        set2esc[s] = 's';
        // set2esc['^' + s] = 'S';
        Pcodes_bitarray_cache['\\s'] = bitarr;

        // `/\D':
        bitarr = [];
        set2bitarray(bitarr, '^' + DIGIT_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['D'] = bitarr;
        set2esc[s] = 'D';
        // set2esc['^' + s] = 'd';
        Pcodes_bitarray_cache['\\D'] = bitarr;

        // `/\d':
        bitarr = [];
        set2bitarray(bitarr, DIGIT_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['d'] = bitarr;
        set2esc[s] = 'd';
        // set2esc['^' + s] = 'D';
        Pcodes_bitarray_cache['\\d'] = bitarr;

        // `/\W':
        bitarr = [];
        set2bitarray(bitarr, '^' + WORDCHAR_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['W'] = bitarr;
        set2esc[s] = 'W';
        // set2esc['^' + s] = 'w';
        Pcodes_bitarray_cache['\\W'] = bitarr;

        // `/\w':
        bitarr = [];
        set2bitarray(bitarr, WORDCHAR_SETSTR);
        s = bitarray2set(bitarr);
        esc2bitarr['w'] = bitarr;
        set2esc[s] = 'w';
        // set2esc['^' + s] = 'W';
        Pcodes_bitarray_cache['\\w'] = bitarr;

        EscCode_bitarray_output_refs = {
            esc2bitarr: esc2bitarr,
            set2esc: set2esc
        };

        updatePcodesBitarrayCacheTestOrder();
    }

    function updatePcodesBitarrayCacheTestOrder(opts) {
        let t = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);
        let l = {};
        let user_has_xregexp = opts && opts.options && opts.options.xregexp;
        let i, j, k, ba;

        // mark every character with which regex pcodes they are part of:
        for (k in Pcodes_bitarray_cache) {
            ba = Pcodes_bitarray_cache[k];

            if (!user_has_xregexp && k.indexOf('\\p{') >= 0) {
                continue;
            }

            let cnt = 0;
            for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                if (ba[i]) {
                    cnt++;
                    if (!t[i]) {
                        t[i] = [ k ];
                    } else {
                        t[i].push(k);
                    }
                }
            }
            l[k] = cnt;
        }

        // now dig out the unique ones: only need one per pcode.
        //
        // We ASSUME every \\p{NAME} 'pcode' has at least ONE character
        // in it that is ONLY matched by that particular pcode.
        // If this assumption fails, nothing is lost, but our 'regex set
        // optimized representation' will be sub-optimal as than this pcode
        // won't be tested during optimization.
        //
        // Now that would be a pity, so the assumption better holds...
        // Turns out the assumption doesn't hold already for /\S/ + /\D/
        // as the second one (\D) is a pure subset of \S. So we have to
        // look for markers which match multiple escapes/pcodes for those
        // ones where a unique item isn't available...
        let lut = [];
        let done = {};
        let keys = Object.keys(Pcodes_bitarray_cache);

        for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
            k = t[i][0];
            if (t[i].length === 1 && !done[k]) {
                assert__default['default'](l[k] > 0);
                lut.push([ i, k ]);
                done[k] = true;
            }
        }

        for (j = 0; keys[j]; j++) {
            k = keys[j];

            if (!user_has_xregexp && k.indexOf('\\p{') >= 0) {
                continue;
            }

            if (!done[k]) {
                assert__default['default'](l[k] > 0);
                // find a minimum span character to mark this one:
                let w = Infinity;
                var rv;
                ba = Pcodes_bitarray_cache[k];
                for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                    if (ba[i]) {
                        let tl = t[i].length;
                        if (tl > 1 && tl < w) {
                            assert__default['default'](l[k] > 0);
                            rv = [ i, k ];
                            w = tl;
                        }
                    }
                }
                if (rv) {
                    done[k] = true;
                    lut.push(rv);
                }
            }
        }

        // order from large set to small set so that small sets don't gobble
        // characters also represented by overlapping larger set pcodes.
        //
        // Again we assume something: that finding the large regex pcode sets
        // before the smaller, more specialized ones, will produce a more
        // optimal minification of the regex set expression.
        //
        // This is a guestimate/heuristic only!
        lut.sort(function (a, b) {
            let k1 = a[1];
            let k2 = b[1];
            let ld = l[k2] - l[k1];
            if (ld) {
                return ld;
            }
            // and for same-size sets, order from high to low unique identifier.
            return b[0] - a[0];
        });

        Pcodes_bitarray_cache_test_order = lut;
    }






    // 'Join' a regex set `[...]` into a Unicode range spanning logic array, flagging every character in the given set.
    function set2bitarray(bitarr, s, opts) {
        let orig = s;
        let set_is_inverted = false;
        let bitarr_orig;

        function mark(d1, d2) {
            if (d2 == null) d2 = d1;
            for (let i = d1; i <= d2; i++) {
                bitarr[i] = true;
            }
        }

        function add2bitarray(dst, src) {
            for (let i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                if (src[i]) {
                    dst[i] = true;
                }
            }
        }

        function eval_escaped_code(s) {
            let c;
            // decode escaped code? If none, just take the character as-is
            if (s.indexOf('\\') === 0) {
                let l = s.substr(0, 2);
                switch (l) {
                case '\\c':
                    c = s.charCodeAt(2) - 'A'.charCodeAt(0) + 1;
                    return String.fromCharCode(c);

                case '\\x':
                    s = s.substr(2);
                    c = parseInt(s, 16);
                    return String.fromCharCode(c);

                case '\\u':
                    s = s.substr(2);
                    if (s[0] === '{') {
                        s = s.substr(1, s.length - 2);
                    }
                    c = parseInt(s, 16);
                    if (c >= 0x10000) {
                        return new Error('We do NOT support Extended Plane Unicode Codepoints (i.e. CodePoints beyond U:FFFF) in regex set expressions, e.g. \\u{' + s + '}');
                    }
                    return String.fromCharCode(c);

                case '\\0':
                case '\\1':
                case '\\2':
                case '\\3':
                case '\\4':
                case '\\5':
                case '\\6':
                case '\\7':
                    s = s.substr(1);
                    c = parseInt(s, 8);
                    return String.fromCharCode(c);

                case '\\r':
                    return '\r';

                case '\\n':
                    return '\n';

                case '\\v':
                    return '\v';

                case '\\f':
                    return '\f';

                case '\\t':
                    return '\t';

                case '\\b':
                    return '\b';

                default:
                    // just the character itself:
                    return s.substr(1);
                }
            } else {
                return s;
            }
        }

        if (s && s.length) {
            let c1, c2;

            // inverted set?
            if (s[0] === '^') {
                set_is_inverted = true;
                s = s.substr(1);
                bitarr_orig = bitarr;
                bitarr = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);
            }

            // BITARR collects flags for characters set. Inversion means the complement set of character is st instead.
            // This results in an OR operations when sets are joined/chained.

            while (s.length) {
                c1 = s.match(CHR_RE);
                if (!c1) {
                    // hit an illegal escape sequence? cope anyway!
                    c1 = s[0];
                } else {
                    c1 = c1[0];
                    // Quick hack for XRegExp escapes inside a regex `[...]` set definition: we *could* try to keep those
                    // intact but it's easier to unfold them here; this is not nice for when the grammar specifies explicit
                    // XRegExp support, but alas, we'll get there when we get there... ;-)
                    switch (c1) {
                    case '\\p':
                        s = s.substr(c1.length);
                        c2 = s.match(XREGEXP_UNICODE_ESCAPE_RE);
                        if (c2) {
                            c2 = c2[0];
                            s = s.substr(c2.length);
                            // do we have this one cached already?
                            let pex = c1 + c2;
                            let ba4p = Pcodes_bitarray_cache[pex];
                            if (!ba4p) {
                                // expand escape:
                                let xr = new XRegExp__default['default']('[' + pex + ']');           // TODO: case-insensitive grammar???
                                // rewrite to a standard `[...]` regex set: XRegExp will do this for us via `XRegExp.toString()`:
                                let xs = '' + xr;
                                // remove the wrapping `/.../` to get at the (possibly *combined* series of) `[...]` sets inside:
                                xs = xs.substr(1, xs.length - 2);

                                ba4p = reduceRegexToSetBitArray(xs, pex, opts);

                                Pcodes_bitarray_cache[pex] = ba4p;
                                updatePcodesBitarrayCacheTestOrder(opts);
                            }
                            // merge bitarrays:
                            add2bitarray(bitarr, ba4p);
                            continue;
                        }
                        break;

                    case '\\S':
                    case '\\s':
                    case '\\W':
                    case '\\w':
                    case '\\d':
                    case '\\D':
                        // these can't participate in a range, but need to be treated special:
                        s = s.substr(c1.length);
                        // check for \S, \s, \D, \d, \W, \w and expand them:
                        var ba4e = EscCode_bitarray_output_refs.esc2bitarr[c1[1]];
                        assert__default['default'](ba4e);
                        add2bitarray(bitarr, ba4e);
                        continue;

                    case '\\b':
                        // matches a backspace: https://developer.mozilla.org/en/docs/Web/JavaScript/Guide/Regular_Expressions#special-backspace
                        c1 = '\u0008';
                        break;
                    }
                }
                let v1 = eval_escaped_code(c1);
                // propagate deferred exceptions = error reports.
                if (v1 instanceof Error) {
                    return v1;
                }
                v1 = v1.charCodeAt(0);
                s = s.substr(c1.length);

                if (s[0] === '-' && s.length >= 2) {
                    // we can expect a range like 'a-z':
                    s = s.substr(1);
                    c2 = s.match(CHR_RE);
                    if (!c2) {
                        // hit an illegal escape sequence? cope anyway!
                        c2 = s[0];
                    } else {
                        c2 = c2[0];
                    }
                    let v2 = eval_escaped_code(c2);
                    // propagate deferred exceptions = error reports.
                    if (v2 instanceof Error) {
                        return v1;
                    }
                    v2 = v2.charCodeAt(0);
                    s = s.substr(c2.length);

                    // legal ranges go UP, not /DOWN!
                    if (v1 <= v2) {
                        mark(v1, v2);
                    } else {
                        console.warn('INVALID CHARACTER RANGE found in regex: ', { re: orig, start: c1, start_n: v1, end: c2, end_n: v2 });
                        mark(v1);
                        mark('-'.charCodeAt(0));
                        mark(v2);
                    }
                    continue;
                }
                mark(v1);
            }

            // When we have marked all slots, '^' NEGATES the set, hence we flip all slots.
            //
            // Since a regex like `[^]` should match everything(?really?), we don't need to check if the MARK
            // phase actually marked anything at all: the `^` negation will correctly flip=mark the entire
            // range then.
            if (set_is_inverted) {
                for (let i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                    if (!bitarr[i]) {
                        bitarr_orig[i] = true;
                    }
                }
            }
        }
        return false;
    }


    // convert a simple bitarray back into a regex set `[...]` content:
    function bitarray2set(l, output_inverted_variant, output_minimized) {
        // construct the inverse(?) set from the mark-set:
        //
        // Before we do that, we inject a sentinel so that our inner loops
        // below can be simple and fast:
        l[UNICODE_BASE_PLANE_MAX_CP + 1] = 1;
        // now reconstruct the regex set:
        let rv = [];
        let i, j, cnt, lut, tn, tspec, match, pcode, ba4pcode, l2;
        let bitarr_is_cloned = false;
        let l_orig = l;

        if (output_inverted_variant) {
            // generate the inverted set, hence all unmarked slots are part of the output range:
            cnt = 0;
            for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                if (!l[i]) {
                    cnt++;
                }
            }
            if (cnt === UNICODE_BASE_PLANE_MAX_CP + 1) {
                // When there's nothing in the output we output a special 'match-nothing' regex: `[^\S\s]`.
                // BUT... since we output the INVERTED set, we output the match-all set instead:
                return '\\S\\s';
            } else if (cnt === 0) {
                // When we find the entire Unicode range is in the output match set, we replace this with
                // a shorthand regex: `[\S\s]`
                // BUT... since we output the INVERTED set, we output the match-nothing set instead:
                return '^\\S\\s';
            }

            // Now see if we can replace several bits by an escape / pcode:
            if (output_minimized) {
                lut = Pcodes_bitarray_cache_test_order;
                for (tn = 0; lut[tn]; tn++) {
                    tspec = lut[tn];
                    // check if the uniquely identifying char is in the inverted set:
                    if (!l[tspec[0]]) {
                        // check if the pcode is covered by the inverted set:
                        pcode = tspec[1];
                        ba4pcode = Pcodes_bitarray_cache[pcode];
                        match = 0;
                        for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                            if (ba4pcode[j]) {
                                if (!l[j]) {
                                    // match in current inverted bitset, i.e. there's at
                                    // least one 'new' bit covered by this pcode/escape:
                                    match++;
                                } else if (l_orig[j]) {
                                    // mismatch!
                                    match = false;
                                    break;
                                }
                            }
                        }

                        // We're only interested in matches which actually cover some
                        // yet uncovered bits: `match !== 0 && match !== false`.
                        //
                        // Apply the heuristic that the pcode/escape is only going to be used
                        // when it covers *more* characters than its own identifier's length:
                        if (match && match > pcode.length) {
                            rv.push(pcode);

                            // and nuke the bits in the array which match the given pcode:
                            // make sure these edits are visible outside this function as
                            // `l` is an INPUT parameter (~ not modified)!
                            if (!bitarr_is_cloned) {
                                l2 = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);
                                for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                                    l2[j] = l[j] || ba4pcode[j];    // `!(!l[j] && !ba4pcode[j])`
                                }
                                // recreate sentinel
                                l2[UNICODE_BASE_PLANE_MAX_CP + 1] = 1;
                                l = l2;
                                bitarr_is_cloned = true;
                            } else {
                                for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                                    l[j] = l[j] || ba4pcode[j];
                                }
                            }
                        }
                    }
                }
            }

            i = 0;
            while (i <= UNICODE_BASE_PLANE_MAX_CP) {
                // find first character not in original set:
                while (l[i]) {
                    i++;
                }
                if (i >= UNICODE_BASE_PLANE_MAX_CP + 1) {
                    break;
                }
                // find next character not in original set:
                for (j = i + 1; !l[j]; j++) {} /* empty loop */
                // generate subset:
                rv.push(i2c(i));
                if (j - 1 > i) {
                    rv.push((j - 2 > i ? '-' : '') + i2c(j - 1));
                }
                i = j;
            }
        } else {
            // generate the non-inverted set, hence all logic checks are inverted here...
            cnt = 0;
            for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP; i++) {
                if (l[i]) {
                    cnt++;
                }
            }
            if (cnt === UNICODE_BASE_PLANE_MAX_CP + 1) {
                // When we find the entire Unicode range is in the output match set, we replace this with
                // a shorthand regex: `[\S\s]`
                return '\\S\\s';
            } else if (cnt === 0) {
                // When there's nothing in the output we output a special 'match-nothing' regex: `[^\S\s]`.
                return '^\\S\\s';
            }

            // Now see if we can replace several bits by an escape / pcode:
            if (output_minimized) {
                lut = Pcodes_bitarray_cache_test_order;
                for (tn = 0; lut[tn]; tn++) {
                    tspec = lut[tn];
                    // check if the uniquely identifying char is in the set:
                    if (l[tspec[0]]) {
                        // check if the pcode is covered by the set:
                        pcode = tspec[1];
                        ba4pcode = Pcodes_bitarray_cache[pcode];
                        match = 0;
                        for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                            if (ba4pcode[j]) {
                                if (l[j]) {
                                    // match in current bitset, i.e. there's at
                                    // least one 'new' bit covered by this pcode/escape:
                                    match++;
                                } else if (!l_orig[j]) {
                                    // mismatch!
                                    match = false;
                                    break;
                                }
                            }
                        }

                        // We're only interested in matches which actually cover some
                        // yet uncovered bits: `match !== 0 && match !== false`.
                        //
                        // Apply the heuristic that the pcode/escape is only going to be used
                        // when it covers *more* characters than its own identifier's length:
                        if (match && match > pcode.length) {
                            rv.push(pcode);

                            // and nuke the bits in the array which match the given pcode:
                            // make sure these edits are visible outside this function as
                            // `l` is an INPUT parameter (~ not modified)!
                            if (!bitarr_is_cloned) {
                                l2 = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);
                                for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                                    l2[j] = l[j] && !ba4pcode[j];
                                }
                                // recreate sentinel
                                l2[UNICODE_BASE_PLANE_MAX_CP + 1] = 1;
                                l = l2;
                                bitarr_is_cloned = true;
                            } else {
                                for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP; j++) {
                                    l[j] = l[j] && !ba4pcode[j];
                                }
                            }
                        }
                    }
                }
            }

            i = 0;
            while (i <= UNICODE_BASE_PLANE_MAX_CP) {
                // find first character not in original set:
                while (!l[i]) {
                    i++;
                }
                if (i >= UNICODE_BASE_PLANE_MAX_CP + 1) {
                    break;
                }
                // find next character not in original set:
                for (j = i + 1; l[j]; j++) {} /* empty loop */
                if (j > UNICODE_BASE_PLANE_MAX_CP + 1) {
                    j = UNICODE_BASE_PLANE_MAX_CP + 1;
                }
                // generate subset:
                rv.push(i2c(i));
                if (j - 1 > i) {
                    rv.push((j - 2 > i ? '-' : '') + i2c(j - 1));
                }
                i = j;
            }
        }

        assert__default['default'](rv.length);
        let s = rv.join('');
        assert__default['default'](s);

        // Check if the set is better represented by one of the regex escapes:
        let esc4s = EscCode_bitarray_output_refs.set2esc[s];
        if (esc4s) {
            // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
            return '\\' + esc4s;
        }
        return s;
    }





    // Pretty brutal conversion of 'regex' `s` back to raw regex set content: strip outer [...] when they're there;
    // ditto for inner combos of sets, i.e. `]|[` as in `[0-9]|[a-z]`.
    function reduceRegexToSetBitArray(s, name, opts) {
        let orig = s;

        // propagate deferred exceptions = error reports.
        if (s instanceof Error) {
            return s;
        }

        let l = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);
        let internal_state = 0;
        let derr;

        while (s.length) {
            let c1 = s.match(CHR_RE);
            if (!c1) {
                // cope with illegal escape sequences too!
                return new Error('illegal escape sequence at start of regex part: "' + s + '" of regex "' + orig + '"');
            }
            c1 = c1[0];
            s = s.substr(c1.length);

            switch (c1) {
            case '[':
                // this is starting a set within the regex: scan until end of set!
                var set_content = [];
                while (s.length) {
                    let inner = s.match(SET_PART_RE);
                    if (!inner) {
                        inner = s.match(CHR_RE);
                        if (!inner) {
                            // cope with illegal escape sequences too!
                            return new Error('illegal escape sequence at start of regex part: ' + s + '" of regex "' + orig + '"');
                        }
                        inner = inner[0];
                        if (inner === ']') break;
                    } else {
                        inner = inner[0];
                    }
                    set_content.push(inner);
                    s = s.substr(inner.length);
                }

                // ensure that we hit the terminating ']':
                var c2 = s.match(CHR_RE);
                if (!c2) {
                    // cope with illegal escape sequences too!
                    return new Error('regex set expression is broken in regex: "' + orig + '" --> "' + s + '"');
                }
                c2 = c2[0];
                if (c2 !== ']') {
                    return new Error('regex set expression is broken in regex: ' + orig);
                }
                s = s.substr(c2.length);

                var se = set_content.join('');
                if (!internal_state) {
                    derr = set2bitarray(l, se, opts);
                    // propagate deferred exceptions = error reports.
                    if (derr instanceof Error) {
                        return derr;
                    }

                    // a set is to use like a single character in a longer literal phrase, hence input `[abc]word[def]` would thus produce output `[abc]`:
                    internal_state = 1;
                }
                break;

            // Strip unescaped pipes to catch constructs like `\\r|\\n` and turn them into
            // something ready for use inside a regex set, e.g. `\\r\\n`.
            //
            // > Of course, we realize that converting more complex piped constructs this way
            // > will produce something you might not expect, e.g. `A|WORD2` which
            // > would end up as the set `[AW]` which is something else than the input
            // > entirely.
            // >
            // > However, we can only depend on the user (grammar writer) to realize this and
            // > prevent this from happening by not creating such oddities in the input grammar.
            case '|':
                // a|b --> [ab]
                internal_state = 0;
                break;

            case '(':
                // (a) --> a
                //
                // TODO - right now we treat this as 'too complex':

                // Strip off some possible outer wrappers which we know how to remove.
                // We don't worry about 'damaging' the regex as any too-complex regex will be caught
                // in the validation check at the end; our 'strippers' here would not damage useful
                // regexes anyway and them damaging the unacceptable ones is fine.
                s = s.replace(/^\((?:\?:)?(.*?)\)$/, '$1');         // (?:...) -> ...  and  (...) -> ...
                s = s.replace(/^\^?(.*?)\$?$/, '$1');               // ^...$ --> ...  (catch these both inside and outside the outer grouping, hence do the ungrouping twice: one before, once after this)
                s = s.replace(/^\((?:\?:)?(.*?)\)$/, '$1');         // (?:...) -> ...  and  (...) -> ...

                return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

            case '.':
            case '*':
            case '+':
            case '?':
                // wildcard
                //
                // TODO - right now we treat this as 'too complex':
                return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

            case '{':                        // range, e.g. `x{1,3}`, or macro?
                // TODO - right now we treat this as 'too complex':
                return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

            default:
                // literal character or word: take the first character only and ignore the rest, so that
                // the constructed set for `word|noun` would be `[wb]`:
                if (!internal_state) {
                    derr = set2bitarray(l, c1, opts);
                    // propagate deferred exceptions = error reports.
                    if (derr instanceof Error) {
                        return derr;
                    }

                    internal_state = 2;
                }
                break;
            }
        }

        s = bitarray2set(l);

        // When this result is suitable for use in a set, than we should be able to compile
        // it in a regex; that way we can easily validate whether macro X is fit to be used
        // inside a regex set:
        try {
            assert__default['default'](s);
            assert__default['default'](!(s instanceof Error));
            let re = new XRegExp__default['default']('[' + s + ']');
            re.test(s[0]);

            // One thing is apparently *not* caught by the RegExp compile action above: `[a[b]c]`
            // so we check for lingering UNESCAPED brackets in here as those cannot be:
            if (/[^\\][\[\]]/.exec(s)) {
                throw new Error('unescaped brackets in set data');
            }
        } catch (ex) {
            // make sure we produce a set range expression which will fail badly when it is used
            // in actual code:
            s = new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + s + ']"]: ' + ex.message);
        }

        assert__default['default'](s);
        // propagate deferred exceptions = error reports.
        if (s instanceof Error) {
            return s;
        }
        return l;
    }




    // Convert bitarray representing, for example, `'0-9'` to regex string `[0-9]`
    // -- or in this example it can be further optimized to only `\d`!
    function produceOptimizedRegex4Set(bitarr) {
        // First try to produce a minimum regex from the bitarray directly:
        let s1 = bitarray2set(bitarr, false, true);

        // and when the regex set turns out to match a single pcode/escape, then
        // use that one as-is:
        if (s1.match(SET_IS_SINGLE_PCODE_RE)) {
            // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
            return s1;
        }
        s1 = '[' + s1 + ']';

        // Now try to produce a minimum regex from the *inverted* bitarray via negation:
        // Because we look at a negated bitset, there's no use looking for matches with
        // special cases here.
        let s2 = bitarray2set(bitarr, true, true);

        if (s2[0] === '^') {
            s2 = s2.substr(1);
            if (s2.match(SET_IS_SINGLE_PCODE_RE)) {
                // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
                return s2;
            }
        } else {
            s2 = '^' + s2;
        }
        s2 = '[' + s2 + ']';

        // Then, as some pcode/escapes still happen to deliver a LARGER regex string in the end,
        // we also check against the plain, unadulterated regex set expressions:
        //
        // First try to produce a minimum regex from the bitarray directly:
        let s3 = bitarray2set(bitarr, false, false);

        // and when the regex set turns out to match a single pcode/escape, then
        // use that one as-is:
        if (s3.match(SET_IS_SINGLE_PCODE_RE)) {
            // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
            return s3;
        }
        s3 = '[' + s3 + ']';

        // Now try to produce a minimum regex from the *inverted* bitarray via negation:
        // Because we look at a negated bitset, there's no use looking for matches with
        // special cases here.
        let s4 = bitarray2set(bitarr, true, false);

        if (s4[0] === '^') {
            s4 = s4.substr(1);
            if (s4.match(SET_IS_SINGLE_PCODE_RE)) {
                // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
                return s4;
            }
        } else {
            s4 = '^' + s4;
        }
        s4 = '[' + s4 + ']';

        if (s2.length < s1.length) {
            s1 = s2;
        }
        if (s3.length < s1.length) {
            s1 = s3;
        }
        if (s4.length < s1.length) {
            s1 = s4;
        }

        return s1;
    }






    var setmgmt = {
        XREGEXP_UNICODE_ESCAPE_RE,
        CHR_RE,
        SET_PART_RE,
        NOTHING_SPECIAL_RE,
        SET_IS_SINGLE_PCODE_RE,

        UNICODE_BASE_PLANE_MAX_CP,

        WHITESPACE_SETSTR,
        DIGIT_SETSTR,
        WORDCHAR_SETSTR,

        set2bitarray,
        bitarray2set,
        produceOptimizedRegex4Set,
        reduceRegexToSetBitArray
    };

    // Basic Lexer implemented using JavaScript regular expressions
    const rmCommonWS$2 = helpers.rmCommonWS;
    const mkIdentifier$3 = helpers.mkIdentifier;
    const code_exec = helpers.exec;

    const version = '0.6.2-220';                              // require('./package.json').version;



    function chkBugger$2(src) {
        src = '' + src;
        if (src.match(/\bcov_\w+/)) {
            console.error('### ISTANBUL COVERAGE CODE DETECTED ###\n', src);
        }
    }



    const XREGEXP_UNICODE_ESCAPE_RE$1 = setmgmt.XREGEXP_UNICODE_ESCAPE_RE;              // Matches the XRegExp Unicode escape braced part, e.g. `{Number}`
    const CHR_RE$1 = setmgmt.CHR_RE;
    const SET_PART_RE$1 = setmgmt.SET_PART_RE;
    const NOTHING_SPECIAL_RE$1 = setmgmt.NOTHING_SPECIAL_RE;
    const UNICODE_BASE_PLANE_MAX_CP$1 = setmgmt.UNICODE_BASE_PLANE_MAX_CP;

    // WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
    //
    // This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
    const ID_REGEX_BASE$1 = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';




    // see also ./lib/cli.js
    /**
    @public
    @nocollapse
    */
    const defaultJisonLexOptions = {
        moduleType: 'commonjs',
        debug: false,
        enableDebugLogs: false,
        json: false,
        main: false,                    // CLI: not:(--main option)
        dumpSourceCodeOnFailure: true,
        throwErrorOnCompileFailure: true,

        moduleName: undefined,
        defaultModuleName: 'lexer',
        file: undefined,
        outfile: undefined,
        inputPath: undefined,
        inputFilename: undefined,
        warn_cb: undefined,             // function(msg) | true (= use Jison.Print) | false (= throw Exception)

        xregexp: false,
        lexerErrorsAreRecoverable: false,
        flex: false,
        backtrack_lexer: false,
        ranges: false,                  // track position range, i.e. start+end indexes in the input string
        trackPosition: true,            // track line+column position in the input string
        caseInsensitive: false,
        showSource: false,
        exportSourceCode: false,
        exportAST: false,
        prettyCfg: true,
        pre_lex: undefined,
        post_lex: undefined
    };


    // Merge sets of options.
    //
    // Convert alternative jison option names to their base option.
    //
    // The *last* option set which overrides the default wins, where 'override' is
    // defined as specifying a not-undefined value which is not equal to the
    // default value.
    //
    // When the FIRST argument is STRING "NODEFAULT", then we MUST NOT mix the
    // default values avialable in Jison.defaultJisonOptions.
    //
    // Return a fresh set of options.
    /** @public */
    function mkStdOptions(/*...args*/) {
        let h = Object.prototype.hasOwnProperty;

        let opts = {};
        let args = [].concat.apply([], arguments);
        // clone defaults, so we do not modify those constants?
        if (args[0] !== 'NODEFAULT') {
            args.unshift(defaultJisonLexOptions);
        } else {
            args.shift();
        }

        for (let i = 0, len = args.length; i < len; i++) {
            let o = args[i];
            if (!o) continue;

            // clone input (while camel-casing the options), so we do not modify those either.
            let o2 = {};

            for (var p in o) {
                if (typeof o[p] !== 'undefined' && h.call(o, p)) {
                    o2[mkIdentifier$3(p)] = o[p];
                }
            }

            // now clean them options up:
            if (typeof o2.main !== 'undefined') {
                o2.noMain = !o2.main;
            }

            delete o2.main;

            // special check for `moduleName` to ensure we detect the 'default' moduleName entering from the CLI
            // NOT overriding the moduleName set in the grammar definition file via an `%options` entry:
            if (o2.moduleName === o2.defaultModuleName) {
                delete o2.moduleName;
            }

            // now see if we have an overriding option here:
            for (var p in o2) {
                if (h.call(o2, p)) {
                    if (typeof o2[p] !== 'undefined') {
                        opts[p] = o2[p];
                    }
                }
            }
        }

        return opts;
    }

    // set up export/output attributes of the `options` object instance
    function prepExportStructures(options) {
        // set up the 'option' `exportSourceCode` as a hash object for returning
        // all generated source code chunks to the caller
        let exportSourceCode = options.exportSourceCode;
        if (!exportSourceCode || typeof exportSourceCode !== 'object') {
            exportSourceCode = {
                enabled: !!exportSourceCode
            };
        } else if (typeof exportSourceCode.enabled !== 'boolean') {
            exportSourceCode.enabled = true;
        }
        options.exportSourceCode = exportSourceCode;
    }

    // Autodetect if the input lexer spec is in JSON or JISON
    // format when the `options.json` flag is `true`.
    //
    // Produce the JSON lexer spec result when these are JSON formatted already as that
    // would save us the trouble of doing this again, anywhere else in the JISON
    // compiler/generator.
    //
    // Otherwise return the *parsed* lexer spec as it has
    // been processed through LexParser.
    function autodetectAndConvertToJSONformat(lexerSpec, options) {
        let chk_l = null;
        let ex1, err;

        if (typeof lexerSpec === 'string') {
            if (options.json) {
                try {
                    chk_l = JSON5__default['default'].parse(lexerSpec);

                    // When JSON5-based parsing of the lexer spec succeeds, this implies the lexer spec is specified in `JSON mode`
                    // *OR* there's a JSON/JSON5 format error in the input:
                } catch (e) {
                    ex1 = e;
                }
            }
            if (!chk_l) {
                // // WARNING: the lexer may receive options specified in the **grammar spec file**,
                // //          hence we should mix the options to ensure the lexParser always
                // //          receives the full set!
                // //
                // // make sure all options are 'standardized' before we go and mix them together:
                // options = mkStdOptions(grammar.options, options);
                try {
                    chk_l = lexParser.parse(lexerSpec);
                } catch (e) {
                    if (options.json) {
                        // When both JSON5 and JISON input modes barf a hairball, assume the most important
                        // error is the JISON one (show that one first!), while it MAY be a JSON5 format
                        // error that triggered it (show that one last!).
                        //
                        // Also check for common JISON errors which are obviously never triggered by any
                        // odd JSON5 input format error: when we encounter such an error here, we don't
                        // confuse matters and forget about the JSON5 fail as it's irrelevant:
                        const commonErrors = [
                            /does not compile/,
                            /you did not correctly separate trailing code/,
                            /You did not specify/,
                            /You cannot specify/,
                            /must be qualified/,
                            /%start/,
                            /%token/,
                            /%import/,
                            /%include/,
                            /%options/,
                            /%parse-params/,
                            /%parser-type/,
                            /%epsilon/,
                            /definition list error/,
                            /token list error/,
                            /declaration error/,
                            /should be followed/,
                            /should be separated/,
                            /an error in one or more of your lexer regex rules/,
                            /an error in your lexer epilogue/,
                            /unsupported definition type/
                        ];
                        let cmnerr = commonErrors.filter(function check(re) {
                            return e.message.match(re);
                        });
                        if (cmnerr.length > 0) {
                            err = e;
                        } else {
                            err = new Error('Could not parse jison lexer spec in JSON AUTODETECT mode:\nin JISON Mode we get Error: ' + e.message + '\n\nwhile JSON5 Mode produces Error: ' + ex1.message);
                            err.secondary_exception = e;
                            err.stack = ex1.stack;
                        }
                    } else {
                        err = new Error('Could not parse lexer spec\nError: ' + e.message);
                        err.stack = e.stack;
                    }
                    throw err;
                }
            }
        } else {
            chk_l = lexerSpec;
        }

        // Save time! Don't reparse the entire lexer spec *again* inside the code generators when that's not necessary:

        return chk_l;
    }


    // expand macros and convert matchers to RegExp's
    function prepareRules(dict, actions, caseHelper, tokens, startConditions, opts) {
        let m, i, k, rule, action, conditions;
        let active_conditions;
        assert__default['default'](Array.isArray(dict.rules));
        let rules = dict.rules.slice(0);    // shallow copy of the rules array as we MAY modify it in here!
        let newRules = [];
        let macros = {};
        let regular_rule_count = 0;
        let simple_rule_count = 0;

        // Assure all options are camelCased:
        assert__default['default'](typeof opts.options['case-insensitive'] === 'undefined');

        if (!tokens) {
            tokens = {};
        }

        if (opts.options.flex && rules.length > 0) {
            rules.push([ '.', 'console.log("", yytext); /* `flex` lexing mode: the last resort rule! */' ]);
        }

        // Depending on the location within the regex we need different expansions of the macros:
        // one expansion for when a macro is *inside* a `[...]` and another expansion when a macro
        // is anywhere else in a regex:
        if (dict.macros) {
            macros = prepareMacros(dict.macros, opts);
        }

        function tokenNumberReplacement(str, token) {
            return 'return ' + (tokens[token] || '\'' + token.replace(/'/g, '\\\'') + '\'');
        }

        // Make sure a comment does not contain any embedded '*/' end-of-comment marker
        // as that would break the generated code
        function postprocessComment(str) {
            if (Array.isArray(str)) {
                str = str.join(' ');
            }
            str = str.replace(/\*\//g, '*\\/');         // destroy any inner `*/` comment terminator sequence.
            return str;
        }

        let routingCode = [ 'switch(yyrulenumber) {' ];

        for (i = 0; i < rules.length; i++) {
            rule = rules[i].slice(0);           // shallow copy: do not modify input rules
            m = rule[0];

            active_conditions = [];
            if (!Array.isArray(m)) {
                // implicit add to all inclusive start conditions
                for (k in startConditions) {
                    if (startConditions[k].inclusive) {
                        active_conditions.push(k);
                        startConditions[k].rules.push(i);
                    }
                }
            } else if (m[0] === '*') {
                // Add to ALL start conditions
                active_conditions.push('*');
                for (k in startConditions) {
                    startConditions[k].rules.push(i);
                }
                rule.shift();
                m = rule[0];
            } else {
                // Add to explicit start conditions
                conditions = rule.shift();
                m = rule[0];
                for (k = 0; k < conditions.length; k++) {
                    if (!startConditions.hasOwnProperty(conditions[k])) {
                        startConditions[conditions[k]] = {
                            rules: [],
                            inclusive: false
                        };
                        console.warn('Lexer Warning:', '"' + conditions[k] + '" start condition should be defined as %s or %x; assuming %x now.');
                    }
                    active_conditions.push(conditions[k]);
                    startConditions[conditions[k]].rules.push(i);
                }
            }

            if (typeof m === 'string') {
                m = expandMacros(m, macros, opts);
                m = new XRegExp__default['default']('^(?:' + m + ')', opts.options.caseInsensitive ? 'i' : '');
            }
            newRules.push(m);
            action = rule[1];
            if (typeof action === 'function') {
                // Also cope with Arrow Functions (and inline those as well?).
                // See also https://github.com/zaach/jison-lex/issues/23
                action = helpers.printFunctionSourceCodeContainer(action).code;
            }
            action = action.replace(/return\s*\(?'((?:\\'|[^']+)+)'\)?/g, tokenNumberReplacement);
            action = action.replace(/return\s*\(?"((?:\\"|[^"]+)+)"\)?/g, tokenNumberReplacement);

            let code = [ '\n/*! Conditions::' ];
            code.push(postprocessComment(active_conditions));
            code.push('*/', '\n/*! Rule::      ');
            code.push(postprocessComment(rule[0]));
            code.push('*/', '\n');

            // When the action is *only* a simple `return TOKEN` statement, then add it to the caseHelpers;
            // otherwise add the additional `break;` at the end.
            //
            // Note: we do NOT analyze the action block any more to see if the *last* line is a simple
            // `return NNN;` statement as there are too many shoddy idioms, e.g.
            //
            // ```
            // %{ if (cond)
            //      return TOKEN;
            // %}
            // ```
            //
            // which would then cause havoc when our action code analysis (using regexes or otherwise) was 'too simple'
            // to catch these culprits; hence we resort and stick with the most fundamental approach here:
            // always append `break;` even when it would be obvious to a human that such would be 'unreachable code'.
            let match_nr = /^return[\s\r\n]+((?:'(?:\\'|[^']+)+')|(?:"(?:\\"|[^"]+)+")|\d+)[\s\r\n]*;?$/.exec(action.trim());
            if (match_nr) {
                simple_rule_count++;
                caseHelper.push([].concat(code, i, ':', match_nr[1]).join(' ').replace(/[\n]/g, '\n  '));
            } else {
                regular_rule_count++;
                // If action includes the keyword `let` or `const`, then it's ES6 code
                // which must be scoped to prevent collisions with other action code chunks
                // in the same large generated switch/case statement:
                if (/\blet\b/.test(action) || /\bconst\b/.test(action)) {
                    action = '{\n' + action + '\n}';
                }
                routingCode.push([].concat('case', i, ':', code, action, '\nbreak;').join(' '));
            }
        }
        if (simple_rule_count) {
            routingCode.push('default:');
            routingCode.push('  return this.simpleCaseActionClusters[yyrulenumber];');
        }
        routingCode.push('}');

        // only inject the big switch/case chunk when there's any `switch` or `default` branch to switch to:
        if (simple_rule_count + regular_rule_count > 0) {
            actions.push.apply(actions, routingCode);
        } else {
            actions.push('/* no rules ==> no rule SWITCH! */');
        }

        return {
            rules: newRules,                // array listing only the lexer spec regexes
            macros: macros,

            regular_rule_count: regular_rule_count,
            simple_rule_count: simple_rule_count
        };
    }







    // expand all macros (with maybe one exception) in the given regex: the macros may exist inside `[...]` regex sets or
    // elsewhere, which requires two different treatments to expand these macros.
    function reduceRegex(s, name, opts, expandAllMacrosInSet_cb, expandAllMacrosElsewhere_cb) {
        let orig = s;

        function errinfo() {
            if (name) {
                return 'macro [[' + name + ']]';
            }
            return 'regex [[' + orig + ']]';
        }

        // propagate deferred exceptions = error reports.
        if (s instanceof Error) {
            return s;
        }

        let c1, c2;
        let rv = [];
        let derr;
        let se;

        while (s.length) {
            c1 = s.match(CHR_RE$1);
            if (!c1) {
                // cope with illegal escape sequences too!
                return new Error(errinfo() + ': illegal escape sequence at start of regex part: ' + s);
            }
            c1 = c1[0];
            s = s.substr(c1.length);

            switch (c1) {
            case '[':
                // this is starting a set within the regex: scan until end of set!
                var set_content = [];
                var l = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);

                while (s.length) {
                    let inner = s.match(SET_PART_RE$1);
                    if (!inner) {
                        inner = s.match(CHR_RE$1);
                        if (!inner) {
                            // cope with illegal escape sequences too!
                            return new Error(errinfo() + ': illegal escape sequence at start of regex part: ' + s);
                        }
                        inner = inner[0];
                        if (inner === ']') break;
                    } else {
                        inner = inner[0];
                    }
                    set_content.push(inner);
                    s = s.substr(inner.length);
                }

                // ensure that we hit the terminating ']':
                c2 = s.match(CHR_RE$1);
                if (!c2) {
                    // cope with illegal escape sequences too!
                    return new Error(errinfo() + ': regex set expression is broken: "' + s + '"');
                }
                c2 = c2[0];
                if (c2 !== ']') {
                    return new Error(errinfo() + ': regex set expression is broken: apparently unterminated');
                }
                s = s.substr(c2.length);

                se = set_content.join('');

                // expand any macros in here:
                if (expandAllMacrosInSet_cb) {
                    se = expandAllMacrosInSet_cb(se);
                    assert__default['default'](se);
                    if (se instanceof Error) {
                        return new Error(errinfo() + ': ' + se.message);
                    }
                }

                derr = setmgmt.set2bitarray(l, se, opts);
                if (derr instanceof Error) {
                    return new Error(errinfo() + ': ' + derr.message);
                }

                // find out which set expression is optimal in size:
                var s1 = setmgmt.produceOptimizedRegex4Set(l);

                // check if the source regex set potentially has any expansions (guestimate!)
                //
                // The indexOf('{') picks both XRegExp Unicode escapes and JISON lexer macros, which is perfect for us here.
                var has_expansions = (se.indexOf('{') >= 0);

                se = '[' + se + ']';

                if (!has_expansions && se.length < s1.length) {
                    s1 = se;
                }
                rv.push(s1);
                break;

            // XRegExp Unicode escape, e.g. `\\p{Number}`:
            case '\\p':
                c2 = s.match(XREGEXP_UNICODE_ESCAPE_RE$1);
                if (c2) {
                    c2 = c2[0];
                    s = s.substr(c2.length);

                    // nothing to expand.
                    rv.push(c1 + c2);
                } else {
                    // nothing to stretch this match, hence nothing to expand.
                    rv.push(c1);
                }
                break;

            // Either a range expression or the start of a macro reference: `.{1,3}` or `{NAME}`.
            // Treat it as a macro reference and see if it will expand to anything:
            case '{':
                c2 = s.match(NOTHING_SPECIAL_RE$1);
                if (c2) {
                    c2 = c2[0];
                    s = s.substr(c2.length);

                    let c3 = s[0];
                    s = s.substr(c3.length);
                    if (c3 === '}') {
                        // possibly a macro name in there... Expand if possible:
                        c2 = c1 + c2 + c3;
                        if (expandAllMacrosElsewhere_cb) {
                            c2 = expandAllMacrosElsewhere_cb(c2);
                            assert__default['default'](c2);
                            if (c2 instanceof Error) {
                                return new Error(errinfo() + ': ' + c2.message);
                            }
                        }
                    } else {
                        // not a well-terminated macro reference or something completely different:
                        // we do not even attempt to expand this as there's guaranteed nothing to expand
                        // in this bit.
                        c2 = c1 + c2 + c3;
                    }
                    rv.push(c2);
                } else {
                    // nothing to stretch this match, hence nothing to expand.
                    rv.push(c1);
                }
                break;

            // Recognize some other regex elements, but there's no need to understand them all.
            //
            // We are merely interested in any chunks now which do *not* include yet another regex set `[...]`
            // nor any `{MACRO}` reference:
            default:
                // non-set character or word: see how much of this there is for us and then see if there
                // are any macros still lurking inside there:
                c2 = s.match(NOTHING_SPECIAL_RE$1);
                if (c2) {
                    c2 = c2[0];
                    s = s.substr(c2.length);

                    // nothing to expand.
                    rv.push(c1 + c2);
                } else {
                    // nothing to stretch this match, hence nothing to expand.
                    rv.push(c1);
                }
                break;
            }
        }

        s = rv.join('');

        // When this result is suitable for use in a set, than we should be able to compile
        // it in a regex; that way we can easily validate whether macro X is fit to be used
        // inside a regex set:
        try {
            let re;
            re = new XRegExp__default['default'](s);
            re.test(s[0]);
        } catch (ex) {
            // make sure we produce a regex expression which will fail badly when it is used
            // in actual code:
            return new Error(errinfo() + ': expands to an invalid regex: /' + s + '/');
        }

        assert__default['default'](s);
        return s;
    }


    // expand macros within macros and cache the result
    function prepareMacros(dict_macros, opts) {
        let macros = {};

        // expand a `{NAME}` macro which exists inside a `[...]` set:
        function expandMacroInSet(i) {
            let k, a, m;
            if (!macros[i]) {
                m = dict_macros[i];

                if (m.indexOf('{') >= 0) {
                    // set up our own record so we can detect definition loops:
                    macros[i] = {
                        in_set: false,
                        elsewhere: null,
                        raw: dict_macros[i]
                    };

                    for (k in dict_macros) {
                        if (dict_macros.hasOwnProperty(k) && i !== k) {
                            // it doesn't matter if the lexer recognized that the inner macro(s)
                            // were sitting inside a `[...]` set or not: the fact that they are used
                            // here in macro `i` which itself sits in a set, makes them *all* live in
                            // a set so all of them get the same treatment: set expansion style.
                            //
                            // Note: make sure we don't try to expand any XRegExp `\p{...}` or `\P{...}`
                            // macros here:
                            if (XRegExp__default['default']._getUnicodeProperty(k)) {
                                // Work-around so that you can use `\p{ascii}` for a XRegExp slug, a.k.a.
                                // Unicode 'General Category' Property cf. http://unicode.org/reports/tr18/#Categories,
                                // while using `\p{ASCII}` as a *macro expansion* of the `ASCII`
                                // macro:
                                if (k.toUpperCase() !== k) {
                                    m = new Error('Cannot use name "' + k + '" as a macro name as it clashes with the same XRegExp "\\p{..}" Unicode \'General Category\' Property name. Use all-uppercase macro names, e.g. name your macro "' + k.toUpperCase() + '" to work around this issue or give your offending macro a different name.');
                                    break;
                                }
                            }

                            a = m.split('{' + k + '}');
                            if (a.length > 1) {
                                let x = expandMacroInSet(k);
                                assert__default['default'](x);
                                if (x instanceof Error) {
                                    m = x;
                                    break;
                                }
                                m = a.join(x);
                            }
                        }
                    }
                }

                let mba = setmgmt.reduceRegexToSetBitArray(m, i, opts);

                let s1;

                // propagate deferred exceptions = error reports.
                if (mba instanceof Error) {
                    s1 = mba;
                } else {
                    s1 = setmgmt.bitarray2set(mba, false);

                    m = s1;
                }

                macros[i] = {
                    in_set: s1,
                    elsewhere: null,
                    raw: dict_macros[i]
                };
            } else {
                m = macros[i].in_set;

                if (m instanceof Error) {
                    // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                    return new Error(m.message);
                }

                // detect definition loop:
                if (m === false) {
                    return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                }
            }

            return m;
        }

        function expandMacroElsewhere(i) {
            let m;

            if (macros[i].elsewhere == null) {
                m = dict_macros[i];

                // set up our own record so we can detect definition loops:
                macros[i].elsewhere = false;

                // the macro MAY contain other macros which MAY be inside a `[...]` set in this
                // macro or elsewhere, hence we must parse the regex:
                m = reduceRegex(m, i, opts, expandAllMacrosInSet, expandAllMacrosElsewhere);
                // propagate deferred exceptions = error reports.
                if (m instanceof Error) {
                    return m;
                }

                macros[i].elsewhere = m;
            } else {
                m = macros[i].elsewhere;

                if (m instanceof Error) {
                    // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                    return m;
                }

                // detect definition loop:
                if (m === false) {
                    return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                }
            }

            return m;
        }

        function expandAllMacrosInSet(s) {
            let i, x;

            // process *all* the macros inside [...] set:
            if (s.indexOf('{') >= 0) {
                for (i in macros) {
                    if (macros.hasOwnProperty(i)) {
                        let a = s.split('{' + i + '}');
                        if (a.length > 1) {
                            x = expandMacroInSet(i);
                            assert__default['default'](x);
                            if (x instanceof Error) {
                                return new Error('failure to expand the macro [' + i + '] in set [' + s + ']: ' + x.message);
                            }
                            s = a.join(x);
                        }

                        // stop the brute-force expansion attempt when we done 'em all:
                        if (s.indexOf('{') === -1) {
                            break;
                        }
                    }
                }
            }

            return s;
        }

        function expandAllMacrosElsewhere(s) {
            let i, x;

            // When we process the remaining macro occurrences in the regex
            // every macro used in a lexer rule will become its own capture group.
            //
            // Meanwhile the cached expansion will expand any submacros into
            // *NON*-capturing groups so that the backreference indexes remain as you'ld
            // expect and using macros doesn't require you to know exactly what your
            // used macro will expand into, i.e. which and how many submacros it has.
            //
            // This is a BREAKING CHANGE from vanilla jison 0.4.15!
            if (s.indexOf('{') >= 0) {
                for (i in macros) {
                    if (macros.hasOwnProperty(i)) {
                        // These are all submacro expansions, hence non-capturing grouping is applied:
                        let a = s.split('{' + i + '}');
                        if (a.length > 1) {
                            x = expandMacroElsewhere(i);
                            assert__default['default'](x);
                            if (x instanceof Error) {
                                return new Error('failure to expand the macro [' + i + '] in regex /' + s + '/: ' + x.message);
                            }
                            s = a.join('(?:' + x + ')');
                        }

                        // stop the brute-force expansion attempt when we done 'em all:
                        if (s.indexOf('{') === -1) {
                            break;
                        }
                    }
                }
            }

            return s;
        }


        let i;

        if (opts.debug) console.log('\n############## RAW macros: ', dict_macros);

        // first we create the part of the dictionary which is targeting the use of macros
        // *inside* `[...]` sets; once we have completed that half of the expansions work,
        // we then go and expand the macros for when they are used elsewhere in a regex:
        // iff we encounter submacros then which are used *inside* a set, we can use that
        // first half dictionary to speed things up a bit as we can use those expansions
        // straight away!
        for (i in dict_macros) {
            if (dict_macros.hasOwnProperty(i)) {
                expandMacroInSet(i);
            }
        }

        for (i in dict_macros) {
            if (dict_macros.hasOwnProperty(i)) {
                expandMacroElsewhere(i);
            }
        }

        if (opts.debug) console.log('\n############### expanded macros: ', macros);

        return macros;
    }



    // expand macros in a regex; expands them recursively
    function expandMacros(src, macros, opts) {
        let expansion_count = 0;

        // By the time we call this function `expandMacros` we MUST have expanded and cached all macros already!
        // Hence things should be easy in there:

        function expandAllMacrosInSet(s) {
            let i, m, x;

            // process *all* the macros inside [...] set:
            if (s.indexOf('{') >= 0) {
                for (i in macros) {
                    if (macros.hasOwnProperty(i)) {
                        m = macros[i];

                        let a = s.split('{' + i + '}');
                        if (a.length > 1) {
                            x = m.in_set;

                            assert__default['default'](x);
                            if (x instanceof Error) {
                                // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                                throw x;
                            }

                            // detect definition loop:
                            if (x === false) {
                                return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                            }

                            s = a.join(x);
                            expansion_count++;
                        }

                        // stop the brute-force expansion attempt when we done 'em all:
                        if (s.indexOf('{') === -1) {
                            break;
                        }
                    }
                }
            }

            return s;
        }

        function expandAllMacrosElsewhere(s) {
            let i, m, x;

            // When we process the main macro occurrences in the regex
            // every macro used in a lexer rule will become its own capture group.
            //
            // Meanwhile the cached expansion will expand any submacros into
            // *NON*-capturing groups so that the backreference indexes remain as you'ld
            // expect and using macros doesn't require you to know exactly what your
            // used macro will expand into, i.e. which and how many submacros it has.
            //
            // This is a BREAKING CHANGE from vanilla jison 0.4.15!
            if (s.indexOf('{') >= 0) {
                for (i in macros) {
                    if (macros.hasOwnProperty(i)) {
                        m = macros[i];

                        let a = s.split('{' + i + '}');
                        if (a.length > 1) {
                            // These are all main macro expansions, hence CAPTURING grouping is applied:
                            x = m.elsewhere;
                            assert__default['default'](x);

                            // detect definition loop:
                            if (x === false) {
                                return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                            }

                            s = a.join('(' + x + ')');
                            expansion_count++;
                        }

                        // stop the brute-force expansion attempt when we done 'em all:
                        if (s.indexOf('{') === -1) {
                            break;
                        }
                    }
                }
            }

            return s;
        }


        // When we process the macro occurrences in the regex
        // every macro used in a lexer rule will become its own capture group.
        //
        // Meanwhile the cached expansion will have expanded any submacros into
        // *NON*-capturing groups so that the backreference indexes remain as you'ld
        // expect and using macros doesn't require you to know exactly what your
        // used macro will expand into, i.e. which and how many submacros it has.
        //
        // This is a BREAKING CHANGE from vanilla jison 0.4.15!
        let s2 = reduceRegex(src, null, opts, expandAllMacrosInSet, expandAllMacrosElsewhere);
        // propagate deferred exceptions = error reports.
        if (s2 instanceof Error) {
            throw s2;
        }

        // only when we did expand some actual macros do we take the re-interpreted/optimized/regenerated regex from reduceRegex()
        // in order to keep our test cases simple and rules recognizable. This assumes the user can code good regexes on his own,
        // as long as no macros are involved...
        //
        // Also pick the reduced regex when there (potentially) are XRegExp extensions in the original, e.g. `\\p{Number}`,
        // unless the `xregexp` output option has been enabled.
        if (expansion_count > 0 || (src.indexOf('\\p{') >= 0 && !opts.options.xregexp)) {
            src = s2;
        } else {
            // Check if the reduced regex is smaller in size; when it is, we still go with the new one!
            if (s2.length < src.length) {
                src = s2;
            }
        }

        return src;
    }

    function prepareStartConditions(conditions) {
        let sc;
        let hash = {};

        for (sc in conditions) {
            if (conditions.hasOwnProperty(sc)) {
                hash[sc] = {
                    rules: [],
                    inclusive: !conditions[sc]
                };
            }
        }
        return hash;
    }

    function buildActions(dict, tokens, opts) {
        let actions = [ dict.actionInclude || '', 'var YYSTATE = YY_START;' ];
        let tok;
        let toks = {};
        let caseHelper = [];

        // tokens: map/array of token numbers to token names
        for (tok in tokens) {
            let idx = parseInt(tok);
            if (idx && idx > 0) {
                toks[tokens[tok]] = idx;
            }
        }

        let gen = prepareRules(dict, actions, caseHelper, tokens && toks, opts.conditions, opts);

        let code = actions.join('\n');
        'yytext yyleng yylineno yylloc yyerror'.split(' ').forEach(function (yy) {
            code = code.replace(new RegExp('\\b(' + yy + ')\\b', 'g'), 'yy_.$1');
        });

        return {
            caseHelperInclude: '{\n' + caseHelper.join(',') + '\n}',

            actions: `function lexer__performAction(yy, yyrulenumber, YY_START) {
            var yy_ = this;

            ${code}
        }`,

            rules: gen.rules,
            macros: gen.macros,                   // propagate these for debugging/diagnostic purposes

            regular_rule_count: gen.regular_rule_count,
            simple_rule_count: gen.simple_rule_count
        };
    }

    //
    // NOTE: this is *almost* a copy of the JisonParserError producing code in
    //       jison/lib/jison.js @ line 2304:lrGeneratorMixin.generateErrorClass
    //
    function generateErrorClass() {
        // --- START lexer error class ---

    const prelude = `/**
 * See also:
 * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
 * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
 * with userland code which might access the derived class in a 'classic' way.
 *
 * @public
 * @constructor
 * @nocollapse
 */
function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonLexerError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    let stacktrace;
    if (hash && hash.exception instanceof Error) {
        const ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) { // V8
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
} else {
    JisonLexerError.prototype = Object.create(Error.prototype);
}
JisonLexerError.prototype.constructor = JisonLexerError;
JisonLexerError.prototype.name = 'JisonLexerError';`;

        // --- END lexer error class ---

        return prelude;
    }


    const jisonLexerErrorDefinition = generateErrorClass();


    function generateFakeXRegExpClassSrcCode() {
        return rmCommonWS$2`
        var __hacky_counter__ = 0;

        /**
         * @constructor
         * @nocollapse
         */
        function XRegExp(re, f) {
            this.re = re;
            this.flags = f;
            this._getUnicodeProperty = function (k) {};
            var fake = /./;    // WARNING: this exact 'fake' is also depended upon by the xregexp unit test!
            __hacky_counter__++;
            fake.__hacky_backy__ = __hacky_counter__;
            return fake;
        }
    `;
    }



    /** @constructor */
    function RegExpLexer(dict, input, tokens, build_options) {
        let opts;
        let dump = false;

        function test_me(tweak_cb, description, src_exception, ex_callback) {
            opts = processGrammar(dict, tokens, build_options);
            opts.__in_rules_failure_analysis_mode__ = false;
            prepExportStructures(opts);
            assert__default['default'](opts.options);
            if (tweak_cb) {
                tweak_cb();
            }
            let source = generateModuleBody(opts);
            try {
                // The generated code will always have the `lexer` variable declared at local scope
                // as `eval()` will use the local scope.
                //
                // The compiled code will look something like this:
                //
                // ```
                // let lexer;
                // bla bla...
                // ```
                //
                // or
                //
                // ```
                // const lexer = { bla... };
                // ```
                let testcode = [
                    '// provide a local version for test purposes:',
                    jisonLexerErrorDefinition,
                    '',
                    generateFakeXRegExpClassSrcCode(),
                    '',
                    source,
                    '',
                    rmCommonWS$2`
                    // JISON INJECTED VALIDATION CODE
                    // which attempts to ascertain you have defined a minimal viable lexer at least:
                    if (typeof lexer === "undefined") {
                        throw new SyntaxError("user-defined lexer does not define the required 'lexer' instance.");
                    }
                    if (!lexer) {
                        throw new SyntaxError("user-defined lexer does not define a non-NULL 'lexer' instance.");
                    }
                    if (typeof lexer.setInput !== 'function') {
                        throw new SyntaxError("user-defined lexer does not provide the mandatory 'lexer.setInput()' API function.");
                    }
                    if (typeof lexer.lex !== 'function') {
                        throw new SyntaxError("user-defined lexer does not provide the mandatory 'lexer.lex()' API function.");
                    }
                    // END OF JISON INJECTED VALIDATION CODE
                `,
                    'return lexer;'
                ].join('\n');
                let lexer = code_exec(testcode, function generated_code_exec_wrapper_regexp_lexer(sourcecode) {
                    //console.log("===============================LEXER TEST CODE\n", sourcecode, "\n=====================END====================\n");
                    chkBugger$2(sourcecode);
                    let lexer_f = new Function('', sourcecode);
                    return lexer_f();
                }, Object.assign({}, opts.options, {
                    throwErrorOnCompileFailure: true 
                }), 'lexer');

                if (!lexer) {
                    throw new Error('no lexer defined *at all*?!');
                }
                if (typeof lexer.options !== 'object' || lexer.options == null) {
                    throw new Error('your lexer class MUST have an .options member object or it won\'t fly!');
                }
                if (typeof lexer.setInput !== 'function') {
                    throw new Error('your lexer class MUST have a .setInput function member or it won\'t fly!');
                }
                if (lexer.EOF !== 1 && lexer.ERROR !== 2) {
                    throw new Error('your lexer class MUST have these constants defined: lexer.EOF = 1 and lexer.ERROR = 2 or it won\'t fly!');
                }

                // When we do NOT crash, we found/killed the problem area just before this call!
                if (src_exception && description) {
                    let msg = description;
                    if (typeof description === 'function') {
                        msg = description();
                    }
                    src_exception.message += '\n        (' + msg + ')';
                }

                // patch the pre and post handlers in there, now that we have some live code to work with:
                if (opts.options) {
                    let pre = opts.options.pre_lex;
                    let post = opts.options.post_lex;
                    // since JSON cannot encode functions, we'll have to do it manually now:
                    if (typeof pre === 'function') {
                        lexer.options.pre_lex = pre;
                    }
                    if (typeof post === 'function') {
                        lexer.options.post_lex = post;
                    }
                }

                if (opts.options.showSource) {
                    if (typeof opts.options.showSource === 'function') {
                        opts.options.showSource(lexer, source, opts, RegExpLexer);
                    } else {
                        console.log('\nGenerated lexer sourcecode:\n----------------------------------------\n', source, '\n----------------------------------------\n');
                    }
                }
                return lexer;
            } catch (ex) {
                // if (src_exception) {
                //     src_exception.message += '\n        (' + description + ': ' + ex.message + ')';
                // }

                if (ex_callback) {
                    ex_callback(ex);
                } else if (dump) {
                    console.log('source code:\n', source);
                }
                return false;
            }
        }

        /** @constructor */
        let lexer = test_me(null, null, null, function (ex) {
            // When we get an exception here, it means some part of the user-specified lexer is botched.
            //
            // Now we go and try to narrow down the problem area/category:
            assert__default['default'](opts.options);
            assert__default['default'](opts.options.xregexp !== undefined);
            let orig_xregexp_opt = !!opts.options.xregexp;
            if (!test_me(function () {
                assert__default['default'](opts.options.xregexp !== undefined);
                opts.options.xregexp = false;
                opts.showSource = false;
            }, 'When you have specified %option xregexp, you must also properly IMPORT the XRegExp library in the generated lexer.', ex, null)) {
                if (!test_me(function () {
                    // restore xregexp option setting: the trouble wasn't caused by the xregexp flag i.c.w. incorrect XRegExp library importing!
                    opts.options.xregexp = orig_xregexp_opt;

                    opts.conditions = [];
                    opts.showSource = false;
                }, function () {
                    assert__default['default'](Array.isArray(opts.rules));
                    return (opts.rules.length > 0 ?
                        'One or more of your lexer state names are possibly botched?' :
                        'Your custom lexer is somehow botched.'
                    );
                }, ex, null)) {
                    let rulesSpecSize;
                    if (!test_me(function () {
                        // store the parsed rule set size so we can use that info in case
                        // this attempt also fails:
                        assert__default['default'](Array.isArray(opts.rules));
                        rulesSpecSize = opts.rules.length;

                        // opts.conditions = [];
                        opts.rules = [];
                        opts.showSource = false;
                        opts.__in_rules_failure_analysis_mode__ = true;
                    }, 'One or more of your lexer rules are possibly botched?', ex, null)) {
                        // kill each rule action block, one at a time and test again after each 'edit':
                        let rv = false;
                        for (var i = 0, len = rulesSpecSize; i < len; i++) {
                            var lastEditedRuleSpec;
                            rv = test_me(function () {
                                assert__default['default'](Array.isArray(opts.rules));
                                assert__default['default'](opts.rules.length === rulesSpecSize);

                                // opts.conditions = [];
                                // opts.rules = [];
                                // opts.__in_rules_failure_analysis_mode__ = true;

                                // nuke all rules' actions up to and including rule numero `i`:
                                for (let j = 0; j <= i; j++) {
                                    // rules, when parsed, have 2 or 3 elements: [conditions, handle, action];
                                    // now we want to edit the *action* part:
                                    let rule = opts.rules[j];
                                    assert__default['default'](Array.isArray(rule));
                                    assert__default['default'](rule.length === 2 || rule.length === 3);
                                    rule.pop();
                                    rule.push('{ /* nada */ }');
                                    lastEditedRuleSpec = rule;
                                }
                            }, function () {
                                return 'Your lexer rule "' + lastEditedRuleSpec[0] + '" action code block is botched?';
                            }, ex, null);
                            if (rv) {
                                break;
                            }
                        }
                        if (!rv) {
                            test_me(function () {
                                opts.conditions = [];
                                opts.rules = [];
                                opts.performAction = 'null';
                                // opts.options = {};
                                // opts.caseHelperInclude = '{}';
                                opts.showSource = false;
                                opts.__in_rules_failure_analysis_mode__ = true;

                                dump = false;
                            }, 'One or more of your lexer rule action code block(s) are possibly botched?', ex, null);
                        }
                    }
                }
            }
            throw ex;
        });

        lexer.setInput(input);

        /** @public */
        lexer.generate = function () {
            return generateFromOpts(opts);
        };
        /** @public */
        lexer.generateModule = function () {
            return generateModule(opts);
        };
        /** @public */
        lexer.generateCommonJSModule = function () {
            return generateCommonJSModule(opts);
        };
        /** @public */
        lexer.generateESModule = function () {
            return generateESModule(opts);
        };
        /** @public */
        lexer.generateAMDModule = function () {
            return generateAMDModule(opts);
        };

        // internal APIs to aid testing:
        /** @public */
        lexer.getExpandedMacros = function () {
            return opts.macros;
        };

        return lexer;
    }

    // code stripping performance test for very simple grammar:
    //
    // - removing backtracking parser code branches:                    730K -> 750K rounds
    // - removing all location info tracking: yylineno, yylloc, etc.:   750K -> 900K rounds
    // - no `yyleng`:                                                   900K -> 905K rounds
    // - no `this.done` as we cannot have a NULL `_input` anymore:      905K -> 930K rounds
    // - `simpleCaseActionClusters` as array instead of hash object:    930K -> 940K rounds
    // - lexers which have only return stmts, i.e. only a
    //   `simpleCaseActionClusters` lookup table to produce
    //   lexer tokens: *inline* the `performAction` call:               940K -> 950K rounds
    // - given all the above, you can *inline* what's left of
    //   `lexer_next()`:                                                950K -> 955K rounds (? this stuff becomes hard to measure; inaccuracy abounds!)
    //
    // Total gain when we forget about very minor (and tough to nail) *inlining* `lexer_next()` gains:
    //
    //     730 -> 950  ~ 30% performance gain.
    //

    // As a function can be reproduced in source-code form by any JavaScript engine, we're going to wrap this chunk
    // of code in a function so that we can easily get it including it comments, etc.:
    /**
    @public
    @nocollapse
    */
    function getRegExpLexerPrototype() {
        // --- START lexer kernel ---
    return `{
    EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup

    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use

    done: false,                                /// INTERNAL USE ONLY
    _backtrack: false,                          /// INTERNAL USE ONLY
    _input: '',                                 /// INTERNAL USE ONLY
    _more: false,                               /// INTERNAL USE ONLY
    _signaled_error_token: false,               /// INTERNAL USE ONLY
    _clear_state: 0,                            /// INTERNAL USE ONLY; 0: clear to do, 1: clear done for lex()/next(); -1: clear done for inut()/unput()/...

    conditionStack: [],                         /// INTERNAL USE ONLY; managed via \`pushState()\`, \`popState()\`, \`topState()\` and \`stateStackSize()\`

    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. \`match\` is identical to \`yytext\` except that this one still contains the matched input string after \`lexer.performAction()\` has been invoked, where userland code MAY have changed/replaced the \`yytext\` value entirely!
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the \`lex()\` API.
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far. (**WARNING:** this value MAY be negative if you \`unput()\` more text than you have already lexed. This type of behaviour is generally observed for one kind of 'lexer/parser hack' where custom token-illiciting characters are pushed in front of the input stream to help simulate multiple-START-points in the parser. When this happens, \`base_position\` will be adjusted to help track the original input's starting point in the \`_input\` buffer.)
    base_position: 0,                           /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: index to the original starting point of the input; always ZERO(0) unless \`unput()\` has pushed content before the input: see the \`offset\` **WARNING** just above.
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (\`yytext\`)
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction
    CRLF_Re: /\\r\\n?|\\n/,                        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: regex used to split lines while tracking the lexer cursor position.

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for \`parseError\`.
     *
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
        msg = '' + msg;

        // heuristic to determine if the error message already contains a (partial) source code dump
        // as produced by either \`showPosition()\` or \`prettyPrintRange()\`:
        if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\\n') > 0 && msg.indexOf('^') > 0);
        }
        if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
                const pretty_src = this.prettyPrintRange(this.yylloc);

                if (!/\\n\\s*$/.test(msg)) {
                    msg += '\\n';
                }
                msg += '\\n  Erroneous area:\\n' + this.prettyPrintRange(this.yylloc);
            } else if (typeof this.showPosition === 'function') {
                const pos_str = this.showPosition();
                if (pos_str) {
                    if (msg.length && msg[msg.length - 1] !== '\\n' && pos_str[0] !== '\\n') {
                        msg += '\\n' + pos_str;
                    } else {
                        msg += pos_str;
                    }
                }
            }
        }
        /** @constructor */
        const pei = {
            errStr: msg,
            recoverable: !!recoverable,
            text: this.match,           // This one MAY be empty; userland code should use the \`upcomingInput\` API to obtain more text which follows the 'lexer cursor position'...
            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
             * and make sure the error info doesn't stay due to potential
             * ref cycle via userland code manipulations.
             * These would otherwise all be memory leak opportunities!
             *
             * Note that only array and object references are nuked as those
             * constitute the set of elements which can produce a cyclic ref.
             * The rest of the members is kept intact as they are harmless.
             *
             * @public
             * @this {LexErrorInfo}
             */
            destroy: function destructLexErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // ...
                const rec = !!this.recoverable;
                for (let key in this) {
                    if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     *
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
        if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
        }
        if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
                return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
                return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            }
        }
        throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements \`yyerror(str, ...args)\` functionality for use inside lexer actions.
     *
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str /*, ...args */) {
        let lineno_msg = 'Lexical error';
        if (this.yylloc) {
            lineno_msg += ' on line ' + (this.yylineno + 1);
        }
        const p = this.constructLexErrorInfo(lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

        // Add any extra args to the hash under the name \`extra_error_attributes\`:
        let args = Array.prototype.slice.call(arguments, 1);
        if (args.length) {
            p.extra_error_attributes = args;
        }

        return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     *
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
        // prevent lingering circular references from causing memory leaks:
        this.setInput('', {});

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (let i = this.__error_infos.length - 1; i >= 0; i--) {
                let el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;
        }

        return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     *
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        // - DO NOT reset \`this.matched\`
        this.matches = false;

        this._more = false;
        this._backtrack = false;

        const col = this.yylloc.last_column;
        this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,

            range: [ this.offset, this.offset ]
        };
    },

    /**
     * resets the lexer, sets new input
     *
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
        this.yy = yy || this.yy || {};

        // also check if we've fully initialized the lexer instance,
        // including expansion work to be done to go from a loaded
        // lexer to a usable lexer:
        if (!this.__decompressed) {
          // step 1: decompress the regex list:
            let rules = this.rules;
            for (var i = 0, len = rules.length; i < len; i++) {
                var rule_re = rules[i];

            // compression: is the RE an xref to another RE slot in the rules[] table?
                if (typeof rule_re === 'number') {
                    rules[i] = rules[rule_re];
                }
            }

          // step 2: unfold the conditions[] set to make these ready for use:
            let conditions = this.conditions;
            for (let k in conditions) {
                let spec = conditions[k];

                let rule_ids = spec.rules;

                var len = rule_ids.length;
                let rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in \`lexer_next()\` fast and simple!
                let rule_new_ids = new Array(len + 1);

                for (var i = 0; i < len; i++) {
                    let idx = rule_ids[i];
                    var rule_re = rules[idx];
                    rule_regexes[i + 1] = rule_re;
                    rule_new_ids[i + 1] = idx;
                }

                spec.rules = rule_new_ids;
                spec.__rule_regexes = rule_regexes;
                spec.__rule_count = len;
            }

            this.__decompressed = true;
        }

        if (input && typeof input !== 'string') {
            input = '' + input;
        }
        this._input = input || '';
        this._clear_state = -1;
        this._signaled_error_token = false;
        this.done = false;
        this.yylineno = 0;
        this.matched = '';
        this.conditionStack = [ 'INITIAL' ];
        this.__currentRuleSet__ = null;
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [ 0, 0 ]
        };
        this.offset = 0;
        this.base_position = 0;
        // apply these bits of \`this.clear()\` as well:
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        this.matches = false;

        this._more = false;
        this._backtrack = false;

        return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse,
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the \`unput()\` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current \`yyloc\` cursor location or any history.
     *
     * Use this API to help implement C-preprocessor-like
     * \`#include\` statements, etc.
     *
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The \`cpsArg\` argument value is passed to the callback
     * as-is.
     *
     * \`callback\` interface:
     * \`function callback(input, cpsArg)\`
     *
     * - \`input\` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - \`cpsArg\` is \`cpsArg\` passed into this API.
     *
     * The \`this\` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API.
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the \`"" + retval\`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html
     * -- that way any returned object's \`toValue()\` and \`toString()\`
     * methods will be invoked in a proper/desirable order.)
     *
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
        const rv = callback.call(this, this._input, cpsArg);
        if (typeof rv !== 'string') {
            if (rv) {
                this._input = '' + rv;
            }
            // else: keep \`this._input\` as is.
        } else {
            this._input = rv;
        }
        return this;
    },

    /**
     * consumes and returns one char from the input
     *
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
        if (!this._input) {
            //this.done = true;    -- don't set \`done\` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
        }
        if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
        }
        let ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        // Count the linenumber up when we hit the LF (or a stand-alone CR).
        // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
        // and we advance immediately past the LF as well, returning both together as if
        // it was all a single 'character' only.
        let slice_len = 1;
        let lines = false;
        if (ch === '\\n') {
            lines = true;
        } else if (ch === '\\r') {
            lines = true;
            const ch2 = this._input[1];
            if (ch2 === '\\n') {
                slice_len++;
                ch += ch2;
                this.yytext += ch2;
                this.yyleng++;
                this.offset++;
                this.match += ch2;
                this.matched += ch2;
                this.yylloc.range[1]++;
            }
        }
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
        } else {
            this.yylloc.last_column++;
        }
        this.yylloc.range[1]++;

        this._input = this._input.slice(slice_len);
        return ch;
    },

    /**
     * unshifts one char (or an entire string) into the input
     *
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
        let len = ch.length;
        let lines = ch.split(this.CRLF_Re);

        if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
        }

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        this.yyleng = this.yytext.length;
        this.offset -= len;
        // **WARNING:**
        // The \`offset\` value MAY be negative if you \`unput()\` more text than you have already lexed.
        // This type of behaviour is generally observed for one kind of 'lexer/parser hack'
        // where custom token-illiciting characters are pushed in front of the input stream to help
        // simulate multiple-START-points in the parser.
        // When this happens, \`base_position\` will be adjusted to help track the original input's
        // starting point in the \`_input\` buffer.
        if (-this.offset > this.base_position) {
            this.base_position = -this.offset;
        }
        this.match = this.match.substr(0, this.match.length - len);
        this.matched = this.matched.substr(0, this.matched.length - len);

        if (lines.length > 1) {
            this.yylineno -= lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the \`pre_lines[]\` array's
            // last index slot; we don't mind when other previously
            // matched lines end up in the array too.
            let pre = this.match;
            let pre_lines = pre.split(this.CRLF_Re);
            if (pre_lines.length === 1) {
                pre = this.matched;
                pre_lines = pre.split(this.CRLF_Re);
            }
            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
        } else {
            this.yylloc.last_column -= len;
        }

        this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;

        this.done = false;
        return this;
    },

    /**
     * return the upcoming input *which has not been lexed yet*.
     * This can, for example, be used for custom look-ahead inspection code
     * in your lexer.
     *
     * The entire pending input string is returned.
     *
     * > ### NOTE ###
     * >
     * > When augmenting error reports and alike, you might want to
     * > look at the \`upcomingInput()\` API instead, which offers more
     * > features for limited input extraction and which includes the
     * > part of the input which has been lexed by the last token a.k.a.
     * > the *currently lexed* input.
     * >
     *
     * @public
     * @this {RegExpLexer}
     */
    lookAhead: function lexer_lookAhead() {
        return this._input || '';
    },

    /**
     * cache matched text and append it on next action
     *
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
        this._more = true;
        return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     *
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            // when the \`parseError()\` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // \`.lex()\` run.
            let lineno_msg = 'Lexical error';
            if (this.yylloc) {
                lineno_msg += ' on line ' + (this.yylineno + 1);
            }
            const p = this.constructLexErrorInfo(lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).', false);
            this._signaled_error_token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
        }
        return this;
    },

    /**
     * retain first n characters of the match
     *
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
        return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     *
     * Limit the returned string length to \`maxSize\` (default: 20).
     *
     * Limit the returned string to the \`maxLines\` number of lines of
     * input (default: 1).
     *
     * A negative \`maxSize\` limit value equals *unlimited*, i.e.
     * produce the entire input that has already been lexed.
     *
     * A negative \`maxLines\` limit value equals *unlimited*, i.e. limit the result
     * to the \`maxSize\` specified number of characters *only*.
     *
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
        let past = this.matched.substring(0, this.matched.length - this.match.length);
        if (maxSize < 0) {
            maxSize = Infinity;
        } else if (!maxSize) {
            maxSize = 20;
        }
        if (maxLines < 0) {
            maxLines = Infinity;          // can't ever have more input lines than this!
        } else if (!maxLines) {
            maxLines = 1;
        }
        // \`substr\` anticipation: treat \\r\\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        past = past.substr(-maxSize * 2 - 2);
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        let a = past.split(this.CRLF_Re);
        a = a.slice(-maxLines);
        past = a.join('\\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis prefix...
        if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
        }
        return past;
    },

    /**
     * return (part of the) upcoming input *including* the input
     * matched by the last token (see also the NOTE below).
     * This can be used to augment error messages, for example.
     *
     * Limit the returned string length to \`maxSize\` (default: 20).
     *
     * Limit the returned string to the \`maxLines\` number of lines of input (default: 1).
     *
     * A negative \`maxSize\` limit value equals *unlimited*, i.e.
     * produce the entire input that is yet to be lexed.
     *
     * A negative \`maxLines\` limit value equals *unlimited*, i.e. limit the result
     * to the \`maxSize\` specified number of characters *only*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block.
     * >
     * > When you want access to the 'upcoming input' in that you want access
     * > to the input *which has not been lexed yet* for look-ahead
     * > inspection or likewise purposes, please consider using the
     * > \`lookAhead()\` API instead.
     * >
     *
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
        let next = this.match;
        let source = this._input || '';
        if (maxSize < 0) {
            maxSize = next.length + source.length;
        } else if (!maxSize) {
            maxSize = 20;
        }

        if (maxLines < 0) {
            maxLines = maxSize;          // can't ever have more input lines than this!
        } else if (!maxLines) {
            maxLines = 1;
        }
        // \`substring\` anticipation: treat \\r\\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        if (next.length < maxSize * 2 + 2) {
            next += source.substring(0, maxSize * 2 + 2 - next.length);  // substring is faster on Chrome/V8
        }
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        let a = next.split(this.CRLF_Re, maxLines + 1);     // stop splitting once we have reached just beyond the reuired number of lines.
        a = a.slice(0, maxLines);
        next = a.join('\\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis postfix...
        if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
        }
        return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     *
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
        const pre = this.pastInput(maxPrefix).replace(/\\s/g, ' ');
        let c = new Array(pre.length + 1).join('-');
        return pre + this.upcomingInput(maxPostfix).replace(/\\s/g, ' ') + '\\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given \`actual\` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the \`preceding\` and \`following\` locations, IFF those are available,
     * and reconstruct the \`actual\` location info from those.
     * If this fails, the heuristic is to take the \`current\` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: \`deriveLocationInfo()\` ALWAYS produces a location info object *copy* of \`actual\`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     *
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
        let loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [ 0, 0 ]
        };
        if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
                loc.range[0] = actual.range[0] | 0;
                loc.range[1] = actual.range[1] | 0;
            }
        }
        if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
                loc.first_line = preceding.last_line | 0;
                loc.first_column = preceding.last_column | 0;

                if (preceding.range) {
                    loc.range[0] = actual.range[1] | 0;
                }
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
                loc.last_line = following.first_line | 0;
                loc.last_column = following.first_column | 0;

                if (following.range) {
                    loc.range[1] = actual.range[0] | 0;
                }
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
                loc.first_line = current.first_line | 0;
                loc.first_column = current.first_column | 0;

                if (current.range) {
                    loc.range[0] = current.range[0] | 0;
                }
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
                loc.last_line = current.last_line | 0;
                loc.last_column = current.last_column | 0;

                if (current.range) {
                    loc.range[1] = current.range[1] | 0;
                }
            }
        }
        // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
        // or plan D heuristics to produce a 'sensible' last_line value:
        if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
                loc.first_line = this.yylloc.first_line;
                loc.last_line = this.yylloc.last_line;
                loc.first_column = this.yylloc.first_column;
                loc.last_column = this.yylloc.last_column;

                loc.range[0] = this.yylloc.range[0];
                loc.range[1] = this.yylloc.range[1];
            } else {
                loc.last_line = this.yylloc.last_line;
                loc.last_column = this.yylloc.last_column;

                loc.range[1] = this.yylloc.range[1];
            }
        }
        if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;

            loc.range[1] = loc.range[0];
        }
        if (loc.first_column < 0) {
            loc.first_column = 0;
        }
        if (loc.last_column < 0) {
            loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
        }
        return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced
     * by the given location info range, plus a few lines of context.
     *
     * This function pretty-prints the indicated section of the input, with line numbers
     * and everything!
     *
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     *
     * - \`loc\` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by \`^\`
     *   characters below each character in the entire input range.
     *
     * - \`context_loc\` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by \`loc\`. This can help provide context for the displayed
     *   error, etc.
     *
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     *
     * - \`context_loc2\` is another *optional* location info object, which serves
     *   a similar purpose to \`context_loc\`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     *
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     *
     * Special Notes:
     *
     * - when the \`loc\`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   \`...continued...\` message will be printed between them.
     *
     *   This serves the purpose of not printing a huge amount of text when the \`loc\`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     *
     * - this function can display lines of input which whave not yet been lexed.
     *   \`prettyPrintRange()\` can access the entire input!
     *
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
        loc = this.deriveLocationInfo(loc, context_loc, context_loc2);

        const CONTEXT = 3;
        const CONTEXT_TAIL = 1;
        const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
        let input = this.matched + (this._input || '');
        let lines = input.split('\\n');
        let l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
        let l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
        let lineno_display_width = (1 + Math.log10(l1 | 1) | 0);
        let ws_prefix = new Array(lineno_display_width).join(' ');
        let nonempty_line_indexes = [ [], [], [] ];
        let rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            let lno = index + l0;
            let lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            let rv = lno_pfx + ': ' + line;
            let errpfx = (new Array(lineno_display_width + 1)).join('^');
            let offset = 2 + 1;
            let len = 0;

            if (lno === loc.first_line) {
                offset += loc.first_column;

                len = Math.max(
                    2,
                    ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
                );
            } else if (lno === loc.last_line) {
                len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
                len = Math.max(2, line.length + 1);
            }

            let nli;
            if (len) {
                let lead = new Array(offset).join('.');
                let mark = new Array(len).join('^');
                rv += '\\n' + errpfx + lead + mark;

                nli = 1;
            } else if (lno < loc.first_line) {
                nli = 0;
            } else if (lno > loc.last_line) {
                nli = 2;
            }

            if (line.trim().length > 0) {
                nonempty_line_indexes[nli].push(index);
            }

            rv = rv.replace(/\\t/g, ' ');
            return rv;
        });

        // now make sure we don't print an overly large amount of lead/error/tail area: limit it
        // to the top and bottom line count:
        for (let i = 0; i <= 2; i++) {
            let line_arr = nonempty_line_indexes[i];
            if (line_arr.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
                let clip_start = line_arr[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
                let clip_end = line_arr[line_arr.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;

                let intermediate_line = (new Array(lineno_display_width + 1)).join(' ') +     '  (...continued...)';
                if (i === 1) {
                    intermediate_line += '\\n' + (new Array(lineno_display_width + 1)).join('-') + '  (---------------)';
                }
                rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
            }
        }

        return rv.join('\\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input \`yylloc\` location object.
     *
     * Set \`display_range_too\` to TRUE to include the string character index position(s)
     * in the description if the \`yylloc.range\` is available.
     *
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
        let l1 = yylloc.first_line;
        let l2 = yylloc.last_line;
        let c1 = yylloc.first_column;
        let c2 = yylloc.last_column;
        let dl = l2 - l1;
        let dc = c2 - c1;
        let rv;
        if (dl === 0) {
            rv = 'line ' + l1 + ', ';
            if (dc <= 1) {
                rv += 'column ' + c1;
            } else {
                rv += 'columns ' + c1 + ' .. ' + c2;
            }
        } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
        }
        if (yylloc.range && display_range_too) {
            let r1 = yylloc.range[0];
            let r2 = yylloc.range[1] - 1;
            if (r2 <= r1) {
                rv += ' {String Offset: ' + r1 + '}';
            } else {
                rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
        }
        return rv;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     *
     * \`match\` is supposed to be an array coming out of a regex match, i.e. \`match[0]\`
     * contains the actually matched text string.
     *
     * Also move the input cursor forward and update the match collectors:
     *
     * - \`yytext\`
     * - \`yyleng\`
     * - \`match\`
     * - \`matches\`
     * - \`yylloc\`
     * - \`offset\`
     *
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
        let backup;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.yylloc.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column,

                    range: this.yylloc.range.slice()
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                //_signaled_error_token: this._signaled_error_token,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(),
                done: this.done
            };
        }

        let match_str = match[0];
        let match_str_len = match_str.length;

        let lines = match_str.split(this.CRLF_Re);
        if (lines.length > 1) {
            this.yylineno += lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;
            this.yylloc.last_column = lines[lines.length - 1].length;
        } else {
            this.yylloc.last_column += match_str_len;
        }

        this.yytext += match_str;
        this.match += match_str;
        this.matched += match_str;
        this.matches = match;
        this.yyleng = this.yytext.length;
        this.yylloc.range[1] += match_str_len;

        // previous lex rules MAY have invoked the \`more()\` API rather than producing a token:
        // those rules will already have moved this \`offset\` forward matching their match lengths,
        // hence we must only add our own match length now:
        this.offset += match_str_len;
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match_str_len);

        // calling this method:
        //
        //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
        let token = this.performAction.call(this, this.yy, indexed_rule, this.conditionStack[this.conditionStack.length - 1] /* = YY_START */);
        // otherwise, when the action codes are all simple return token statements:
        //token = this.simpleCaseActionClusters[indexed_rule];

        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (let k in backup) {
                this[k] = backup[k];
            }
            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
        } else if (this._signaled_error_token) {
            // produce one 'error' token as \`.parseError()\` in \`reject()\`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;
            this._signaled_error_token = false;
            return token;
        }
        return false;
    },

    /**
     * return next match in input
     *
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
        if (this.done) {
            this.clear();
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        if (!this._more) {
            if (!this._clear_state) {
                this._clear_state = 1;
            }
            this.clear();
        }
        let spec = this.__currentRuleSet__;
        if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the \`lex()\` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();
            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
                let lineno_msg = '';
                if (this.yylloc) {
                    lineno_msg = ' on line ' + (this.yylineno + 1);
                }
                const p = this.constructLexErrorInfo('Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!', false);
                // produce one 'error' token until this situation has been resolved, most probably by parse termination!
                return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            }
        }

        {
            let rule_ids = spec.rules;
            let regexes = spec.__rule_regexes;
            let len = spec.__rule_count;
            let match;
            let index;

            // Note: the arrays are 1-based, while \`len\` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (let i = 1; i <= len; i++) {
                let tempMatch = this._input.match(regexes[i]);
                if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                    match = tempMatch;
                    index = i;
                    if (this.options.backtrack_lexer) {
                        let token = this.test_match(tempMatch, rule_ids[i]);
                        if (token !== false) {
                            return token;
                        } else if (this._backtrack) {
                            match = undefined;
                            continue; // rule action called reject() implying a rule MISmatch.
                        } else {
                            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                            return false;
                        }
                    } else if (!this.options.flex) {
                        break;
                    }
                }
            }

            if (match) {
                let token = this.test_match(match, rule_ids[index]);
                if (token !== false) {
                    return token;
                }
                // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                return false;
            }
        }

        if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
        }

        {
            let lineno_msg = 'Lexical error';
            if (this.yylloc) {
                lineno_msg += ' on line ' + (this.yylineno + 1);
            }
            const p = this.constructLexErrorInfo(lineno_msg + ': Unrecognized text.', this.options.lexerErrorsAreRecoverable);

            let pendingInput = this._input;
            let activeCondition = this.topState();
            let conditionStackDepth = this.conditionStack.length;

            let token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            if (token === this.ERROR) {
                // we can try to recover from a lexer error that \`parseError()\` did not 'recover' for us
                // by moving forward at least one character at a time IFF the (user-specified?) \`parseError()\`
                // has not consumed/modified any pending input or changed state in the error handler:
                if (!this.matches &&
                    // and make sure the input has been modified/consumed ...
                    pendingInput === this._input &&
                    // ...or the lexer state has been modified significantly enough
                    // to merit a non-consuming error handling action right now.
                    activeCondition === this.topState() &&
                    conditionStackDepth === this.conditionStack.length
                ) {
                    this.input();
                }
            }
            return token;
        }
    },

    /**
     * return next match that has a token
     *
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
        let r;

        //this._clear_state = 0;

        if (!this._more) {
            if (!this._clear_state) {
                this._clear_state = 1;
            }
            this.clear();
        }

        // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
        if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
        }
        if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
        }
        if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
        }

        while (!r) {
            r = this.next();
        }

        if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
        }
        if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
        }
        if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
        }

        if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value \`r\`).
            // 2) make sure any subsequent \`lex()\` API invocation CANNOT
            //    edit the \`yytext\`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);
            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);

            this._clear_state = 0;
        }

        return r;
    },

    /**
     * return next match that has a token. Identical to the \`lex()\` API but does not invoke any of the
     * \`pre_lex()\` nor any of the \`post_lex()\` callbacks.
     *
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
        let r;

        //this._clear_state = 0;

        while (!r) {
            r = this.next();
        }

        if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value \`r\`).
            // 2) make sure any subsequent \`lex()\` API invocation CANNOT
            //    edit the \`yytext\`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);
            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);

            this._clear_state = 0;
        }

        return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     *
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
        const rv = {
            fastLex: !(
                typeof this.pre_lex === 'function' ||
                typeof this.options.pre_lex === 'function' ||
                (this.yy && typeof this.yy.pre_lex === 'function') ||
                (this.yy && typeof this.yy.post_lex === 'function') ||
                typeof this.options.post_lex === 'function' ||
                typeof this.post_lex === 'function'
            ) && typeof this.fastLex === 'function'
        };
        return rv;
    },


    /**
     * backwards compatible alias for \`pushState()\`;
     * the latter is symmetrical with \`popState()\` and we advise to use
     * those APIs in any modern lexer code, rather than \`begin()\`.
     *
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
        return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     *
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
        this.conditionStack.push(condition);
        this.__currentRuleSet__ = null;
        return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     *
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
        const n = this.conditionStack.length - 1;
        if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
        }
        return this.conditionStack[0];
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     *
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        }
        return 'INITIAL';
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     *
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
        const n = this.conditionStack.length - 1;
        let state;
        if (n >= 0) {
            state = this.conditionStack[n];
        } else {
            state = 'INITIAL';
        }
        return this.conditions[state] || this.conditions.INITIAL;
    },

    /**
     * return the number of states currently on the stack
     *
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
        return this.conditionStack.length;
    }
}`;
        // --- END lexer kernel ---
    }

    chkBugger$2(getRegExpLexerPrototype());
    RegExpLexer.prototype = (new Function(rmCommonWS$2`
    "use strict";

    return ${getRegExpLexerPrototype()};
`))();


    // The lexer code stripper, driven by optimization analysis settings and
    // lexer options, which cannot be changed at run-time.
    function stripUnusedLexerCode(src, opt) {
        //   uses yyleng: ..................... ${opt.lexerActionsUseYYLENG}
        //   uses yylineno: ................... ${opt.lexerActionsUseYYLINENO}
        //   uses yytext: ..................... ${opt.lexerActionsUseYYTEXT}
        //   uses yylloc: ..................... ${opt.lexerActionsUseYYLOC}
        //   uses ParseError API: ............. ${opt.lexerActionsUseParseError}
        //   uses location tracking & editing:  ${opt.lexerActionsUseLocationTracking}
        //   uses more() API: ................. ${opt.lexerActionsUseMore}
        //   uses unput() API: ................ ${opt.lexerActionsUseUnput}
        //   uses reject() API: ............... ${opt.lexerActionsUseReject}
        //   uses less() API: ................. ${opt.lexerActionsUseLess}
        //   uses display APIs pastInput(), upcomingInput(), showPosition():
        //        ............................. ${opt.lexerActionsUseDisplayAPIs}
        //   uses describeYYLLOC() API: ....... ${opt.lexerActionsUseDescribeYYLOC}

        let new_src;
        try {
            let ast = helpers.parseCodeChunkToAST(src, opt);
            new_src = helpers.prettyPrintAST(ast, opt);
        } catch (ex) {
            let line = ex.lineNumber || 0;
            let a = src.split(/\r?\n/g);
            let len = a.length;
            let minl = Math.max(0, line - 10);
            let b = a.slice(minl, line + 10);
            let c = b.splice(line - minl, 0, '', '^^^^^^^^^^^ source line above is reported as erroneous ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^', '');
            let offendingChunk = '        ' + b.join('\n        ');
            console.error(rmCommonWS$2`
            stripUnusedLexerCode WARNING: 

                JISON failed to reformat the generated lexer.
                Using the generated code as-is instead and pray it works in your final output!

                Internal error report:

                    ${ex}

                The offending action code chunk as reported above:

            ${offendingChunk}
        `);

            new_src = src;
        }


        // inject analysis report now:
        new_src = new_src.replace(/\/\*\s*JISON-LEX-ANALYTICS-REPORT\s*\*\//g, rmCommonWS$2`
        // Code Generator Information Report
        // ---------------------------------
        //
        // Options:
        //
        //   backtracking: .................... ${opt.options.backtrack_lexer}
        //   location.ranges: ................. ${opt.options.ranges}
        //   location line+column tracking: ... ${opt.options.trackPosition}
        //
        //
        // Forwarded Parser Analysis flags:
        //
        //   uses yyleng: ..................... ${opt.parseActionsUseYYLENG}
        //   uses yylineno: ................... ${opt.parseActionsUseYYLINENO}
        //   uses yytext: ..................... ${opt.parseActionsUseYYTEXT}
        //   uses yylloc: ..................... ${opt.parseActionsUseYYLOC}
        //   uses lexer values: ............... ${opt.parseActionsUseValueTracking} / ${opt.parseActionsUseValueAssignment}
        //   location tracking: ............... ${opt.parseActionsUseLocationTracking}
        //   location assignment: ............. ${opt.parseActionsUseLocationAssignment}
        //
        //
        // Lexer Analysis flags:
        //
        //   uses yyleng: ..................... ${opt.lexerActionsUseYYLENG}
        //   uses yylineno: ................... ${opt.lexerActionsUseYYLINENO}
        //   uses yytext: ..................... ${opt.lexerActionsUseYYTEXT}
        //   uses yylloc: ..................... ${opt.lexerActionsUseYYLOC}
        //   uses ParseError API: ............. ${opt.lexerActionsUseParseError}
        //   uses yyerror: .................... ${opt.lexerActionsUseYYERROR}
        //   uses location tracking & editing:  ${opt.lexerActionsUseLocationTracking}
        //   uses more() API: ................. ${opt.lexerActionsUseMore}
        //   uses unput() API: ................ ${opt.lexerActionsUseUnput}
        //   uses reject() API: ............... ${opt.lexerActionsUseReject}
        //   uses less() API: ................. ${opt.lexerActionsUseLess}
        //   uses display APIs pastInput(), upcomingInput(), showPosition():
        //        ............................. ${opt.lexerActionsUseDisplayAPIs}
        //   uses describeYYLLOC() API: ....... ${opt.lexerActionsUseDescribeYYLOC}
        //
        // --------- END OF REPORT -----------

    `);

        return new_src;
    }





    // generate lexer source from a grammar
    /**  @public */
    function generate(dict, tokens, build_options) {
        let opt = processGrammar(dict, tokens, build_options);

        return generateFromOpts(opt);
    }

    // process the grammar and build final data structures and functions
    /**  @public */
    function processGrammar(dict, tokens, build_options) {
        build_options = build_options || {};
        let opts = {
            // include the knowledge passed through `build_options` about which lexer
            // features will actually be *used* by the environment (which in 99.9%
            // of cases is a jison *parser*):
            //
            // (this stuff comes straight from the jison Optimization Analysis.)
            //
            parseActionsUseYYLENG: build_options.parseActionsUseYYLENG,
            parseActionsUseYYLINENO: build_options.parseActionsUseYYLINENO,
            parseActionsUseYYTEXT: build_options.parseActionsUseYYTEXT,
            parseActionsUseYYLOC: build_options.parseActionsUseYYLOC,
            parseActionsUseParseError: build_options.parseActionsUseParseError,
            parseActionsUseYYERROR: build_options.parseActionsUseYYERROR,
            parseActionsUseYYERROK: build_options.parseActionsUseYYERROK,
            parseActionsUseYYRECOVERING: build_options.parseActionsUseYYRECOVERING,
            parseActionsUseYYCLEARIN: build_options.parseActionsUseYYCLEARIN,
            parseActionsUseValueTracking: build_options.parseActionsUseValueTracking,
            parseActionsUseValueAssignment: build_options.parseActionsUseValueAssignment,
            parseActionsUseLocationTracking: build_options.parseActionsUseLocationTracking,
            parseActionsUseLocationAssignment: build_options.parseActionsUseLocationAssignment,
            parseActionsUseYYSTACK: build_options.parseActionsUseYYSTACK,
            parseActionsUseYYSSTACK: build_options.parseActionsUseYYSSTACK,
            parseActionsUseYYSTACKPOINTER: build_options.parseActionsUseYYSTACKPOINTER,
            parseActionsUseYYRULELENGTH: build_options.parseActionsUseYYRULELENGTH,
            parseActionsUseYYMERGELOCATIONINFO: build_options.parseActionsUseYYMERGELOCATIONINFO,
            parserHasErrorRecovery: build_options.parserHasErrorRecovery,
            parserHasErrorReporting: build_options.parserHasErrorReporting,

            lexerActionsUseYYLENG: '???',
            lexerActionsUseYYLINENO: '???',
            lexerActionsUseYYTEXT: '???',
            lexerActionsUseYYLOC: '???',
            lexerActionsUseParseError: '???',
            lexerActionsUseYYERROR: '???',
            lexerActionsUseLocationTracking: '???',
            lexerActionsUseMore: '???',
            lexerActionsUseUnput: '???',
            lexerActionsUseReject: '???',
            lexerActionsUseLess: '???',
            lexerActionsUseDisplayAPIs: '???',
            lexerActionsUseDescribeYYLOC: '???'
        };

        dict = autodetectAndConvertToJSONformat(dict, build_options) || {};

        // Feed the possibly reprocessed 'dictionary' above back to the caller
        // (for use by our error diagnostic assistance code)
        opts.lex_rule_dictionary = dict;

        // Always provide the lexer with an options object, even if it's empty!
        // Make sure to camelCase all options:
        opts.options = mkStdOptions(build_options, dict.options);

        opts.moduleType = opts.options.moduleType;
        opts.moduleName = opts.options.moduleName;

        opts.conditions = prepareStartConditions(dict.startConditions);
        opts.conditions.INITIAL = {
            rules: [],
            inclusive: true
        };

        // only produce rule action code blocks when there are any rules at all;
        // a "custom lexer" has ZERO rules and must be defined entirely in
        // other code blocks:
        let code = (dict.rules ? buildActions(dict, tokens, opts) : {});
        opts.performAction = code.actions;
        opts.caseHelperInclude = code.caseHelperInclude;
        opts.rules = code.rules || [];
        opts.macros = code.macros;

        opts.regular_rule_count = code.regular_rule_count;
        opts.simple_rule_count = code.simple_rule_count;

        opts.conditionStack = [ 'INITIAL' ];

        opts.actionInclude = (dict.actionInclude || '');
        opts.moduleInclude = (opts.moduleInclude || '') + (dict.moduleInclude || '').trim();

        return opts;
    }

    // Assemble the final source from the processed grammar
    /**  @public */
    function generateFromOpts(opt) {
        let code = '';

        switch (opt.moduleType) {
        case 'js':
            code = generateModule(opt);
            break;
        case 'amd':
            code = generateAMDModule(opt);
            break;
        case 'es':
            code = generateESModule(opt);
            break;
        case 'commonjs':
            code = generateCommonJSModule(opt);
            break;
        default:
            throw new Error('unsupported moduleType: ' + opt.moduleType);
        }

        return code;
    }

    function generateRegexesInitTableCode(opt) {
        let a = opt.rules;
        let print_xregexp = opt.options && opt.options.xregexp;
        let id_display_width = (1 + Math.log10(a.length | 1) | 0);
        let ws_prefix = new Array(id_display_width).join(' ');
        let b = a.map(function generateXRegExpInitCode(re, idx) {
            let idx_str = (ws_prefix + idx).substr(-id_display_width);

            if (re instanceof XRegExp__default['default']) {
                // When we don't need the special XRegExp sauce at run-time, we do with the original
                // JavaScript RegExp instance a.k.a. 'native regex':
                if (re.xregexp.isNative || !print_xregexp) {
                    return `/* ${idx_str}: */  ${re}`;
                }
                // And make sure to escape the regex to make it suitable for placement inside a *string*
                // as it is passed as a string argument to the XRegExp constructor here.
                let re_src = re.xregexp.source.replace(/[\\"]/g, '\\$&');
                return `/* ${idx_str}: */  new XRegExp("${re_src}", "${re.xregexp.flags}")`;
            }
            return `/* ${idx_str}: */  ${re}`;

        });
        return b.join(',\n');
    }

    function generateModuleBody(opt) {
        // make the JSON output look more like JavaScript:
        function cleanupJSON(str) {
            str = str.replace(/ {2}"rules": \[/g, '  rules: [');
            str = str.replace(/ {2}"inclusive": /g, '  inclusive: ');
            return str;
        }

        function produceOptions(opts) {
            let obj = {};
            const do_not_pass = {
                debug: !opts.debug,     // do not include this item when it is FALSE as there's no debug tracing built into the generated grammar anyway!
                enableDebugLogs: 1,
                json: 1,
                _: 1,
                noMain: 1,
                dumpSourceCodeOnFailure: 1,
                throwErrorOnCompileFailure: 1,
                reportStats: 1,
                file: 1,
                outfile: 1,
                inputPath: 1,
                inputFilename: 1,
                defaultModuleName: 1,
                moduleName: 1,
                moduleType: 1,
                lexerErrorsAreRecoverable: 0,
                flex: 0,
                backtrack_lexer: 0,
                caseInsensitive: 0,
                showSource: 1,
                exportAST: 1,
                exportAllTables: 1,
                exportSourceCode: 1,
                prettyCfg: 1,
                parseActionsUseYYLENG: 1,
                parseActionsUseYYLINENO: 1,
                parseActionsUseYYTEXT: 1,
                parseActionsUseYYLOC: 1,
                parseActionsUseParseError: 1,
                parseActionsUseYYERROR: 1,
                parseActionsUseYYRECOVERING: 1,
                parseActionsUseYYERROK: 1,
                parseActionsUseYYCLEARIN: 1,
                parseActionsUseValueTracking: 1,
                parseActionsUseValueAssignment: 1,
                parseActionsUseLocationTracking: 1,
                parseActionsUseLocationAssignment: 1,
                parseActionsUseYYSTACK: 1,
                parseActionsUseYYSSTACK: 1,
                parseActionsUseYYSTACKPOINTER: 1,
                parseActionsUseYYRULELENGTH: 1,
                parseActionsUseYYMERGELOCATIONINFO: 1,
                parserHasErrorRecovery: 1,
                parserHasErrorReporting: 1,
                lexerActionsUseYYLENG: 1,
                lexerActionsUseYYLINENO: 1,
                lexerActionsUseYYTEXT: 1,
                lexerActionsUseYYLOC: 1,
                lexerActionsUseParseError: 1,
                lexerActionsUseYYERROR: 1,
                lexerActionsUseLocationTracking: 1,
                lexerActionsUseMore: 1,
                lexerActionsUseUnput: 1,
                lexerActionsUseReject: 1,
                lexerActionsUseLess: 1,
                lexerActionsUseDisplayAPIs: 1,
                lexerActionsUseDescribeYYLOC: 1
            };
            for (let k in opts) {
                if (!do_not_pass[k] && opts[k] != null && opts[k] !== false) {
                    // make sure numeric values are encoded as numeric, the rest as boolean/string.
                    if (typeof opts[k] === 'string') {
                        let f = parseFloat(opts[k]);
                        if (f == opts[k]) {
                            obj[k] = f;
                            continue;
                        }
                    }
                    obj[k] = opts[k];
                }
            }

            // And now some options which should receive some special processing:
            let pre = obj.pre_lex;
            let post = obj.post_lex;
            // since JSON cannot encode functions, we'll have to do it manually at run-time, i.e. later on:
            if (pre) {
                obj.pre_lex = true;
            }
            if (post) {
                obj.post_lex = true;
            }

            let js = JSON.stringify(obj, null, 2);

            js = js.replace(new XRegExp__default['default'](`  "(${ID_REGEX_BASE$1})": `, 'g'), '  $1: ');
            js = js.replace(/^( +)pre_lex: true(,)?$/gm, function (m, ls, tc) {
                return ls + 'pre_lex: ' + String(pre) + (tc || '');
            });
            js = js.replace(/^( +)post_lex: true(,)?$/gm, function (m, ls, tc) {
                return ls + 'post_lex: ' + String(post) + (tc || '');
            });
            return js;
        }


        let out;
        if (opt.rules.length > 0 || opt.__in_rules_failure_analysis_mode__) {
            // we don't mind that the `test_me()` code above will have this `lexer` variable re-defined:
            // JavaScript is fine with that.
            let code = [ rmCommonWS$2`
            const lexer = {
              `, '/* JISON-LEX-ANALYTICS-REPORT */\n' /* slot #1: placeholder for analysis report further below */
            ];

            // get the RegExpLexer.prototype in source code form:
            let protosrc = getRegExpLexerPrototype();
            // and strip off the surrounding bits we don't want:
            protosrc = protosrc
            .replace(/^[\s\r\n]*\{/, '')
            .replace(/\s*\}[\s\r\n]*$/, '')
            .trim();
            code.push(protosrc + ',\n');

            assert__default['default'](opt.options);
            // Assure all options are camelCased:
            assert__default['default'](typeof opt.options['case-insensitive'] === 'undefined');

            code.push('    options: ' + produceOptions(opt.options));

    /*
            function isEmpty(code) {
                switch (typeof code) {
                case 'undefined':
                case 'null':
                    return true;

                case 'string':

                }
            }
    */

            let performActionCode = String(opt.performAction);
            let simpleCaseActionClustersCode = String(opt.caseHelperInclude);
            let rulesCode = generateRegexesInitTableCode(opt);
            let conditionsCode = cleanupJSON(JSON.stringify(opt.conditions, null, 2));
            code.push(rmCommonWS$2`,
            JisonLexerError: JisonLexerError,
            performAction: ${performActionCode},
            simpleCaseActionClusters: ${simpleCaseActionClustersCode},
            rules: [
                ${rulesCode}
            ],
            conditions: ${conditionsCode}
        };
        `);

            opt.is_custom_lexer = false;

            out = code.join('');
        } else {
            // We're clearly looking at a custom lexer here as there's no lexer rules at all.
            //
            // We are re-purposing the `%{...%}` `actionInclude` code block here as it serves no purpose otherwise.
            //
            // Try to make sure we have the `lexer` variable declared in *local scope* no matter
            // what crazy stuff (or lack thereof) the userland code is pulling in the `actionInclude` chunk.
            out = '\n';

            assert__default['default'](opt.regular_rule_count === 0);
            assert__default['default'](opt.simple_rule_count === 0);
            opt.is_custom_lexer = true;

            if (opt.actionInclude) {
                out += opt.actionInclude + (!opt.actionInclude.match(/;[\s\r\n]*$/) ? ';' : '') + '\n';
            }
        }

        // The output of this function is guaranteed to read something like this:
        //
        // ```
        // bla bla bla bla ... lotsa bla bla;
        // ```
        //
        // and that should work nicely as an `eval()`-able piece of source code.
        return out;
    }

    function generateGenericHeaderComment() {
        let out = rmCommonWS$2`
    /* lexer generated by jison-lex ${version} */

    /*
     * Returns a Lexer object of the following structure:
     *
     *  Lexer: {
     *    yy: {}     The so-called "shared state" or rather the *source* of it;
     *               the real "shared state" \`yy\` passed around to
     *               the rule actions, etc. is a direct reference!
     *
     *               This "shared context" object was passed to the lexer by way of
     *               the \`lexer.setInput(str, yy)\` API before you may use it.
     *
     *               This "shared context" object is passed to the lexer action code in \`performAction()\`
     *               so userland code in the lexer actions may communicate with the outside world
     *               and/or other lexer rules' actions in more or less complex ways.
     *
     *  }
     *
     *  Lexer.prototype: {
     *    EOF: 1,
     *    ERROR: 2,
     *
     *    yy:        The overall "shared context" object reference.
     *
     *    JisonLexerError: function(msg, hash),
     *
     *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
     *
     *               The function parameters and \`this\` have the following value/meaning:
     *               - \`this\`    : reference to the \`lexer\` instance.
     *                               \`yy_\` is an alias for \`this\` lexer instance reference used internally.
     *
     *               - \`yy\`      : a reference to the \`yy\` "shared state" object which was passed to the lexer
     *                             by way of the \`lexer.setInput(str, yy)\` API before.
     *
     *                             Note:
     *                             The extra arguments you specified in the \`%parse-param\` statement in your
     *                             **parser** grammar definition file are passed to the lexer via this object
     *                             reference as member variables.
     *
     *               - \`yyrulenumber\`   : index of the matched lexer rule (regex), used internally.
     *
     *               - \`YY_START\`: the current lexer "start condition" state.
     *
     *    parseError: function(str, hash, ExceptionClass),
     *
     *    constructLexErrorInfo: function(error_message, is_recoverable),
     *               Helper function.
     *               Produces a new errorInfo \'hash object\' which can be passed into \`parseError()\`.
     *               See it\'s use in this lexer kernel in many places; example usage:
     *
     *                   var infoObj = lexer.constructParseErrorInfo(\'fail!\', true);
     *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
     *
     *    options: { ... lexer %options ... },
     *
     *    lex: function(),
     *               Produce one token of lexed input, which was passed in earlier via the \`lexer.setInput()\` API.
     *               You MAY use the additional \`args...\` parameters as per \`%parse-param\` spec of the **lexer** grammar:
     *               these extra \`args...\` are added verbatim to the \`yy\` object reference as member variables.
     *
     *               WARNING:
     *               Lexer's additional \`args...\` parameters (via lexer's \`%parse-param\`) MAY conflict with
     *               any attributes already added to \`yy\` by the **parser** or the jison run-time;
     *               when such a collision is detected an exception is thrown to prevent the generated run-time
     *               from silently accepting this confusing and potentially hazardous situation!
     *
     *    cleanupAfterLex: function(do_not_nuke_errorinfos),
     *               Helper function.
     *
     *               This helper API is invoked when the **parse process** has completed: it is the responsibility
     *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
     *
     *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
     *
     *    setInput: function(input, [yy]),
     *
     *
     *    input: function(),
     *
     *
     *    unput: function(str),
     *
     *
     *    more: function(),
     *
     *
     *    reject: function(),
     *
     *
     *    less: function(n),
     *
     *
     *    pastInput: function(n),
     *
     *
     *    upcomingInput: function(n),
     *
     *
     *    showPosition: function(),
     *
     *
     *    test_match: function(regex_match_array, rule_index),
     *
     *
     *    next: function(),
     *
     *
     *    begin: function(condition),
     *
     *
     *    pushState: function(condition),
     *
     *
     *    popState: function(),
     *
     *
     *    topState: function(),
     *
     *
     *    _currentRules: function(),
     *
     *
     *    stateStackSize: function(),
     *
     *
     *    performAction: function(yy, yy_, yyrulenumber, YY_START),
     *
     *
     *    rules: [...],
     *
     *
     *    conditions: {associative list: name ==> set},
     *  }
     *
     *
     *  token location info (\`yylloc\`): {
     *    first_line: n,
     *    last_line: n,
     *    first_column: n,
     *    last_column: n,
     *    range: [start_number, end_number]
     *               (where the numbers are indexes into the input string, zero-based)
     *  }
     *
     * ---
     *
     * The \`parseError\` function receives a \'hash\' object with these members for lexer errors:
     *
     *  {
     *    text:        (matched text)
     *    token:       (the produced terminal token, if any)
     *    token_id:    (the produced terminal token numeric ID, if any)
     *    line:        (yylineno)
     *    loc:         (yylloc)
     *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
     *                  available for this particular error)
     *    yy:          (object: the current parser internal "shared state" \`yy\`
     *                  as is also available in the rule actions; this can be used,
     *                  for instance, for advanced error analysis and reporting)
     *    lexer:       (reference to the current lexer instance used by the parser)
     *  }
     *
     * while \`this\` will reference the current lexer instance.
     *
     * When \`parseError\` is invoked by the lexer, the default implementation will
     * attempt to invoke \`yy.parser.parseError()\`; when this callback is not provided
     * it will try to invoke \`yy.parseError()\` instead. When that callback is also not
     * provided, a \`JisonLexerError\` exception will be thrown containing the error
     * message and \`hash\`, as constructed by the \`constructLexErrorInfo()\` API.
     *
     * Note that the lexer\'s \`JisonLexerError\` error class is passed via the
     * \`ExceptionClass\` argument, which is invoked to construct the exception
     * instance to be thrown, so technically \`parseError\` will throw the object
     * produced by the \`new ExceptionClass(str, hash)\` JavaScript expression.
     *
     * ---
     *
     * You can specify lexer options by setting / modifying the \`.options\` object of your Lexer instance.
     * These options are available:
     *
     * (Options are permanent.)
     *
     *  yy: {
     *      parseError: function(str, hash, ExceptionClass)
     *                 optional: overrides the default \`parseError\` function.
     *  }
     *
     *  lexer.options: {
     *      pre_lex:  function()
     *                 optional: is invoked before the lexer is invoked to produce another token.
     *                 \`this\` refers to the Lexer object.
     *      post_lex: function(token) { return token; }
     *                 optional: is invoked when the lexer has produced a token \`token\`;
     *                 this function can override the returned token value by returning another.
     *                 When it does not return any (truthy) value, the lexer will return
     *                 the original \`token\`.
     *                 \`this\` refers to the Lexer object.
     *
     * WARNING: the next set of options are not meant to be changed. They echo the abilities of
     * the lexer as per when it was compiled!
     *
     *      ranges: boolean
     *                 optional: \`true\` ==> token location info will include a .range[] member.
     *      flex: boolean
     *                 optional: \`true\` ==> flex-like lexing behaviour where the rules are tested
     *                 exhaustively to find the longest match.
     *      backtrack_lexer: boolean
     *                 optional: \`true\` ==> lexer regexes are tested in order and for invoked;
     *                 the lexer terminates the scan when a token is returned by the action code.
     *      xregexp: boolean
     *                 optional: \`true\` ==> lexer rule regexes are "extended regex format" requiring the
     *                 \`XRegExp\` library. When this %option has not been specified at compile time, all lexer
     *                 rule regexes have been written as standard JavaScript RegExp expressions.
     *  }
     */
     `;

        return out;
    }

    function prepareOptions(opt) {
        opt = opt || {};

        // check for illegal identifier
        if (!opt.moduleName || !opt.moduleName.match(/^[a-zA-Z_$][a-zA-Z0-9_$\.]*$/)) {
            if (opt.moduleName) {
                let msg = 'WARNING: The specified moduleName "' + opt.moduleName + '" is illegal (only characters [a-zA-Z0-9_$] and "." dot are accepted); using the default moduleName "lexer" instead.';
                if (typeof opt.warn_cb === 'function') {
                    opt.warn_cb(msg);
                } else {
                    // do not treat as warning; barf hairball instead so that this oddity gets noticed right away!
                    throw new Error(msg);
                }
            }
            opt.moduleName = 'lexer';
        }

        prepExportStructures(opt);

        return opt;
    }

    function generateModule(opt) {
        opt = prepareOptions(opt);
        let modIncSrc = (opt.moduleInclude ? opt.moduleInclude + ';' : '');

        let src = rmCommonWS$2`
        ${generateGenericHeaderComment()}

        var ${opt.moduleName} = (function () {
            "use strict";

            ${jisonLexerErrorDefinition}

            ${generateModuleBody(opt)}

            ${modIncSrc}

            return lexer;
        })();
    `;

        src = stripUnusedLexerCode(src, opt);
        opt.exportSourceCode.all = src;
        return src;
    }

    function generateAMDModule(opt) {
        opt = prepareOptions(opt);
        let modIncSrc = (opt.moduleInclude ? opt.moduleInclude + ';' : '');

        let src = rmCommonWS$2`
        ${generateGenericHeaderComment()}

        define([], function () {
            "use strict";

            ${jisonLexerErrorDefinition}

            ${generateModuleBody(opt)}

            ${modIncSrc}

            return lexer;
        });
    `;

        src = stripUnusedLexerCode(src, opt);
        opt.exportSourceCode.all = src;
        return src;
    }

    function generateESModule(opt) {
        opt = prepareOptions(opt);
        let modIncSrc = (opt.moduleInclude ? opt.moduleInclude + ';' : '');

        let src = rmCommonWS$2`
        ${generateGenericHeaderComment()}

        const lexer = (function () {
            "use strict";

            ${jisonLexerErrorDefinition}

            ${generateModuleBody(opt)}

            ${modIncSrc}

            return lexer;
        })();

        function yylex() {
            return lexer.lex.apply(lexer, arguments);
        }

        export {
            lexer,
            yylex as lex
        };
    `;

        src = stripUnusedLexerCode(src, opt);
        opt.exportSourceCode.all = src;
        return src;
    }

    function generateCommonJSModule(opt) {
        opt = prepareOptions(opt);
        let modIncSrc = (opt.moduleInclude ? opt.moduleInclude + ';' : '');

        let src = rmCommonWS$2`
        ${generateGenericHeaderComment()}

        var ${opt.moduleName} = (function () {
            "use strict";

            ${jisonLexerErrorDefinition}

            ${generateModuleBody(opt)}

            ${modIncSrc}

            return lexer;
        })();

        if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
            exports.lexer = ${opt.moduleName};
            exports.lex = function () {
                return ${opt.moduleName}.lex.apply(lexer, arguments);
            };
        }
    `;

        src = stripUnusedLexerCode(src, opt);
        opt.exportSourceCode.all = src;
        return src;
    }

    RegExpLexer.generate = generate;

    RegExpLexer.version = version;
    RegExpLexer.defaultJisonLexOptions = defaultJisonLexOptions;
    RegExpLexer.mkStdOptions = mkStdOptions;
    RegExpLexer.camelCase = helpers.camelCase;
    RegExpLexer.mkIdentifier = mkIdentifier$3;
    RegExpLexer.autodetectAndConvertToJSONformat = autodetectAndConvertToJSONformat;

    // See also:
    // http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
    // but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
    // with userland code which might access the derived class in a 'classic' way.
    function JisonParserError$1(msg, hash) {
        Object.defineProperty(this, 'name', {
            enumerable: false,
            writable: false,
            value: 'JisonParserError'
        });

        if (msg == null) msg = '???';

        Object.defineProperty(this, 'message', {
            enumerable: false,
            writable: true,
            value: msg
        });

        this.hash = hash;

        let stacktrace;
        if (hash && hash.exception instanceof Error) {
            let ex2 = hash.exception;
            this.message = ex2.message || msg;
            stacktrace = ex2.stack;
        }
        if (!stacktrace) {
            if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
                Error.captureStackTrace(this, this.constructor);
            } else {
                stacktrace = (new Error(msg)).stack;
            }
        }
        if (stacktrace) {
            Object.defineProperty(this, 'stack', {
                enumerable: false,
                writable: false,
                value: stacktrace
            });
        }
    }

    if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonParserError$1.prototype, Error.prototype);
    } else {
        JisonParserError$1.prototype = Object.create(Error.prototype);
    }
    JisonParserError$1.prototype.constructor = JisonParserError$1;
    JisonParserError$1.prototype.name = 'JisonParserError';




            // helper: reconstruct the productions[] table
            function bp$1(s) {
                let rv = [];
                let p = s.pop;
                let r = s.rule;
                for (let i = 0, l = p.length; i < l; i++) {
                    rv.push([
                        p[i],
                        r[i]
                    ]);
                }
                return rv;
            }
        




            // helper: reconstruct the 'goto' table
            function bt$1(s) {
                let rv = [];
                let d = s.len;
                let y = s.symbol;
                let t = s.type;
                let a = s.state;
                let m = s.mode;
                let g = s.goto;
                for (let i = 0, l = d.length; i < l; i++) {
                    let n = d[i];
                    let q = {};
                    for (let j = 0; j < n; j++) {
                        let z = y.shift();
                        switch (t.shift()) {
                        case 2:
                            q[z] = [
                                m.shift(),
                                g.shift()
                            ];
                            break;

                        case 0:
                            q[z] = a.shift();
                            break;

                        default:
                            // type === 1: accept
                            q[z] = [
                                3
                            ];
                        }
                    }
                    rv.push(q);
                }
                return rv;
            }
        


            // helper: runlength encoding with increment step: code, length: step (default step = 0)
            // `this` references an array
            function s$1(c, l, a) {
                a = a || 0;
                for (let i = 0; i < l; i++) {
                    this.push(c);
                    c += a;
                }
            }

            // helper: duplicate sequence from *relative* offset and length.
            // `this` references an array
            function c$1(i, l) {
                i = this.length - i;
                for (l += i; i < l; i++) {
                    this.push(this[i]);
                }
            }

            // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
            function u$1(a) {
                let rv = [];
                for (let i = 0, l = a.length; i < l; i++) {
                    let e = a[i];
                    // Is this entry a helper function?
                    if (typeof e === 'function') {
                        i++;
                        e.apply(rv, a[i]);
                    } else {
                        rv.push(e);
                    }
                }
                return rv;
            }
        

    let parser$1 = {
        // Code Generator Information Report
        // ---------------------------------
        //
        // Options:
        //
        //   default action mode: ............. ["classic","merge"]
        //   test-compile action mode: ........ "parser:*,lexer:*"
        //   try..catch: ...................... true
        //   default resolve on conflict: ..... true
        //   on-demand look-ahead: ............ false
        //   error recovery token skip maximum: 3
        //   yyerror in parse actions is: ..... NOT recoverable,
        //   yyerror in lexer actions and other non-fatal lexer are:
        //   .................................. NOT recoverable,
        //   debug grammar/output: ............ false
        //   has partial LR conflict upgrade:   true
        //   rudimentary token-stack support:   false
        //   parser table compression mode: ... 2
        //   export debug tables: ............. false
        //   export *all* tables: ............. false
        //   module type: ..................... es
        //   parser engine type: .............. lalr
        //   output main() in the module: ..... true
        //   has user-specified main(): ....... false
        //   has user-specified require()/import modules for main():
        //   .................................. false
        //   number of expected conflicts: .... 0
        //
        //
        // Parser Analysis flags:
        //
        //   no significant actions (parser is a language matcher only):
        //   .................................. false
        //   uses yyleng: ..................... false
        //   uses yylineno: ................... false
        //   uses yytext: ..................... false
        //   uses yylloc: ..................... false
        //   uses ParseError API: ............. false
        //   uses YYERROR: .................... false
        //   uses YYRECOVERING: ............... false
        //   uses YYERROK: .................... false
        //   uses YYCLEARIN: .................. false
        //   tracks rule values: .............. true
        //   assigns rule values: ............. true
        //   uses location tracking: .......... false
        //   assigns location: ................ false
        //   uses yystack: .................... false
        //   uses yysstack: ................... false
        //   uses yysp: ....................... true
        //   uses yyrulelength: ............... false
        //   uses yyMergeLocationInfo API: .... false
        //   has error recovery: .............. false
        //   has error reporting: ............. false
        //
        // --------- END OF REPORT -----------

    trace: function no_op_trace() { },
    JisonParserError: JisonParserError$1,
    yy: {},
    options: {
      type: "lalr",
      hasPartialLrUpgradeOnConflict: true,
      errorRecoveryTokenDiscardCount: 3
    },
    symbols_: {
      "$accept": 0,
      "$end": 1,
      "(": 4,
      ")": 5,
      "*": 6,
      "+": 8,
      "?": 7,
      "ALIAS": 9,
      "EOF": 1,
      "SYMBOL": 10,
      "error": 2,
      "expression": 16,
      "handle": 13,
      "handle_list": 12,
      "production": 11,
      "rule": 14,
      "suffix": 17,
      "suffixed_expression": 15,
      "|": 3
    },
    terminals_: {
      1: "EOF",
      2: "error",
      3: "|",
      4: "(",
      5: ")",
      6: "*",
      7: "?",
      8: "+",
      9: "ALIAS",
      10: "SYMBOL"
    },
    TERROR: 2,
        EOF: 1,

        // internals: defined here so the object *structure* doesn't get modified by parse() et al,
        // thus helping JIT compilers like Chrome V8.
        originalQuoteName: null,
        originalParseError: null,
        cleanupAfterParse: null,
        constructParseErrorInfo: null,
        yyMergeLocationInfo: null,
        copy_yytext: null,
        copy_yylloc: null,

        __reentrant_call_depth: 0,      // INTERNAL USE ONLY
        __error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
        __error_recovery_infos: [],     // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

        // APIs which will be set up depending on user action code analysis:
        //yyRecovering: 0,
        //yyErrOk: 0,
        //yyClearIn: 0,

        // Helper APIs
        // -----------

        // Helper function which can be overridden by user code later on: put suitable quotes around
        // literal IDs in a description string.
        quoteName: function parser_quoteName(id_str) {
            return '"' + id_str + '"';
        },

        // Return the name of the given symbol (terminal or non-terminal) as a string, when available.
        //
        // Return NULL when the symbol is unknown to the parser.
        getSymbolName: function parser_getSymbolName(symbol) {
            if (this.terminals_[symbol]) {
                return this.terminals_[symbol];
            }

            // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
            //
            // An example of this may be where a rule's action code contains a call like this:
            //
            //      parser.getSymbolName(#$)
            //
            // to obtain a human-readable name of the current grammar rule.
            const s = this.symbols_;
            for (let key in s) {
                if (s[key] === symbol) {
                    return key;
                }
            }
            return null;
        },

        // Return a more-or-less human-readable description of the given symbol, when available,
        // or the symbol itself, serving as its own 'description' for lack of something better to serve up.
        //
        // Return NULL when the symbol is unknown to the parser.
        describeSymbol: function parser_describeSymbol(symbol) {
            if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
                return this.terminal_descriptions_[symbol];
            } else if (symbol === this.EOF) {
                return 'end of input';
            }

            let id = this.getSymbolName(symbol);
            if (id) {
                return this.quoteName(id);
            }
            return null;
        },

        // Produce a (more or less) human-readable list of expected tokens at the point of failure.
        //
        // The produced list may contain token or token set descriptions instead of the tokens
        // themselves to help turning this output into something that easier to read by humans
        // unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
        // expected terminals and nonterminals is produced.
        //
        // The returned list (array) will not contain any duplicate entries.
        collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
            const TERROR = this.TERROR;
            let tokenset = [];
            let check = {};

            // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
            // If so, use that one instead of the less palatable token set.
            if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
                return [
                    this.state_descriptions_[state]
                ];
            }
            for (let p in this.table[state]) {
                p = +p;
                if (p !== TERROR) {
                    let d = do_not_describe ? p : this.describeSymbol(p);
                    if (d && !check[d]) {
                        tokenset.push(d);
                        check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
                    }
                }
            }
            return tokenset;
        },
    productions_: bp$1({
      pop: u$1([
      11,
      12,
      12,
      13,
      13,
      14,
      14,
      15,
      15,
      16,
      16,
      s$1,
      [17, 4]
    ]),
      rule: u$1([
      2,
      1,
      3,
      0,
      1,
      1,
      2,
      3,
      c$1,
      [8, 6],
      1
    ])
    }),
    performAction: function parser__PerformAction(yystate /* action[1] */, yysp, yyvstack) {

              /* this == yyval */

              // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
              let yy = this.yy;
              let yyparser = yy.parser;
              let yylexer = yy.lexer;

              

              switch (yystate) {
    case 0:
        /*! Production::    $accept : production $end */

        // default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,-,-,-,-):
        this.$ = yyvstack[yysp - 1];
        // END of default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,-,-,-,-)
        break;

    case 1:
        /*! Production::    production : handle EOF */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,-,-,-,-):
        this.$ = yyvstack[yysp - 1];
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,-,-,-,-)
        
        
        return yyvstack[yysp - 1];

    case 2:
        /*! Production::    handle_list : handle */
    case 6:
        /*! Production::    rule : suffixed_expression */

        this.$ = [yyvstack[yysp]];
        break;

    case 3:
        /*! Production::    handle_list : handle_list "|" handle */

        yyvstack[yysp - 2].push(yyvstack[yysp]);
        this.$ = yyvstack[yysp - 2];
        break;

    case 4:
        /*! Production::    handle : %epsilon */

        this.$ = [];
        break;

    case 5:
        /*! Production::    handle : rule */
    case 13:
        /*! Production::    suffix : "*" */
    case 14:
        /*! Production::    suffix : "?" */
    case 15:
        /*! Production::    suffix : "+" */

        this.$ = yyvstack[yysp];
        break;

    case 7:
        /*! Production::    rule : rule suffixed_expression */

        yyvstack[yysp - 1].push(yyvstack[yysp]);
        this.$ = yyvstack[yysp - 1];
        break;

    case 8:
        /*! Production::    suffixed_expression : expression suffix ALIAS */

        this.$ = ['xalias', yyvstack[yysp - 1], yyvstack[yysp - 2], yyvstack[yysp]];
        break;

    case 9:
        /*! Production::    suffixed_expression : expression suffix */

        if (yyvstack[yysp]) {
          this.$ = [yyvstack[yysp], yyvstack[yysp - 1]];
        } else {
          this.$ = yyvstack[yysp - 1];
        }
        break;

    case 10:
        /*! Production::    expression : SYMBOL */

        this.$ = ['symbol', yyvstack[yysp]];
        break;

    case 11:
        /*! Production::    expression : "(" handle_list ")" */

        this.$ = ['()', yyvstack[yysp - 1]];
        break;

    case 12:
        /*! Production::    suffix : %epsilon */

        this.$ = undefined;
        break;

    }
    },
    table: bt$1({
      len: u$1([
      8,
      1,
      1,
      7,
      0,
      10,
      0,
      9,
      0,
      0,
      6,
      s$1,
      [0, 3],
      2,
      s$1,
      [0, 3],
      8,
      0
    ]),
      symbol: u$1([
      1,
      4,
      10,
      11,
      s$1,
      [13, 4, 1],
      s$1,
      [1, 3],
      3,
      4,
      5,
      10,
      c$1,
      [9, 3],
      s$1,
      [3, 8, 1],
      17,
      c$1,
      [16, 4],
      s$1,
      [12, 5, 1],
      c$1,
      [19, 4],
      9,
      10,
      3,
      5,
      c$1,
      [17, 4],
      c$1,
      [16, 4]
    ]),
      type: u$1([
      s$1,
      [2, 3],
      s$1,
      [0, 5],
      1,
      s$1,
      [2, 6],
      0,
      0,
      s$1,
      [2, 9],
      c$1,
      [10, 5],
      s$1,
      [0, 5],
      s$1,
      [2, 12],
      s$1,
      [0, 4]
    ]),
      state: u$1([
      s$1,
      [1, 5, 1],
      9,
      5,
      10,
      14,
      15,
      c$1,
      [8, 3],
      19,
      c$1,
      [4, 3]
    ]),
      mode: u$1([
      2,
      s$1,
      [1, 3],
      2,
      2,
      1,
      2,
      c$1,
      [5, 3],
      c$1,
      [7, 3],
      c$1,
      [12, 4],
      c$1,
      [13, 9],
      c$1,
      [15, 3],
      c$1,
      [5, 4]
    ]),
      goto: u$1([
      4,
      7,
      6,
      8,
      5,
      5,
      7,
      5,
      6,
      s$1,
      [12, 4],
      11,
      12,
      13,
      12,
      12,
      4,
      7,
      4,
      6,
      s$1,
      [9, 4],
      16,
      9,
      18,
      17,
      c$1,
      [12, 4]
    ])
    }),
    defaultActions: {
      4: 6,
      6: 10,
      8: 1,
      9: 7,
      11: 13,
      12: 14,
      13: 15,
      15: 2,
      16: 8,
      17: 11,
      19: 3
    },
    parseError: function parseError(str, hash, ExceptionClass) {
        if (hash.recoverable) {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            hash.destroy();             // destroy... well, *almost*!
        } else {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            throw new ExceptionClass(str, hash);
        }
    },
    parse: function parse(input) {
        let self = this;
        let stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
        let sstack = new Array(128);        // state stack: stores states (column storage)

        let vstack = new Array(128);        // semantic value stack

        let table = this.table;
        let sp = 0;                         // 'stack pointer': index into the stacks

        let symbol = 0;



        const TERROR = this.TERROR;
        const EOF = this.EOF;
        const ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
        const NO_ACTION = [ 0, 20 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

        let lexer;
        if (this.__lexer__) {
            lexer = this.__lexer__;
        } else {
            lexer = this.__lexer__ = Object.create(this.lexer);
        }

        let sharedState_yy = {
            parseError: undefined,
            quoteName: undefined,
            lexer: undefined,
            parser: undefined,
            pre_parse: undefined,
            post_parse: undefined,
            pre_lex: undefined,
            post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly!
        };

        const ASSERT = (
            typeof assert !== 'function' ?
                function JisonAssert(cond, msg) {
                    if (!cond) {
                        throw new Error('assertion failed: ' + (msg || '***'));
                    }
                } :
                assert
        );

        this.yyGetSharedState = function yyGetSharedState() {
            return sharedState_yy;
        };


        // shallow clone objects & arrays, straight copy of simple `src` values
        // e.g. `lexer.yytext` MAY be a complex value object,
        // rather than a simple string/value.
        //
        // https://jsperf.com/new-array-vs-splice-vs-slice/72
        // https://jsperf.com/instanceof-vs-typeof/20
        // benchmark:: http://127.0.0.1:8080/example/jsperf/#testfile=test0020-typeof-instanceof-isArray.json5
        // benchmark:: http://127.0.0.1:8080/example/jsperf/?333#testfile=test0021-shallow-clones.json5
        //
        function shallow_copy(src) {
            if (src && typeof src === 'object') {
                // non-Object-type objects, e.g. RegExp, Date, etc., can usually be shallow cloned
                // using their constructor:
                if (src.constructor !== Object) {
                    if (Array.isArray(src)) {
                        return src.slice();
                    }
                    let dst = new src.constructor(src);

                    // and make sure all custom attributes are added to the clone:
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
                // native objects must be cloned a different way:
                {
                    //return Object.assign({}, src);
                    let dst = {};
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
            }
            return src;
        }
        // add elements from `src` to `dst` when:
        // - either the element does not yet exist in `src`
        // - or exists in `src` but is NULL or UNDEFINED there, while its value is non-NULL in `dst`
        function shallow_copy_noclobber(dst, src) {
            const chk = Object.prototype.hasOwnProperty;
            for (let k in src) {
                if (!(k in dst)) {
                    if (chk.call(src, k)) {
                        dst[k] = src[k];
                    }
                } else if (src[k] != null && dst[k] == null && chk.call(src, k)) {
                    dst[k] = src[k];
                }
            }
        }

        // copy state
        shallow_copy_noclobber(sharedState_yy, this.yy);

        sharedState_yy.lexer = lexer;
        sharedState_yy.parser = this;


        this.copy_yytext = this.options.copy_yytext || sharedState_yy.copy_yytext || shallow_copy;






        // Does the shared state override the default `parseError` that already comes with this instance?
        if (typeof sharedState_yy.parseError === 'function') {
            this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
                if (!ExceptionClass) {
                    ExceptionClass = this.JisonParserError;
                }
                return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
            };
        } else {
            this.parseError = this.originalParseError;
        }

        // Does the shared state override the default `quoteName` that already comes with this instance?
        if (typeof sharedState_yy.quoteName === 'function') {
            this.quoteName = function quoteNameAlt(id_str) {
                return sharedState_yy.quoteName.call(this, id_str);
            };
        } else {
            this.quoteName = this.originalQuoteName;
        }

        // set up the cleanup function; make it an API so that external code can re-use this one in case of
        // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
        // case this parse() API method doesn't come with a `finally { ... }` block any more!
        //
        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `sharedState`, etc. references will be *wrong*!
        this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
            let rv;

            if (invoke_post_methods) {
                let hash;

                if (sharedState_yy.post_parse || this.post_parse) {
                    // create an error hash info instance: we re-use this API in a **non-error situation**
                    // as this one delivers all parser internals ready for access by userland code.
                    hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
                }

                if (sharedState_yy.post_parse) {
                    rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }
                if (this.post_parse) {
                    rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }

                // cleanup:
                if (hash && hash.destroy) {
                    hash.destroy();
                }
            }

            if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

            // clean up the lingering lexer structures as well:
            if (lexer.cleanupAfterLex) {
                lexer.cleanupAfterLex(do_not_nuke_errorinfos);
            }

            // prevent lingering circular references from causing memory leaks:
            if (sharedState_yy) {
                sharedState_yy.lexer = undefined;
                sharedState_yy.parser = undefined;
                if (lexer.yy === sharedState_yy) {
                    lexer.yy = undefined;
                }
            }
            sharedState_yy = undefined;
            this.parseError = this.originalParseError;
            this.quoteName = this.originalQuoteName;

            // nuke the vstack[] array at least as that one will still reference obsoleted user values.
            // To be safe, we nuke the other internal stack columns as well...
            stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
            sstack.length = 0;

            vstack.length = 0;
            sp = 0;

            // nuke the error hash info instances created during this run.
            // Userland code must COPY any data/references
            // in the error hash instance(s) it is more permanently interested in.
            if (!do_not_nuke_errorinfos) {
                for (let i = this.__error_infos.length - 1; i >= 0; i--) {
                    let el = this.__error_infos[i];
                    if (el && typeof el.destroy === 'function') {
                        el.destroy();
                    }
                }
                this.__error_infos.length = 0;


            }

            return resultValue;
        };






































































































































        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
        this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
            const pei = {
                errStr: msg,
                exception: ex,
                text: lexer.match,
                value: this.copy_yytext(lexer.yytext),
                token: this.describeSymbol(symbol) || symbol,
                token_id: symbol,
                line: lexer.yylineno,

                expected,
                recoverable,
                state,
                action,
                new_state: newState,
                symbol_stack: stack,
                state_stack: sstack,
                value_stack: vstack,

                stack_pointer: sp,
                yy: sharedState_yy,
                lexer,
                parser: this,

                // and make sure the error info doesn't stay due to potential
                // ref cycle via userland code manipulations.
                // These would otherwise all be memory leak opportunities!
                //
                // Note that only array and object references are nuked as those
                // constitute the set of elements which can produce a cyclic ref.
                // The rest of the members is kept intact as they are harmless.
                destroy: function destructParseErrorInfo() {
                    // remove cyclic references added to error info:
                    // info.yy = null;
                    // info.lexer = null;
                    // info.value = null;
                    // info.value_stack = null;
                    // ...
                    const rec = !!this.recoverable;
                    for (let key in this) {
                        if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                            this[key] = undefined;
                        }
                    }
                    this.recoverable = rec;
                }
            };
            // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
            this.__error_infos.push(pei);
            return pei;
        };













        function getNonTerminalFromCode(symbol) {
            let tokenName = self.getSymbolName(symbol);
            if (!tokenName) {
                tokenName = symbol;
            }
            return tokenName;
        }


        function stdLex() {
            let token = lexer.lex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        function fastLex() {
            let token = lexer.fastLex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        let lex = stdLex;


        let state, action, r, t;
        let yyval = {
            $: true,
            _$: undefined,
            yy: sharedState_yy
        };
        let p;
        let yyrulelen;
        let this_production;
        let newState;
        let retval = false;


        try {
            this.__reentrant_call_depth++;

            lexer.setInput(input, sharedState_yy);

            // NOTE: we *assume* no lexer pre/post handlers are set up *after*
            // this initial `setInput()` call: hence we can now check and decide
            // whether we'll go with the standard, slower, lex() API or the
            // `fast_lex()` one:
            if (typeof lexer.canIUse === 'function') {
                let lexerInfo = lexer.canIUse();
                if (lexerInfo.fastLex && typeof fastLex === 'function') {
                    lex = fastLex;
                }
            }



            vstack[sp] = null;
            sstack[sp] = 0;
            stack[sp] = 0;
            ++sp;





            if (this.pre_parse) {
                this.pre_parse.call(this, sharedState_yy);
            }
            if (sharedState_yy.pre_parse) {
                sharedState_yy.pre_parse.call(this, sharedState_yy);
            }

            newState = sstack[sp - 1];
            for (;;) {
                // retrieve state number from top of stack
                state = newState;               // sstack[sp - 1];

                // use default actions if available
                if (this.defaultActions[state]) {
                    action = 2;
                    newState = this.defaultActions[state];
                } else {
                    // The single `==` condition below covers both these `===` comparisons in a single
                    // operation:
                    //
                    //     if (symbol === null || typeof symbol === 'undefined') ...
                    if (!symbol) {
                        symbol = lex();
                    }
                    // read action for current state and first input
                    t = (table[state] && table[state][symbol]) || NO_ACTION;
                    newState = t[1];
                    action = t[0];








    // handle parse error
                    if (!action) {
                        let errStr;
                        let errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                        let expected = this.collect_expected_token_set(state);

                        // Report error
                        errStr = 'Parse error';
                        if (typeof lexer.yylineno === 'number') {
                            errStr += ' on line ' + (lexer.yylineno + 1);
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += ':\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        } else {
                            errStr += ': ';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }
                        // we cannot recover from the error!
                        p = this.constructParseErrorInfo(errStr, null, expected, false);
                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }


                }








    switch (action) {
                // catch misc. parse failures:
                default:
                    // this shouldn't happen, unless resolve defaults are off
                    if (action instanceof Array) {
                        p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }
                    // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                    // or a buggy LUT (LookUp Table):
                    p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;

                // shift:
                case 1:
                    stack[sp] = symbol;
                    vstack[sp] = lexer.yytext;

                    sstack[sp] = newState; // push state

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let tokenName = this.getSymbolName(symbol || EOF);
                        if (!tokenName) {
                            tokenName = symbol;
                        }

                        Jison.parserDebugger.push({
                            action: 'shift',
                            text: lexer.yytext,
                            terminal: tokenName,
                            terminal_id: symbol
                        });
                    }

                    ++sp;

                    symbol = 0;




                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:




                    continue;

                // reduce:
                case 2:



                    this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                    yyrulelen = this_production[1];








    r = this.performAction.call(yyval, newState, sp - 1, vstack);

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                        let debuggableProductions = [];
                        for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                            let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                            debuggableProductions.push(debuggableProduction);
                        }

                        // find the current nonterminal name (- nolan)
                        let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                        let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                        Jison.parserDebugger.push({
                            action: 'reduce',
                            nonterminal: currentNonterminal,
                            nonterminal_id: currentNonterminalCode,
                            prereduce: prereduceValue,
                            result: r,
                            productions: debuggableProductions,
                            text: yyval.$
                        });
                    }

                    if (typeof r !== 'undefined') {
                        retval = r;

                        if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                            Jison.parserDebugger.push({
                                action: 'accept',
                                text: retval
                            });
                            console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                        }

                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // don't overwrite the `symbol` variable: use a local var to speed things up:
                    {
                        let ntsymbol = this_production[0];    // push nonterminal (reduce)
                        stack[sp] = ntsymbol;
                        vstack[sp] = yyval.$;

                        // goto new state = table[STATE][NONTERMINAL]
                        newState = table[sstack[sp - 1]][ntsymbol];
                        sstack[sp] = newState;
                        ++sp;









                    }
                    continue;

                // accept:
                case 3:
                    if (sp !== -2) {
                        retval = true;
                        // Return the `$accept` rule's `$$` result, if available.
                        //
                        // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                        // default, action):
                        //
                        //     $accept: <startSymbol> $end
                        //                  %{ $$ = $1; @$ = @1; %}
                        //
                        // which, combined with the parse kernel's `$accept` state behaviour coded below,
                        // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                        // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                        //
                        // In code:
                        //
                        //                  %{
                        //                      @$ = @1;            // if location tracking support is included
                        //                      if (typeof $1 !== 'undefined')
                        //                          return $1;
                        //                      else
                        //                          return true;           // the default parse result if the rule actions don't produce anything
                        //                  %}
                        sp--;
                        if (typeof vstack[sp] !== 'undefined') {
                            retval = vstack[sp];
                        }
                    }

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        Jison.parserDebugger.push({
                            action: 'accept',
                            text: retval
                        });
                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                    }

                    break;
                }

                // break out of loop: we accept or fail with error
                break;
            }
        } catch (ex) {
            // report exceptions through the parseError callback too, but keep the exception intact
            // if it is a known parser or lexer error which has been thrown by parseError() already:
            if (ex instanceof this.JisonParserError) {
                throw ex;
            } else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
                throw ex;
            }

            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        } finally {
            retval = this.cleanupAfterParse(retval, true, true);
            this.__reentrant_call_depth--;

            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                Jison.parserDebugger.push({
                    action: 'return',
                    text: retval
                });
                console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
            }
        }   // /finally

        return retval;
    }
    };
    parser$1.originalParseError = parser$1.parseError;
    parser$1.originalQuoteName = parser$1.quoteName;
    /* lexer generated by jison-lex 0.6.2-220 */

    /*
     * Returns a Lexer object of the following structure:
     *
     *  Lexer: {
     *    yy: {}     The so-called "shared state" or rather the *source* of it;
     *               the real "shared state" `yy` passed around to
     *               the rule actions, etc. is a direct reference!
     *
     *               This "shared context" object was passed to the lexer by way of
     *               the `lexer.setInput(str, yy)` API before you may use it.
     *
     *               This "shared context" object is passed to the lexer action code in `performAction()`
     *               so userland code in the lexer actions may communicate with the outside world
     *               and/or other lexer rules' actions in more or less complex ways.
     *
     *  }
     *
     *  Lexer.prototype: {
     *    EOF: 1,
     *    ERROR: 2,
     *
     *    yy:        The overall "shared context" object reference.
     *
     *    JisonLexerError: function(msg, hash),
     *
     *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
     *
     *               The function parameters and `this` have the following value/meaning:
     *               - `this`    : reference to the `lexer` instance.
     *                               `yy_` is an alias for `this` lexer instance reference used internally.
     *
     *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
     *                             by way of the `lexer.setInput(str, yy)` API before.
     *
     *                             Note:
     *                             The extra arguments you specified in the `%parse-param` statement in your
     *                             **parser** grammar definition file are passed to the lexer via this object
     *                             reference as member variables.
     *
     *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
     *
     *               - `YY_START`: the current lexer "start condition" state.
     *
     *    parseError: function(str, hash, ExceptionClass),
     *
     *    constructLexErrorInfo: function(error_message, is_recoverable),
     *               Helper function.
     *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
     *               See it's use in this lexer kernel in many places; example usage:
     *
     *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
     *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
     *
     *    options: { ... lexer %options ... },
     *
     *    lex: function(),
     *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
     *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
     *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
     *
     *               WARNING:
     *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
     *               any attributes already added to `yy` by the **parser** or the jison run-time;
     *               when such a collision is detected an exception is thrown to prevent the generated run-time
     *               from silently accepting this confusing and potentially hazardous situation!
     *
     *    cleanupAfterLex: function(do_not_nuke_errorinfos),
     *               Helper function.
     *
     *               This helper API is invoked when the **parse process** has completed: it is the responsibility
     *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
     *
     *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
     *
     *    setInput: function(input, [yy]),
     *
     *
     *    input: function(),
     *
     *
     *    unput: function(str),
     *
     *
     *    more: function(),
     *
     *
     *    reject: function(),
     *
     *
     *    less: function(n),
     *
     *
     *    pastInput: function(n),
     *
     *
     *    upcomingInput: function(n),
     *
     *
     *    showPosition: function(),
     *
     *
     *    test_match: function(regex_match_array, rule_index),
     *
     *
     *    next: function(),
     *
     *
     *    begin: function(condition),
     *
     *
     *    pushState: function(condition),
     *
     *
     *    popState: function(),
     *
     *
     *    topState: function(),
     *
     *
     *    _currentRules: function(),
     *
     *
     *    stateStackSize: function(),
     *
     *
     *    performAction: function(yy, yy_, yyrulenumber, YY_START),
     *
     *
     *    rules: [...],
     *
     *
     *    conditions: {associative list: name ==> set},
     *  }
     *
     *
     *  token location info (`yylloc`): {
     *    first_line: n,
     *    last_line: n,
     *    first_column: n,
     *    last_column: n,
     *    range: [start_number, end_number]
     *               (where the numbers are indexes into the input string, zero-based)
     *  }
     *
     * ---
     *
     * The `parseError` function receives a 'hash' object with these members for lexer errors:
     *
     *  {
     *    text:        (matched text)
     *    token:       (the produced terminal token, if any)
     *    token_id:    (the produced terminal token numeric ID, if any)
     *    line:        (yylineno)
     *    loc:         (yylloc)
     *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
     *                  available for this particular error)
     *    yy:          (object: the current parser internal "shared state" `yy`
     *                  as is also available in the rule actions; this can be used,
     *                  for instance, for advanced error analysis and reporting)
     *    lexer:       (reference to the current lexer instance used by the parser)
     *  }
     *
     * while `this` will reference the current lexer instance.
     *
     * When `parseError` is invoked by the lexer, the default implementation will
     * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
     * it will try to invoke `yy.parseError()` instead. When that callback is also not
     * provided, a `JisonLexerError` exception will be thrown containing the error
     * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
     *
     * Note that the lexer's `JisonLexerError` error class is passed via the
     * `ExceptionClass` argument, which is invoked to construct the exception
     * instance to be thrown, so technically `parseError` will throw the object
     * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
     *
     * ---
     *
     * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
     * These options are available:
     *
     * (Options are permanent.)
     *
     *  yy: {
     *      parseError: function(str, hash, ExceptionClass)
     *                 optional: overrides the default `parseError` function.
     *  }
     *
     *  lexer.options: {
     *      pre_lex:  function()
     *                 optional: is invoked before the lexer is invoked to produce another token.
     *                 `this` refers to the Lexer object.
     *      post_lex: function(token) { return token; }
     *                 optional: is invoked when the lexer has produced a token `token`;
     *                 this function can override the returned token value by returning another.
     *                 When it does not return any (truthy) value, the lexer will return
     *                 the original `token`.
     *                 `this` refers to the Lexer object.
     *
     * WARNING: the next set of options are not meant to be changed. They echo the abilities of
     * the lexer as per when it was compiled!
     *
     *      ranges: boolean
     *                 optional: `true` ==> token location info will include a .range[] member.
     *      flex: boolean
     *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
     *                 exhaustively to find the longest match.
     *      backtrack_lexer: boolean
     *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
     *                 the lexer terminates the scan when a token is returned by the action code.
     *      xregexp: boolean
     *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
     *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
     *                 rule regexes have been written as standard JavaScript RegExp expressions.
     *  }
     */


    var lexer$1 = function() {

      /**
       * See also:
       * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
       * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
       * with userland code which might access the derived class in a 'classic' way.
       *
       * @public
       * @constructor
       * @nocollapse
       */
      function JisonLexerError(msg, hash) {
        Object.defineProperty(this, 'name', {
          enumerable: false,
          writable: false,
          value: 'JisonLexerError'
        });

        if (msg == null)
          msg = '???';

        Object.defineProperty(this, 'message', {
          enumerable: false,
          writable: true,
          value: msg
        });

        this.hash = hash;
        let stacktrace;

        if (hash && hash.exception instanceof Error) {
          const ex2 = hash.exception;
          this.message = ex2.message || msg;
          stacktrace = ex2.stack;
        }

        if (!stacktrace) {
          if (Error.hasOwnProperty('captureStackTrace')) {
            // V8
            Error.captureStackTrace(this, this.constructor);
          } else {
            stacktrace = new Error(msg).stack;
          }
        }

        if (stacktrace) {
          Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
          });
        }
      }

      if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
      } else {
        JisonLexerError.prototype = Object.create(Error.prototype);
      }

      JisonLexerError.prototype.constructor = JisonLexerError;
      JisonLexerError.prototype.name = 'JisonLexerError';

      const lexer = {
        
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   backtracking: .................... false
    //   location.ranges: ................. true
    //   location line+column tracking: ... true
    //
    //
    // Forwarded Parser Analysis flags:
    //
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses lexer values: ............... true / true
    //   location tracking: ............... false
    //   location assignment: ............. false
    //
    //
    // Lexer Analysis flags:
    //
    //   uses yyleng: ..................... ???
    //   uses yylineno: ................... ???
    //   uses yytext: ..................... ???
    //   uses yylloc: ..................... ???
    //   uses ParseError API: ............. ???
    //   uses yyerror: .................... ???
    //   uses location tracking & editing:  ???
    //   uses more() API: ................. ???
    //   uses unput() API: ................ ???
    //   uses reject() API: ............... ???
    //   uses less() API: ................. ???
    //   uses display APIs pastInput(), upcomingInput(), showPosition():
    //        ............................. ???
    //   uses describeYYLLOC() API: ....... ???
    //
    // --------- END OF REPORT -----------


        EOF: 1,

        ERROR: 2,

        // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

        // options: {},                             /// <-- injected by the code generator

        // yy: ...,                                 /// <-- injected by setInput()

        /// INTERNAL USE ONLY: internal rule set cache for the current lexer state
        __currentRuleSet__: null,

        /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup
        __error_infos: [],

        /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use
        __decompressed: false,

        /// INTERNAL USE ONLY
        done: false,

        /// INTERNAL USE ONLY
        _backtrack: false,

        /// INTERNAL USE ONLY
        _input: '',

        /// INTERNAL USE ONLY
        _more: false,

        /// INTERNAL USE ONLY
        _signaled_error_token: false,

        /// INTERNAL USE ONLY; 0: clear to do, 1: clear done for lex()/next(); -1: clear done for inut()/unput()/...
        _clear_state: 0,

        /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`
        conditionStack: [],

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!
        match: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
        matched: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
        matches: false,

        /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.
        yytext: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far. (**WARNING:** this value MAY be negative if you `unput()` more text than you have already lexed. This type of behaviour is generally observed for one kind of 'lexer/parser hack' where custom token-illiciting characters are pushed in front of the input stream to help simulate multiple-START-points in the parser. When this happens, `base_position` will be adjusted to help track the original input's starting point in the `_input` buffer.)
        offset: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: index to the original starting point of the input; always ZERO(0) unless `unput()` has pushed content before the input: see the `offset` **WARNING** just above.
        base_position: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)
        yyleng: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
        yylineno: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction
        yylloc: null,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: regex used to split lines while tracking the lexer cursor position.
        CRLF_Re: /\r\n?|\n/,

        /**
             * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
             *
             * @public
             * @this {RegExpLexer}
             */
        constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
          msg = '' + msg;

          // heuristic to determine if the error message already contains a (partial) source code dump
          // as produced by either `showPosition()` or `prettyPrintRange()`:
          if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
          }

          if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
              const pretty_src = this.prettyPrintRange(this.yylloc);

              if (!/\n\s*$/.test(msg)) {
                msg += '\n';
              }

              msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
            } else if (typeof this.showPosition === 'function') {
              const pos_str = this.showPosition();

              if (pos_str) {
                if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
                  msg += '\n' + pos_str;
                } else {
                  msg += pos_str;
                }
              }
            }
          }

          /** @constructor */
          const pei = {
            errStr: msg,
            recoverable: !!recoverable,

            // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...
            text: this.match,

            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
                         * and make sure the error info doesn't stay due to potential
                         * ref cycle via userland code manipulations.
                         * These would otherwise all be memory leak opportunities!
                         *
                         * Note that only array and object references are nuked as those
                         * constitute the set of elements which can produce a cyclic ref.
                         * The rest of the members is kept intact as they are harmless.
                         *
                         * @public
                         * @this {LexErrorInfo}
                         */
            destroy: function destructLexErrorInfo() {
              // remove cyclic references added to error info:
              // info.yy = null;
              // info.lexer = null;
              // ...
              const rec = !!this.recoverable;

              for (let key in this) {
                if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                  this[key] = undefined;
                }
              }

              this.recoverable = rec;
            }
          };

          // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
          this.__error_infos.push(pei);

          return pei;
        },

        /**
             * handler which is invoked when a lexer error occurs.
             *
             * @public
             * @this {RegExpLexer}
             */
        parseError: function lexer_parseError(str, hash, ExceptionClass) {
          if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
          }

          if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
              return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
              return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            }
          }

          throw new ExceptionClass(str, hash);
        },

        /**
             * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
             *
             * @public
             * @this {RegExpLexer}
             */
        yyerror: function yyError(str /*, ...args */) {
          let lineno_msg = 'Lexical error';

          if (this.yylloc) {
            lineno_msg += ' on line ' + (this.yylineno + 1);
          }

          const p = this.constructLexErrorInfo(lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

          // Add any extra args to the hash under the name `extra_error_attributes`:
          let args = Array.prototype.slice.call(arguments, 1);

          if (args.length) {
            p.extra_error_attributes = args;
          }

          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        },

        /**
             * final cleanup function for when we have completed lexing the input;
             * make it an API so that external code can use this one once userland
             * code has decided it's time to destroy any lingering lexer error
             * hash object instances and the like: this function helps to clean
             * up these constructs, which *may* carry cyclic references which would
             * otherwise prevent the instances from being properly and timely
             * garbage-collected, i.e. this function helps prevent memory leaks!
             *
             * @public
             * @this {RegExpLexer}
             */
        cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
          // prevent lingering circular references from causing memory leaks:
          this.setInput('', {});

          // nuke the error hash info instances created during this run.
          // Userland code must COPY any data/references
          // in the error hash instance(s) it is more permanently interested in.
          if (!do_not_nuke_errorinfos) {
            for (let i = this.__error_infos.length - 1; i >= 0; i--) {
              let el = this.__error_infos[i];

              if (el && typeof el.destroy === 'function') {
                el.destroy();
              }
            }

            this.__error_infos.length = 0;
          }

          return this;
        },

        /**
             * clear the lexer token context; intended for internal use only
             *
             * @public
             * @this {RegExpLexer}
             */
        clear: function lexer_clear() {
          this.yytext = '';
          this.yyleng = 0;
          this.match = '';

          // - DO NOT reset `this.matched`
          this.matches = false;

          this._more = false;
          this._backtrack = false;
          const col = this.yylloc.last_column;

          this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,
            range: [this.offset, this.offset]
          };
        },

        /**
             * resets the lexer, sets new input
             *
             * @public
             * @this {RegExpLexer}
             */
        setInput: function lexer_setInput(input, yy) {
          this.yy = yy || this.yy || {};

          // also check if we've fully initialized the lexer instance,
          // including expansion work to be done to go from a loaded
          // lexer to a usable lexer:
          if (!this.__decompressed) {
            // step 1: decompress the regex list:
            let rules = this.rules;

            for (var i = 0, len = rules.length; i < len; i++) {
              var rule_re = rules[i];

              // compression: is the RE an xref to another RE slot in the rules[] table?
              if (typeof rule_re === 'number') {
                rules[i] = rules[rule_re];
              }
            }

            // step 2: unfold the conditions[] set to make these ready for use:
            let conditions = this.conditions;

            for (let k in conditions) {
              let spec = conditions[k];
              let rule_ids = spec.rules;
              var len = rule_ids.length;
              let rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
              let rule_new_ids = new Array(len + 1);

              for (var i = 0; i < len; i++) {
                let idx = rule_ids[i];
                var rule_re = rules[idx];
                rule_regexes[i + 1] = rule_re;
                rule_new_ids[i + 1] = idx;
              }

              spec.rules = rule_new_ids;
              spec.__rule_regexes = rule_regexes;
              spec.__rule_count = len;
            }

            this.__decompressed = true;
          }

          if (input && typeof input !== 'string') {
            input = '' + input;
          }

          this._input = input || '';
          this._clear_state = -1;
          this._signaled_error_token = false;
          this.done = false;
          this.yylineno = 0;
          this.matched = '';
          this.conditionStack = ['INITIAL'];
          this.__currentRuleSet__ = null;

          this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          this.offset = 0;
          this.base_position = 0;

          // apply these bits of `this.clear()` as well:
          this.yytext = '';

          this.yyleng = 0;
          this.match = '';
          this.matches = false;
          this._more = false;
          this._backtrack = false;
          return this;
        },

        /**
             * edit the remaining input via user-specified callback.
             * This can be used to forward-adjust the input-to-parse,
             * e.g. inserting macro expansions and alike in the
             * input which has yet to be lexed.
             * The behaviour of this API contrasts the `unput()` et al
             * APIs as those act on the *consumed* input, while this
             * one allows one to manipulate the future, without impacting
             * the current `yyloc` cursor location or any history.
             *
             * Use this API to help implement C-preprocessor-like
             * `#include` statements, etc.
             *
             * The provided callback must be synchronous and is
             * expected to return the edited input (string).
             *
             * The `cpsArg` argument value is passed to the callback
             * as-is.
             *
             * `callback` interface:
             * `function callback(input, cpsArg)`
             *
             * - `input` will carry the remaining-input-to-lex string
             *   from the lexer.
             * - `cpsArg` is `cpsArg` passed into this API.
             *
             * The `this` reference for the callback will be set to
             * reference this lexer instance so that userland code
             * in the callback can easily and quickly access any lexer
             * API.
             *
             * When the callback returns a non-string-type falsey value,
             * we assume the callback did not edit the input and we
             * will using the input as-is.
             *
             * When the callback returns a non-string-type value, it
             * is converted to a string for lexing via the `"" + retval`
             * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html
             * -- that way any returned object's `toValue()` and `toString()`
             * methods will be invoked in a proper/desirable order.)
             *
             * @public
             * @this {RegExpLexer}
             */
        editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
          const rv = callback.call(this, this._input, cpsArg);

          if (typeof rv !== 'string') {
            if (rv) {
              this._input = '' + rv;
            }
            // else: keep `this._input` as is.
          } else {
            this._input = rv;
          }

          return this;
        },

        /**
             * consumes and returns one char from the input
             *
             * @public
             * @this {RegExpLexer}
             */
        input: function lexer_input() {
          if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
          }

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          let ch = this._input[0];
          this.yytext += ch;
          this.yyleng++;
          this.offset++;
          this.match += ch;
          this.matched += ch;

          // Count the linenumber up when we hit the LF (or a stand-alone CR).
          // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
          // and we advance immediately past the LF as well, returning both together as if
          // it was all a single 'character' only.
          let slice_len = 1;

          let lines = false;

          if (ch === '\n') {
            lines = true;
          } else if (ch === '\r') {
            lines = true;
            const ch2 = this._input[1];

            if (ch2 === '\n') {
              slice_len++;
              ch += ch2;
              this.yytext += ch2;
              this.yyleng++;
              this.offset++;
              this.match += ch2;
              this.matched += ch2;
              this.yylloc.range[1]++;
            }
          }

          if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
          } else {
            this.yylloc.last_column++;
          }

          this.yylloc.range[1]++;
          this._input = this._input.slice(slice_len);
          return ch;
        },

        /**
             * unshifts one char (or an entire string) into the input
             *
             * @public
             * @this {RegExpLexer}
             */
        unput: function lexer_unput(ch) {
          let len = ch.length;
          let lines = ch.split(this.CRLF_Re);

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          this._input = ch + this._input;
          this.yytext = this.yytext.substr(0, this.yytext.length - len);
          this.yyleng = this.yytext.length;
          this.offset -= len;

          // **WARNING:**
          // The `offset` value MAY be negative if you `unput()` more text than you have already lexed.
          // This type of behaviour is generally observed for one kind of 'lexer/parser hack'
          // where custom token-illiciting characters are pushed in front of the input stream to help
          // simulate multiple-START-points in the parser.
          // When this happens, `base_position` will be adjusted to help track the original input's
          // starting point in the `_input` buffer.
          if (-this.offset > this.base_position) {
            this.base_position = -this.offset;
          }

          this.match = this.match.substr(0, this.match.length - len);
          this.matched = this.matched.substr(0, this.matched.length - len);

          if (lines.length > 1) {
            this.yylineno -= lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the `pre_lines[]` array's
            // last index slot; we don't mind when other previously
            // matched lines end up in the array too.
            let pre = this.match;

            let pre_lines = pre.split(this.CRLF_Re);

            if (pre_lines.length === 1) {
              pre = this.matched;
              pre_lines = pre.split(this.CRLF_Re);
            }

            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
          } else {
            this.yylloc.last_column -= len;
          }

          this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
          this.done = false;
          return this;
        },

        /**
             * return the upcoming input *which has not been lexed yet*.
             * This can, for example, be used for custom look-ahead inspection code
             * in your lexer.
             *
             * The entire pending input string is returned.
             *
             * > ### NOTE ###
             * >
             * > When augmenting error reports and alike, you might want to
             * > look at the `upcomingInput()` API instead, which offers more
             * > features for limited input extraction and which includes the
             * > part of the input which has been lexed by the last token a.k.a.
             * > the *currently lexed* input.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        lookAhead: function lexer_lookAhead() {
          return this._input || '';
        },

        /**
             * cache matched text and append it on next action
             *
             * @public
             * @this {RegExpLexer}
             */
        more: function lexer_more() {
          this._more = true;
          return this;
        },

        /**
             * signal the lexer that this rule fails to match the input, so the
             * next matching rule (regex) should be tested instead.
             *
             * @public
             * @this {RegExpLexer}
             */
        reject: function lexer_reject() {
          if (this.options.backtrack_lexer) {
            this._backtrack = true;
          } else {
            // when the `parseError()` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // `.lex()` run.
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
              false
            );

            this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
          }

          return this;
        },

        /**
             * retain first n characters of the match
             *
             * @public
             * @this {RegExpLexer}
             */
        less: function lexer_less(n) {
          return this.unput(this.match.slice(n));
        },

        /**
             * return (part of the) already matched input, i.e. for error
             * messages.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of
             * input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that has already been lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * @public
             * @this {RegExpLexer}
             */
        pastInput: function lexer_pastInput(maxSize, maxLines) {
          let past = this.matched.substring(0, this.matched.length - this.match.length);

          if (maxSize < 0) {
            maxSize = Infinity;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = Infinity;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substr` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          past = past.substr(-maxSize * 2 - 2);

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = past.split(this.CRLF_Re);

          a = a.slice(-maxLines);
          past = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis prefix...
          if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
          }

          return past;
        },

        /**
             * return (part of the) upcoming input *including* the input
             * matched by the last token (see also the NOTE below).
             * This can be used to augment error messages, for example.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that is yet to be lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * > ### NOTE ###
             * >
             * > *"upcoming input"* is defined as the whole of the both
             * > the *currently lexed* input, together with any remaining input
             * > following that. *"currently lexed"* input is the input
             * > already recognized by the lexer but not yet returned with
             * > the lexer token. This happens when you are invoking this API
             * > from inside any lexer rule action code block.
             * >
             * > When you want access to the 'upcoming input' in that you want access
             * > to the input *which has not been lexed yet* for look-ahead
             * > inspection or likewise purposes, please consider using the
             * > `lookAhead()` API instead.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
          let next = this.match;
          let source = this._input || '';

          if (maxSize < 0) {
            maxSize = next.length + source.length;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = maxSize;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substring` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          if (next.length < maxSize * 2 + 2) {
            next += source.substring(0, maxSize * 2 + 2 - next.length);  // substring is faster on Chrome/V8
          }

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = next.split(this.CRLF_Re, maxLines + 1);     // stop splitting once we have reached just beyond the reuired number of lines.

          a = a.slice(0, maxLines);
          next = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis postfix...
          if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
          }

          return next;
        },

        /**
             * return a string which displays the character position where the
             * lexing error occurred, i.e. for error messages
             *
             * @public
             * @this {RegExpLexer}
             */
        showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
          const pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
          let c = new Array(pre.length + 1).join('-');
          return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
        },

        /**
             * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
             * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
             * it MAY be NULL) and you MUST have a valid location info object anyway:
             * then we take the given context of the `preceding` and `following` locations, IFF those are available,
             * and reconstruct the `actual` location info from those.
             * If this fails, the heuristic is to take the `current` location, IFF available.
             * If this fails as well, we assume the sought location is at/around the current lexer position
             * and then produce that one as a response. DO NOTE that these heuristic/derived location info
             * values MAY be inaccurate!
             *
             * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
             * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
             *
             * @public
             * @this {RegExpLexer}
             */
        deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
          let loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
              loc.range[0] = actual.range[0] | 0;
              loc.range[1] = actual.range[1] | 0;
            }
          }

          if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
              loc.first_line = preceding.last_line | 0;
              loc.first_column = preceding.last_column | 0;

              if (preceding.range) {
                loc.range[0] = actual.range[1] | 0;
              }
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
              loc.last_line = following.first_line | 0;
              loc.last_column = following.first_column | 0;

              if (following.range) {
                loc.range[1] = actual.range[0] | 0;
              }
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
              loc.first_line = current.first_line | 0;
              loc.first_column = current.first_column | 0;

              if (current.range) {
                loc.range[0] = current.range[0] | 0;
              }
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
              loc.last_line = current.last_line | 0;
              loc.last_column = current.last_column | 0;

              if (current.range) {
                loc.range[1] = current.range[1] | 0;
              }
            }
          }

          // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
          // or plan D heuristics to produce a 'sensible' last_line value:
          if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
              loc.first_line = this.yylloc.first_line;
              loc.last_line = this.yylloc.last_line;
              loc.first_column = this.yylloc.first_column;
              loc.last_column = this.yylloc.last_column;
              loc.range[0] = this.yylloc.range[0];
              loc.range[1] = this.yylloc.range[1];
            } else {
              loc.last_line = this.yylloc.last_line;
              loc.last_column = this.yylloc.last_column;
              loc.range[1] = this.yylloc.range[1];
            }
          }

          if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;
            loc.range[1] = loc.range[0];
          }

          if (loc.first_column < 0) {
            loc.first_column = 0;
          }

          if (loc.last_column < 0) {
            loc.last_column = loc.first_column > 0 ? loc.first_column : 80;
          }

          return loc;
        },

        /**
             * return a string which displays the lines & columns of input which are referenced
             * by the given location info range, plus a few lines of context.
             *
             * This function pretty-prints the indicated section of the input, with line numbers
             * and everything!
             *
             * This function is very useful to provide highly readable error reports, while
             * the location range may be specified in various flexible ways:
             *
             * - `loc` is the location info object which references the area which should be
             *   displayed and 'marked up': these lines & columns of text are marked up by `^`
             *   characters below each character in the entire input range.
             *
             * - `context_loc` is the *optional* location info object which instructs this
             *   pretty-printer how much *leading* context should be displayed alongside
             *   the area referenced by `loc`. This can help provide context for the displayed
             *   error, etc.
             *
             *   When this location info is not provided, a default context of 3 lines is
             *   used.
             *
             * - `context_loc2` is another *optional* location info object, which serves
             *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
             *   context lines to display in the pretty-print output.
             *
             *   When this location info is not provided, a default context of 1 line only is
             *   used.
             *
             * Special Notes:
             *
             * - when the `loc`-indicated range is very large (about 5 lines or more), then
             *   only the first and last few lines of this block are printed while a
             *   `...continued...` message will be printed between them.
             *
             *   This serves the purpose of not printing a huge amount of text when the `loc`
             *   range happens to be huge: this way a manageable & readable output results
             *   for arbitrary large ranges.
             *
             * - this function can display lines of input which whave not yet been lexed.
             *   `prettyPrintRange()` can access the entire input!
             *
             * @public
             * @this {RegExpLexer}
             */
        prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
          loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
          const CONTEXT = 3;
          const CONTEXT_TAIL = 1;
          const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
          let input = this.matched + (this._input || '');
          let lines = input.split('\n');
          let l0 = Math.max(1, context_loc ? context_loc.first_line : loc.first_line - CONTEXT);
          let l1 = Math.max(1, context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL);
          let lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
          let ws_prefix = new Array(lineno_display_width).join(' ');
          let nonempty_line_indexes = [[], [], []];

          let rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            let lno = index + l0;
            let lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            let rv = lno_pfx + ': ' + line;
            let errpfx = new Array(lineno_display_width + 1).join('^');
            let offset = 2 + 1;
            let len = 0;

            if (lno === loc.first_line) {
              offset += loc.first_column;

              len = Math.max(
                2,
                (lno === loc.last_line ? loc.last_column : line.length) - loc.first_column + 1
              );
            } else if (lno === loc.last_line) {
              len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
              len = Math.max(2, line.length + 1);
            }

            let nli;

            if (len) {
              let lead = new Array(offset).join('.');
              let mark = new Array(len).join('^');
              rv += '\n' + errpfx + lead + mark;
              nli = 1;
            } else if (lno < loc.first_line) {
              nli = 0;
            } else if (lno > loc.last_line) {
              nli = 2;
            }

            if (line.trim().length > 0) {
              nonempty_line_indexes[nli].push(index);
            }

            rv = rv.replace(/\t/g, ' ');
            return rv;
          });

          // now make sure we don't print an overly large amount of lead/error/tail area: limit it
          // to the top and bottom line count:
          for (let i = 0; i <= 2; i++) {
            let line_arr = nonempty_line_indexes[i];

            if (line_arr.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
              let clip_start = line_arr[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
              let clip_end = line_arr[line_arr.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
              let intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';

              if (i === 1) {
                intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
              }

              rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
            }
          }

          return rv.join('\n');
        },

        /**
             * helper function, used to produce a human readable description as a string, given
             * the input `yylloc` location object.
             *
             * Set `display_range_too` to TRUE to include the string character index position(s)
             * in the description if the `yylloc.range` is available.
             *
             * @public
             * @this {RegExpLexer}
             */
        describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
          let l1 = yylloc.first_line;
          let l2 = yylloc.last_line;
          let c1 = yylloc.first_column;
          let c2 = yylloc.last_column;
          let dl = l2 - l1;
          let dc = c2 - c1;
          let rv;

          if (dl === 0) {
            rv = 'line ' + l1 + ', ';

            if (dc <= 1) {
              rv += 'column ' + c1;
            } else {
              rv += 'columns ' + c1 + ' .. ' + c2;
            }
          } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
          }

          if (yylloc.range && display_range_too) {
            let r1 = yylloc.range[0];
            let r2 = yylloc.range[1] - 1;

            if (r2 <= r1) {
              rv += ' {String Offset: ' + r1 + '}';
            } else {
              rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
          }

          return rv;
        },

        /**
             * test the lexed token: return FALSE when not a match, otherwise return token.
             *
             * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
             * contains the actually matched text string.
             *
             * Also move the input cursor forward and update the match collectors:
             *
             * - `yytext`
             * - `yyleng`
             * - `match`
             * - `matches`
             * - `yylloc`
             * - `offset`
             *
             * @public
             * @this {RegExpLexer}
             */
        test_match: function lexer_test_match(match, indexed_rule) {
          let backup;

          if (this.options.backtrack_lexer) {
            // save context
            backup = {
              yylineno: this.yylineno,

              yylloc: {
                first_line: this.yylloc.first_line,
                last_line: this.yylloc.last_line,
                first_column: this.yylloc.first_column,
                last_column: this.yylloc.last_column,
                range: this.yylloc.range.slice()
              },

              yytext: this.yytext,
              match: this.match,
              matches: this.matches,
              matched: this.matched,
              yyleng: this.yyleng,
              offset: this.offset,
              _more: this._more,
              _input: this._input,

              //_signaled_error_token: this._signaled_error_token,
              yy: this.yy,

              conditionStack: this.conditionStack.slice(),
              done: this.done
            };
          }

          let match_str = match[0];
          let match_str_len = match_str.length;
          let lines = match_str.split(this.CRLF_Re);

          if (lines.length > 1) {
            this.yylineno += lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;
            this.yylloc.last_column = lines[lines.length - 1].length;
          } else {
            this.yylloc.last_column += match_str_len;
          }

          this.yytext += match_str;
          this.match += match_str;
          this.matched += match_str;
          this.matches = match;
          this.yyleng = this.yytext.length;
          this.yylloc.range[1] += match_str_len;

          // previous lex rules MAY have invoked the `more()` API rather than producing a token:
          // those rules will already have moved this `offset` forward matching their match lengths,
          // hence we must only add our own match length now:
          this.offset += match_str_len;

          this._more = false;
          this._backtrack = false;
          this._input = this._input.slice(match_str_len);

          // calling this method:
          //
          //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
          let token = this.performAction.call(
            this,
            this.yy,
            indexed_rule,
            this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
          );

          // otherwise, when the action codes are all simple return token statements:
          //token = this.simpleCaseActionClusters[indexed_rule];

          if (this.done && this._input) {
            this.done = false;
          }

          if (token) {
            return token;
          } else if (this._backtrack) {
            // recover context
            for (let k in backup) {
              this[k] = backup[k];
            }

            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
          } else if (this._signaled_error_token) {
            // produce one 'error' token as `.parseError()` in `reject()`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;

            this._signaled_error_token = false;
            return token;
          }

          return false;
        },

        /**
             * return next match in input
             *
             * @public
             * @this {RegExpLexer}
             */
        next: function lexer_next() {
          if (this.done) {
            this.clear();
            return this.EOF;
          }

          if (!this._input) {
            this.done = true;
          }

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          let spec = this.__currentRuleSet__;

          if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();

            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
              let lineno_msg = '';

              if (this.yylloc) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
              }

              const p = this.constructLexErrorInfo(
                'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
                false
              );

              // produce one 'error' token until this situation has been resolved, most probably by parse termination!
              return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
            }
          }

          {
            let rule_ids = spec.rules;
            let regexes = spec.__rule_regexes;
            let len = spec.__rule_count;
            let match;
            let index;

            // Note: the arrays are 1-based, while `len` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (let i = 1; i <= len; i++) {
              let tempMatch = this._input.match(regexes[i]);

              if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;

                if (this.options.backtrack_lexer) {
                  let token = this.test_match(tempMatch, rule_ids[i]);

                  if (token !== false) {
                    return token;
                  } else if (this._backtrack) {
                    match = undefined;
                    continue; // rule action called reject() implying a rule MISmatch.
                  } else {
                    // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                    return false;
                  }
                } else if (!this.options.flex) {
                  break;
                }
              }
            }

            if (match) {
              let token = this.test_match(match, rule_ids[index]);

              if (token !== false) {
                return token;
              }

              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          }

          if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
          }

          {
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': Unrecognized text.',
              this.options.lexerErrorsAreRecoverable
            );

            let pendingInput = this._input;
            let activeCondition = this.topState();
            let conditionStackDepth = this.conditionStack.length;
            let token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

            if (token === this.ERROR) {
              // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
              // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
              // has not consumed/modified any pending input or changed state in the error handler:
              if (!this.matches && // and make sure the input has been modified/consumed ...
              pendingInput === this._input && // ...or the lexer state has been modified significantly enough
              // to merit a non-consuming error handling action right now.
              activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
                this.input();
              }
            }

            return token;
          }
        },

        /**
             * return next match that has a token
             *
             * @public
             * @this {RegExpLexer}
             */
        lex: function lexer_lex() {
          let r;

          //this._clear_state = 0;

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
          if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
          }

          if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
          }

          if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
          }

          while (!r) {
            r = this.next();
          }

          if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
          }

          if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
          }

          if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return next match that has a token. Identical to the `lex()` API but does not invoke any of the
             * `pre_lex()` nor any of the `post_lex()` callbacks.
             *
             * @public
             * @this {RegExpLexer}
             */
        fastLex: function lexer_fastLex() {
          let r;

          //this._clear_state = 0;

          while (!r) {
            r = this.next();
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return info about the lexer state that can help a parser or other lexer API user to use the
             * most efficient means available. This API is provided to aid run-time performance for larger
             * systems which employ this lexer.
             *
             * @public
             * @this {RegExpLexer}
             */
        canIUse: function lexer_canIUse() {
          const rv = {
            fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
          };

          return rv;
        },

        /**
             * backwards compatible alias for `pushState()`;
             * the latter is symmetrical with `popState()` and we advise to use
             * those APIs in any modern lexer code, rather than `begin()`.
             *
             * @public
             * @this {RegExpLexer}
             */
        begin: function lexer_begin(condition) {
          return this.pushState(condition);
        },

        /**
             * activates a new lexer condition state (pushes the new lexer
             * condition state onto the condition stack)
             *
             * @public
             * @this {RegExpLexer}
             */
        pushState: function lexer_pushState(condition) {
          this.conditionStack.push(condition);
          this.__currentRuleSet__ = null;
          return this;
        },

        /**
             * pop the previously active lexer condition state off the condition
             * stack
             *
             * @public
             * @this {RegExpLexer}
             */
        popState: function lexer_popState() {
          const n = this.conditionStack.length - 1;

          if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
          }

          return this.conditionStack[0];
        },

        /**
             * return the currently active lexer condition state; when an index
             * argument is provided it produces the N-th previous condition state,
             * if available
             *
             * @public
             * @this {RegExpLexer}
             */
        topState: function lexer_topState(n) {
          n = this.conditionStack.length - 1 - Math.abs(n || 0);

          if (n >= 0) {
            return this.conditionStack[n];
          }

          return 'INITIAL';
        },

        /**
             * (internal) determine the lexer rule set which is active for the
             * currently active lexer condition state
             *
             * @public
             * @this {RegExpLexer}
             */
        _currentRules: function lexer__currentRules() {
          const n = this.conditionStack.length - 1;
          let state;

          if (n >= 0) {
            state = this.conditionStack[n];
          } else {
            state = 'INITIAL';
          }

          return this.conditions[state] || this.conditions.INITIAL;
        },

        /**
             * return the number of states currently on the stack
             *
             * @public
             * @this {RegExpLexer}
             */
        stateStackSize: function lexer_stateStackSize() {
          return this.conditionStack.length;
        },

        options: {
          xregexp: true,
          ranges: true,
          trackPosition: true,
          easy_keyword_rules: true
        },

        JisonLexerError: JisonLexerError,

        performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
          var yy_ = this;

          switch (yyrulenumber) {
          case 0:
            /*! Conditions:: INITIAL */
            /*! Rule::       \s+ */
            /* skip whitespace */
            break;
          case 3:
            /*! Conditions:: INITIAL */
            /*! Rule::       \[{ID}\] */
            yy_.yytext = this.matches[1];

            return 9;
          default:
            return this.simpleCaseActionClusters[yyrulenumber];
          }
        },

        simpleCaseActionClusters: {
          /*! Conditions:: INITIAL */
          /*! Rule::       {ID} */
          1: 10,

          /*! Conditions:: INITIAL */
          /*! Rule::       \$end\b */
          2: 10,

          /*! Conditions:: INITIAL */
          /*! Rule::       '{QUOTED_STRING_CONTENT}' */
          4: 10,

          /*! Conditions:: INITIAL */
          /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
          5: 10,

          /*! Conditions:: INITIAL */
          /*! Rule::       \. */
          6: 10,

          /*! Conditions:: INITIAL */
          /*! Rule::       \( */
          7: 4,

          /*! Conditions:: INITIAL */
          /*! Rule::       \) */
          8: 5,

          /*! Conditions:: INITIAL */
          /*! Rule::       \* */
          9: 6,

          /*! Conditions:: INITIAL */
          /*! Rule::       \? */
          10: 7,

          /*! Conditions:: INITIAL */
          /*! Rule::       \| */
          11: 3,

          /*! Conditions:: INITIAL */
          /*! Rule::       \+ */
          12: 8,

          /*! Conditions:: INITIAL */
          /*! Rule::       $ */
          13: 1
        },

        rules: [
          /*  0: */  /^(?:\s+)/,
          /*  1: */  new XRegExp__default['default']('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
          /*  2: */  /^(?:\$end\b)/,
          /*  3: */  new XRegExp__default['default']('^(?:\\[([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\])', ''),
          /*  4: */  /^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
          /*  5: */  /^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
          /*  6: */  /^(?:\.)/,
          /*  7: */  /^(?:\()/,
          /*  8: */  /^(?:\))/,
          /*  9: */  /^(?:\*)/,
          /* 10: */  /^(?:\?)/,
          /* 11: */  /^(?:\|)/,
          /* 12: */  /^(?:\+)/,
          /* 13: */  /^(?:$)/
        ],

        conditions: {
          'INITIAL': {
            rules: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],
            inclusive: true
          }
        }
      };

      return lexer;
    }();
    parser$1.lexer = lexer$1;




    function Parser$1() {
        this.yy = {};
    }
    Parser$1.prototype = parser$1;
    parser$1.Parser = Parser$1;

    function yyparse$1() {
        return parser$1.parse.apply(parser$1, arguments);
    }



    var parser$2 = {
        parser: parser$1,
        Parser: Parser$1,
        parse: yyparse$1,
        
    };

    // WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
    //
    // This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
    const ID_REGEX_BASE$2 = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';

    // produce a unique production symbol.
    // Use this to produce rule productions from transformed EBNF which are
    // guaranteed not to collide with previously generated / already existing
    // rules (~ symbols).
    function generateUniqueSymbol(id, postfix, opts) {
        let sym = id + postfix;
        if (opts.grammar[sym]) {
            let i = 2;              // the first occurrence won't have a number, this is already a collision, so start numbering at *2*.
            do {
                sym = id + postfix + i;
                i++;
            } while (opts.grammar[sym]);
        }
        return sym;
    }

    function generatePushAction(handle, offset) {
        const terms = handle.terms;
        let rv = [];

        for (var i = 0, len = terms.length; i < len; i++) {
            rv.push('$' + (i + offset));
        }
        rv = rv.join(', ');
        // and make sure we contain a term series unambiguously, i.e. anything more complex than
        // a single term inside an EBNF check is produced as an array so we can differentiate
        // between */+/? EBNF operator results and groups of tokens per individual match.
        if (len > 1) {
            rv = '[' + rv + ']';
        }
        return rv;
    }

    function transformExpression(e, opts, emit) {
        let type = e[0];
        let value = e[1];
        let name = false;
        let has_transformed = 0;
        let list, n;

        if (type === 'xalias') {
            type = e[1];
            value = e[2];
            name = e[3];
            if (type) {
                e = e.slice(1);
            } else {
                e = value;
                type = e[0];
                value = e[1];
            }
        }

        if (type === 'symbol') {
            n = e[1];
            emit(n + (name ? '[' + name + ']' : ''));
        } else if (type === '+') {
            if (!name) {
                name = generateUniqueSymbol(opts.production, '_repetition_plus', opts);
            }
            emit(name);

            has_transformed = 1;

            opts = optsForProduction(name, opts.grammar);
            list = transformExpressionList([ value ], opts);
            opts.grammar[name] = [
                [
                    list.fragment,
                    '$$ = [' + generatePushAction(list, 1) + '];'
                ],
                [
                    name + ' ' + list.fragment,
                    '$1.push(' + generatePushAction(list, 2) + ');\n$$ = $1;'
                ]
            ];
        } else if (type === '*') {
            if (!name) {
                name = generateUniqueSymbol(opts.production, '_repetition', opts);
            }
            emit(name);

            has_transformed = 1;

            opts = optsForProduction(name, opts.grammar);
            list = transformExpressionList([ value ], opts);
            opts.grammar[name] = [
                [
                    '',
                    '$$ = [];'
                ],
                [
                    name + ' ' + list.fragment,
                    '$1.push(' + generatePushAction(list, 2) + ');\n$$ = $1;'
                ]
            ];
        } else if (type === '?') {
            if (!name) {
                name = generateUniqueSymbol(opts.production, '_option', opts);
            }
            emit(name);

            has_transformed = 1;

            opts = optsForProduction(name, opts.grammar);
            list = transformExpressionList([ value ], opts);
            // you want to be able to check if 0 or 1 occurrences were recognized: since jison
            // by default *copies* the lexer token value, i.e. `$$ = $1` is the (optional) default action,
            // we will need to set the action up explicitly in case of the 0-count match:
            // `$$ = undefined`.
            //
            // Note that we MUST return an array as the
            // '1 occurrence' match CAN carry multiple terms, e.g. in constructs like
            // `(T T T)?`, which would otherwise be unrecognizable from the `T*` construct.
            opts.grammar[name] = [
                [
                    '',
                    '$$ = undefined;'
                ],
                [
                    list.fragment,
                    '$$ = ' + generatePushAction(list, 1) + ';'
                ]
            ];
        } else if (type === '()') {
            if (value.length === 1 && !name) {
                list = transformExpressionList(value[0], opts);
                if (list.first_transformed_term_index) {
                    has_transformed = list.first_transformed_term_index;
                }
                emit(list);
            } else {
                if (!name) {
                    name = generateUniqueSymbol(opts.production, '_group', opts);
                }
                emit(name);

                has_transformed = 1;

                opts = optsForProduction(name, opts.grammar);
                opts.grammar[name] = value.map(function (handle) {
                    let list = transformExpressionList(handle, opts);
                    return [
                        list.fragment,
                        '$$ = ' + generatePushAction(list, 1) + ';'
                    ];
                });
            }
        }

        return has_transformed;
    }

    function transformExpressionList(list, opts) {
        let first_transformed_term_index = false;
        let terms = list.reduce(function (tot, e) {
            let ci = tot.length;

            let has_transformed = transformExpression(e, opts, function (name) {
                if (name.terms) {
                    tot.push.apply(tot, name.terms);
                } else {
                    tot.push(name);
                }
            });

            if (has_transformed) {
                first_transformed_term_index = ci + has_transformed;
            }
            return tot;
        }, []);

        return {
            fragment: terms.join(' '),
            terms: terms,
            first_transformed_term_index: first_transformed_term_index              // 1-based index
        };
    }

    function optsForProduction(id, grammar) {
        return {
            production: id,
            grammar: grammar
        };
    }

    function transformProduction(id, production, grammar) {
        let transform_opts = optsForProduction(id, grammar);
        return production.map(function (handle) {
            let action = null;
            let opts = null;
            let i, len, n;

            if (typeof handle !== 'string') {
                action = handle[1];
                opts = handle[2];
                handle = handle[0];
            }
            let expressions = handle;
            if (typeof expressions === 'string') {
                expressions = parser$2.parse(handle);
            }

            let list = transformExpressionList(expressions, transform_opts);

            let ret = [ list.fragment ];
            if (action) {
                // make sure the action doesn't address any inner items.
                if (list.first_transformed_term_index) {
                    // seek out all names and aliases; strip out literal tokens first as those cannot serve as $names:
                    let alist = list.terms; // rhs.replace(/'[^']+'/g, '~').replace(/"[^"]+"/g, '~').split(' ');

                    let alias_re = new XRegExp__default['default'](`\\[${ID_REGEX_BASE$2}\\]`);
                    let term_re = new XRegExp__default['default'](`^${ID_REGEX_BASE$2}$`);
                    // and collect the PERMITTED aliases: the names of the terms and all the remaining aliases
                    let good_aliases = {};
                    let alias_cnt = {};
                    let donotalias = {};

                    // WARNING: this replicates the knowledge/code of jison.js::addName()
                    let addName = function addNameEBNF(s, i) {
                        let base = s.replace(/[0-9]+$/, '');
                        let dna = donotalias[base];

                        if (good_aliases[s]) {
                            alias_cnt[s]++;
                            if (!dna) {
                                good_aliases[s + alias_cnt[s]] = i + 1;
                                alias_cnt[s + alias_cnt[s]] = 1;
                            }
                        } else {
                            good_aliases[s] = i + 1;
                            alias_cnt[s] = 1;
                            if (!dna) {
                                good_aliases[s + alias_cnt[s]] = i + 1;
                                alias_cnt[s + alias_cnt[s]] = 1;
                            }
                        }
                    };

                    // WARNING: this replicates the knowledge/code of jison.js::markBasename()
                    let markBasename = function markBasenameEBNF(s) {
                        if (/[0-9]$/.test(s)) {
                            s = s.replace(/[0-9]+$/, '');
                            donotalias[s] = true;
                        }
                    };

                    // mark both regular and aliased names, e.g., `id[alias1]` and `id1`
                    //
                    // WARNING: this replicates the knowledge/code of jison.js::markBasename()+addName() usage
                    for (i = 0, len = alist.length; i < len; i++) {
                        var term = alist[i];
                        var alias = term.match(alias_re);
                        if (alias) {
                            markBasename(alias[0].substr(1, alias[0].length - 2));
                            term = term.replace(alias_re, '');
                        }
                        if (term.match(term_re)) {
                            markBasename(term);
                        }
                    }
                    // then check & register both regular and aliased names, e.g., `id[alias1]` and `id1`
                    for (i = 0, len = alist.length; i < len; i++) {
                        var term = alist[i];
                        var alias = term.match(alias_re);
                        if (alias) {
                            addName(alias[0].substr(1, alias[0].length - 2), i);
                            term = term.replace(alias_re, '');
                        }
                        if (term.match(term_re)) {
                            addName(term, i);
                        }
                    }

                    // now scan the action for all named and numeric semantic values ($nonterminal / $1 / @1, ##1, ...)
                    //
                    // Note that `#name` are straight **static** symbol translations, which are okay as they don't
                    // require access to the parse stack: `#n` references can be resolved completely
                    // at grammar compile time.
                    //
                    let nameref_re = new XRegExp__default['default'](`(?:[$@]|##)${ID_REGEX_BASE$2}`, 'g');
                    let named_spots = nameref_re.exec(action);
                    let numbered_spots = action.match(/(?:[$@]|##)[0-9]+\b/g);
                    let max_term_index = list.terms.length;

                    // loop through the XRegExp alias regex matches in `action`
                    while (named_spots) {
                        n = named_spots[0].replace(/^(?:[$@]|##)/, '');
                        if (!good_aliases[n]) {
                            throw new Error('The action block references the named alias "' + n + '" ' +
                                            'which is not available in production "' + handle + '"; ' +
                                            'it probably got removed by the EBNF rule rewrite process.\n' +
                                            'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                            'only the outer-most EBNF group alias will remain available at all times ' +
                                            'due to the EBNF-to-BNF rewrite process.');
                        }

                        if (alias_cnt[n] !== 1) {
                            throw new Error('The action block references the ambiguous named alias or term reference "' + n + '" ' +
                                            'which is mentioned ' + alias_cnt[n] + ' times in production "' + handle + '", implicit and explicit aliases included.\n' +
                                            'You should either provide unambiguous = uniquely named aliases for these terms or use numeric index references (e.g. `$3`) as a stop-gap in your action code.\n' +
                                            'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                            'only the outer-most EBNF group alias will remain available at all times ' +
                                            'due to the EBNF-to-BNF rewrite process.');
                        }
                        //assert(good_aliases[n] <= max_term_index, 'max term index');

                        named_spots = nameref_re.exec(action);
                    }
                    if (numbered_spots) {
                        for (i = 0, len = numbered_spots.length; i < len; i++) {
                            n = parseInt(numbered_spots[i].replace(/^(?:[$@]|##)/, ''));
                            if (n > max_term_index) {
                                /* @const */ let n_suffixes = [ 'st', 'nd', 'rd', 'th' ];
                                throw new Error('The action block references the ' + n + n_suffixes[Math.max(0, Math.min(3, n - 1))] + ' term, ' +
                                                'which is not available in production "' + handle + '"; ' +
                                                'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                                'only the outer-most EBNF group alias will remain available at all times ' +
                                                'due to the EBNF-to-BNF rewrite process.');
                            }
                        }
                    }
                }
                ret.push(action);
            }
            if (opts) {
                ret.push(opts);
            }

            if (ret.length === 1) {
                return ret[0];
            }
            return ret;

        });
    }

    let ref_list;
    let ref_names;

    // create a deep copy of the input, so we will keep the input constant.
    function deepClone(from, sub) {
        if (sub == null) {
            ref_list = [];
            ref_names = [];
            sub = 'root';
        }
        if (typeof from === 'function') return from;
        if (from == null || typeof from !== 'object') return from;
        if (from.constructor !== Object && from.constructor !== Array) {
            return from;
        }

        let idx = ref_list.indexOf(from);
        if (idx >= 0) {
            throw new Error('[Circular/Xref:' + ref_names[i] + ']');   // circular or cross reference
        }
        ref_list.push(from);
        ref_names.push(sub);

        if (from.constructor === Array) {
            var to = from.slice();
            for (var i = 0, len = to.length; i < len; i++) {
                to[i] = deepClone(from[i], sub + '[' + i + ']');
            }
        } else {
            sub += '.';

            var to = new from.constructor();
            for (let name in from) {
                to[name] = deepClone(from[name], sub + name);
            }
        }
        return to;
    }

    function transformGrammar(grammar) {
        grammar = deepClone(grammar);

        Object.keys(grammar).forEach(function transformGrammarForKey(id) {
            grammar[id] = transformProduction(id, grammar[id], grammar);
        });

        return grammar;
    }

    function transform(ebnf) {
        let rv = transformGrammar(ebnf);

        return rv;
    }

    // See also:
    // http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
    // but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
    // with userland code which might access the derived class in a 'classic' way.
    function JisonParserError$2(msg, hash) {
        Object.defineProperty(this, 'name', {
            enumerable: false,
            writable: false,
            value: 'JisonParserError'
        });

        if (msg == null) msg = '???';

        Object.defineProperty(this, 'message', {
            enumerable: false,
            writable: true,
            value: msg
        });

        this.hash = hash;

        let stacktrace;
        if (hash && hash.exception instanceof Error) {
            let ex2 = hash.exception;
            this.message = ex2.message || msg;
            stacktrace = ex2.stack;
        }
        if (!stacktrace) {
            if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
                Error.captureStackTrace(this, this.constructor);
            } else {
                stacktrace = (new Error(msg)).stack;
            }
        }
        if (stacktrace) {
            Object.defineProperty(this, 'stack', {
                enumerable: false,
                writable: false,
                value: stacktrace
            });
        }
    }

    if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonParserError$2.prototype, Error.prototype);
    } else {
        JisonParserError$2.prototype = Object.create(Error.prototype);
    }
    JisonParserError$2.prototype.constructor = JisonParserError$2;
    JisonParserError$2.prototype.name = 'JisonParserError';




            // helper: reconstruct the productions[] table
            function bp$2(s) {
                let rv = [];
                let p = s.pop;
                let r = s.rule;
                for (let i = 0, l = p.length; i < l; i++) {
                    rv.push([
                        p[i],
                        r[i]
                    ]);
                }
                return rv;
            }
        


            // helper: reconstruct the defaultActions[] table
            function bda$1(s) {
                let rv = {};
                let d = s.idx;
                let g = s.goto;
                for (let i = 0, l = d.length; i < l; i++) {
                    let j = d[i];
                    rv[j] = g[i];
                }
                return rv;
            }
        


            // helper: reconstruct the 'goto' table
            function bt$2(s) {
                let rv = [];
                let d = s.len;
                let y = s.symbol;
                let t = s.type;
                let a = s.state;
                let m = s.mode;
                let g = s.goto;
                for (let i = 0, l = d.length; i < l; i++) {
                    let n = d[i];
                    let q = {};
                    for (let j = 0; j < n; j++) {
                        let z = y.shift();
                        switch (t.shift()) {
                        case 2:
                            q[z] = [
                                m.shift(),
                                g.shift()
                            ];
                            break;

                        case 0:
                            q[z] = a.shift();
                            break;

                        default:
                            // type === 1: accept
                            q[z] = [
                                3
                            ];
                        }
                    }
                    rv.push(q);
                }
                return rv;
            }
        


            // helper: runlength encoding with increment step: code, length: step (default step = 0)
            // `this` references an array
            function s$2(c, l, a) {
                a = a || 0;
                for (let i = 0; i < l; i++) {
                    this.push(c);
                    c += a;
                }
            }

            // helper: duplicate sequence from *relative* offset and length.
            // `this` references an array
            function c$2(i, l) {
                i = this.length - i;
                for (l += i; i < l; i++) {
                    this.push(this[i]);
                }
            }

            // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
            function u$2(a) {
                let rv = [];
                for (let i = 0, l = a.length; i < l; i++) {
                    let e = a[i];
                    // Is this entry a helper function?
                    if (typeof e === 'function') {
                        i++;
                        e.apply(rv, a[i]);
                    } else {
                        rv.push(e);
                    }
                }
                return rv;
            }
        

    let parser$3 = {
        // Code Generator Information Report
        // ---------------------------------
        //
        // Options:
        //
        //   default action mode: ............. ["classic","merge"]
        //   test-compile action mode: ........ "parser:*,lexer:*"
        //   try..catch: ...................... true
        //   default resolve on conflict: ..... true
        //   on-demand look-ahead: ............ false
        //   error recovery token skip maximum: 3
        //   yyerror in parse actions is: ..... NOT recoverable,
        //   yyerror in lexer actions and other non-fatal lexer are:
        //   .................................. NOT recoverable,
        //   debug grammar/output: ............ false
        //   has partial LR conflict upgrade:   true
        //   rudimentary token-stack support:   false
        //   parser table compression mode: ... 2
        //   export debug tables: ............. false
        //   export *all* tables: ............. false
        //   module type: ..................... es
        //   parser engine type: .............. lalr
        //   output main() in the module: ..... true
        //   has user-specified main(): ....... false
        //   has user-specified require()/import modules for main():
        //   .................................. false
        //   number of expected conflicts: .... 0
        //
        //
        // Parser Analysis flags:
        //
        //   no significant actions (parser is a language matcher only):
        //   .................................. false
        //   uses yyleng: ..................... false
        //   uses yylineno: ................... false
        //   uses yytext: ..................... false
        //   uses yylloc: ..................... false
        //   uses ParseError API: ............. false
        //   uses YYERROR: .................... true
        //   uses YYRECOVERING: ............... false
        //   uses YYERROK: .................... false
        //   uses YYCLEARIN: .................. false
        //   tracks rule values: .............. true
        //   assigns rule values: ............. true
        //   uses location tracking: .......... true
        //   assigns location: ................ true
        //   uses yystack: .................... false
        //   uses yysstack: ................... false
        //   uses yysp: ....................... true
        //   uses yyrulelength: ............... false
        //   uses yyMergeLocationInfo API: .... true
        //   has error recovery: .............. true
        //   has error reporting: ............. true
        //
        // --------- END OF REPORT -----------

    trace: function no_op_trace() { },
    JisonParserError: JisonParserError$2,
    yy: {},
    options: {
      type: "lalr",
      hasPartialLrUpgradeOnConflict: true,
      errorRecoveryTokenDiscardCount: 3
    },
    symbols_: {
      "$accept": 0,
      "$end": 1,
      "%%": 14,
      "(": 7,
      ")": 8,
      "*": 9,
      "+": 11,
      ":": 5,
      ";": 4,
      "=": 3,
      "?": 10,
      "ACTION": 15,
      "ACTION_BODY": 43,
      "ALIAS": 40,
      "ARROW_ACTION": 38,
      "CODE": 46,
      "DEBUG": 19,
      "EBNF": 20,
      "EOF": 1,
      "EOF_ID": 41,
      "EPSILON": 39,
      "ID": 24,
      "IMPORT": 22,
      "INCLUDE": 44,
      "INIT_CODE": 23,
      "INTEGER": 37,
      "LEFT": 33,
      "LEX_BLOCK": 17,
      "NAME": 25,
      "NONASSOC": 35,
      "OPTIONS": 27,
      "OPTIONS_END": 28,
      "OPTION_STRING_VALUE": 29,
      "OPTION_VALUE": 30,
      "PARSER_TYPE": 32,
      "PARSE_PARAM": 31,
      "PATH": 45,
      "PREC": 42,
      "RIGHT": 34,
      "START": 16,
      "STRING": 26,
      "TOKEN": 18,
      "TOKEN_TYPE": 36,
      "UNKNOWN_DECL": 21,
      "action": 85,
      "action_body": 86,
      "action_comments_body": 87,
      "action_ne": 84,
      "associativity": 61,
      "declaration": 51,
      "declaration_list": 50,
      "error": 2,
      "expression": 79,
      "extra_parser_module_code": 88,
      "full_token_definitions": 63,
      "grammar": 69,
      "handle": 76,
      "handle_action": 75,
      "handle_list": 74,
      "handle_sublist": 77,
      "id": 83,
      "id_list": 68,
      "import_name": 53,
      "import_path": 54,
      "include_macro_code": 89,
      "init_code_name": 52,
      "module_code_chunk": 90,
      "one_full_token": 64,
      "operator": 60,
      "option": 57,
      "option_list": 56,
      "optional_action_header_block": 49,
      "optional_end_block": 48,
      "optional_module_code_chunk": 91,
      "optional_production_description": 73,
      "optional_token_type": 65,
      "options": 55,
      "parse_params": 58,
      "parser_type": 59,
      "prec": 81,
      "production": 71,
      "production_id": 72,
      "production_list": 70,
      "spec": 47,
      "suffix": 80,
      "suffixed_expression": 78,
      "symbol": 82,
      "token_description": 67,
      "token_list": 62,
      "token_value": 66,
      "{": 12,
      "|": 6,
      "}": 13
    },
    terminals_: {
      1: "EOF",
      2: "error",
      3: "=",
      4: ";",
      5: ":",
      6: "|",
      7: "(",
      8: ")",
      9: "*",
      10: "?",
      11: "+",
      12: "{",
      13: "}",
      14: "%%",
      15: "ACTION",
      16: "START",
      17: "LEX_BLOCK",
      18: "TOKEN",
      19: "DEBUG",
      20: "EBNF",
      21: "UNKNOWN_DECL",
      22: "IMPORT",
      23: "INIT_CODE",
      24: "ID",
      25: "NAME",
      26: "STRING",
      27: "OPTIONS",
      28: "OPTIONS_END",
      29: "OPTION_STRING_VALUE",
      30: "OPTION_VALUE",
      31: "PARSE_PARAM",
      32: "PARSER_TYPE",
      33: "LEFT",
      34: "RIGHT",
      35: "NONASSOC",
      36: "TOKEN_TYPE",
      37: "INTEGER",
      38: "ARROW_ACTION",
      39: "EPSILON",
      40: "ALIAS",
      41: "EOF_ID",
      42: "PREC",
      43: "ACTION_BODY",
      44: "INCLUDE",
      45: "PATH",
      46: "CODE"
    },
    TERROR: 2,
        EOF: 1,

        // internals: defined here so the object *structure* doesn't get modified by parse() et al,
        // thus helping JIT compilers like Chrome V8.
        originalQuoteName: null,
        originalParseError: null,
        cleanupAfterParse: null,
        constructParseErrorInfo: null,
        yyMergeLocationInfo: null,
        copy_yytext: null,
        copy_yylloc: null,

        __reentrant_call_depth: 0,      // INTERNAL USE ONLY
        __error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
        __error_recovery_infos: [],     // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

        // APIs which will be set up depending on user action code analysis:
        //yyRecovering: 0,
        //yyErrOk: 0,
        //yyClearIn: 0,

        // Helper APIs
        // -----------

        // Helper function which can be overridden by user code later on: put suitable quotes around
        // literal IDs in a description string.
        quoteName: function parser_quoteName(id_str) {
            return '"' + id_str + '"';
        },

        // Return the name of the given symbol (terminal or non-terminal) as a string, when available.
        //
        // Return NULL when the symbol is unknown to the parser.
        getSymbolName: function parser_getSymbolName(symbol) {
            if (this.terminals_[symbol]) {
                return this.terminals_[symbol];
            }

            // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
            //
            // An example of this may be where a rule's action code contains a call like this:
            //
            //      parser.getSymbolName(#$)
            //
            // to obtain a human-readable name of the current grammar rule.
            const s = this.symbols_;
            for (let key in s) {
                if (s[key] === symbol) {
                    return key;
                }
            }
            return null;
        },

        // Return a more-or-less human-readable description of the given symbol, when available,
        // or the symbol itself, serving as its own 'description' for lack of something better to serve up.
        //
        // Return NULL when the symbol is unknown to the parser.
        describeSymbol: function parser_describeSymbol(symbol) {
            if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
                return this.terminal_descriptions_[symbol];
            } else if (symbol === this.EOF) {
                return 'end of input';
            }

            let id = this.getSymbolName(symbol);
            if (id) {
                return this.quoteName(id);
            }
            return null;
        },

        // Produce a (more or less) human-readable list of expected tokens at the point of failure.
        //
        // The produced list may contain token or token set descriptions instead of the tokens
        // themselves to help turning this output into something that easier to read by humans
        // unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
        // expected terminals and nonterminals is produced.
        //
        // The returned list (array) will not contain any duplicate entries.
        collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
            const TERROR = this.TERROR;
            let tokenset = [];
            let check = {};

            // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
            // If so, use that one instead of the less palatable token set.
            if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
                return [
                    this.state_descriptions_[state]
                ];
            }
            for (let p in this.table[state]) {
                p = +p;
                if (p !== TERROR) {
                    let d = do_not_describe ? p : this.describeSymbol(p);
                    if (d && !check[d]) {
                        tokenset.push(d);
                        check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
                    }
                }
            }
            return tokenset;
        },
    productions_: bp$2({
      pop: u$2([
      s$2,
      [47, 3],
      48,
      48,
      s$2,
      [49, 3],
      s$2,
      [50, 3],
      s$2,
      [51, 20],
      s$2,
      [52, 3],
      53,
      53,
      54,
      54,
      s$2,
      [55, 3],
      56,
      56,
      s$2,
      [57, 6],
      58,
      58,
      59,
      59,
      60,
      60,
      s$2,
      [61, 3],
      62,
      62,
      63,
      63,
      s$2,
      [64, 3],
      65,
      s$2,
      [65, 4, 1],
      68,
      69,
      70,
      70,
      s$2,
      [71, 3],
      s$2,
      [72, 3],
      73,
      73,
      s$2,
      [74, 4],
      s$2,
      [75, 3],
      76,
      76,
      77,
      77,
      78,
      78,
      s$2,
      [79, 5],
      s$2,
      [80, 4],
      s$2,
      [81, 3],
      82,
      82,
      83,
      s$2,
      [84, 4],
      s$2,
      [85, 3],
      s$2,
      [86, 5],
      87,
      87,
      88,
      88,
      89,
      89,
      s$2,
      [90, 3],
      91,
      91
    ]),
      rule: u$2([
      5,
      5,
      3,
      0,
      2,
      0,
      s$2,
      [2, 3],
      c$2,
      [4, 3],
      1,
      1,
      c$2,
      [3, 3],
      s$2,
      [1, 6],
      s$2,
      [3, 5],
      s$2,
      [2, 3],
      c$2,
      [15, 9],
      c$2,
      [11, 4],
      c$2,
      [20, 7],
      s$2,
      [2, 4],
      s$2,
      [1, 3],
      2,
      1,
      2,
      2,
      c$2,
      [15, 3],
      0,
      c$2,
      [11, 7],
      c$2,
      [36, 4],
      s$2,
      [3, 3],
      1,
      0,
      3,
      c$2,
      [40, 4],
      c$2,
      [81, 4],
      c$2,
      [9, 3],
      c$2,
      [40, 4],
      3,
      3,
      c$2,
      [35, 5],
      c$2,
      [41, 5],
      c$2,
      [32, 3],
      s$2,
      [1, 3],
      0,
      0,
      1,
      5,
      4,
      4,
      c$2,
      [54, 3],
      c$2,
      [86, 4],
      c$2,
      [35, 3],
      0
    ])
    }),
    performAction: function parser__PerformAction(yyloc, yystate /* action[1] */, yysp, yyvstack, yylstack) {

              /* this == yyval */

              // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
              let yy = this.yy;
              let yyparser = yy.parser;
              let yylexer = yy.lexer;

              switch (yystate) {
    case 0:
        /*! Production::    $accept : spec $end */

        // default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yylstack[yysp - 1];
        // END of default action (generated by JISON mode classic/merge :: 1/2,VT,VA,-,-,LT,LA,-,-)
        break;

    case 1:
        /*! Production::    spec : declaration_list "%%" grammar optional_end_block EOF */

        // default action (generated by JISON mode classic/merge :: 5/5,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
        // END of default action (generated by JISON mode classic/merge :: 5/5,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 4];
        if (yyvstack[yysp - 1].trim() !== '') {
            yy.addDeclaration(this.$, { include: yyvstack[yysp - 1] });
        }
        return extend(this.$, yyvstack[yysp - 2]);

    case 2:
        /*! Production::    spec : declaration_list "%%" grammar error EOF */

        // default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 4];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
        // END of default action (generated by JISON mode classic/merge :: 5/5,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        illegal input in the parser grammar productions definition section.
    
        Maybe you did not correctly separate trailing code from the grammar rule set with a '%%' marker on an otherwise empty line?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 3:
        /*! Production::    spec : declaration_list error EOF */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Maybe you did not correctly separate the parse 'header section' (token definitions, options, lexer spec, etc.) from the grammar rule set with a '%%' on an otherwise empty line?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
        break;

    case 4:
        /*! Production::    optional_end_block : %epsilon */
    case 101:
        /*! Production::    suffix : %epsilon */
    case 118:
        /*! Production::    action_body : %epsilon */
    case 133:
        /*! Production::    optional_module_code_chunk : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '';
        break;

    case 5:
        /*! Production::    optional_end_block : "%%" extra_parser_module_code */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            The extra parser module code section (a.k.a. 'epilogue') does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
        }
        this.$ = yyvstack[yysp];
        }
        break;

    case 6:
        /*! Production::    optional_action_header_block : %epsilon */
    case 10:
        /*! Production::    declaration_list : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {};
        break;

    case 7:
        /*! Production::    optional_action_header_block : optional_action_header_block ACTION */
    case 8:
        /*! Production::    optional_action_header_block : optional_action_header_block include_macro_code */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        this.$ = yyvstack[yysp - 1];
        let rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            action header code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
        }
        yy.addDeclaration(this.$, { actionInclude: yyvstack[yysp] });
        }
        break;

    case 9:
        /*! Production::    declaration_list : declaration_list declaration */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1]; yy.addDeclaration(this.$, yyvstack[yysp]);
        break;

    case 11:
        /*! Production::    declaration_list : declaration_list error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        declaration list error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 12:
        /*! Production::    declaration : START id */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {start: yyvstack[yysp]};
        break;

    case 13:
        /*! Production::    declaration : LEX_BLOCK */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {lex: {text: yyvstack[yysp], position: yylstack[yysp]}};
        break;

    case 14:
        /*! Production::    declaration : operator */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {operator: yyvstack[yysp]};
        break;

    case 15:
        /*! Production::    declaration : TOKEN full_token_definitions */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {token_list: yyvstack[yysp]};
        break;

    case 16:
        /*! Production::    declaration : ACTION */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            action code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
        }
        this.$ = {include: yyvstack[yysp]};
        }
        break;

    case 17:
        /*! Production::    declaration : include_macro_code */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            action header code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
        }
        this.$ = {include: yyvstack[yysp]};
        }
        break;

    case 18:
        /*! Production::    declaration : parse_params */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {parseParams: yyvstack[yysp]};
        break;

    case 19:
        /*! Production::    declaration : parser_type */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {parserType: yyvstack[yysp]};
        break;

    case 20:
        /*! Production::    declaration : options */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {options: yyvstack[yysp]};
        break;

    case 21:
        /*! Production::    declaration : DEBUG */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {options: [['debug', true]]};
        break;

    case 22:
        /*! Production::    declaration : EBNF */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        ebnf = true; 
        this.$ = {options: [['ebnf', true]]};
        break;

    case 23:
        /*! Production::    declaration : UNKNOWN_DECL */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {unknownDecl: yyvstack[yysp]};
        break;

    case 24:
        /*! Production::    declaration : IMPORT import_name import_path */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {imports: {name: yyvstack[yysp - 1], path: yyvstack[yysp]}};
        break;

    case 25:
        /*! Production::    declaration : IMPORT import_name error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        You did not specify a legal file path for the '%import' initialization code statement, which must have the format:
    
            %import qualifier_name file_path
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 26:
        /*! Production::    declaration : IMPORT error import_path */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Each '%import'-ed initialization code section must be qualified by a name, e.g. 'required' before the import path itself:
    
            %import qualifier_name file_path
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
        break;

    case 27:
        /*! Production::    declaration : INIT_CODE init_code_name action_ne */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            %code "${$init_code_name}" initialization section action code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
        `);
        }
        this.$ = {
            initCode: {
                qualifier: yyvstack[yysp - 1],
                include: yyvstack[yysp]
            }
        };
        }
        break;

    case 28:
        /*! Production::    declaration : INIT_CODE error action_ne */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Each '%code' initialization code section must be qualified by a name, e.g. 'required' before the action code itself:
    
            %code qualifier_name {action code}
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2], yylstack[yysp])}
    `);
        break;

    case 29:
        /*! Production::    declaration : START error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %start token error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 30:
        /*! Production::    declaration : TOKEN error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %token definition list error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 31:
        /*! Production::    declaration : IMPORT error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %import name or source filename missing maybe?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 32:
        /*! Production::    init_code_name : ID */
    case 33:
        /*! Production::    init_code_name : NAME */
    case 34:
        /*! Production::    init_code_name : STRING */
    case 35:
        /*! Production::    import_name : ID */
    case 36:
        /*! Production::    import_name : STRING */
    case 37:
        /*! Production::    import_path : ID */
    case 38:
        /*! Production::    import_path : STRING */
    case 67:
        /*! Production::    optional_token_type : TOKEN_TYPE */
    case 68:
        /*! Production::    token_value : INTEGER */
    case 69:
        /*! Production::    token_description : STRING */
    case 81:
        /*! Production::    optional_production_description : STRING */
    case 96:
        /*! Production::    expression : ID */
    case 102:
        /*! Production::    suffix : "*" */
    case 103:
        /*! Production::    suffix : "?" */
    case 104:
        /*! Production::    suffix : "+" */
    case 108:
        /*! Production::    symbol : id */
    case 109:
        /*! Production::    symbol : STRING */
    case 110:
        /*! Production::    id : ID */
    case 113:
        /*! Production::    action_ne : ACTION */
    case 114:
        /*! Production::    action_ne : include_macro_code */
    case 119:
        /*! Production::    action_body : action_comments_body */
    case 123:
        /*! Production::    action_comments_body : ACTION_BODY */
    case 125:
        /*! Production::    extra_parser_module_code : optional_module_code_chunk */
    case 129:
        /*! Production::    module_code_chunk : CODE */
    case 132:
        /*! Production::    optional_module_code_chunk : module_code_chunk */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp];
        break;

    case 39:
        /*! Production::    options : OPTIONS option_list OPTIONS_END */
    case 111:
        /*! Production::    action_ne : "{" action_body "}" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1];
        break;

    case 40:
        /*! Production::    options : OPTIONS error OPTIONS_END */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %options ill defined / error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2], yylstack[yysp])}
    `);
        break;

    case 41:
        /*! Production::    options : OPTIONS error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %options don't seem terminated?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 42:
        /*! Production::    option_list : option_list option */
    case 59:
        /*! Production::    token_list : token_list symbol */
    case 70:
        /*! Production::    id_list : id_list id */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1]; this.$.push(yyvstack[yysp]);
        break;

    case 43:
        /*! Production::    option_list : option */
    case 60:
        /*! Production::    token_list : symbol */
    case 71:
        /*! Production::    id_list : id */
    case 84:
        /*! Production::    handle_list : handle_action */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp]];
        break;

    case 44:
        /*! Production::    option : NAME */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp], true];
        break;

    case 45:
        /*! Production::    option : NAME "=" OPTION_STRING_VALUE */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
        break;

    case 46:
        /*! Production::    option : NAME "=" OPTION_VALUE */
    case 47:
        /*! Production::    option : NAME "=" NAME */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 2], parseValue$1(yyvstack[yysp])];
        break;

    case 48:
        /*! Production::    option : NAME "=" error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        named %option value error for ${yyvstack[yysp - 2]}?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 49:
        /*! Production::    option : NAME error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        named %option value assignment error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 50:
        /*! Production::    parse_params : PARSE_PARAM token_list */
    case 52:
        /*! Production::    parser_type : PARSER_TYPE symbol */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp];
        break;

    case 51:
        /*! Production::    parse_params : PARSE_PARAM error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %parse-params declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 53:
        /*! Production::    parser_type : PARSER_TYPE error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %parser-type declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 54:
        /*! Production::    operator : associativity token_list */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 1]]; this.$.push.apply(this.$, yyvstack[yysp]);
        break;

    case 55:
        /*! Production::    operator : associativity error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        operator token list error in an associativity statement?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 56:
        /*! Production::    associativity : LEFT */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = 'left';
        break;

    case 57:
        /*! Production::    associativity : RIGHT */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = 'right';
        break;

    case 58:
        /*! Production::    associativity : NONASSOC */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = 'nonassoc';
        break;

    case 61:
        /*! Production::    full_token_definitions : optional_token_type id_list */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let rv = [];
        let lst = yyvstack[yysp];
        for (let i = 0, len = lst.length; i < len; i++) {
            let id = lst[i];
            let m = {id: id};
            if (yyvstack[yysp - 1]) {
                m.type = yyvstack[yysp - 1];
            }
            rv.push(m);
        }
        this.$ = rv;
        }
        break;

    case 62:
        /*! Production::    full_token_definitions : optional_token_type one_full_token */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let m = yyvstack[yysp];
        if (yyvstack[yysp - 1]) {
            m.type = yyvstack[yysp - 1];
        }
        this.$ = [m];
        }
        break;

    case 63:
        /*! Production::    one_full_token : id token_value token_description */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
            id: yyvstack[yysp - 2],
            value: yyvstack[yysp - 1],
            description: yyvstack[yysp]
        };
        break;

    case 64:
        /*! Production::    one_full_token : id token_description */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
            id: yyvstack[yysp - 1],
            description: yyvstack[yysp]
        };
        break;

    case 65:
        /*! Production::    one_full_token : id token_value */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
            id: yyvstack[yysp - 1],
            value: yyvstack[yysp]
        };
        break;

    case 66:
        /*! Production::    optional_token_type : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = false;
        break;

    case 72:
        /*! Production::    grammar : optional_action_header_block production_list */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1];
        this.$.grammar = yyvstack[yysp];
        break;

    case 73:
        /*! Production::    production_list : production_list production */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1];
        if (yyvstack[yysp][0] in this.$) {
            this.$[yyvstack[yysp][0]] = this.$[yyvstack[yysp][0]].concat(yyvstack[yysp][1]);
        } else {
            this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
        }
        break;

    case 74:
        /*! Production::    production_list : production */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {}; this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
        break;

    case 75:
        /*! Production::    production : production_id handle_list ";" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp - 2], yyvstack[yysp - 1]];
        break;

    case 76:
        /*! Production::    production : production_id error ";" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        rule production declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
        break;

    case 77:
        /*! Production::    production : production_id error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        rule production declaration error: did you terminate the rule production set with a semicolon?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 78:
        /*! Production::    production_id : id optional_production_description ":" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2];
        
        // TODO: carry rule description support into the parser generator...
        break;

    case 79:
        /*! Production::    production_id : id optional_production_description error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        rule id should be followed by a colon, but that one seems missing?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 80:
        /*! Production::    production_id : id optional_production_description ARROW_ACTION */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        Production for rule '${$id}' is missing: arrows introduce action code in Jison.
    
        Jison does not support rule production definition using arrows (->, =>, →) but expects
        colons (:) instead, so maybe you intended this:
    
            ${yyvstack[yysp - 2]} : ${yyvstack[yysp]}
    
        while the user-defined action code block MAY be an arrow function, e.g.
    
            rule: math_production -> Math.min($math_production, 42);
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 82:
        /*! Production::    optional_production_description : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = undefined;
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,-,-,LT,LA,-,-)
        break;

    case 83:
        /*! Production::    handle_list : handle_list "|" handle_action */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2];
        this.$.push(yyvstack[yysp]);
        break;

    case 85:
        /*! Production::    handle_list : handle_list "|" error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        rule alternative production declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 86:
        /*! Production::    handle_list : handle_list ":" error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        multiple alternative rule productions should be separated by a '|' pipe character, not a ':' colon!
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 87:
        /*! Production::    handle_action : handle prec action */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        this.$ = [(yyvstack[yysp - 2].length ? yyvstack[yysp - 2].join(' ') : '')];
        if (yyvstack[yysp]) {
            let rv = checkActionBlock$2(yyvstack[yysp].action, yylstack[yysp]);
            if (rv) {
                if (!yyvstack[yysp].isArrowAction) {
                    yyparser.yyError(rmCommonWS$3`
                    production rule action code block does not compile: ${rv}
    
                      Erroneous area:
                    ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
                `);
                } else {
                    let indentedSrc = rmCommonWS$3([yyvstack[yysp].action]).split('\n').join('\n    ');
        
                    yyparser.yyError(rmCommonWS$3`
                    production rule arrow action code block does not compile: ${rv}
    
                    Please be aware that the reported compile error MAY be referring
                    to the wrapper code which is added by JISON automatically when
                    processing arrow actions: the entire action code chunk 
                    (including wrapper) is:
    
                        ${indentedSrc}
    
                      Erroneous area:
                    ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
                `);
                }
            }
            this.$.push(yyvstack[yysp].action);
        }
        if (yyvstack[yysp - 1]) {
            if (yyvstack[yysp - 2].length === 0) {
                yyparser.yyError(rmCommonWS$3`
                You cannot specify a precedence override for an epsilon (a.k.a. empty) rule!
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp - 2], yylstack[yysp - 3], yylstack[yysp] /* @handle is very probably NULL! We need this one for some decent location info! */)}
            `);
            }
            this.$.push(yyvstack[yysp - 1]);
        }
        if (this.$.length === 1) {
            this.$ = this.$[0];
        }
        }
        break;

    case 88:
        /*! Production::    handle_action : EPSILON action */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        this.$ = [''];
        if (yyvstack[yysp]) {
            let rv = checkActionBlock$2(yyvstack[yysp].action, yylstack[yysp]);
            if (rv) {
                if (!yyvstack[yysp].isArrowAction) {
                    yyparser.yyError(rmCommonWS$3`
                    epsilon production rule action code block does not compile: ${rv}
    
                      Erroneous area:
                    ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
                `);
                } else {
                    let indentedSrc = rmCommonWS$3([yyvstack[yysp].action]).split('\n').join('\n    ');
        
                    yyparser.yyError(rmCommonWS$3`
                    epsilon production rule arrow action code block does not compile: ${rv}
    
                    Please be aware that the reported compile error MAY be referring
                    to the wrapper code which is added by JISON automatically when
                    processing arrow actions: the entire action code chunk 
                    (including wrapper) is:
    
                        ${indentedSrc}
    
                      Erroneous area:
                    ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
                `);
                }
            }
            this.$.push(yyvstack[yysp].action);
        }
        if (this.$.length === 1) {
            this.$ = this.$[0];
        }
        }
        break;

    case 89:
        /*! Production::    handle_action : EPSILON error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %epsilon rule action declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
        break;

    case 90:
        /*! Production::    handle : handle suffixed_expression */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1];
        this.$.push(yyvstack[yysp]);
        break;

    case 91:
        /*! Production::    handle : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [];
        break;

    case 92:
        /*! Production::    handle_sublist : handle_sublist "|" handle */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2];
        this.$.push(yyvstack[yysp].join(' '));
        break;

    case 93:
        /*! Production::    handle_sublist : handle */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = [yyvstack[yysp].join(' ')];
        break;

    case 94:
        /*! Production::    suffixed_expression : expression suffix ALIAS */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + "[" + yyvstack[yysp] + "]";
        break;

    case 95:
        /*! Production::    suffixed_expression : expression suffix */
    case 124:
        /*! Production::    action_comments_body : action_comments_body ACTION_BODY */
    case 130:
        /*! Production::    module_code_chunk : module_code_chunk CODE */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 97:
        /*! Production::    expression : EOF_ID */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '$end';
        break;

    case 98:
        /*! Production::    expression : STRING */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        // Re-encode the string *anyway* as it will
        // be made part of the rule rhs a.k.a. production (type: *string*) again and we want
        // to be able to handle all tokens, including *significant space*
        // encoded as literal tokens in a grammar such as this: `rule: A ' ' B`.
        this.$ = dquote$2(yyvstack[yysp]);
        break;

    case 99:
        /*! Production::    expression : "(" handle_sublist ")" */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = '(' + yyvstack[yysp - 1].join(' | ') + ')';
        break;

    case 100:
        /*! Production::    expression : "(" handle_sublist error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Seems you did not correctly bracket a grammar rule sublist in '( ... )' brackets.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 105:
        /*! Production::    prec : PREC symbol */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = { prec: yyvstack[yysp] };
        break;

    case 106:
        /*! Production::    prec : PREC error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        %prec precedence override declaration error?
    
          Erroneous precedence declaration:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
        break;

    case 107:
        /*! Production::    prec : %epsilon */
    case 117:
        /*! Production::    action : %epsilon */

        // default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
        // END of default action (generated by JISON mode classic/merge :: 0/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = null;
        break;

    case 112:
        /*! Production::    action_ne : "{" action_body error */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 2];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Seems you did not correctly bracket a parser rule action block in curly braces: '{ ... }'.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 115:
        /*! Production::    action : action_ne */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = {
            action: yyvstack[yysp],
            isArrowAction: false
        };
        break;

    case 116:
        /*! Production::    action : ARROW_ACTION */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let src = trimActionCode$2(yyvstack[yysp]);
        this.$ = {
            action: `
                this.$ = (
                    ${src}
                );
            `,
            isArrowAction: true
        };
        }
        break;

    case 120:
        /*! Production::    action_body : action_body "{" action_body "}" action_comments_body */

        // default action (generated by JISON mode classic/merge :: 5/5,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
        // END of default action (generated by JISON mode classic/merge :: 5/5,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 4] + yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 121:
        /*! Production::    action_body : action_body "{" action_body "}" */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 122:
        /*! Production::    action_body : action_body "{" action_body error */

        // default action (generated by JISON mode classic/merge :: 4/4,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 3];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
        // END of default action (generated by JISON mode classic/merge :: 4/4,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
        Seems you did not correctly match curly braces '{ ... }' in a parser rule action block.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
        break;

    case 126:
        /*! Production::    extra_parser_module_code : optional_module_code_chunk include_macro_code extra_parser_module_code */

        // default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
        // END of default action (generated by JISON mode classic/merge :: 3/3,VT,VA,VU,-,LT,LA,-,-)
        
        
        this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
        break;

    case 127:
        /*! Production::    include_macro_code : INCLUDE PATH */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-):
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,VU,-,LT,LA,-,-)
        
        
        {
        let fileContent = fs__default['default'].readFileSync(yyvstack[yysp], { encoding: 'utf-8' });
        let rv = checkActionBlock$2(fileContent);
        if (rv) {
            yyparser.yyError(rmCommonWS$3`
            included action code file "${$PATH}" does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
        `);
        }
        // And no, we don't support nested '%include':
        this.$ = '\n// Included by Jison: ' + yyvstack[yysp] + ':\n\n' + fileContent + '\n\n// End Of Include by Jison: ' + yyvstack[yysp] + '\n\n';
        }
        break;

    case 128:
        /*! Production::    include_macro_code : INCLUDE error */

        // default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp - 1];
        this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
        // END of default action (generated by JISON mode classic/merge :: 2/2,VT,VA,-,-,LT,LA,-,-)
        
        
        yyparser.yyError(rmCommonWS$3`
    %include MUST be followed by a valid file path.
    
      Erroneous path:
    ` + yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1]));
        break;

    case 131:
        /*! Production::    module_code_chunk : error */

        // default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-):
        this.$ = yyvstack[yysp];
        this._$ = yylstack[yysp];
        // END of default action (generated by JISON mode classic/merge :: 1/1,VT,VA,-,-,LT,LA,-,-)
        
        
        // TODO ...
        yyparser.yyError(rmCommonWS$3`
        module code declaration error?
    
          Erroneous area:
        ` + yylexer.prettyPrintRange(yylstack[yysp]));
        break;
                
    }
    },
    table: bt$2({
      len: u$2([
      20,
      1,
      25,
      5,
      19,
      18,
      3,
      18,
      18,
      5,
      s$2,
      [18, 8],
      4,
      5,
      6,
      2,
      s$2,
      [6, 4, -1],
      3,
      3,
      4,
      8,
      1,
      18,
      18,
      26,
      c$2,
      [18, 3],
      1,
      4,
      21,
      3,
      3,
      5,
      5,
      s$2,
      [3, 3],
      22,
      18,
      20,
      25,
      25,
      24,
      24,
      22,
      s$2,
      [18, 3],
      3,
      19,
      2,
      4,
      1,
      1,
      7,
      7,
      c$2,
      [40, 3],
      17,
      5,
      20,
      18,
      23,
      s$2,
      [18, 6],
      6,
      21,
      21,
      18,
      20,
      18,
      2,
      18,
      4,
      2,
      s$2,
      [1, 3],
      s$2,
      [3, 4],
      4,
      3,
      5,
      3,
      15,
      11,
      3,
      3,
      19,
      20,
      18,
      c$2,
      [104, 3],
      4,
      4,
      s$2,
      [2, 4],
      7,
      3,
      4,
      16,
      1,
      4,
      10,
      14,
      c$2,
      [122, 3],
      18,
      18,
      9,
      s$2,
      [3, 4],
      s$2,
      [14, 3],
      18,
      21,
      21,
      6,
      4,
      c$2,
      [51, 5],
      7,
      7,
      s$2,
      [15, 4],
      3,
      9,
      3,
      14,
      18,
      18,
      8,
      5,
      3,
      9,
      4
    ]),
      symbol: u$2([
      2,
      s$2,
      [14, 10, 1],
      27,
      s$2,
      [31, 5, 1],
      44,
      47,
      50,
      1,
      c$2,
      [21, 18],
      51,
      55,
      s$2,
      [58, 4, 1],
      89,
      15,
      24,
      44,
      49,
      69,
      c$2,
      [31, 19],
      c$2,
      [18, 19],
      24,
      83,
      c$2,
      [39, 38],
      36,
      63,
      65,
      c$2,
      [41, 37],
      c$2,
      [18, 108],
      24,
      26,
      53,
      2,
      24,
      25,
      26,
      52,
      c$2,
      [9, 3],
      62,
      82,
      83,
      2,
      45,
      c$2,
      [8, 7],
      24,
      26,
      c$2,
      [5, 3],
      25,
      56,
      57,
      c$2,
      [9, 3],
      c$2,
      [3, 6],
      c$2,
      [266, 3],
      48,
      c$2,
      [275, 3],
      70,
      71,
      72,
      83,
      89,
      c$2,
      [278, 38],
      4,
      5,
      6,
      12,
      s$2,
      [14, 11, 1],
      26,
      c$2,
      [24, 6],
      37,
      38,
      c$2,
      [152, 37],
      24,
      64,
      68,
      83,
      24,
      c$2,
      [119, 3],
      54,
      c$2,
      [27, 11],
      c$2,
      [67, 8],
      44,
      54,
      c$2,
      [147, 6],
      12,
      15,
      44,
      84,
      89,
      c$2,
      [5, 8],
      c$2,
      [3, 6],
      c$2,
      [46, 20],
      c$2,
      [201, 3],
      c$2,
      [113, 28],
      c$2,
      [40, 9],
      c$2,
      [177, 23],
      c$2,
      [176, 3],
      c$2,
      [25, 24],
      1,
      c$2,
      [26, 4],
      c$2,
      [25, 11],
      c$2,
      [73, 7],
      46,
      c$2,
      [24, 24],
      c$2,
      [158, 51],
      c$2,
      [18, 25],
      25,
      28,
      57,
      c$2,
      [21, 12],
      28,
      c$2,
      [22, 8],
      2,
      3,
      25,
      28,
      s$2,
      [1, 3],
      2,
      44,
      46,
      88,
      90,
      91,
      c$2,
      [425, 3],
      24,
      c$2,
      [433, 3],
      c$2,
      [440, 3],
      c$2,
      [3, 3],
      c$2,
      [13, 4],
      c$2,
      [153, 4],
      7,
      12,
      15,
      24,
      26,
      38,
      39,
      41,
      42,
      44,
      74,
      75,
      76,
      2,
      5,
      26,
      38,
      73,
      c$2,
      [152, 12],
      c$2,
      [95, 7],
      c$2,
      [308, 38],
      37,
      44,
      66,
      67,
      c$2,
      [686, 109],
      12,
      13,
      43,
      86,
      87,
      c$2,
      [350, 14],
      c$2,
      [446, 11],
      c$2,
      [84, 46],
      c$2,
      [505, 10],
      c$2,
      [349, 19],
      c$2,
      [58, 19],
      25,
      29,
      30,
      c$2,
      [347, 5],
      1,
      44,
      89,
      1,
      c$2,
      [484, 3],
      c$2,
      [3, 6],
      c$2,
      [340, 3],
      c$2,
      [121, 3],
      c$2,
      [497, 3],
      c$2,
      [8, 5],
      c$2,
      [350, 9],
      c$2,
      [349, 3],
      78,
      79,
      81,
      c$2,
      [569, 5],
      15,
      38,
      44,
      84,
      85,
      89,
      2,
      5,
      38,
      c$2,
      [3, 4],
      c$2,
      [361, 18],
      c$2,
      [19, 11],
      c$2,
      [144, 8],
      c$2,
      [339, 30],
      c$2,
      [182, 26],
      c$2,
      [286, 3],
      c$2,
      [289, 4],
      c$2,
      [4, 4],
      25,
      28,
      25,
      28,
      c$2,
      [4, 4],
      c$2,
      [520, 8],
      c$2,
      [170, 6],
      c$2,
      [510, 14],
      c$2,
      [509, 3],
      c$2,
      [191, 7],
      c$2,
      [164, 8],
      s$2,
      [4, 5, 1],
      c$2,
      [192, 8],
      c$2,
      [1027, 6],
      s$2,
      [4, 9, 1],
      c$2,
      [22, 4],
      40,
      c$2,
      [23, 3],
      80,
      c$2,
      [19, 18],
      c$2,
      [18, 37],
      c$2,
      [16, 3],
      24,
      26,
      41,
      76,
      77,
      c$2,
      [294, 6],
      c$2,
      [3, 6],
      c$2,
      [144, 14],
      c$2,
      [14, 29],
      c$2,
      [496, 39],
      c$2,
      [21, 21],
      c$2,
      [565, 6],
      c$2,
      [6, 3],
      1,
      c$2,
      [125, 12],
      c$2,
      [248, 7],
      c$2,
      [7, 7],
      c$2,
      [252, 11],
      c$2,
      [193, 10],
      c$2,
      [15, 40],
      6,
      8,
      c$2,
      [223, 7],
      78,
      79,
      c$2,
      [388, 4],
      c$2,
      [327, 14],
      c$2,
      [285, 43],
      c$2,
      [164, 4],
      c$2,
      [169, 4],
      c$2,
      [78, 12],
      43
    ]),
      type: u$2([
      s$2,
      [2, 18],
      0,
      0,
      1,
      c$2,
      [21, 20],
      s$2,
      [0, 5],
      c$2,
      [10, 5],
      s$2,
      [2, 39],
      c$2,
      [40, 41],
      c$2,
      [41, 40],
      s$2,
      [2, 108],
      c$2,
      [148, 5],
      c$2,
      [239, 6],
      c$2,
      [159, 6],
      c$2,
      [253, 10],
      c$2,
      [176, 14],
      c$2,
      [36, 7],
      c$2,
      [197, 102],
      c$2,
      [103, 7],
      c$2,
      [108, 21],
      c$2,
      [21, 10],
      c$2,
      [423, 36],
      c$2,
      [373, 149],
      c$2,
      [158, 67],
      c$2,
      [57, 32],
      c$2,
      [322, 8],
      c$2,
      [98, 26],
      c$2,
      [356, 27],
      c$2,
      [722, 154],
      c$2,
      [463, 131],
      c$2,
      [130, 37],
      c$2,
      [376, 11],
      c$2,
      [819, 47],
      c$2,
      [225, 79],
      c$2,
      [126, 24],
      c$2,
      [989, 15],
      c$2,
      [38, 19],
      c$2,
      [57, 20],
      c$2,
      [157, 62],
      c$2,
      [445, 120],
      c$2,
      [120, 103],
      c$2,
      [103, 62],
      c$2,
      [909, 16],
      c$2,
      [78, 6]
    ]),
      state: u$2([
      1,
      2,
      5,
      14,
      12,
      13,
      8,
      20,
      11,
      29,
      28,
      31,
      34,
      36,
      38,
      42,
      47,
      49,
      50,
      54,
      49,
      50,
      56,
      50,
      58,
      60,
      62,
      65,
      68,
      69,
      70,
      67,
      72,
      71,
      73,
      74,
      78,
      79,
      82,
      83,
      82,
      84,
      50,
      84,
      50,
      86,
      92,
      94,
      93,
      97,
      69,
      70,
      98,
      100,
      101,
      103,
      105,
      106,
      107,
      110,
      111,
      117,
      124,
      126,
      123,
      133,
      131,
      82,
      138,
      143,
      94,
      93,
      144,
      101,
      133,
      147,
      82,
      148,
      50,
      150,
      155,
      154,
      156,
      111,
      124,
      126,
      163,
      164,
      124,
      126
    ]),
      mode: u$2([
      s$2,
      [2, 18],
      s$2,
      [1, 18],
      c$2,
      [21, 4],
      s$2,
      [2, 36],
      c$2,
      [42, 5],
      c$2,
      [38, 34],
      c$2,
      [77, 38],
      s$2,
      [2, 108],
      s$2,
      [1, 20],
      c$2,
      [30, 15],
      c$2,
      [134, 100],
      c$2,
      [106, 4],
      c$2,
      [335, 26],
      c$2,
      [151, 16],
      c$2,
      [376, 48],
      c$2,
      [347, 120],
      c$2,
      [63, 75],
      c$2,
      [13, 9],
      c$2,
      [23, 4],
      c$2,
      [4, 3],
      c$2,
      [587, 6],
      c$2,
      [427, 12],
      c$2,
      [10, 15],
      c$2,
      [62, 22],
      c$2,
      [390, 31],
      c$2,
      [45, 43],
      c$2,
      [510, 77],
      c$2,
      [763, 121],
      c$2,
      [129, 9],
      c$2,
      [757, 14],
      c$2,
      [368, 12],
      c$2,
      [367, 6],
      c$2,
      [368, 7],
      c$2,
      [650, 26],
      c$2,
      [210, 76],
      c$2,
      [1145, 20],
      c$2,
      [1084, 10],
      c$2,
      [490, 14],
      c$2,
      [22, 9],
      c$2,
      [152, 17],
      c$2,
      [223, 10],
      c$2,
      [806, 156],
      c$2,
      [332, 76],
      c$2,
      [231, 49],
      c$2,
      [491, 7],
      c$2,
      [470, 39],
      c$2,
      [122, 33],
      c$2,
      [1223, 8],
      1
    ]),
      goto: u$2([
      s$2,
      [10, 18],
      4,
      3,
      10,
      6,
      7,
      9,
      s$2,
      [15, 5, 1],
      24,
      22,
      23,
      25,
      26,
      27,
      21,
      s$2,
      [6, 3],
      30,
      s$2,
      [11, 18],
      s$2,
      [9, 18],
      32,
      33,
      s$2,
      [13, 18],
      s$2,
      [14, 18],
      35,
      66,
      37,
      s$2,
      [16, 18],
      s$2,
      [17, 18],
      s$2,
      [18, 18],
      s$2,
      [19, 18],
      s$2,
      [20, 18],
      s$2,
      [21, 18],
      s$2,
      [22, 18],
      s$2,
      [23, 18],
      39,
      40,
      41,
      s$2,
      [43, 4, 1],
      48,
      33,
      51,
      53,
      52,
      55,
      33,
      51,
      57,
      33,
      51,
      59,
      61,
      s$2,
      [56, 3],
      s$2,
      [57, 3],
      s$2,
      [58, 3],
      4,
      63,
      64,
      66,
      33,
      21,
      3,
      s$2,
      [12, 18],
      s$2,
      [29, 18],
      s$2,
      [110, 26],
      s$2,
      [15, 18],
      s$2,
      [30, 18],
      33,
      67,
      75,
      76,
      77,
      s$2,
      [31, 11],
      c$2,
      [13, 9],
      s$2,
      [35, 3],
      s$2,
      [36, 3],
      80,
      81,
      21,
      c$2,
      [3, 3],
      s$2,
      [32, 3],
      s$2,
      [33, 3],
      s$2,
      [34, 3],
      s$2,
      [54, 11],
      33,
      51,
      s$2,
      [54, 7],
      s$2,
      [55, 18],
      s$2,
      [60, 20],
      s$2,
      [108, 25],
      s$2,
      [109, 25],
      s$2,
      [127, 24],
      s$2,
      [128, 24],
      s$2,
      [50, 11],
      33,
      51,
      s$2,
      [50, 7],
      s$2,
      [51, 18],
      s$2,
      [52, 18],
      s$2,
      [53, 18],
      61,
      85,
      s$2,
      [41, 12],
      87,
      s$2,
      [41, 6],
      43,
      43,
      89,
      88,
      44,
      44,
      90,
      91,
      133,
      96,
      133,
      95,
      s$2,
      [72, 3],
      33,
      s$2,
      [7, 3],
      s$2,
      [8, 3],
      s$2,
      [74, 4],
      99,
      s$2,
      [91, 9],
      102,
      s$2,
      [91, 3],
      82,
      82,
      104,
      82,
      s$2,
      [61, 11],
      33,
      s$2,
      [61, 7],
      s$2,
      [62, 18],
      s$2,
      [71, 12],
      109,
      s$2,
      [71, 6],
      108,
      71,
      s$2,
      [24, 18],
      s$2,
      [25, 18],
      s$2,
      [37, 18],
      s$2,
      [38, 18],
      s$2,
      [26, 18],
      s$2,
      [27, 18],
      s$2,
      [118, 3],
      112,
      s$2,
      [113, 21],
      s$2,
      [114, 21],
      s$2,
      [28, 18],
      s$2,
      [59, 20],
      s$2,
      [39, 18],
      42,
      42,
      s$2,
      [40, 18],
      116,
      115,
      113,
      114,
      49,
      49,
      1,
      2,
      5,
      125,
      21,
      132,
      132,
      118,
      s$2,
      [129, 3],
      s$2,
      [131, 3],
      s$2,
      [73, 4],
      119,
      121,
      120,
      77,
      77,
      122,
      77,
      77,
      s$2,
      [84, 3],
      s$2,
      [107, 3],
      130,
      107,
      107,
      127,
      129,
      107,
      128,
      125,
      107,
      132,
      s$2,
      [117, 3],
      80,
      81,
      134,
      21,
      136,
      135,
      137,
      s$2,
      [81, 3],
      s$2,
      [70, 19],
      s$2,
      [65, 11],
      109,
      s$2,
      [65, 7],
      s$2,
      [64, 18],
      s$2,
      [68, 19],
      s$2,
      [69, 18],
      140,
      141,
      139,
      s$2,
      [119, 3],
      142,
      s$2,
      [123, 4],
      45,
      45,
      46,
      46,
      47,
      47,
      48,
      48,
      c$2,
      [497, 4],
      s$2,
      [130, 3],
      s$2,
      [75, 4],
      145,
      c$2,
      [490, 13],
      146,
      s$2,
      [76, 4],
      c$2,
      [155, 7],
      s$2,
      [90, 14],
      149,
      33,
      51,
      s$2,
      [101, 6],
      151,
      152,
      153,
      s$2,
      [101, 9],
      s$2,
      [96, 18],
      s$2,
      [97, 18],
      s$2,
      [98, 18],
      s$2,
      [91, 7],
      s$2,
      [88, 3],
      s$2,
      [89, 3],
      s$2,
      [115, 3],
      s$2,
      [116, 3],
      s$2,
      [78, 14],
      s$2,
      [79, 14],
      s$2,
      [80, 14],
      s$2,
      [63, 18],
      s$2,
      [111, 21],
      s$2,
      [112, 21],
      c$2,
      [542, 4],
      s$2,
      [124, 4],
      126,
      s$2,
      [83, 3],
      s$2,
      [85, 3],
      s$2,
      [86, 3],
      s$2,
      [87, 3],
      s$2,
      [105, 7],
      s$2,
      [106, 7],
      s$2,
      [95, 11],
      157,
      s$2,
      [95, 3],
      s$2,
      [102, 15],
      s$2,
      [103, 15],
      s$2,
      [104, 15],
      159,
      160,
      158,
      93,
      93,
      130,
      93,
      127,
      129,
      128,
      162,
      141,
      161,
      s$2,
      [94, 14],
      s$2,
      [99, 18],
      s$2,
      [100, 18],
      s$2,
      [91, 7],
      s$2,
      [121, 3],
      112,
      s$2,
      [122, 3],
      92,
      92,
      130,
      92,
      c$2,
      [74, 3],
      s$2,
      [120, 3],
      142
    ])
    }),
    defaultActions: bda$1({
      idx: u$2([
      0,
      3,
      5,
      7,
      8,
      s$2,
      [10, 8, 1],
      25,
      26,
      27,
      s$2,
      [30, 6, 1],
      37,
      40,
      41,
      44,
      45,
      46,
      s$2,
      [48, 6, 1],
      55,
      56,
      57,
      60,
      66,
      67,
      68,
      72,
      s$2,
      [74, 6, 1],
      s$2,
      [81, 7, 1],
      s$2,
      [89, 4, 1],
      95,
      96,
      97,
      100,
      104,
      105,
      107,
      108,
      109,
      s$2,
      [112, 5, 1],
      118,
      119,
      122,
      124,
      s$2,
      [127, 14, 1],
      s$2,
      [142, 8, 1],
      151,
      152,
      153,
      s$2,
      [157, 4, 1],
      162
    ]),
      goto: u$2([
      10,
      6,
      9,
      13,
      14,
      s$2,
      [16, 8, 1],
      56,
      57,
      58,
      3,
      12,
      29,
      110,
      15,
      30,
      67,
      35,
      36,
      32,
      33,
      34,
      55,
      60,
      108,
      109,
      127,
      128,
      51,
      52,
      53,
      43,
      7,
      8,
      74,
      62,
      24,
      25,
      37,
      38,
      26,
      27,
      113,
      114,
      28,
      59,
      39,
      42,
      40,
      49,
      1,
      2,
      5,
      129,
      131,
      73,
      84,
      81,
      70,
      64,
      68,
      69,
      123,
      s$2,
      [45, 4, 1],
      130,
      75,
      76,
      90,
      96,
      97,
      98,
      91,
      88,
      89,
      115,
      116,
      78,
      79,
      80,
      63,
      111,
      112,
      124,
      126,
      83,
      85,
      86,
      87,
      105,
      106,
      102,
      103,
      104,
      94,
      99,
      100,
      91,
      122
    ])
    }),
    parseError: function parseError(str, hash, ExceptionClass) {
        if (hash.recoverable) {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            hash.destroy();             // destroy... well, *almost*!
        } else {
            if (typeof this.trace === 'function') {
                this.trace(str);
            }
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            throw new ExceptionClass(str, hash);
        }
    },
    parse: function parse(input) {
        let self = this;
        let stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
        let sstack = new Array(128);        // state stack: stores states (column storage)

        let vstack = new Array(128);        // semantic value stack
        let lstack = new Array(128);        // location stack
        let table = this.table;
        let sp = 0;                         // 'stack pointer': index into the stacks
        let yyloc;

        let symbol = 0;
        let preErrorSymbol = 0;
        let lastEofErrorStateDepth = Infinity;
        let recoveringErrorInfo = null;
        let recovering = 0;                 // (only used when the grammar contains error recovery rules)
        const TERROR = this.TERROR;
        const EOF = this.EOF;
        const ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
        const NO_ACTION = [ 0, 165 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

        let lexer;
        if (this.__lexer__) {
            lexer = this.__lexer__;
        } else {
            lexer = this.__lexer__ = Object.create(this.lexer);
        }

        let sharedState_yy = {
            parseError: undefined,
            quoteName: undefined,
            lexer: undefined,
            parser: undefined,
            pre_parse: undefined,
            post_parse: undefined,
            pre_lex: undefined,
            post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly!
        };

        const ASSERT = (
            typeof assert !== 'function' ?
                function JisonAssert(cond, msg) {
                    if (!cond) {
                        throw new Error('assertion failed: ' + (msg || '***'));
                    }
                } :
                assert
        );

        this.yyGetSharedState = function yyGetSharedState() {
            return sharedState_yy;
        };


        this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
            return recoveringErrorInfo;
        };


        // shallow clone objects & arrays, straight copy of simple `src` values
        // e.g. `lexer.yytext` MAY be a complex value object,
        // rather than a simple string/value.
        //
        // https://jsperf.com/new-array-vs-splice-vs-slice/72
        // https://jsperf.com/instanceof-vs-typeof/20
        // benchmark:: http://127.0.0.1:8080/example/jsperf/#testfile=test0020-typeof-instanceof-isArray.json5
        // benchmark:: http://127.0.0.1:8080/example/jsperf/?333#testfile=test0021-shallow-clones.json5
        //
        function shallow_copy(src) {
            if (src && typeof src === 'object') {
                // non-Object-type objects, e.g. RegExp, Date, etc., can usually be shallow cloned
                // using their constructor:
                if (src.constructor !== Object) {
                    if (Array.isArray(src)) {
                        return src.slice();
                    }
                    let dst = new src.constructor(src);

                    // and make sure all custom attributes are added to the clone:
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
                // native objects must be cloned a different way:
                {
                    //return Object.assign({}, src);
                    let dst = {};
                    shallow_copy_noclobber(dst, src);
                    return dst;
                }
            }
            return src;
        }
        // add elements from `src` to `dst` when:
        // - either the element does not yet exist in `src`
        // - or exists in `src` but is NULL or UNDEFINED there, while its value is non-NULL in `dst`
        function shallow_copy_noclobber(dst, src) {
            const chk = Object.prototype.hasOwnProperty;
            for (let k in src) {
                if (!(k in dst)) {
                    if (chk.call(src, k)) {
                        dst[k] = src[k];
                    }
                } else if (src[k] != null && dst[k] == null && chk.call(src, k)) {
                    dst[k] = src[k];
                }
            }
        }
        function copy_yylloc_native(loc) {
            let rv = shallow_copy(loc);
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            if (rv) {
                rv.range = rv.range.slice();
            }
            return rv;
        }

        // copy state
        shallow_copy_noclobber(sharedState_yy, this.yy);

        sharedState_yy.lexer = lexer;
        sharedState_yy.parser = this;

        // allow userland code to override the yytext and yylloc copy/clone functions:
        this.copy_yytext = this.options.copy_yytext || sharedState_yy.copy_yytext || shallow_copy;
        this.copy_yylloc = this.options.copy_yylloc || sharedState_yy.copy_yylloc || copy_yylloc_native;





        // *Always* setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions as it is paramount
        // to have *their* closure match ours -- if we only set them up once,
        // any subsequent `parse()` runs will fail in very obscure ways when
        // these functions are invoked in the user action code block(s) as
        // their closure will still refer to the `parse()` instance which set
        // them up. Hence we MUST set them up at the start of every `parse()` run!
        if (this.yyError) {
            this.yyError = function yyError(str /*, ...args */) {








    let error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
                let expected = this.collect_expected_token_set(state);
                let hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
                // append to the old one?
                if (recoveringErrorInfo) {
                    let esp = recoveringErrorInfo.info_stack_pointer;

                    recoveringErrorInfo.symbol_stack[esp] = symbol;
                    let v = this.shallowCopyErrorInfo(hash);
                    v.yyError = true;
                    v.errorRuleDepth = error_rule_depth;
                    v.recovering = recovering;
                    // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                    recoveringErrorInfo.value_stack[esp] = v;
                    recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;
                } else {
                    recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                    recoveringErrorInfo.yyError = true;
                    recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                    recoveringErrorInfo.recovering = recovering;
                }


                // Add any extra args to the hash under the name `extra_error_attributes`:
                let args = Array.prototype.slice.call(arguments, 1);
                if (args.length) {
                    hash.extra_error_attributes = args;
                }

                return this.parseError(str, hash, this.JisonParserError);
            };
        }







        // Does the shared state override the default `parseError` that already comes with this instance?
        if (typeof sharedState_yy.parseError === 'function') {
            this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
                if (!ExceptionClass) {
                    ExceptionClass = this.JisonParserError;
                }
                return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
            };
        } else {
            this.parseError = this.originalParseError;
        }

        // Does the shared state override the default `quoteName` that already comes with this instance?
        if (typeof sharedState_yy.quoteName === 'function') {
            this.quoteName = function quoteNameAlt(id_str) {
                return sharedState_yy.quoteName.call(this, id_str);
            };
        } else {
            this.quoteName = this.originalQuoteName;
        }

        // set up the cleanup function; make it an API so that external code can re-use this one in case of
        // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
        // case this parse() API method doesn't come with a `finally { ... }` block any more!
        //
        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `sharedState`, etc. references will be *wrong*!
        this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
            let rv;

            if (invoke_post_methods) {
                let hash;

                if (sharedState_yy.post_parse || this.post_parse) {
                    // create an error hash info instance: we re-use this API in a **non-error situation**
                    // as this one delivers all parser internals ready for access by userland code.
                    hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
                }

                if (sharedState_yy.post_parse) {
                    rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }
                if (this.post_parse) {
                    rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                    if (typeof rv !== 'undefined') resultValue = rv;
                }

                // cleanup:
                if (hash && hash.destroy) {
                    hash.destroy();
                }
            }

            if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

            // clean up the lingering lexer structures as well:
            if (lexer.cleanupAfterLex) {
                lexer.cleanupAfterLex(do_not_nuke_errorinfos);
            }

            // prevent lingering circular references from causing memory leaks:
            if (sharedState_yy) {
                sharedState_yy.lexer = undefined;
                sharedState_yy.parser = undefined;
                if (lexer.yy === sharedState_yy) {
                    lexer.yy = undefined;
                }
            }
            sharedState_yy = undefined;
            this.parseError = this.originalParseError;
            this.quoteName = this.originalQuoteName;

            // nuke the vstack[] array at least as that one will still reference obsoleted user values.
            // To be safe, we nuke the other internal stack columns as well...
            stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
            sstack.length = 0;
            lstack.length = 0;
            vstack.length = 0;
            sp = 0;

            // nuke the error hash info instances created during this run.
            // Userland code must COPY any data/references
            // in the error hash instance(s) it is more permanently interested in.
            if (!do_not_nuke_errorinfos) {
                for (let i = this.__error_infos.length - 1; i >= 0; i--) {
                    let el = this.__error_infos[i];
                    if (el && typeof el.destroy === 'function') {
                        el.destroy();
                    }
                }
                this.__error_infos.length = 0;


                for (let i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                    let el = this.__error_recovery_infos[i];
                    if (el && typeof el.destroy === 'function') {
                        el.destroy();
                    }
                }
                this.__error_recovery_infos.length = 0;

                // `recoveringErrorInfo` is also part of the `__error_recovery_infos` array,
                // hence has been destroyed already: no need to do that *twice*.
                if (recoveringErrorInfo) {
                    recoveringErrorInfo = undefined;
                }


            }

            return resultValue;
        };

        // merge yylloc info into a new yylloc instance.
        //
        // `first_index` and `last_index` MAY be UNDEFINED/NULL or these are indexes into the `lstack[]` location stack array.
        //
        // `first_yylloc` and `last_yylloc` MAY be UNDEFINED/NULL or explicit (custom or regular) `yylloc` instances, in which
        // case these override the corresponding first/last indexes.
        //
        // `dont_look_back` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
        // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
        // yylloc info.
        //
        // Note: epsilon rule's yylloc situation is detected by passing both `first_index` and `first_yylloc` as UNDEFINED/NULL.
        this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
            let i1 = first_index | 0;
            let i2 = last_index | 0;
            let l1 = first_yylloc;
            let l2 = last_yylloc;
            let rv;

            // rules:
            // - first/last yylloc entries override first/last indexes

            if (!l1) {
                if (first_index != null) {
                    for (let i = i1; i <= i2; i++) {
                        l1 = lstack[i];
                        if (l1) {
                            break;
                        }
                    }
                }
            }

            if (!l2) {
                if (last_index != null) {
                    for (let i = i2; i >= i1; i--) {
                        l2 = lstack[i];
                        if (l2) {
                            break;
                        }
                    }
                }
            }

            // - detect if an epsilon rule is being processed and act accordingly:
            if (!l1 && first_index == null) {
                // epsilon rule span merger. With optional look-ahead in l2.
                if (!dont_look_back) {
                    for (let i = (i1 || sp) - 1; i >= 0; i--) {
                        l1 = lstack[i];
                        if (l1) {
                            break;
                        }
                    }
                }
                if (!l1) {
                    if (!l2) {
                        // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                        // without look-ahead and no preceding terms and/or `dont_look_back` set:
                        // in that case we ca do nothing but return NULL/UNDEFINED:
                        return null;
                    }
                    // shallow-copy L2: after all, we MAY be looking
                    // at unconventional yylloc info objects...
                    rv = this.copy_yylloc(l2);
                    return rv;
                }
                // shallow-copy L1, then adjust first col/row 1 column past the end.
                rv = this.copy_yylloc(l1);
                rv.first_line = rv.last_line;
                rv.first_column = rv.last_column;
                rv.range[0] = rv.range[1];

                if (l2) {
                    // shallow-mixin L2, then adjust last col/row accordingly.
                    shallow_copy_noclobber(rv, l2);
                    rv.last_line = l2.last_line;
                    rv.last_column = l2.last_column;
                    rv.range[1] = l2.range[1];
                }
                return rv;
            }

            if (!l1) {
                l1 = l2;
                l2 = null;
            }
            if (!l1) {
                return null;
            }

            // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
            // at unconventional yylloc info objects...
            rv = this.copy_yylloc(l1);

            if (l2) {
                shallow_copy_noclobber(rv, l2);
                rv.last_line = l2.last_line;
                rv.last_column = l2.last_column;
                rv.range[1] = l2.range[1];
            }

            return rv;
        };

        // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
        //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
        this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
            const pei = {
                errStr: msg,
                exception: ex,
                text: lexer.match,
                value: this.copy_yytext(lexer.yytext),
                token: this.describeSymbol(symbol) || symbol,
                token_id: symbol,
                line: lexer.yylineno,
                loc: this.copy_yylloc(lexer.yylloc),
                expected,
                recoverable,
                state,
                action,
                new_state: newState,
                symbol_stack: stack,
                state_stack: sstack,
                value_stack: vstack,
                location_stack: lstack,
                stack_pointer: sp,
                yy: sharedState_yy,
                lexer,
                parser: this,

                // and make sure the error info doesn't stay due to potential
                // ref cycle via userland code manipulations.
                // These would otherwise all be memory leak opportunities!
                //
                // Note that only array and object references are nuked as those
                // constitute the set of elements which can produce a cyclic ref.
                // The rest of the members is kept intact as they are harmless.
                destroy: function destructParseErrorInfo() {
                    // remove cyclic references added to error info:
                    // info.yy = null;
                    // info.lexer = null;
                    // info.value = null;
                    // info.value_stack = null;
                    // ...
                    const rec = !!this.recoverable;
                    for (let key in this) {
                        if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                            this[key] = undefined;
                        }
                    }
                    this.recoverable = rec;
                }
            };
            // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
            this.__error_infos.push(pei);
            return pei;
        };

        // clone some parts of the (possibly enhanced!) errorInfo object
        // to give them some persistence.
        this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
            let rv = shallow_copy(p);

            // remove the large parts which can only cause cyclic references
            // and are otherwise available from the parser kernel anyway.
            delete rv.sharedState_yy;
            delete rv.parser;
            delete rv.lexer;

            // lexer.yytext MAY be a complex value object, rather than a simple string/value:
            rv.value = this.copy_yytext(rv.value);

            // yylloc info:
            rv.loc = this.copy_yylloc(rv.loc);

            // the 'expected' set won't be modified, so no need to clone it:
            //rv.expected = rv.expected.slice();

            // symbol stack is a simple array:
            rv.symbol_stack = rv.symbol_stack.slice();
            // ditto for state stack:
            rv.state_stack = rv.state_stack.slice();
            // clone the yylloc's in the location stack?:
            rv.location_stack = rv.location_stack.map(this.copy_yylloc);
            // and the value stack may carry both simple and complex values:
            // shallow-copy the latter.
            rv.value_stack = rv.value_stack.map(this.copy_yytext);

            // and we don't bother with the sharedState_yy reference:
            //delete rv.yy;

            // now we prepare for tracking the COMBINE actions
            // in the error recovery code path:
            //
            // as we want to keep the maximum error info context, we
            // *scan* the state stack to find the first *empty* slot.
            // This position will surely be AT OR ABOVE the current
            // stack pointer, but we want to keep the 'used but discarded'
            // part of the parse stacks *intact* as those slots carry
            // error context that may be useful when you want to produce
            // very detailed error diagnostic reports.
            //
            // ### Purpose of each stack pointer:
            //
            // - stack_pointer: points at the top of the parse stack
            //                  **as it existed at the time of the error
            //                  occurrence, i.e. at the time the stack
            //                  snapshot was taken and copied into the
            //                  errorInfo object.**
            // - base_pointer:  the bottom of the **empty part** of the
            //                  stack, i.e. **the start of the rest of
            //                  the stack space /above/ the existing
            //                  parse stack. This section will be filled
            //                  by the error recovery process as it
            //                  travels the parse state machine to
            //                  arrive at the resolving error recovery rule.**
            // - info_stack_pointer:
            //                  this stack pointer points to the **top of
            //                  the error recovery tracking stack space**, i.e.
            //                  this stack pointer takes up the role of
            //                  the `stack_pointer` for the error recovery
            //                  process. Any mutations in the **parse stack**
            //                  are **copy-appended** to this part of the
            //                  stack space, keeping the bottom part of the
            //                  stack (the 'snapshot' part where the parse
            //                  state at the time of error occurrence was kept)
            //                  intact.
            // - root_failure_pointer:
            //                  copy of the `stack_pointer`...
            //
            {
                let i;
                for (i = rv.stack_pointer; rv.state_stack[i] != null; i++) {
                    // empty
                }
                rv.base_pointer = i;
                rv.info_stack_pointer = i;
            }

            rv.root_failure_pointer = rv.stack_pointer;

            // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
            this.__error_recovery_infos.push(rv);

            return rv;
        };

        function getNonTerminalFromCode(symbol) {
            let tokenName = self.getSymbolName(symbol);
            if (!tokenName) {
                tokenName = symbol;
            }
            return tokenName;
        }


        function stdLex() {
            let token = lexer.lex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        function fastLex() {
            let token = lexer.fastLex();
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }

            if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
                let tokenName = self.getSymbolName(token || EOF);
                if (!tokenName) {
                    tokenName = token;
                }

                Jison.lexDebugger.push({
                    tokenName,
                    tokenText: lexer.match,
                    tokenValue: lexer.yytext
                });
            }

            return token || EOF;
        }

        let lex = stdLex;


        let state, action, r, t;
        let yyval = {
            $: true,
            _$: undefined,
            yy: sharedState_yy
        };
        let p;
        let yyrulelen;
        let this_production;
        let newState;
        let retval = false;


        // Return the rule stack depth where the nearest error rule can be found.
        // Return -1 when no error recovery rule was found.
        function locateNearestErrorRecoveryRule(state) {
            let stack_probe = sp - 1;
            let depth = 0;

            // try to recover from error
            while (stack_probe >= 0) {
                // check for error recovery rule in this state








    const t = (table[state] && table[state][TERROR]) || NO_ACTION;
                if (t[0]) {
                    // We need to make sure we're not cycling forever:
                    // once we hit EOF, even when we `yyerrok()` an error, we must
                    // prevent the core from running forever,
                    // e.g. when parent rules are still expecting certain input to
                    // follow after this, for example when you handle an error inside a set
                    // of braces which are matched by a parent rule in your grammar.
                    //
                    // Hence we require that every error handling/recovery attempt
                    // *after we've hit EOF* has a diminishing state stack: this means
                    // we will ultimately have unwound the state stack entirely and thus
                    // terminate the parse in a controlled fashion even when we have
                    // very complex error/recovery code interplay in the core + user
                    // action code blocks:








    if (symbol === EOF) {
                        if (lastEofErrorStateDepth > sp - 1 - depth) {
                            lastEofErrorStateDepth = sp - 1 - depth;
                        } else {








    --stack_probe; // popStack(1): [symbol, action]
                            state = sstack[stack_probe];
                            ++depth;
                            continue;
                        }
                    }
                    return depth;
                }
                if (state === 0 /* $accept rule */ || stack_probe < 1) {








    return -1; // No suitable error recovery rule available.
                }
                --stack_probe; // popStack(1): [symbol, action]
                state = sstack[stack_probe];
                ++depth;
            }








    return -1; // No suitable error recovery rule available.
        }


        try {
            this.__reentrant_call_depth++;

            lexer.setInput(input, sharedState_yy);

            // NOTE: we *assume* no lexer pre/post handlers are set up *after*
            // this initial `setInput()` call: hence we can now check and decide
            // whether we'll go with the standard, slower, lex() API or the
            // `fast_lex()` one:
            if (typeof lexer.canIUse === 'function') {
                let lexerInfo = lexer.canIUse();
                if (lexerInfo.fastLex && typeof fastLex === 'function') {
                    lex = fastLex;
                }
            }

            yyloc = this.copy_yylloc(lexer.yylloc);
            lstack[sp] = yyloc;
            vstack[sp] = null;
            sstack[sp] = 0;
            stack[sp] = 0;
            ++sp;





            if (this.pre_parse) {
                this.pre_parse.call(this, sharedState_yy);
            }
            if (sharedState_yy.pre_parse) {
                sharedState_yy.pre_parse.call(this, sharedState_yy);
            }

            newState = sstack[sp - 1];
            for (;;) {
                // retrieve state number from top of stack
                state = newState;               // sstack[sp - 1];

                // use default actions if available
                if (this.defaultActions[state]) {
                    action = 2;
                    newState = this.defaultActions[state];
                } else {
                    // The single `==` condition below covers both these `===` comparisons in a single
                    // operation:
                    //
                    //     if (symbol === null || typeof symbol === 'undefined') ...
                    if (!symbol) {
                        symbol = lex();
                    }
                    // read action for current state and first input
                    t = (table[state] && table[state][symbol]) || NO_ACTION;
                    newState = t[1];
                    action = t[0];








    // handle parse error
                    if (!action) {
                        // first see if there's any chance at hitting an error recovery rule:
                        let error_rule_depth = locateNearestErrorRecoveryRule(state);
                        let errStr = null;
                        let errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                        let expected = this.collect_expected_token_set(state);

                        if (!recovering) {
                            // Report error
                            errStr = 'Parse error';
                            if (typeof lexer.yylineno === 'number') {
                                errStr += ' on line ' + (lexer.yylineno + 1);
                            }

                            if (typeof lexer.showPosition === 'function') {
                                errStr += ':\n' + lexer.showPosition(79 - 10, 10) + '\n';
                            } else {
                                errStr += ': ';
                            }
                            if (expected.length) {
                                errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                            } else {
                                errStr += 'Unexpected ' + errSymbolDescr;
                            }

                            p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                            // DO NOT cleanup the old one before we start the new error info track:
                            // the old one will *linger* on the error stack and stay alive until we
                            // invoke the parser's cleanup API!
                            recoveringErrorInfo = this.shallowCopyErrorInfo(p);








    r = this.parseError(p.errStr, p, this.JisonParserError);
                            if (typeof r !== 'undefined') {
                                retval = r;
                                break;
                            }

                            // Protect against overly blunt userland `parseError` code which *sets*
                            // the `recoverable` flag without properly checking first:
                            // we always terminate the parse when there's no recovery rule available anyhow!
                            if (!p.recoverable || error_rule_depth < 0) {
                                break;
                            } else {
                                // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                            }
                        }








    let esp = recoveringErrorInfo.info_stack_pointer;

                        // just recovered from another error
                        if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                            // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                            yyloc = this.copy_yylloc(lexer.yylloc);

                            // SHIFT current lookahead and grab another
                            recoveringErrorInfo.symbol_stack[esp] = symbol;

                            recoveringErrorInfo.location_stack[esp] = yyloc;
                            recoveringErrorInfo.state_stack[esp] = newState; // push state
                            ++esp;

                            preErrorSymbol = 0;
                            symbol = lex();








    }

                        // try to recover from error
                        if (error_rule_depth < 0) {
                            ASSERT(recovering > 0, 'Line 1048');
                            recoveringErrorInfo.info_stack_pointer = esp;

                            // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                            // while we are still busy recovering from another error:
                            let po = this.__error_infos[this.__error_infos.length - 1];

                            // Report error
                            if (typeof lexer.yylineno === 'number') {
                                errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                            } else {
                                errStr = 'Parsing halted while starting to recover from another error';
                            }

                            if (po) {
                                errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                            } else {
                                errStr += ': ';
                            }

                            if (typeof lexer.showPosition === 'function') {
                                errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                            }
                            if (expected.length) {
                                errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                            } else {
                                errStr += 'Unexpected ' + errSymbolDescr;
                            }

                            p = this.constructParseErrorInfo(errStr, null, expected, false);
                            if (po) {
                                p.extra_error_attributes = po;
                            }

                            r = this.parseError(p.errStr, p, this.JisonParserError);
                            if (typeof r !== 'undefined') {
                                retval = r;
                            }
                            break;
                        }

                        preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                        symbol = TERROR;            // insert generic error symbol as new lookahead

                        const EXTRA_STACK_SAMPLE_DEPTH = 3;

                        // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                        recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                        if (errStr) {
                            recoveringErrorInfo.value_stack[esp] = {
                                yytext: this.copy_yytext(lexer.yytext),
                                errorRuleDepth: error_rule_depth,
                                errStr,
                                errSymbolDescr,
                                expectedStr: expected,
                                stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                            };








    } else {
                            recoveringErrorInfo.value_stack[esp] = {
                                yytext: this.copy_yytext(lexer.yytext),
                                errorRuleDepth: error_rule_depth,
                                stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                            };
                        }
                        recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                        recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                        ++esp;
                        recoveringErrorInfo.info_stack_pointer = esp;

                        yyval.$ = recoveringErrorInfo;
                        yyval._$ = undefined;

                        yyrulelen = error_rule_depth;

                        let combineState = NO_ACTION[1];








    r = this.performAction.call(yyval, yyloc, combineState, sp - 1, vstack, lstack);

                        if (typeof r !== 'undefined') {
                            retval = r;
                            break;
                        }

                        // pop off stack
                        sp -= yyrulelen;

                        // and move the top entries + discarded part of the parse stacks onto the error info stack:
                        for (let idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                            recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                            recoveringErrorInfo.value_stack[esp] = vstack[idx];
                            recoveringErrorInfo.location_stack[esp] = lstack[idx];
                            recoveringErrorInfo.state_stack[esp] = sstack[idx];
                        }

                        recoveringErrorInfo.symbol_stack[esp] = TERROR;
                        recoveringErrorInfo.value_stack[esp] = this.copy_yytext(yyval.$);
                        recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(yyval._$);

                        // goto new state = table[STATE][NONTERMINAL]
                        newState = sstack[sp - 1];

                        if (this.defaultActions[newState]) {
                            recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                        } else {
                            t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                            recoveringErrorInfo.state_stack[esp] = t[1];
                        }

                        ++esp;
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // allow N (default: 3) real symbols to be shifted before reporting a new error
                        recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;










                        // Now duplicate the standard parse machine here, at least its initial
                        // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                        // as we wish to push something special then!
                        //
                        // Run the state machine in this copy of the parser state machine
                        // until we *either* consume the error symbol (and its related information)
                        // *or* we run into another error while recovering from this one
                        // *or* we execute a `reduce` action which outputs a final parse
                        // result (yes, that MAY happen!).
                        //
                        // We stay in this secondary parse loop until we have completed
                        // the *error recovery phase* as the main parse loop (further below)
                        // is optimized for regular parse operation and DOES NOT cope with
                        // error recovery *at all*.
                        //
                        // We call the secondary parse loop just below the "slow parse loop",
                        // while the main parse loop, which is an almost-duplicate of this one,
                        // yet optimized for regular parse operation, is called the "fast
                        // parse loop".
                        //
                        // Compare this to `bison` & (vanilla) `jison`, both of which have
                        // only a single parse loop, which handles everything. Our goal is
                        // to eke out every drop of performance in the main parse loop...

                        ASSERT(recoveringErrorInfo, 'Line 1204');
                        ASSERT(symbol === TERROR, 'Line 1205');
                        ASSERT(!action, 'Line 1206');
                        let errorSymbolFromParser = true;
                        for (;;) {
                            // retrieve state number from top of stack
                            state = newState;               // sstack[sp - 1];

                            // use default actions if available
                            if (this.defaultActions[state]) {
                                action = 2;
                                newState = this.defaultActions[state];
                            } else {
                                // The single `==` condition below covers both these `===` comparisons in a single
                                // operation:
                                //
                                //     if (symbol === null || typeof symbol === 'undefined') ...
                                if (!symbol) {
                                    symbol = lex();
                                    // **Warning: Edge Case**: the *lexer* may produce
                                    // TERROR tokens of its own volition: *those* TERROR
                                    // tokens should be treated like *regular tokens*
                                    // i.e. tokens which have a lexer-provided `yyvalue`
                                    // and `yylloc`:
                                    errorSymbolFromParser = false;
                                }
                                // read action for current state and first input
                                t = (table[state] && table[state][symbol]) || NO_ACTION;
                                newState = t[1];
                                action = t[0];








    // encountered another parse error? If so, break out to main loop
                                // and take it from there!
                                if (!action) {










                                    ASSERT(recoveringErrorInfo, 'Line 1248');

                                    // Prep state variables so that upon breaking out of
                                    // this "slow parse loop" and hitting the `continue;`
                                    // statement in the outer "fast parse loop" we redo
                                    // the exact same state table lookup as the one above
                                    // so that the outer=main loop will also correctly
                                    // detect the 'parse error' state (`!action`) we have
                                    // just encountered above.
                                    newState = state;
                                    break;
                                }
                            }








    switch (action) {
                            // catch misc. parse failures:
                            default:
                                // this shouldn't happen, unless resolve defaults are off
                                //
                                // SILENTLY SIGNAL that the outer "fast parse loop" should
                                // take care of this internal error condition:
                                // prevent useless code duplication now/here.
                                break;

                            // shift:
                            case 1:
                                stack[sp] = symbol;
                                // ### Note/Warning ###
                                //
                                // The *lexer* may also produce TERROR tokens on its own,
                                // so we specifically test for the TERROR we did set up
                                // in the error recovery logic further above!
                                if (symbol === TERROR && errorSymbolFromParser) {
                                    // Push a special value onto the stack when we're
                                    // shifting the `error` symbol that is related to the
                                    // error we're recovering from.
                                    ASSERT(recoveringErrorInfo, 'Line 1305');
                                    vstack[sp] = recoveringErrorInfo;
                                    lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                                } else {
                                    ASSERT(symbol !== 0, 'Line 1309');
                                    ASSERT(preErrorSymbol === 0, 'Line 1310');
                                    vstack[sp] = lexer.yytext;
                                    lstack[sp] = this.copy_yylloc(lexer.yylloc);
                                }
                                sstack[sp] = newState; // push state

                                ++sp;

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    let tokenName = this.getSymbolName(symbol || EOF);
                                    if (!tokenName) {
                                        tokenName = symbol;
                                    }

                                    Jison.parserDebugger.push({
                                        action: 'shift',
                                        text: lexer.yytext,
                                        terminal: tokenName,
                                        terminal_id: symbol
                                    });
                                }

                                symbol = 0;
                                // **Warning: Edge Case**: the *lexer* may have produced
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided `yyvalue`
                                // and `yylloc`:
                                errorSymbolFromParser = false;
                                if (!preErrorSymbol) { // normal execution / no error
                                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                                    yyloc = this.copy_yylloc(lexer.yylloc);

                                    if (recovering > 0) {
                                        recovering--;









                                    }
                                } else {
                                    // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                    ASSERT(recovering > 0, 'Line 1352');
                                    symbol = preErrorSymbol;
                                    preErrorSymbol = 0;









                                    // read action for current state and first input
                                    t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                    if (!t[0] || symbol === TERROR) {
                                        // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                        // (simple) stuff might have been missing before the token which caused the error we're
                                        // recovering from now...
                                        //
                                        // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                        // recovery, for then this we would we idling (cycling) on the error forever.
                                        // Yes, this does not take into account the possibility that the *lexer* may have
                                        // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!









                                        symbol = 0;
                                    }
                                }

                                // once we have pushed the special ERROR token value,
                                // we REMAIN in this inner, "slow parse loop" until
                                // the entire error recovery phase has completed.
                                //
                                // ### Note About Edge Case ###
                                //
                                // Userland action code MAY already have 'reset' the
                                // error recovery phase marker `recovering` to ZERO(0)
                                // while the error symbol hasn't been shifted onto
                                // the stack yet. Hence we only exit this "slow parse loop"
                                // when *both* conditions are met!
                                ASSERT(preErrorSymbol === 0, 'Line 1383');
                                if (recovering === 0) {
                                    break;
                                }
                                continue;

                            // reduce:
                            case 2:
                                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                                yyrulelen = this_production[1];








    r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                                    let debuggableProductions = [];
                                    for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                                        let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                                        debuggableProductions.push(debuggableProduction);
                                    }

                                    // find the current nonterminal name (- nolan)
                                    let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                                    let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                                    Jison.parserDebugger.push({
                                        action: 'reduce',
                                        nonterminal: currentNonterminal,
                                        nonterminal_id: currentNonterminalCode,
                                        prereduce: prereduceValue,
                                        result: r,
                                        productions: debuggableProductions,
                                        text: yyval.$
                                    });
                                }

                                if (typeof r !== 'undefined') {
                                    // signal end of error recovery loop AND end of outer parse loop
                                    action = 3;
                                    retval = r;

                                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                        Jison.parserDebugger.push({
                                            action: 'accept',
                                            text: retval
                                        });
                                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                                    }

                                    sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                    break;
                                }

                                // pop off stack
                                sp -= yyrulelen;

                                // don't overwrite the `symbol` variable: use a local var to speed things up:
                                {
                                    let ntsymbol = this_production[0];    // push nonterminal (reduce)
                                    stack[sp] = ntsymbol;
                                    vstack[sp] = yyval.$;
                                    lstack[sp] = yyval._$;
                                    // goto new state = table[STATE][NONTERMINAL]
                                    newState = table[sstack[sp - 1]][ntsymbol];
                                    sstack[sp] = newState;
                                    ++sp;









                                }
                                continue;

                            // accept:
                            case 3:
                                retval = true;
                                // Return the `$accept` rule's `$$` result, if available.
                                //
                                // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                                // default, action):
                                //
                                //     $accept: <startSymbol> $end
                                //                  %{ $$ = $1; @$ = @1; %}
                                //
                                // which, combined with the parse kernel's `$accept` state behaviour coded below,
                                // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                                // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                                //
                                // In code:
                                //
                                //                  %{
                                //                      @$ = @1;            // if location tracking support is included
                                //                      if (typeof $1 !== 'undefined')
                                //                          return $1;
                                //                      else
                                //                          return true;           // the default parse result if the rule actions don't produce anything
                                //                  %}
                                sp--;
                                if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                    retval = vstack[sp];
                                }

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    Jison.parserDebugger.push({
                                        action: 'accept',
                                        text: retval
                                    });
                                    console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                                }

                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                break;
                            }

                            // break out of loop: we accept or fail with error
                            break;
                        }

                        // should we also break out of the regular/outer parse loop,
                        // i.e. did the parser already produce a parse result in here?!
                        // *or* did we hit an unsupported parse state, to be handled
                        // in the `switch/default` code further below?
                        ASSERT(action !== 2, 'Line 1509');
                        if (!action || action === 1) {
                            continue;
                        }
                    }


                }








    switch (action) {
                // catch misc. parse failures:
                default:
                    // this shouldn't happen, unless resolve defaults are off
                    if (action instanceof Array) {
                        p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }
                    // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                    // or a buggy LUT (LookUp Table):
                    p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;

                // shift:
                case 1:
                    stack[sp] = symbol;
                    vstack[sp] = lexer.yytext;
                    lstack[sp] = this.copy_yylloc(lexer.yylloc);
                    sstack[sp] = newState; // push state

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let tokenName = this.getSymbolName(symbol || EOF);
                        if (!tokenName) {
                            tokenName = symbol;
                        }

                        Jison.parserDebugger.push({
                            action: 'shift',
                            text: lexer.yytext,
                            terminal: tokenName,
                            terminal_id: symbol
                        });
                    }

                    ++sp;

                    symbol = 0;

                    ASSERT(preErrorSymbol === 0, 'Line 1619');         // normal execution / no error
                    ASSERT(recovering === 0, 'Line 1620');             // normal execution / no error

                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                    yyloc = this.copy_yylloc(lexer.yylloc);
                    continue;

                // reduce:
                case 2:
                    ASSERT(preErrorSymbol === 0, 'Line 1631');         // normal execution / no error
                    ASSERT(recovering === 0, 'Line 1632');             // normal execution / no error

                    this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                    yyrulelen = this_production[1];








    r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                        let debuggableProductions = [];
                        for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                            let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                            debuggableProductions.push(debuggableProduction);
                        }

                        // find the current nonterminal name (- nolan)
                        let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                        let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                        Jison.parserDebugger.push({
                            action: 'reduce',
                            nonterminal: currentNonterminal,
                            nonterminal_id: currentNonterminalCode,
                            prereduce: prereduceValue,
                            result: r,
                            productions: debuggableProductions,
                            text: yyval.$
                        });
                    }

                    if (typeof r !== 'undefined') {
                        retval = r;

                        if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                            Jison.parserDebugger.push({
                                action: 'accept',
                                text: retval
                            });
                            console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                        }

                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // don't overwrite the `symbol` variable: use a local var to speed things up:
                    {
                        let ntsymbol = this_production[0];    // push nonterminal (reduce)
                        stack[sp] = ntsymbol;
                        vstack[sp] = yyval.$;
                        lstack[sp] = yyval._$;
                        // goto new state = table[STATE][NONTERMINAL]
                        newState = table[sstack[sp - 1]][ntsymbol];
                        sstack[sp] = newState;
                        ++sp;









                    }
                    continue;

                // accept:
                case 3:
                    if (sp !== -2) {
                        retval = true;
                        // Return the `$accept` rule's `$$` result, if available.
                        //
                        // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                        // default, action):
                        //
                        //     $accept: <startSymbol> $end
                        //                  %{ $$ = $1; @$ = @1; %}
                        //
                        // which, combined with the parse kernel's `$accept` state behaviour coded below,
                        // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                        // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                        //
                        // In code:
                        //
                        //                  %{
                        //                      @$ = @1;            // if location tracking support is included
                        //                      if (typeof $1 !== 'undefined')
                        //                          return $1;
                        //                      else
                        //                          return true;           // the default parse result if the rule actions don't produce anything
                        //                  %}
                        sp--;
                        if (typeof vstack[sp] !== 'undefined') {
                            retval = vstack[sp];
                        }
                    }

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        Jison.parserDebugger.push({
                            action: 'accept',
                            text: retval
                        });
                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                    }

                    break;
                }

                // break out of loop: we accept or fail with error
                break;
            }
        } catch (ex) {
            // report exceptions through the parseError callback too, but keep the exception intact
            // if it is a known parser or lexer error which has been thrown by parseError() already:
            if (ex instanceof this.JisonParserError) {
                throw ex;
            } else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
                throw ex;
            }

            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        } finally {
            retval = this.cleanupAfterParse(retval, true, true);
            this.__reentrant_call_depth--;

            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                Jison.parserDebugger.push({
                    action: 'return',
                    text: retval
                });
                console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
            }
        }   // /finally

        return retval;
    },
    yyError: 1
    };
    parser$3.originalParseError = parser$3.parseError;
    parser$3.originalQuoteName = parser$3.quoteName;
    /* lexer generated by jison-lex 0.6.2-220 */

    /*
     * Returns a Lexer object of the following structure:
     *
     *  Lexer: {
     *    yy: {}     The so-called "shared state" or rather the *source* of it;
     *               the real "shared state" `yy` passed around to
     *               the rule actions, etc. is a direct reference!
     *
     *               This "shared context" object was passed to the lexer by way of
     *               the `lexer.setInput(str, yy)` API before you may use it.
     *
     *               This "shared context" object is passed to the lexer action code in `performAction()`
     *               so userland code in the lexer actions may communicate with the outside world
     *               and/or other lexer rules' actions in more or less complex ways.
     *
     *  }
     *
     *  Lexer.prototype: {
     *    EOF: 1,
     *    ERROR: 2,
     *
     *    yy:        The overall "shared context" object reference.
     *
     *    JisonLexerError: function(msg, hash),
     *
     *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
     *
     *               The function parameters and `this` have the following value/meaning:
     *               - `this`    : reference to the `lexer` instance.
     *                               `yy_` is an alias for `this` lexer instance reference used internally.
     *
     *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
     *                             by way of the `lexer.setInput(str, yy)` API before.
     *
     *                             Note:
     *                             The extra arguments you specified in the `%parse-param` statement in your
     *                             **parser** grammar definition file are passed to the lexer via this object
     *                             reference as member variables.
     *
     *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
     *
     *               - `YY_START`: the current lexer "start condition" state.
     *
     *    parseError: function(str, hash, ExceptionClass),
     *
     *    constructLexErrorInfo: function(error_message, is_recoverable),
     *               Helper function.
     *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
     *               See it's use in this lexer kernel in many places; example usage:
     *
     *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
     *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
     *
     *    options: { ... lexer %options ... },
     *
     *    lex: function(),
     *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
     *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
     *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
     *
     *               WARNING:
     *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
     *               any attributes already added to `yy` by the **parser** or the jison run-time;
     *               when such a collision is detected an exception is thrown to prevent the generated run-time
     *               from silently accepting this confusing and potentially hazardous situation!
     *
     *    cleanupAfterLex: function(do_not_nuke_errorinfos),
     *               Helper function.
     *
     *               This helper API is invoked when the **parse process** has completed: it is the responsibility
     *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired.
     *
     *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
     *
     *    setInput: function(input, [yy]),
     *
     *
     *    input: function(),
     *
     *
     *    unput: function(str),
     *
     *
     *    more: function(),
     *
     *
     *    reject: function(),
     *
     *
     *    less: function(n),
     *
     *
     *    pastInput: function(n),
     *
     *
     *    upcomingInput: function(n),
     *
     *
     *    showPosition: function(),
     *
     *
     *    test_match: function(regex_match_array, rule_index),
     *
     *
     *    next: function(),
     *
     *
     *    begin: function(condition),
     *
     *
     *    pushState: function(condition),
     *
     *
     *    popState: function(),
     *
     *
     *    topState: function(),
     *
     *
     *    _currentRules: function(),
     *
     *
     *    stateStackSize: function(),
     *
     *
     *    performAction: function(yy, yy_, yyrulenumber, YY_START),
     *
     *
     *    rules: [...],
     *
     *
     *    conditions: {associative list: name ==> set},
     *  }
     *
     *
     *  token location info (`yylloc`): {
     *    first_line: n,
     *    last_line: n,
     *    first_column: n,
     *    last_column: n,
     *    range: [start_number, end_number]
     *               (where the numbers are indexes into the input string, zero-based)
     *  }
     *
     * ---
     *
     * The `parseError` function receives a 'hash' object with these members for lexer errors:
     *
     *  {
     *    text:        (matched text)
     *    token:       (the produced terminal token, if any)
     *    token_id:    (the produced terminal token numeric ID, if any)
     *    line:        (yylineno)
     *    loc:         (yylloc)
     *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
     *                  available for this particular error)
     *    yy:          (object: the current parser internal "shared state" `yy`
     *                  as is also available in the rule actions; this can be used,
     *                  for instance, for advanced error analysis and reporting)
     *    lexer:       (reference to the current lexer instance used by the parser)
     *  }
     *
     * while `this` will reference the current lexer instance.
     *
     * When `parseError` is invoked by the lexer, the default implementation will
     * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
     * it will try to invoke `yy.parseError()` instead. When that callback is also not
     * provided, a `JisonLexerError` exception will be thrown containing the error
     * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
     *
     * Note that the lexer's `JisonLexerError` error class is passed via the
     * `ExceptionClass` argument, which is invoked to construct the exception
     * instance to be thrown, so technically `parseError` will throw the object
     * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
     *
     * ---
     *
     * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
     * These options are available:
     *
     * (Options are permanent.)
     *
     *  yy: {
     *      parseError: function(str, hash, ExceptionClass)
     *                 optional: overrides the default `parseError` function.
     *  }
     *
     *  lexer.options: {
     *      pre_lex:  function()
     *                 optional: is invoked before the lexer is invoked to produce another token.
     *                 `this` refers to the Lexer object.
     *      post_lex: function(token) { return token; }
     *                 optional: is invoked when the lexer has produced a token `token`;
     *                 this function can override the returned token value by returning another.
     *                 When it does not return any (truthy) value, the lexer will return
     *                 the original `token`.
     *                 `this` refers to the Lexer object.
     *
     * WARNING: the next set of options are not meant to be changed. They echo the abilities of
     * the lexer as per when it was compiled!
     *
     *      ranges: boolean
     *                 optional: `true` ==> token location info will include a .range[] member.
     *      flex: boolean
     *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
     *                 exhaustively to find the longest match.
     *      backtrack_lexer: boolean
     *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
     *                 the lexer terminates the scan when a token is returned by the action code.
     *      xregexp: boolean
     *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
     *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
     *                 rule regexes have been written as standard JavaScript RegExp expressions.
     *  }
     */


    var lexer$2 = function() {

      /**
       * See also:
       * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
       * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
       * with userland code which might access the derived class in a 'classic' way.
       *
       * @public
       * @constructor
       * @nocollapse
       */
      function JisonLexerError(msg, hash) {
        Object.defineProperty(this, 'name', {
          enumerable: false,
          writable: false,
          value: 'JisonLexerError'
        });

        if (msg == null)
          msg = '???';

        Object.defineProperty(this, 'message', {
          enumerable: false,
          writable: true,
          value: msg
        });

        this.hash = hash;
        let stacktrace;

        if (hash && hash.exception instanceof Error) {
          const ex2 = hash.exception;
          this.message = ex2.message || msg;
          stacktrace = ex2.stack;
        }

        if (!stacktrace) {
          if (Error.hasOwnProperty('captureStackTrace')) {
            // V8
            Error.captureStackTrace(this, this.constructor);
          } else {
            stacktrace = new Error(msg).stack;
          }
        }

        if (stacktrace) {
          Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
          });
        }
      }

      if (typeof Object.setPrototypeOf === 'function') {
        Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
      } else {
        JisonLexerError.prototype = Object.create(Error.prototype);
      }

      JisonLexerError.prototype.constructor = JisonLexerError;
      JisonLexerError.prototype.name = 'JisonLexerError';

      const lexer = {
        
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   backtracking: .................... false
    //   location.ranges: ................. true
    //   location line+column tracking: ... true
    //
    //
    // Forwarded Parser Analysis flags:
    //
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses lexer values: ............... true / true
    //   location tracking: ............... true
    //   location assignment: ............. true
    //
    //
    // Lexer Analysis flags:
    //
    //   uses yyleng: ..................... ???
    //   uses yylineno: ................... ???
    //   uses yytext: ..................... ???
    //   uses yylloc: ..................... ???
    //   uses ParseError API: ............. ???
    //   uses yyerror: .................... ???
    //   uses location tracking & editing:  ???
    //   uses more() API: ................. ???
    //   uses unput() API: ................ ???
    //   uses reject() API: ............... ???
    //   uses less() API: ................. ???
    //   uses display APIs pastInput(), upcomingInput(), showPosition():
    //        ............................. ???
    //   uses describeYYLLOC() API: ....... ???
    //
    // --------- END OF REPORT -----------


        EOF: 1,

        ERROR: 2,

        // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

        // options: {},                             /// <-- injected by the code generator

        // yy: ...,                                 /// <-- injected by setInput()

        /// INTERNAL USE ONLY: internal rule set cache for the current lexer state
        __currentRuleSet__: null,

        /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup
        __error_infos: [],

        /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use
        __decompressed: false,

        /// INTERNAL USE ONLY
        done: false,

        /// INTERNAL USE ONLY
        _backtrack: false,

        /// INTERNAL USE ONLY
        _input: '',

        /// INTERNAL USE ONLY
        _more: false,

        /// INTERNAL USE ONLY
        _signaled_error_token: false,

        /// INTERNAL USE ONLY; 0: clear to do, 1: clear done for lex()/next(); -1: clear done for inut()/unput()/...
        _clear_state: 0,

        /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`
        conditionStack: [],

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!
        match: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
        matched: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
        matches: false,

        /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.
        yytext: '',

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far. (**WARNING:** this value MAY be negative if you `unput()` more text than you have already lexed. This type of behaviour is generally observed for one kind of 'lexer/parser hack' where custom token-illiciting characters are pushed in front of the input stream to help simulate multiple-START-points in the parser. When this happens, `base_position` will be adjusted to help track the original input's starting point in the `_input` buffer.)
        offset: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: index to the original starting point of the input; always ZERO(0) unless `unput()` has pushed content before the input: see the `offset` **WARNING** just above.
        base_position: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)
        yyleng: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
        yylineno: 0,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction
        yylloc: null,

        /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: regex used to split lines while tracking the lexer cursor position.
        CRLF_Re: /\r\n?|\n/,

        /**
             * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
             *
             * @public
             * @this {RegExpLexer}
             */
        constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
          msg = '' + msg;

          // heuristic to determine if the error message already contains a (partial) source code dump
          // as produced by either `showPosition()` or `prettyPrintRange()`:
          if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
          }

          if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
              const pretty_src = this.prettyPrintRange(this.yylloc);

              if (!/\n\s*$/.test(msg)) {
                msg += '\n';
              }

              msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
            } else if (typeof this.showPosition === 'function') {
              const pos_str = this.showPosition();

              if (pos_str) {
                if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
                  msg += '\n' + pos_str;
                } else {
                  msg += pos_str;
                }
              }
            }
          }

          /** @constructor */
          const pei = {
            errStr: msg,
            recoverable: !!recoverable,

            // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...
            text: this.match,

            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
                         * and make sure the error info doesn't stay due to potential
                         * ref cycle via userland code manipulations.
                         * These would otherwise all be memory leak opportunities!
                         *
                         * Note that only array and object references are nuked as those
                         * constitute the set of elements which can produce a cyclic ref.
                         * The rest of the members is kept intact as they are harmless.
                         *
                         * @public
                         * @this {LexErrorInfo}
                         */
            destroy: function destructLexErrorInfo() {
              // remove cyclic references added to error info:
              // info.yy = null;
              // info.lexer = null;
              // ...
              const rec = !!this.recoverable;

              for (let key in this) {
                if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                  this[key] = undefined;
                }
              }

              this.recoverable = rec;
            }
          };

          // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
          this.__error_infos.push(pei);

          return pei;
        },

        /**
             * handler which is invoked when a lexer error occurs.
             *
             * @public
             * @this {RegExpLexer}
             */
        parseError: function lexer_parseError(str, hash, ExceptionClass) {
          if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
          }

          if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
              return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
              return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            }
          }

          throw new ExceptionClass(str, hash);
        },

        /**
             * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
             *
             * @public
             * @this {RegExpLexer}
             */
        yyerror: function yyError(str /*, ...args */) {
          let lineno_msg = 'Lexical error';

          if (this.yylloc) {
            lineno_msg += ' on line ' + (this.yylineno + 1);
          }

          const p = this.constructLexErrorInfo(lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

          // Add any extra args to the hash under the name `extra_error_attributes`:
          let args = Array.prototype.slice.call(arguments, 1);

          if (args.length) {
            p.extra_error_attributes = args;
          }

          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        },

        /**
             * final cleanup function for when we have completed lexing the input;
             * make it an API so that external code can use this one once userland
             * code has decided it's time to destroy any lingering lexer error
             * hash object instances and the like: this function helps to clean
             * up these constructs, which *may* carry cyclic references which would
             * otherwise prevent the instances from being properly and timely
             * garbage-collected, i.e. this function helps prevent memory leaks!
             *
             * @public
             * @this {RegExpLexer}
             */
        cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
          // prevent lingering circular references from causing memory leaks:
          this.setInput('', {});

          // nuke the error hash info instances created during this run.
          // Userland code must COPY any data/references
          // in the error hash instance(s) it is more permanently interested in.
          if (!do_not_nuke_errorinfos) {
            for (let i = this.__error_infos.length - 1; i >= 0; i--) {
              let el = this.__error_infos[i];

              if (el && typeof el.destroy === 'function') {
                el.destroy();
              }
            }

            this.__error_infos.length = 0;
          }

          return this;
        },

        /**
             * clear the lexer token context; intended for internal use only
             *
             * @public
             * @this {RegExpLexer}
             */
        clear: function lexer_clear() {
          this.yytext = '';
          this.yyleng = 0;
          this.match = '';

          // - DO NOT reset `this.matched`
          this.matches = false;

          this._more = false;
          this._backtrack = false;
          const col = this.yylloc.last_column;

          this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,
            range: [this.offset, this.offset]
          };
        },

        /**
             * resets the lexer, sets new input
             *
             * @public
             * @this {RegExpLexer}
             */
        setInput: function lexer_setInput(input, yy) {
          this.yy = yy || this.yy || {};

          // also check if we've fully initialized the lexer instance,
          // including expansion work to be done to go from a loaded
          // lexer to a usable lexer:
          if (!this.__decompressed) {
            // step 1: decompress the regex list:
            let rules = this.rules;

            for (var i = 0, len = rules.length; i < len; i++) {
              var rule_re = rules[i];

              // compression: is the RE an xref to another RE slot in the rules[] table?
              if (typeof rule_re === 'number') {
                rules[i] = rules[rule_re];
              }
            }

            // step 2: unfold the conditions[] set to make these ready for use:
            let conditions = this.conditions;

            for (let k in conditions) {
              let spec = conditions[k];
              let rule_ids = spec.rules;
              var len = rule_ids.length;
              let rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
              let rule_new_ids = new Array(len + 1);

              for (var i = 0; i < len; i++) {
                let idx = rule_ids[i];
                var rule_re = rules[idx];
                rule_regexes[i + 1] = rule_re;
                rule_new_ids[i + 1] = idx;
              }

              spec.rules = rule_new_ids;
              spec.__rule_regexes = rule_regexes;
              spec.__rule_count = len;
            }

            this.__decompressed = true;
          }

          if (input && typeof input !== 'string') {
            input = '' + input;
          }

          this._input = input || '';
          this._clear_state = -1;
          this._signaled_error_token = false;
          this.done = false;
          this.yylineno = 0;
          this.matched = '';
          this.conditionStack = ['INITIAL'];
          this.__currentRuleSet__ = null;

          this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          this.offset = 0;
          this.base_position = 0;

          // apply these bits of `this.clear()` as well:
          this.yytext = '';

          this.yyleng = 0;
          this.match = '';
          this.matches = false;
          this._more = false;
          this._backtrack = false;
          return this;
        },

        /**
             * edit the remaining input via user-specified callback.
             * This can be used to forward-adjust the input-to-parse,
             * e.g. inserting macro expansions and alike in the
             * input which has yet to be lexed.
             * The behaviour of this API contrasts the `unput()` et al
             * APIs as those act on the *consumed* input, while this
             * one allows one to manipulate the future, without impacting
             * the current `yyloc` cursor location or any history.
             *
             * Use this API to help implement C-preprocessor-like
             * `#include` statements, etc.
             *
             * The provided callback must be synchronous and is
             * expected to return the edited input (string).
             *
             * The `cpsArg` argument value is passed to the callback
             * as-is.
             *
             * `callback` interface:
             * `function callback(input, cpsArg)`
             *
             * - `input` will carry the remaining-input-to-lex string
             *   from the lexer.
             * - `cpsArg` is `cpsArg` passed into this API.
             *
             * The `this` reference for the callback will be set to
             * reference this lexer instance so that userland code
             * in the callback can easily and quickly access any lexer
             * API.
             *
             * When the callback returns a non-string-type falsey value,
             * we assume the callback did not edit the input and we
             * will using the input as-is.
             *
             * When the callback returns a non-string-type value, it
             * is converted to a string for lexing via the `"" + retval`
             * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html
             * -- that way any returned object's `toValue()` and `toString()`
             * methods will be invoked in a proper/desirable order.)
             *
             * @public
             * @this {RegExpLexer}
             */
        editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
          const rv = callback.call(this, this._input, cpsArg);

          if (typeof rv !== 'string') {
            if (rv) {
              this._input = '' + rv;
            }
            // else: keep `this._input` as is.
          } else {
            this._input = rv;
          }

          return this;
        },

        /**
             * consumes and returns one char from the input
             *
             * @public
             * @this {RegExpLexer}
             */
        input: function lexer_input() {
          if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
          }

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          let ch = this._input[0];
          this.yytext += ch;
          this.yyleng++;
          this.offset++;
          this.match += ch;
          this.matched += ch;

          // Count the linenumber up when we hit the LF (or a stand-alone CR).
          // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
          // and we advance immediately past the LF as well, returning both together as if
          // it was all a single 'character' only.
          let slice_len = 1;

          let lines = false;

          if (ch === '\n') {
            lines = true;
          } else if (ch === '\r') {
            lines = true;
            const ch2 = this._input[1];

            if (ch2 === '\n') {
              slice_len++;
              ch += ch2;
              this.yytext += ch2;
              this.yyleng++;
              this.offset++;
              this.match += ch2;
              this.matched += ch2;
              this.yylloc.range[1]++;
            }
          }

          if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
          } else {
            this.yylloc.last_column++;
          }

          this.yylloc.range[1]++;
          this._input = this._input.slice(slice_len);
          return ch;
        },

        /**
             * unshifts one char (or an entire string) into the input
             *
             * @public
             * @this {RegExpLexer}
             */
        unput: function lexer_unput(ch) {
          let len = ch.length;
          let lines = ch.split(this.CRLF_Re);

          if (!this._clear_state && !this._more) {
            this._clear_state = -1;
            this.clear();
          }

          this._input = ch + this._input;
          this.yytext = this.yytext.substr(0, this.yytext.length - len);
          this.yyleng = this.yytext.length;
          this.offset -= len;

          // **WARNING:**
          // The `offset` value MAY be negative if you `unput()` more text than you have already lexed.
          // This type of behaviour is generally observed for one kind of 'lexer/parser hack'
          // where custom token-illiciting characters are pushed in front of the input stream to help
          // simulate multiple-START-points in the parser.
          // When this happens, `base_position` will be adjusted to help track the original input's
          // starting point in the `_input` buffer.
          if (-this.offset > this.base_position) {
            this.base_position = -this.offset;
          }

          this.match = this.match.substr(0, this.match.length - len);
          this.matched = this.matched.substr(0, this.matched.length - len);

          if (lines.length > 1) {
            this.yylineno -= lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the `pre_lines[]` array's
            // last index slot; we don't mind when other previously
            // matched lines end up in the array too.
            let pre = this.match;

            let pre_lines = pre.split(this.CRLF_Re);

            if (pre_lines.length === 1) {
              pre = this.matched;
              pre_lines = pre.split(this.CRLF_Re);
            }

            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
          } else {
            this.yylloc.last_column -= len;
          }

          this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
          this.done = false;
          return this;
        },

        /**
             * return the upcoming input *which has not been lexed yet*.
             * This can, for example, be used for custom look-ahead inspection code
             * in your lexer.
             *
             * The entire pending input string is returned.
             *
             * > ### NOTE ###
             * >
             * > When augmenting error reports and alike, you might want to
             * > look at the `upcomingInput()` API instead, which offers more
             * > features for limited input extraction and which includes the
             * > part of the input which has been lexed by the last token a.k.a.
             * > the *currently lexed* input.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        lookAhead: function lexer_lookAhead() {
          return this._input || '';
        },

        /**
             * cache matched text and append it on next action
             *
             * @public
             * @this {RegExpLexer}
             */
        more: function lexer_more() {
          this._more = true;
          return this;
        },

        /**
             * signal the lexer that this rule fails to match the input, so the
             * next matching rule (regex) should be tested instead.
             *
             * @public
             * @this {RegExpLexer}
             */
        reject: function lexer_reject() {
          if (this.options.backtrack_lexer) {
            this._backtrack = true;
          } else {
            // when the `parseError()` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // `.lex()` run.
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
              false
            );

            this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
          }

          return this;
        },

        /**
             * retain first n characters of the match
             *
             * @public
             * @this {RegExpLexer}
             */
        less: function lexer_less(n) {
          return this.unput(this.match.slice(n));
        },

        /**
             * return (part of the) already matched input, i.e. for error
             * messages.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of
             * input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that has already been lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * @public
             * @this {RegExpLexer}
             */
        pastInput: function lexer_pastInput(maxSize, maxLines) {
          let past = this.matched.substring(0, this.matched.length - this.match.length);

          if (maxSize < 0) {
            maxSize = Infinity;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = Infinity;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substr` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          past = past.substr(-maxSize * 2 - 2);

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = past.split(this.CRLF_Re);

          a = a.slice(-maxLines);
          past = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis prefix...
          if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
          }

          return past;
        },

        /**
             * return (part of the) upcoming input *including* the input
             * matched by the last token (see also the NOTE below).
             * This can be used to augment error messages, for example.
             *
             * Limit the returned string length to `maxSize` (default: 20).
             *
             * Limit the returned string to the `maxLines` number of lines of input (default: 1).
             *
             * A negative `maxSize` limit value equals *unlimited*, i.e.
             * produce the entire input that is yet to be lexed.
             *
             * A negative `maxLines` limit value equals *unlimited*, i.e. limit the result
             * to the `maxSize` specified number of characters *only*.
             *
             * > ### NOTE ###
             * >
             * > *"upcoming input"* is defined as the whole of the both
             * > the *currently lexed* input, together with any remaining input
             * > following that. *"currently lexed"* input is the input
             * > already recognized by the lexer but not yet returned with
             * > the lexer token. This happens when you are invoking this API
             * > from inside any lexer rule action code block.
             * >
             * > When you want access to the 'upcoming input' in that you want access
             * > to the input *which has not been lexed yet* for look-ahead
             * > inspection or likewise purposes, please consider using the
             * > `lookAhead()` API instead.
             * >
             *
             * @public
             * @this {RegExpLexer}
             */
        upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
          let next = this.match;
          let source = this._input || '';

          if (maxSize < 0) {
            maxSize = next.length + source.length;
          } else if (!maxSize) {
            maxSize = 20;
          }

          if (maxLines < 0) {
            maxLines = maxSize;          // can't ever have more input lines than this!
          } else if (!maxLines) {
            maxLines = 1;
          }

          // `substring` anticipation: treat \r\n as a single character and take a little
          // more than necessary so that we can still properly check against maxSize
          // after we've transformed and limited the newLines in here:
          if (next.length < maxSize * 2 + 2) {
            next += source.substring(0, maxSize * 2 + 2 - next.length);  // substring is faster on Chrome/V8
          }

          // now that we have a significantly reduced string to process, transform the newlines
          // and chop them, then limit them:
          let a = next.split(this.CRLF_Re, maxLines + 1);     // stop splitting once we have reached just beyond the reuired number of lines.

          a = a.slice(0, maxLines);
          next = a.join('\n');

          // When, after limiting to maxLines, we still have too much to return,
          // do add an ellipsis postfix...
          if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
          }

          return next;
        },

        /**
             * return a string which displays the character position where the
             * lexing error occurred, i.e. for error messages
             *
             * @public
             * @this {RegExpLexer}
             */
        showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
          const pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
          let c = new Array(pre.length + 1).join('-');
          return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
        },

        /**
             * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
             * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
             * it MAY be NULL) and you MUST have a valid location info object anyway:
             * then we take the given context of the `preceding` and `following` locations, IFF those are available,
             * and reconstruct the `actual` location info from those.
             * If this fails, the heuristic is to take the `current` location, IFF available.
             * If this fails as well, we assume the sought location is at/around the current lexer position
             * and then produce that one as a response. DO NOTE that these heuristic/derived location info
             * values MAY be inaccurate!
             *
             * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
             * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
             *
             * @public
             * @this {RegExpLexer}
             */
        deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
          let loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,
            range: [0, 0]
          };

          if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
              loc.range[0] = actual.range[0] | 0;
              loc.range[1] = actual.range[1] | 0;
            }
          }

          if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
              loc.first_line = preceding.last_line | 0;
              loc.first_column = preceding.last_column | 0;

              if (preceding.range) {
                loc.range[0] = actual.range[1] | 0;
              }
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
              loc.last_line = following.first_line | 0;
              loc.last_column = following.first_column | 0;

              if (following.range) {
                loc.range[1] = actual.range[0] | 0;
              }
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
              loc.first_line = current.first_line | 0;
              loc.first_column = current.first_column | 0;

              if (current.range) {
                loc.range[0] = current.range[0] | 0;
              }
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
              loc.last_line = current.last_line | 0;
              loc.last_column = current.last_column | 0;

              if (current.range) {
                loc.range[1] = current.range[1] | 0;
              }
            }
          }

          // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
          // or plan D heuristics to produce a 'sensible' last_line value:
          if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
              loc.first_line = this.yylloc.first_line;
              loc.last_line = this.yylloc.last_line;
              loc.first_column = this.yylloc.first_column;
              loc.last_column = this.yylloc.last_column;
              loc.range[0] = this.yylloc.range[0];
              loc.range[1] = this.yylloc.range[1];
            } else {
              loc.last_line = this.yylloc.last_line;
              loc.last_column = this.yylloc.last_column;
              loc.range[1] = this.yylloc.range[1];
            }
          }

          if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;
            loc.range[1] = loc.range[0];
          }

          if (loc.first_column < 0) {
            loc.first_column = 0;
          }

          if (loc.last_column < 0) {
            loc.last_column = loc.first_column > 0 ? loc.first_column : 80;
          }

          return loc;
        },

        /**
             * return a string which displays the lines & columns of input which are referenced
             * by the given location info range, plus a few lines of context.
             *
             * This function pretty-prints the indicated section of the input, with line numbers
             * and everything!
             *
             * This function is very useful to provide highly readable error reports, while
             * the location range may be specified in various flexible ways:
             *
             * - `loc` is the location info object which references the area which should be
             *   displayed and 'marked up': these lines & columns of text are marked up by `^`
             *   characters below each character in the entire input range.
             *
             * - `context_loc` is the *optional* location info object which instructs this
             *   pretty-printer how much *leading* context should be displayed alongside
             *   the area referenced by `loc`. This can help provide context for the displayed
             *   error, etc.
             *
             *   When this location info is not provided, a default context of 3 lines is
             *   used.
             *
             * - `context_loc2` is another *optional* location info object, which serves
             *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
             *   context lines to display in the pretty-print output.
             *
             *   When this location info is not provided, a default context of 1 line only is
             *   used.
             *
             * Special Notes:
             *
             * - when the `loc`-indicated range is very large (about 5 lines or more), then
             *   only the first and last few lines of this block are printed while a
             *   `...continued...` message will be printed between them.
             *
             *   This serves the purpose of not printing a huge amount of text when the `loc`
             *   range happens to be huge: this way a manageable & readable output results
             *   for arbitrary large ranges.
             *
             * - this function can display lines of input which whave not yet been lexed.
             *   `prettyPrintRange()` can access the entire input!
             *
             * @public
             * @this {RegExpLexer}
             */
        prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
          loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
          const CONTEXT = 3;
          const CONTEXT_TAIL = 1;
          const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
          let input = this.matched + (this._input || '');
          let lines = input.split('\n');
          let l0 = Math.max(1, context_loc ? context_loc.first_line : loc.first_line - CONTEXT);
          let l1 = Math.max(1, context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL);
          let lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
          let ws_prefix = new Array(lineno_display_width).join(' ');
          let nonempty_line_indexes = [[], [], []];

          let rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            let lno = index + l0;
            let lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            let rv = lno_pfx + ': ' + line;
            let errpfx = new Array(lineno_display_width + 1).join('^');
            let offset = 2 + 1;
            let len = 0;

            if (lno === loc.first_line) {
              offset += loc.first_column;

              len = Math.max(
                2,
                (lno === loc.last_line ? loc.last_column : line.length) - loc.first_column + 1
              );
            } else if (lno === loc.last_line) {
              len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
              len = Math.max(2, line.length + 1);
            }

            let nli;

            if (len) {
              let lead = new Array(offset).join('.');
              let mark = new Array(len).join('^');
              rv += '\n' + errpfx + lead + mark;
              nli = 1;
            } else if (lno < loc.first_line) {
              nli = 0;
            } else if (lno > loc.last_line) {
              nli = 2;
            }

            if (line.trim().length > 0) {
              nonempty_line_indexes[nli].push(index);
            }

            rv = rv.replace(/\t/g, ' ');
            return rv;
          });

          // now make sure we don't print an overly large amount of lead/error/tail area: limit it
          // to the top and bottom line count:
          for (let i = 0; i <= 2; i++) {
            let line_arr = nonempty_line_indexes[i];

            if (line_arr.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
              let clip_start = line_arr[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
              let clip_end = line_arr[line_arr.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
              let intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';

              if (i === 1) {
                intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
              }

              rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
            }
          }

          return rv.join('\n');
        },

        /**
             * helper function, used to produce a human readable description as a string, given
             * the input `yylloc` location object.
             *
             * Set `display_range_too` to TRUE to include the string character index position(s)
             * in the description if the `yylloc.range` is available.
             *
             * @public
             * @this {RegExpLexer}
             */
        describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
          let l1 = yylloc.first_line;
          let l2 = yylloc.last_line;
          let c1 = yylloc.first_column;
          let c2 = yylloc.last_column;
          let dl = l2 - l1;
          let dc = c2 - c1;
          let rv;

          if (dl === 0) {
            rv = 'line ' + l1 + ', ';

            if (dc <= 1) {
              rv += 'column ' + c1;
            } else {
              rv += 'columns ' + c1 + ' .. ' + c2;
            }
          } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
          }

          if (yylloc.range && display_range_too) {
            let r1 = yylloc.range[0];
            let r2 = yylloc.range[1] - 1;

            if (r2 <= r1) {
              rv += ' {String Offset: ' + r1 + '}';
            } else {
              rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
          }

          return rv;
        },

        /**
             * test the lexed token: return FALSE when not a match, otherwise return token.
             *
             * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
             * contains the actually matched text string.
             *
             * Also move the input cursor forward and update the match collectors:
             *
             * - `yytext`
             * - `yyleng`
             * - `match`
             * - `matches`
             * - `yylloc`
             * - `offset`
             *
             * @public
             * @this {RegExpLexer}
             */
        test_match: function lexer_test_match(match, indexed_rule) {
          let backup;

          if (this.options.backtrack_lexer) {
            // save context
            backup = {
              yylineno: this.yylineno,

              yylloc: {
                first_line: this.yylloc.first_line,
                last_line: this.yylloc.last_line,
                first_column: this.yylloc.first_column,
                last_column: this.yylloc.last_column,
                range: this.yylloc.range.slice()
              },

              yytext: this.yytext,
              match: this.match,
              matches: this.matches,
              matched: this.matched,
              yyleng: this.yyleng,
              offset: this.offset,
              _more: this._more,
              _input: this._input,

              //_signaled_error_token: this._signaled_error_token,
              yy: this.yy,

              conditionStack: this.conditionStack.slice(),
              done: this.done
            };
          }

          let match_str = match[0];
          let match_str_len = match_str.length;
          let lines = match_str.split(this.CRLF_Re);

          if (lines.length > 1) {
            this.yylineno += lines.length - 1;
            this.yylloc.last_line = this.yylineno + 1;
            this.yylloc.last_column = lines[lines.length - 1].length;
          } else {
            this.yylloc.last_column += match_str_len;
          }

          this.yytext += match_str;
          this.match += match_str;
          this.matched += match_str;
          this.matches = match;
          this.yyleng = this.yytext.length;
          this.yylloc.range[1] += match_str_len;

          // previous lex rules MAY have invoked the `more()` API rather than producing a token:
          // those rules will already have moved this `offset` forward matching their match lengths,
          // hence we must only add our own match length now:
          this.offset += match_str_len;

          this._more = false;
          this._backtrack = false;
          this._input = this._input.slice(match_str_len);

          // calling this method:
          //
          //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
          let token = this.performAction.call(
            this,
            this.yy,
            indexed_rule,
            this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
          );

          // otherwise, when the action codes are all simple return token statements:
          //token = this.simpleCaseActionClusters[indexed_rule];

          if (this.done && this._input) {
            this.done = false;
          }

          if (token) {
            return token;
          } else if (this._backtrack) {
            // recover context
            for (let k in backup) {
              this[k] = backup[k];
            }

            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
          } else if (this._signaled_error_token) {
            // produce one 'error' token as `.parseError()` in `reject()`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;

            this._signaled_error_token = false;
            return token;
          }

          return false;
        },

        /**
             * return next match in input
             *
             * @public
             * @this {RegExpLexer}
             */
        next: function lexer_next() {
          if (this.done) {
            this.clear();
            return this.EOF;
          }

          if (!this._input) {
            this.done = true;
          }

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          let spec = this.__currentRuleSet__;

          if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();

            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
              let lineno_msg = '';

              if (this.yylloc) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
              }

              const p = this.constructLexErrorInfo(
                'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
                false
              );

              // produce one 'error' token until this situation has been resolved, most probably by parse termination!
              return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
            }
          }

          {
            let rule_ids = spec.rules;
            let regexes = spec.__rule_regexes;
            let len = spec.__rule_count;
            let match;
            let index;

            // Note: the arrays are 1-based, while `len` itself is a valid index,
            // hence the non-standard less-or-equal check in the next loop condition!
            for (let i = 1; i <= len; i++) {
              let tempMatch = this._input.match(regexes[i]);

              if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;

                if (this.options.backtrack_lexer) {
                  let token = this.test_match(tempMatch, rule_ids[i]);

                  if (token !== false) {
                    return token;
                  } else if (this._backtrack) {
                    match = undefined;
                    continue; // rule action called reject() implying a rule MISmatch.
                  } else {
                    // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                    return false;
                  }
                } else if (!this.options.flex) {
                  break;
                }
              }
            }

            if (match) {
              let token = this.test_match(match, rule_ids[index]);

              if (token !== false) {
                return token;
              }

              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          }

          if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
          }

          {
            let lineno_msg = 'Lexical error';

            if (this.yylloc) {
              lineno_msg += ' on line ' + (this.yylineno + 1);
            }

            const p = this.constructLexErrorInfo(
              lineno_msg + ': Unrecognized text.',
              this.options.lexerErrorsAreRecoverable
            );

            let pendingInput = this._input;
            let activeCondition = this.topState();
            let conditionStackDepth = this.conditionStack.length;
            let token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

            if (token === this.ERROR) {
              // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
              // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
              // has not consumed/modified any pending input or changed state in the error handler:
              if (!this.matches && // and make sure the input has been modified/consumed ...
              pendingInput === this._input && // ...or the lexer state has been modified significantly enough
              // to merit a non-consuming error handling action right now.
              activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
                this.input();
              }
            }

            return token;
          }
        },

        /**
             * return next match that has a token
             *
             * @public
             * @this {RegExpLexer}
             */
        lex: function lexer_lex() {
          let r;

          //this._clear_state = 0;

          if (!this._more) {
            if (!this._clear_state) {
              this._clear_state = 1;
            }

            this.clear();
          }

          // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
          if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
          }

          if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
          }

          if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
          }

          while (!r) {
            r = this.next();
          }

          if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
          }

          if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
          }

          if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return next match that has a token. Identical to the `lex()` API but does not invoke any of the
             * `pre_lex()` nor any of the `post_lex()` callbacks.
             *
             * @public
             * @this {RegExpLexer}
             */
        fastLex: function lexer_fastLex() {
          let r;

          //this._clear_state = 0;

          while (!r) {
            r = this.next();
          }

          if (!this._more) {
            //
            // 1) make sure any outside interference is detected ASAP:
            //    these attributes are to be treated as 'const' values
            //    once the lexer has produced them with the token (return value `r`).
            // 2) make sure any subsequent `lex()` API invocation CANNOT
            //    edit the `yytext`, etc. token attributes for the *current*
            //    token, i.e. provide a degree of 'closure safety' so that
            //    code like this:
            //
            //        t1 = lexer.lex();
            //        v = lexer.yytext;
            //        l = lexer.yylloc;
            //        t2 = lexer.lex();
            //        assert(lexer.yytext !== v);
            //        assert(lexer.yylloc !== l);
            //
            //    succeeds. Older (pre-v0.6.5) jison versions did not *guarantee*
            //    these conditions.
            //
            this.yytext = Object.freeze(this.yytext);

            this.matches = Object.freeze(this.matches);
            this.yylloc.range = Object.freeze(this.yylloc.range);
            this.yylloc = Object.freeze(this.yylloc);
            this._clear_state = 0;
          }

          return r;
        },

        /**
             * return info about the lexer state that can help a parser or other lexer API user to use the
             * most efficient means available. This API is provided to aid run-time performance for larger
             * systems which employ this lexer.
             *
             * @public
             * @this {RegExpLexer}
             */
        canIUse: function lexer_canIUse() {
          const rv = {
            fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
          };

          return rv;
        },

        /**
             * backwards compatible alias for `pushState()`;
             * the latter is symmetrical with `popState()` and we advise to use
             * those APIs in any modern lexer code, rather than `begin()`.
             *
             * @public
             * @this {RegExpLexer}
             */
        begin: function lexer_begin(condition) {
          return this.pushState(condition);
        },

        /**
             * activates a new lexer condition state (pushes the new lexer
             * condition state onto the condition stack)
             *
             * @public
             * @this {RegExpLexer}
             */
        pushState: function lexer_pushState(condition) {
          this.conditionStack.push(condition);
          this.__currentRuleSet__ = null;
          return this;
        },

        /**
             * pop the previously active lexer condition state off the condition
             * stack
             *
             * @public
             * @this {RegExpLexer}
             */
        popState: function lexer_popState() {
          const n = this.conditionStack.length - 1;

          if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
          }

          return this.conditionStack[0];
        },

        /**
             * return the currently active lexer condition state; when an index
             * argument is provided it produces the N-th previous condition state,
             * if available
             *
             * @public
             * @this {RegExpLexer}
             */
        topState: function lexer_topState(n) {
          n = this.conditionStack.length - 1 - Math.abs(n || 0);

          if (n >= 0) {
            return this.conditionStack[n];
          }

          return 'INITIAL';
        },

        /**
             * (internal) determine the lexer rule set which is active for the
             * currently active lexer condition state
             *
             * @public
             * @this {RegExpLexer}
             */
        _currentRules: function lexer__currentRules() {
          const n = this.conditionStack.length - 1;
          let state;

          if (n >= 0) {
            state = this.conditionStack[n];
          } else {
            state = 'INITIAL';
          }

          return this.conditions[state] || this.conditions.INITIAL;
        },

        /**
             * return the number of states currently on the stack
             *
             * @public
             * @this {RegExpLexer}
             */
        stateStackSize: function lexer_stateStackSize() {
          return this.conditionStack.length;
        },

        options: {
          xregexp: true,
          ranges: true,
          trackPosition: true,
          easy_keyword_rules: true
        },

        JisonLexerError: JisonLexerError,

        performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
          var yy_ = this;

          switch (yyrulenumber) {
          case 2:
            /*! Conditions:: action */
            /*! Rule::       \/[^ /]*?['"{}][^ ]*?\/ */
            return 43; // regexp with braces or quotes (and no spaces) 
          case 7:
            /*! Conditions:: action */
            /*! Rule::       \{ */
            yy.depth++;

            return 12;
          case 8:
            /*! Conditions:: action */
            /*! Rule::       \} */
            if (yy.depth === 0) {
              this.popState();
            } else {
              yy.depth--;
            }

            return 13;
          case 9:
            /*! Conditions:: token */
            /*! Rule::       {BR} */
            this.popState();

            break;
          case 10:
            /*! Conditions:: token */
            /*! Rule::       %% */
            this.popState();

            break;
          case 11:
            /*! Conditions:: token */
            /*! Rule::       ; */
            this.popState();

            break;
          case 12:
            /*! Conditions:: bnf ebnf */
            /*! Rule::       %% */
            this.pushState('code');

            return 14;
          case 25:
            /*! Conditions:: options */
            /*! Rule::       = */
            this.pushState('option_values');

            return 3;
          case 26:
            /*! Conditions:: option_values */
            /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
            yy_.yytext = unescQuote(this.matches[1]);

            this.popState();
            return 29;   // value is always a string type 
          case 27:
            /*! Conditions:: option_values */
            /*! Rule::       '{QUOTED_STRING_CONTENT}' */
            yy_.yytext = unescQuote(this.matches[1]);

            this.popState();
            return 29;   // value is always a string type 
          case 28:
            /*! Conditions:: option_values */
            /*! Rule::       `{ES2017_STRING_CONTENT}` */
            yy_.yytext = unescQuote(this.matches[1]);

            this.popState();
            return 29;   // value is always a string type 
          case 29:
            /*! Conditions:: INITIAL ebnf bnf token path options option_values */
            /*! Rule::       \/\/[^\r\n]* */
            /* skip single-line comment */
            break;
          case 30:
            /*! Conditions:: INITIAL ebnf bnf token path options option_values */
            /*! Rule::       \/\*[^]*?\*\/ */
            /* skip multi-line comment */
            break;
          case 31:
            /*! Conditions:: option_values */
            /*! Rule::       [^\s\r\n]+ */
            this.popState();

            return 30;
          case 32:
            /*! Conditions:: options */
            /*! Rule::       {BR}{WS}+(?=\S) */
            /* skip leading whitespace on the next line of input, when followed by more options */
            break;
          case 33:
            /*! Conditions:: options */
            /*! Rule::       {BR} */
            this.popState();

            return 28;
          case 34:
            /*! Conditions:: options option_values */
            /*! Rule::       {WS}+ */
            /* skip whitespace */
            break;
          case 35:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       {WS}+ */
            /* skip whitespace */
            break;
          case 36:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       {BR}+ */
            /* skip newlines */
            break;
          case 37:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       \[{ID}\] */
            yy_.yytext = this.matches[1];

            return 40;
          case 42:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
            yy_.yytext = unescQuote(this.matches[1]);

            return 26;
          case 43:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       '{QUOTED_STRING_CONTENT}' */
            yy_.yytext = unescQuote(this.matches[1]);

            return 26;
          case 48:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %% */
            this.pushState(yy.ebnf ? 'ebnf' : 'bnf');

            return 14;
          case 49:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %ebnf\b */
            yy.ebnf = true;

            return 20;
          case 57:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %token\b */
            this.pushState('token');

            return 18;
          case 59:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %option[s]? */
            this.pushState('options');

            return 27;
          case 60:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %lex{LEX_CONTENT}\/lex\b */
            // remove the %lex../lex wrapper and return the pure lex section:
            yy_.yytext = this.matches[1];

            return 17;
          case 63:
            /*! Conditions:: INITIAL ebnf bnf code */
            /*! Rule::       %include\b */
            this.pushState('path');

            return 44;
          case 64:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %{NAME}([^\r\n]*) */
            /* ignore unrecognized decl */
            this.warn(rmCommonWS`
                                                EBNF: ignoring unsupported parser option ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

            yy_.yytext = [// {NAME}
            this.matches[1], // optional value/parameters
            this.matches[2].trim()];

            return 21;
          case 65:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       <{ID}> */
            yy_.yytext = this.matches[1];

            return 36;
          case 66:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       \{\{([^]*?)\}\} */
            yy_.yytext = this.matches[1].replace(/\}\\\}/g, '}}');  // unescape any literal '}\}' that exists within the action code block

            return 15;
          case 67:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       %\{([^]*?)%\} */
            yy_.yytext = this.matches[1].replace(/%\\\}/g, '%}');   // unescape any literal '%\}' that exists within the action code block

            return 15;
          case 68:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       \{ */
            yy.depth = 0;

            this.pushState('action');
            return 12;
          case 69:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       ->.* */
            yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 2).trim();

            return 38;
          case 70:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       →.* */
            yy_.yytext = yy_.yytext.substr(1, yy_.yyleng - 1).trim();

            return 38;
          case 71:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       =>.* */
            yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 2).trim();

            return 38;
          case 72:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       {HEX_NUMBER} */
            yy_.yytext = parseInt(yy_.yytext, 16);

            return 37;
          case 73:
            /*! Conditions:: token bnf ebnf INITIAL */
            /*! Rule::       {DECIMAL_NUMBER}(?![xX0-9a-fA-F]) */
            yy_.yytext = parseInt(yy_.yytext, 10);

            return 37;
          case 75:
            /*! Conditions:: code */
            /*! Rule::       [^\r\n]+ */
            return 46;      // the bit of CODE just before EOF... 
          case 76:
            /*! Conditions:: path */
            /*! Rule::       {BR} */
            this.popState();

            this.unput(yy_.yytext);
            break;
          case 77:
            /*! Conditions:: path */
            /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
            yy_.yytext = unescQuote(this.matches[1]);

            this.popState();
            return 45;
          case 78:
            /*! Conditions:: path */
            /*! Rule::       '{QUOTED_STRING_CONTENT}' */
            yy_.yytext = unescQuote(this.matches[1]);

            this.popState();
            return 45;
          case 79:
            /*! Conditions:: path */
            /*! Rule::       {WS}+ */
            // skip whitespace in the line 
            break;
          case 80:
            /*! Conditions:: path */
            /*! Rule::       [^\s\r\n]+ */
            this.popState();

            return 45;
          case 81:
            /*! Conditions:: action */
            /*! Rule::       " */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 82:
            /*! Conditions:: action */
            /*! Rule::       ' */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 83:
            /*! Conditions:: action */
            /*! Rule::       ` */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 84:
            /*! Conditions:: option_values */
            /*! Rule::       " */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 85:
            /*! Conditions:: option_values */
            /*! Rule::       ' */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 86:
            /*! Conditions:: option_values */
            /*! Rule::       ` */
            yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

            return 'UNTERMINATED_STRING_ERROR';
          case 87:
            /*! Conditions:: * */
            /*! Rule::       " */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 'UNTERMINATED_STRING_ERROR';
            }
          case 88:
            /*! Conditions:: * */
            /*! Rule::       ' */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 'UNTERMINATED_STRING_ERROR';
            }
          case 89:
            /*! Conditions:: * */
            /*! Rule::       ` */
            {
              let rules = this.topState() === 'macro' ? 'macro\'s' : this.topState();

              yy_.yyerror(rmCommonWS`
                                            unterminated string constant encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

              return 'UNTERMINATED_STRING_ERROR';
            }
          case 90:
            /*! Conditions:: * */
            /*! Rule::       . */
            /* b0rk on bad characters */
            yy_.yyerror(rmCommonWS`
                                                unsupported parser input: ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.
                                                
                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

            return 2;
          default:
            return this.simpleCaseActionClusters[yyrulenumber];
          }
        },

        simpleCaseActionClusters: {
          /*! Conditions:: action */
          /*! Rule::       \/\*[^]*?\*\/ */
          0: 43,

          /*! Conditions:: action */
          /*! Rule::       \/\/[^\r\n]* */
          1: 43,

          /*! Conditions:: action */
          /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
          3: 43,

          /*! Conditions:: action */
          /*! Rule::       '{QUOTED_STRING_CONTENT}' */
          4: 43,

          /*! Conditions:: action */
          /*! Rule::       [/"'][^{}/"']+ */
          5: 43,

          /*! Conditions:: action */
          /*! Rule::       [^{}/"']+ */
          6: 43,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       %empty\b */
          13: 39,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       %epsilon\b */
          14: 39,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       Ɛ */
          15: 39,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       ɛ */
          16: 39,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       ε */
          17: 39,

          /*! Conditions:: bnf ebnf */
          /*! Rule::       ϵ */
          18: 39,

          /*! Conditions:: ebnf */
          /*! Rule::       \( */
          19: 7,

          /*! Conditions:: ebnf */
          /*! Rule::       \) */
          20: 8,

          /*! Conditions:: ebnf */
          /*! Rule::       \* */
          21: 9,

          /*! Conditions:: ebnf */
          /*! Rule::       \? */
          22: 10,

          /*! Conditions:: ebnf */
          /*! Rule::       \+ */
          23: 11,

          /*! Conditions:: options */
          /*! Rule::       {NAME} */
          24: 25,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       {ID} */
          38: 24,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       {NAME} */
          39: 25,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       \$end\b */
          40: 41,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       \$eof\b */
          41: 41,

          /*! Conditions:: token */
          /*! Rule::       [^\s\r\n]+ */
          44: 'TOKEN_WORD',

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       : */
          45: 5,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       ; */
          46: 4,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       \| */
          47: 6,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %debug\b */
          50: 19,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %parser-type\b */
          51: 32,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %prec\b */
          52: 42,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %start\b */
          53: 16,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %left\b */
          54: 33,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %right\b */
          55: 34,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %nonassoc\b */
          56: 35,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %parse-param[s]? */
          58: 31,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %code\b */
          61: 23,

          /*! Conditions:: token bnf ebnf INITIAL */
          /*! Rule::       %import\b */
          62: 22,

          /*! Conditions:: code */
          /*! Rule::       [^\r\n]*(\r|\n)+ */
          74: 46,

          /*! Conditions:: * */
          /*! Rule::       $ */
          91: 1
        },

        rules: [
          /*  0: */  /^(?:\/\*[\s\S]*?\*\/)/,
          /*  1: */  /^(?:\/\/[^\r\n]*)/,
          /*  2: */  /^(?:\/[^ /]*?['"{}][^ ]*?\/)/,
          /*  3: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /*  4: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /*  5: */  /^(?:[/"'][^{}/"']+)/,
          /*  6: */  /^(?:[^{}/"']+)/,
          /*  7: */  /^(?:\{)/,
          /*  8: */  /^(?:\})/,
          /*  9: */  /^(?:(\r\n|\n|\r))/,
          /* 10: */  /^(?:%%)/,
          /* 11: */  /^(?:;)/,
          /* 12: */  /^(?:%%)/,
          /* 13: */  /^(?:%empty\b)/,
          /* 14: */  /^(?:%epsilon\b)/,
          /* 15: */  /^(?:Ɛ)/,
          /* 16: */  /^(?:ɛ)/,
          /* 17: */  /^(?:ε)/,
          /* 18: */  /^(?:ϵ)/,
          /* 19: */  /^(?:\()/,
          /* 20: */  /^(?:\))/,
          /* 21: */  /^(?:\*)/,
          /* 22: */  /^(?:\?)/,
          /* 23: */  /^(?:\+)/,
          /* 24: */  new XRegExp__default['default'](
            '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
            ''
          ),
          /* 25: */  /^(?:=)/,
          /* 26: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /* 27: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /* 28: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
          /* 29: */  /^(?:\/\/[^\r\n]*)/,
          /* 30: */  /^(?:\/\*[\s\S]*?\*\/)/,
          /* 31: */  /^(?:\S+)/,
          /* 32: */  /^(?:(\r\n|\n|\r)([^\S\n\r])+(?=\S))/,
          /* 33: */  /^(?:(\r\n|\n|\r))/,
          /* 34: */  /^(?:([^\S\n\r])+)/,
          /* 35: */  /^(?:([^\S\n\r])+)/,
          /* 36: */  /^(?:(\r\n|\n|\r)+)/,
          /* 37: */  new XRegExp__default['default']('^(?:\\[([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\])', ''),
          /* 38: */  new XRegExp__default['default']('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
          /* 39: */  new XRegExp__default['default'](
            '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
            ''
          ),
          /* 40: */  /^(?:\$end\b)/,
          /* 41: */  /^(?:\$eof\b)/,
          /* 42: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /* 43: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /* 44: */  /^(?:\S+)/,
          /* 45: */  /^(?::)/,
          /* 46: */  /^(?:;)/,
          /* 47: */  /^(?:\|)/,
          /* 48: */  /^(?:%%)/,
          /* 49: */  /^(?:%ebnf\b)/,
          /* 50: */  /^(?:%debug\b)/,
          /* 51: */  /^(?:%parser-type\b)/,
          /* 52: */  /^(?:%prec\b)/,
          /* 53: */  /^(?:%start\b)/,
          /* 54: */  /^(?:%left\b)/,
          /* 55: */  /^(?:%right\b)/,
          /* 56: */  /^(?:%nonassoc\b)/,
          /* 57: */  /^(?:%token\b)/,
          /* 58: */  /^(?:%parse-param[s]?)/,
          /* 59: */  /^(?:%option[s]?)/,
          /* 60: */  /^(?:%lex((?:[^\S\n\r])*(?:(?:\r\n|\n|\r)[\s\S]*?)?(?:\r\n|\n|\r)(?:[^\S\n\r])*)\/lex\b)/,
          /* 61: */  /^(?:%code\b)/,
          /* 62: */  /^(?:%import\b)/,
          /* 63: */  /^(?:%include\b)/,
          /* 64: */  new XRegExp__default['default'](
            '^(?:%([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?)([^\\n\\r]*))',
            ''
          ),
          /* 65: */  new XRegExp__default['default']('^(?:<([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)>)', ''),
          /* 66: */  /^(?:\{\{([\s\S]*?)\}\})/,
          /* 67: */  /^(?:%\{([\s\S]*?)%\})/,
          /* 68: */  /^(?:\{)/,
          /* 69: */  /^(?:->.*)/,
          /* 70: */  /^(?:→.*)/,
          /* 71: */  /^(?:=>.*)/,
          /* 72: */  /^(?:(0[Xx][\dA-Fa-f]+))/,
          /* 73: */  /^(?:([1-9]\d*)(?![\dA-FXa-fx]))/,
          /* 74: */  /^(?:[^\r\n]*(\r|\n)+)/,
          /* 75: */  /^(?:[^\r\n]+)/,
          /* 76: */  /^(?:(\r\n|\n|\r))/,
          /* 77: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
          /* 78: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
          /* 79: */  /^(?:([^\S\n\r])+)/,
          /* 80: */  /^(?:\S+)/,
          /* 81: */  /^(?:")/,
          /* 82: */  /^(?:')/,
          /* 83: */  /^(?:`)/,
          /* 84: */  /^(?:")/,
          /* 85: */  /^(?:')/,
          /* 86: */  /^(?:`)/,
          /* 87: */  /^(?:")/,
          /* 88: */  /^(?:')/,
          /* 89: */  /^(?:`)/,
          /* 90: */  /^(?:.)/,
          /* 91: */  /^(?:$)/
        ],

        conditions: {
          'action': {
            rules: [0, 1, 2, 3, 4, 5, 6, 7, 8, 81, 82, 83, 87, 88, 89, 90, 91],
            inclusive: false
          },

          'code': {
            rules: [63, 74, 75, 87, 88, 89, 90, 91],
            inclusive: false
          },

          'path': {
            rules: [29, 30, 76, 77, 78, 79, 80, 87, 88, 89, 90, 91],
            inclusive: false
          },

          'options': {
            rules: [24, 25, 29, 30, 32, 33, 34, 87, 88, 89, 90, 91],
            inclusive: false
          },

          'option_values': {
            rules: [26, 27, 28, 29, 30, 31, 34, 84, 85, 86, 87, 88, 89, 90, 91],
            inclusive: false
          },

          'token': {
            rules: [
              9,
              10,
              11,
              29,
              30,
              35,
              36,
              37,
              38,
              39,
              40,
              41,
              42,
              43,
              44,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              87,
              88,
              89,
              90,
              91
            ],

            inclusive: true
          },

          'bnf': {
            rules: [
              12,
              13,
              14,
              15,
              16,
              17,
              18,
              29,
              30,
              35,
              36,
              37,
              38,
              39,
              40,
              41,
              42,
              43,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              87,
              88,
              89,
              90,
              91
            ],

            inclusive: true
          },

          'ebnf': {
            rules: [
              12,
              13,
              14,
              15,
              16,
              17,
              18,
              19,
              20,
              21,
              22,
              23,
              29,
              30,
              35,
              36,
              37,
              38,
              39,
              40,
              41,
              42,
              43,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              87,
              88,
              89,
              90,
              91
            ],

            inclusive: true
          },

          'INITIAL': {
            rules: [
              29,
              30,
              35,
              36,
              37,
              38,
              39,
              40,
              41,
              42,
              43,
              45,
              46,
              47,
              48,
              49,
              50,
              51,
              52,
              53,
              54,
              55,
              56,
              57,
              58,
              59,
              60,
              61,
              62,
              63,
              64,
              65,
              66,
              67,
              68,
              69,
              70,
              71,
              72,
              73,
              87,
              88,
              89,
              90,
              91
            ],

            inclusive: true
          }
        }
      };

      const rmCommonWS = helpers.rmCommonWS;
      const dquote = helpers.dquote;

      // unescape a string value which is wrapped in quotes/doublequotes
      function unescQuote(str) {
        str = '' + str;
        let a = str.split('\\\\');

        a = a.map(function(s) {
          return s.replace(/\\'/g, '\'').replace(/\\"/g, '"');
        });

        str = a.join('\\\\');
        return str;
      }

      lexer.warn = function l_warn() {
        if (this.yy && this.yy.parser && typeof this.yy.parser.warn === 'function') {
          return this.yy.parser.warn.apply(this, arguments);
        } else {
          console.warn.apply(console, arguments);
        }
      };

      lexer.log = function l_log() {
        if (this.yy && this.yy.parser && typeof this.yy.parser.log === 'function') {
          return this.yy.parser.log.apply(this, arguments);
        } else {
          console.log.apply(console, arguments);
        }
      };

      return lexer;
    }();
    parser$3.lexer = lexer$2;

    var ebnf = false;





    const rmCommonWS$3 = helpers.rmCommonWS;
    const dquote$2 = helpers.dquote;
    const checkActionBlock$2 = helpers.checkActionBlock;
    const trimActionCode$2 = helpers.trimActionCode;


    // transform ebnf to bnf if necessary
    function extend(json, grammar) {
        if (ebnf) {
            json.ebnf = grammar.grammar;        // keep the original source EBNF around for possible pretty-printing & AST exports.
            json.bnf = transform(grammar.grammar);
        }
        else {
            json.bnf = grammar.grammar;
        }
        if (grammar.actionInclude) {
            json.actionInclude = grammar.actionInclude;
        }
        return json;
    }

    // convert string value to number or boolean value, when possible
    // (and when this is more or less obviously the intent)
    // otherwise produce the string itself as value.
    function parseValue$1(v) {
        if (v === 'false') {
            return false;
        }
        if (v === 'true') {
            return true;
        }
        // http://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number
        // Note that the `v` check ensures that we do not convert `undefined`, `null` and `''` (empty string!)
        if (v && !isNaN(v)) {
            let rv = +v;
            if (isFinite(rv)) {
                return rv;
            }
        }
        return v;
    }


    parser$3.warn = function p_warn() {
        console.warn.apply(console, arguments);
    };

    parser$3.log = function p_log() {
        console.log.apply(console, arguments);
    };


    function Parser$2() {
        this.yy = {};
    }
    Parser$2.prototype = parser$3;
    parser$3.Parser = Parser$2;

    function yyparse$2() {
        return parser$3.parse.apply(parser$3, arguments);
    }



    var bnf = {
        parser: parser$3,
        Parser: Parser$2,
        parse: yyparse$2,
        
    };

    const version$1 = '0.6.2-220';                              // require('./package.json').version;

    function parse(grammar) {
        return bnf.parser.parse(grammar);
    }

    // adds a declaration to the grammar
    bnf.parser.yy.addDeclaration = function bnfAddDeclaration(grammar, decl) {
        if (!decl) {
            return;
        }

        if (decl.start) {
            grammar.start = decl.start;
        }
        if (decl.lex) {
            grammar.lex = parseLex(decl.lex.text, decl.lex.position);
        }
        if (decl.grammar) {
            grammar.grammar = decl.grammar;
        }
        if (decl.ebnf) {
            grammar.ebnf = decl.ebnf;
        }
        if (decl.bnf) {
            grammar.bnf = decl.bnf;
        }
        if (decl.operator) {
            if (!grammar.operators) grammar.operators = [];
            grammar.operators.push(decl.operator);
        }
        if (decl.token) {
            if (!grammar.extra_tokens) grammar.extra_tokens = [];
            grammar.extra_tokens.push(decl.token);
        }
        if (decl.token_list) {
            if (!grammar.extra_tokens) grammar.extra_tokens = [];
            decl.token_list.forEach(function (tok) {
                grammar.extra_tokens.push(tok);
            });
        }
        if (decl.parseParams) {
            if (!grammar.parseParams) grammar.parseParams = [];
            grammar.parseParams = grammar.parseParams.concat(decl.parseParams);
        }
        if (decl.parserType) {
            if (!grammar.options) grammar.options = {};
            grammar.options.type = decl.parserType;
        }
        if (decl.include) {
            if (!grammar.moduleInclude) {
                grammar.moduleInclude = decl.include;
            } else {
                grammar.moduleInclude += '\n\n' + decl.include;
            }
        }
        if (decl.actionInclude) {
            if (!grammar.actionInclude) {
                grammar.actionInclude = decl.actionInclude;
            } else {
                grammar.actionInclude += '\n\n' + decl.actionInclude;
            }
        }
        if (decl.options) {
            if (!grammar.options) grammar.options = {};
            // last occurrence of `%options` wins:
            for (let i = 0; i < decl.options.length; i++) {
                grammar.options[decl.options[i][0]] = decl.options[i][1];
            }
        }
        if (decl.unknownDecl) {
            if (!grammar.unknownDecls) grammar.unknownDecls = [];         // [ array of {name,value} pairs ]
            grammar.unknownDecls.push(decl.unknownDecl);
        }
        if (decl.imports) {
            if (!grammar.imports) grammar.imports = [];                   // [ array of {name,path} pairs ]
            grammar.imports.push(decl.imports);
        }
        if (decl.initCode) {
            if (!grammar.moduleInit) {
                grammar.moduleInit = [];
            }
            grammar.moduleInit.push(decl.initCode);       // {qualifier: <name>, include: <source code chunk>}
        }
        if (decl.codeSection) {
            if (!grammar.moduleInit) {
                grammar.moduleInit = [];
            }
            grammar.moduleInit.push(decl.codeSection);                    // {qualifier: <name>, include: <source code chunk>}
        }
        if (decl.onErrorRecovery) {
            if (!grammar.errorRecoveryActions) {
                grammar.errorRecoveryActions = [];
            }
            grammar.errorRecoveryActions.push(decl.onErrorRecovery);      // {qualifier: <name>, include: <source code chunk>}
        }
    };

    // parse an embedded lex section
    function parseLex(text, position) {
        text = text.replace(/(?:^%lex)|(?:\/lex$)/g, '');
        // We want the lex input to start at the given 'position', if any,
        // so that error reports will produce a line number and character index
        // which matches the original input file:
        position = position || {};
        position.range = position.range || [];
        let l = position.first_line | 0;
        let c = position.range[0] | 0;
        let prelude = '';
        if (l > 1) {
            prelude += (new Array(l)).join('\n');
            c -= prelude.length;
        }
        if (c > 3) {
            prelude = '// ' + (new Array(c - 3)).join('.') + prelude;
        }
        return lexParser.parse(prelude + text);
    }

    const ebnf_parser = {
        transform
    };

    var ebnfParser = {
        parse,

        transform,

        // assistant exports for debugging/testing:
        bnf_parser: bnf,
        ebnf_parser,
        bnf_lexer: lexParser,

        version: version$1
    };

    const rmCommonWS$4 = helpers.rmCommonWS;


    /**
     * Output the `raw` input (JSON format or plain STRING containing JSON-formatted data)
     * as JISON source file format in the returned string.
     *
     * @returns a string containing the file contents of an input-equivalent JISON parser/lexer source file.
     * @public
     */
    function grammarPrinter(raw, options) {
        if (typeof raw !== 'object') {
            raw = JSON5__default['default'].parse(raw);
        }
        options = Object.assign({}, options);
        options.showLexer = (options.showLexer !== undefined ? !!options.showLexer : true);
        options.showParser = (options.showParser !== undefined ? !!options.showParser : true);
        switch (String(options.format).toLowerCase()) {
        default:
        case 'jison':
            options.format = 'jison';
            break;

        case 'json5':
            options.format = 'json5';
            break;

        case '.y':
        case '.yacc':
            options.format = 'jison';
            options.showLexer = false;
            options.showParser = true;
            break;

        case '.l':
        case '.lex':
            options.format = 'jison';
            options.showLexer = true;
            options.showParser = false;
            break;
        }

        function makeIndent(num) {
            return (new Array(num + 1)).join(' ');
        }

        function padRight(str, num) {
            return str + (new Array(Math.max(0, num - str.length) + 1)).join(' ');
        }

        function indentAction(src, num) {
            // It's dangerous to indent an action code chunk as it MAY contain **template strings**
            // which MAY get corrupted that way as their actual content would change then!

            // construct fake nesting levels to arrive at the intended start indent value: `num`
            let nesting_levels = num / 2;
            let pre = '// **PRE**';
            let post = '// **POST**';
            for (; nesting_levels > 0; nesting_levels--) {
                pre = 'function x() {\n' + pre;
                post += '\n}';
            }
            src = '\n' + pre + '\n' + src + '\n' + post + '\n';

            let ast = helpers.parseCodeChunkToAST(src, options);
            let new_src = helpers.prettyPrintAST(ast, options);

            let start = new_src.indexOf('// **PRE**');
            let end = new_src.lastIndexOf('// **POST**');
            new_src = new_src
            .substring(start + 10, end)
            .trim();

            return new_src;
        }

        function isEmptyObj(obj) {
            let keys = obj && typeof obj === 'object' && Object.keys(obj);
            return keys && keys.length === 0;
        }

        function isEmptyArr(arr) {
            if (arr && arr instanceof Array) {
                for (let i = 0, len = arr.length; i < len; i++) {
                    if (arr[i] !== undefined) {
                        return false;
                    }
                }
                return true;
            }
            return false;
        }

        // Copied from Crokford's implementation of JSON
        // See https://github.com/douglascrockford/JSON-js/blob/e39db4b7e6249f04a195e7dd0840e610cc9e941e/json2.js#L195
        // Begin
        let escapable = /[\\\"\x00-\x1f\x7f-\x9f\u00ad\u0600-\u0604\u070f\u17b4\u17b5\u200c-\u200f\u2028-\u202f\u2060-\u206f\ufeff\ufff0-\uffff]/g;
        let meta = { // table of character substitutions
            '\b': '\\b',
            '\t': '\\t',
            '\n': '\\n',
            '\f': '\\f',
            '\r': '\\r',
            '"' : '\\"',
            '\\': '\\\\'
        };

        function escapeString(string) {
            // If the string contains no control characters, no quote characters, and no
            // backslash characters, then we can safely slap some quotes around it.
            // Otherwise we must also replace the offending characters with safe escape
            // sequences.
            escapable.lastIndex = 0;
            return escapable.test(string) ? '"' + string.replace(escapable, function (a) {
                let c = meta[a];
                return typeof c === 'string' ?
                    c :
                    '\\u' + ('0000' + a.charCodeAt(0).toString(16)).slice(-4);
            }) + '"' : '"' + string + '"';
        }

        let ref_list;
        let ref_names;

        // create a deep copy of the input, so we can delete the parts we converted and dump the remainder
        // so that we always output the entire thing, even when we don't know all the details about the
        // actual input:
        function deepClone(from, sub) {
            if (sub == null) {
                ref_list = [];
                ref_names = [];
                sub = 'root';
            }
            if (typeof from === 'function') return '[Function]';
            if (from == null || typeof from !== 'object') return from;
            if (from.constructor !== Object && from.constructor !== Array) {
                return from;
            }

            for (let i = 0, len = ref_list.length; i < len; i++) {
                if (ref_list[i] === from) {
                    return '[Circular/Xref:' + ref_names[i] + ']';   // circular or cross reference
                }
            }
            ref_list.push(from);
            ref_names.push(sub);
            sub += '.';

            let to = new from.constructor();
            for (let name in from) {
                to[name] = deepClone(from[name], sub + name);
            }
            return to;
        }


        let originalInput = raw;
        raw = deepClone(raw);

        let lex_out_str = '';
        if (raw.lex) {
            var lex_pre = [];
            let lex_rules = [];
            let lex_post = [];

            {
                let src = raw.lex.macros;
                delete raw.lex.macros;
                if (src && !isEmptyObj(src)) {
                    lex_pre.push(rmCommonWS$4`
                    // macros:
                `);

                    let keylen = 0;
                    for (let key in src) {
                        keylen = Math.max(keylen, key.length);
                    }
                    console.log('macros keylen:', keylen);
                    keylen = ((keylen / 4) | 0) * 4 + 4;
                    console.log('macros keylen B:', keylen);
                    for (let key in src) {
                        lex_pre.push(padRight(key, keylen) + src[key]);
                    }

                    lex_pre.push(rmCommonWS$4`
                    // END of the lexer macros.
                `);
                }
            }

            {
                let src = raw.lex.unknownDecls;
                delete raw.lex.unknownDecls;
                if (src && !isEmptyObj(src)) {
                    lex_pre.push(rmCommonWS$4`
                    // unknown declarations:
                `);

                    for (let i = 0, len = src.length; i < len; i++) {
                        let entry = src[i];
                        let key = entry.name;
                        let value = entry.value;

                        lex_pre.push('%' + key + ' ' + value);
                    }

                    lex_pre.push(rmCommonWS$4`
                    // END of unknown declarations.
                `);
                }
            }

            {
                let src = raw.lex.options;
                delete raw.lex.options;
                if (src && !isEmptyObj(src)) {
                    lex_pre.push(rmCommonWS$4`
                    // options:
                `);

                    for (let key in src) {
                        let value = src[key];
                        if (value) {
                            lex_pre.push('%options ' + key + '=' + value);
                        } else {
                            lex_pre.push('%options ' + key);
                        }
                    }
                }
            }

            {
                let src = raw.lex.startConditions;
                delete raw.lex.startConditions;
                if (src && !isEmptyObj(src)) {
                    for (let key in src) {
                        let value = src[key];

                        lex_pre.push((value ? '%x ' : '%s ') + key);
                    }
                }
            }

            {
                let src = raw.lex.actionInclude;
                delete raw.lex.actionInclude;
                if (src && src.trim()) {
                    lex_pre.push('%{\n' + indentAction(src.trim(), 4) + '\n%}');
                }
            }

            {
                let src = raw.lex.rules;
                delete raw.lex.rules;
                if (src) {
                    for (let i = 0, len = src.length; i < len; i++) {
                        let entry = src[i];
                        let key = entry[0];
                        let action = indentAction(entry[1], 4);

                        let actionHasLF = /[\r\n]/.test(action);
                        console.log('indented action:', {
                            entry: entry[1],
                            action,
                            actionHasLF
                        });
                        if (key.length <= 12) {
                            if (!actionHasLF) {
                                lex_rules.push(padRight(key, 16) + indentAction(action, 16));
                            } else {
                                lex_rules.push(padRight(key, 16) + '%' + indentAction('{ ' + action + ' }', 16) + '%');
                            }
                        } else if (!actionHasLF) {
                            lex_rules.push(key, makeIndent(16) + indentAction(action, 16));
                        } else {
                            lex_rules.push(key, makeIndent(16) + '%' + indentAction('{ ' + action + ' }', 16) + '%');
                        }
                    }
                }
            }

            {
                let src = raw.lex.moduleInclude;
                delete raw.lex.moduleInclude;
                if (src && src.trim()) {
                    lex_post.push(indentAction(src.trim(), 0));
                }
            }

            {
                let out = '';

                if (!isEmptyObj(raw.lex)) {
                    // dump the remainder as a comment:
                    let rem = JSON5__default['default'].stringify(raw.lex, null, 2);
                    out += rmCommonWS$4`
                    /*
                     * Lexer stuff that's unknown to the JISON prettyPrint service:
                     *
                     * ${rem.replace(/\*\//g, '*\\/')}
                     */
                
                `;
                }
                delete raw.lex;

                out += lex_pre.join('\n') + '\n\n';
                out += rmCommonWS$4`

                %%

            ` + lex_rules.join('\n') + '\n\n';
                if (lex_post.length > 0) {
                    out += rmCommonWS$4`

                    %%

                ` + lex_post.join('\n') + '\n\n';
                }
                lex_out_str = out;
            }
        }

        let grammar_pre = [];
        let grammar_mid = [];
        let ebnf_rules = [];
        let bnf_rules = [];
        let grammar_post = [];

        let fmtprod = function fmtprod(rule, prodset) {
            let backup = deepClone(prodset);

            rule += prodset[0] ? prodset[0] : '%epsilon';
            let prec = null;
            let lead = rule.split(/\r\n\|\n|\r/).pop();
            delete prodset[0];

            if (prodset.length === 3 && typeof prodset[2] === 'object') {
                prec = '%prec ' + prodset[2].prec;
                if (lead.length < 12) {
                    rule += makeIndent(12 - lead.length);
                }
                rule += '  ' + prec;

                delete prodset[2].prec;
                if (isEmptyObj(prodset[2])) {
                    delete prodset[2];
                }
            } else if (prodset.length === 2 && typeof prodset[1] === 'object') {
                prec = '%prec ' + prodset[1].prec;
                if (lead.length < 12) {
                    rule += makeIndent(12 - lead.length);
                }
                rule += '  ' + prec;

                delete prodset[1].prec;
                if (isEmptyObj(prodset[1])) {
                    delete prodset[1];
                }
            }
            if (typeof prodset[1] === 'string') {
                let action = prodset[1];
                if (lead.length < 12 - 1) {
                    rule += makeIndent(12 - lead.length) + indentAction('{ ' + action + ' }', 12);
                } else {
                    rule += '\n' + makeIndent(12) + indentAction('{ ' + action + ' }', 12);
                }
                delete prodset[1];
            }

            if (isEmptyArr(prodset)) {
                prodset.length = 0;
            } else {
                prodset = backup;
            }
            return rule;
        };

        let grammarfmt = function grammarfmt(src) {
            let dst = [];

            for (let key in src) {
                let prodset = src[key];
                let rule;
                console.log('format one rule:', {
                    key,
                    prodset
                });

                if (typeof prodset === 'string') {
                    rule = fmtprod(key + ' : ', [ prodset ]) + ';';
                    delete src[key];
                } else if (prodset instanceof Array) {
                    if (prodset.length === 1) {
                        if (typeof prodset[0] === 'string') {
                            rule = fmtprod(key + ' : ', [ prodset ]) + ';';
                            delete src[key];
                        } else if (prodset[0] instanceof Array) {
                            rule = fmtprod(key + ' : ', prodset[0]);
                            rule += '\n    ;';
                            if (prodset[0].length === 0) {
                                delete src[key];
                            }
                        } else {
                            rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[0];
                        }
                    } else if (prodset.length > 1) {
                        if (typeof prodset[0] === 'string') {
                            rule = fmtprod(key + '\n    : ', [ prodset[0] ]);
                            delete prodset[0];
                        } else if (prodset[0] instanceof Array) {
                            rule = fmtprod(key + '\n    : ', prodset[0]);
                            if (prodset[0].length === 0) {
                                delete prodset[0];
                            }
                        } else {
                            rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[0];
                        }
                        for (let i = 1, len = prodset.length; i < len; i++) {
                            if (typeof prodset[i] === 'string') {
                                rule += fmtprod('\n    | ', [ prodset[i] ]);
                                delete prodset[i];
                            } else if (prodset[i] instanceof Array) {
                                rule += fmtprod('\n    | ', prodset[i]);
                                if (prodset[i].length === 0) {
                                    delete prodset[i];
                                }
                            } else {
                                rule += '\n    | **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[i];
                            }
                        }
                        rule += '\n    ;';

                        if (isEmptyArr(prodset)) {
                            delete src[key];
                        }
                    }
                } else {
                    rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset;
                }
                dst.push(rule);
            }

            return dst;
        };

        {
            let src = raw.ebnf;
            if (src) {
                ebnf_rules = grammarfmt(src);

                if (isEmptyObj(src)) {
                    delete raw.ebnf;
                }
            }
        }

        {
            let src = raw.bnf;
            //delete raw.bnf;
            if (src) {
                bnf_rules = grammarfmt(src);

                if (isEmptyObj(src)) {
                    delete raw.bnf;
                }
            }
        }

        {
            let src = raw.unknownDecls;
            delete raw.unknownDecls;
            if (src && !isEmptyObj(src)) {
                lex_pre.push(rmCommonWS$4`
                // unknown declarations:
            `);

                for (let i = 0, len = src.length; i < len; i++) {
                    let entry = src[i];
                    let key = entry.name;
                    let value = entry.value;

                    lex_pre.push('%' + key + ' ' + value);
                }

                lex_pre.push(rmCommonWS$4`
                // END of unknown declarations.
            `);
            }
        }

        //let src = raw.lex;
        //delete raw.lex;
        //if (src) {
        if (lex_out_str.trim() && options.showLexer) {
            grammar_pre.push(rmCommonWS$4`
            // ============================== START lexer section =========================== 
            
            %lex
            
            ${lex_out_str}

            /lex

            // ============================== END lexer section =============================

        `);
        }

        {
            let src = raw.options;
            delete raw.options;
            if (src && !isEmptyObj(src)) {
                let a = [];
                for (let key in src) {
                    let value = src[key];
                    switch (key) {
                    default:
                        if (value !== true) {
                            a.push('options', '%options ' + key + '=' + value);
                        } else {
                            a.push('options', '%options ' + key);
                        }
                        break;

                    case 'ebnf':
                        if (value) {
                            a.push(key, '%ebnf');
                        }
                        break;

                    case 'type':
                        if (value) {
                            a.push(key, '%parser-type ' + value);
                        }
                        break;

                    case 'debug':
                        if (typeof value !== 'boolean') {
                            a.push(key, '%debug ' + value);
                        } else if (value) {
                            a.push(key, '%debug');
                        }
                        break;
                    }
                }
                let type = null;
                for (let i = 0, len = a.length; i < len; i += 2) {
                    let t = a[i];
                    let line = a[i + 1];
                    if (t !== type) {
                        type = t;
                        grammar_pre.push('');
                    }
                    grammar_pre.push(line);
                }
                grammar_pre.push('');
            }
        }

        {
            let src = raw.imports;
            if (src) {
                let clean = true;
                for (let i = 0, len = src.length; i < len; i++) {
                    let entry = src[i];

                    grammar_pre.push('%import ' + entry.name + '  ' + entry.path);
                    delete entry.name;
                    delete entry.path;
                    if (isEmptyObj(entry)) {
                        delete src[i];
                    } else {
                        clean = false;
                    }
                }
                if (clean) {
                    delete raw.imports;
                }
            }
        }

        {
            let src = raw.moduleInit;
            if (src) {
                let clean = true;
                for (let i = 0, len = src.length; i < len; i++) {
                    let entry = src[i];

                    grammar_pre.push('%code ' + entry.qualifier + '  ' + entry.include);
                    delete entry.qualifier;
                    delete entry.include;
                    if (isEmptyObj(entry)) {
                        delete src[i];
                    } else {
                        clean = false;
                    }
                }
                if (clean) {
                    delete raw.moduleInit;
                }
            }
        }

        {
            let src = raw.operators;
            if (src) {
                let clean = true;
                for (let i = 0, len = src.length; i < len; i++) {
                    let entry = src[i];
                    let tokens = entry[1];
                    let line = '%' + entry[0] + ' ';

                    for (let t = 0, tlen = tokens.length; t < tlen; t++) {
                        line += ' ' + tokens[t];
                    }

                    grammar_pre.push(line);

                    if (entry.length === 2) {
                        delete src[i];
                    } else {
                        clean = false;
                    }
                }
                if (clean) {
                    delete raw.operators;
                }
            }
        }

        {
            let src = raw.extra_tokens;
            if (src) {
                let clean = true;
                for (let i = 0, len = src.length; i < len; i++) {
                    let entry = src[i];
                    let line = '%token ' + entry.id;

                    if (entry.type) {
                        line += ' <' + entry.type + '>';
                        delete entry.type;
                    }
                    if (entry.value) {
                        line += ' ' + entry.value;
                        delete entry.value;
                    }
                    if (entry.description) {
                        line += ' ' + escapeString(entry.description);
                        delete entry.description;
                    }

                    grammar_pre.push(line);

                    delete entry.id;
                    if (isEmptyObj(entry)) {
                        delete src[i];
                    } else {
                        clean = false;
                    }
                }
                if (clean) {
                    delete raw.extra_tokens;
                }
            }
        }

        {
            let src = raw.parseParams;
            delete raw.parseParams;
            if (src) {
                grammar_pre.push('%parse-param ' + src.join(' '));
            }
        }

        {
            let src = raw.start;
            delete raw.start;
            if (src) {
                grammar_pre.push('%start ' + src);
            }
        }

        {
            let src = raw.moduleInclude;
            delete raw.moduleInclude;
            if (src && src.trim()) {
                grammar_post.push(indentAction(src.trim(), 0));
            }
        }

        {
            let src = raw.actionInclude;
            delete raw.actionInclude;
            if (src && src.trim()) {
                grammar_mid.push('%{\n' + indentAction(src.trim(), 4) + '\n%}');
            }
        }

        {
            let out = '';

            if (!isEmptyObj(raw)) {
                // dump the remainder as a comment:
                let rem = JSON5__default['default'].stringify(raw, null, 2);
                out += rmCommonWS$4`
                /*
                 * Parser stuff that's unknown to the JISON prettyPrint service:
                 *
                 * ${rem.replace(/\*\//g, '*\\/')}
                 */
            
            `;
                // delete raw;
            }

            if (!options.showParser) {
                out += lex_out_str;
            } else {
                out += grammar_pre.join('\n') + '\n\n';
                out += rmCommonWS$4`

                %%

            `;
                if (grammar_mid.length > 0) {
                    out += grammar_mid.join('\n') + '\n\n';
                }
                if (ebnf_rules.length > 0) {
                    if (bnf_rules.length > 0) {
                    // dump the original EBNF grammar as source and dump the BNF derivative as COMMENT:
                        let bnf_deriv = bnf_rules.join('\n\n');
                        let a = bnf_deriv.split(/\r\n|\n|\r/).map(function (line) {
                            return '// ' + line;
                        });

                        out += rmCommonWS$4`
                        //
                        // JISON says:
                        //
                        // This is a EBNF grammar. The resulting **BNF** grammar has been
                        // reproduced here for your convenience:
                        //
                        // ---------------------------- START ---------------------------
                        ${a.join('\n')}
                        // ---------------------------- END OF BNF grammar --------------
                        //


                    `;
                    }
                    out += ebnf_rules.join('\n\n') + '\n\n';
                } else if (bnf_rules.length > 0) {
                    out += bnf_rules.join('\n\n') + '\n\n';
                }

                if (grammar_post.length > 0) {
                    out += rmCommonWS$4`

                    %%

                ` + grammar_post.join('\n') + '\n\n';
                }
            }

            if (options.format === 'json5') {
                let a = out.split(/\r\n|\n|\r/).map(function (line) {
                    return '// ' + line;
                });

                out = rmCommonWS$4`
                //
                // JISON says:
                //
                // The JISON ${options.showParser ? 'grammar' : 'lexer'} has been
                // reproduced here for your convenience:
                //
                // ---------------------------- START ---------------------------
                ${a.join('\n')}
                // ---------------------------- END -----------------------------
                //

            `;

                // process the original input once again: this time via JSON5
                raw = deepClone(originalInput);

                if (!options.showLexer) {
                    delete raw.lex;
                    out += JSON5__default['default'].stringify(raw, null, 2);
                } else if (!options.showParser) {
                    out += JSON5__default['default'].stringify(raw.lex, null, 2);
                }
            }

            return out;
        }
    }

    // Jison, an LR(0), SLR(1), LARL(1), LR(1) Parser Generator
    const rmCommonWS$5 = helpers.rmCommonWS;
    const mkIdentifier$4  = helpers.mkIdentifier;
    const code_exec$1  = helpers.exec;


    const version$2 = '0.7.0-220';

    let devDebug = 0;

    function chkBugger$3(src) {
        src = '' + src;
        if (src.match(/\bcov_\w+/)) {
            // TODO
            console.error('### ISTANBUL COVERAGE CODE DETECTED ###\n', src);
        }
    }


    // WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
    //
    // This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
    const ID_REGEX_BASE$3 = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';

    let Jison$1 = {
        version: version$2
    };

    // see also ./lib/cli.js
    const defaultJisonOptions = {
        moduleType: 'commonjs',
        debug: false,
        enableDebugLogs: false,
        numExpectedConflictStates: 0,
        json: false,
        type: 'lalr',                   // CLI: --parserType option
        compressTables: 2,              // 0, 1, 2
        outputDebugTables: false,
        noDefaultResolve: false,
        defaultActionMode: [ 'classic', 'merge' ],       // {classic, ast, none, skip}, {classic, ast, merge, none, skip}
        testCompileActionCode: 'parser:*,lexer:*',
        noTryCatch: false,
        hasPartialLrUpgradeOnConflict: true,
        errorRecoveryTokenDiscardCount: 3,
        exportAllTables: false,
        exportSourceCode: false,
        noMain: true,                   // CLI: not:(--main option)
        moduleMain: null,               // `main()` function source code if `!noMain` is true
        moduleMainImports: null,        // require()/import statements required by the `moduleMain` function source code if `!noMain` is true
        tokenStack: false,
        dumpSourceCodeOnFailure: true,
        throwErrorOnCompileFailure: true,

        moduleName: undefined,
        defaultModuleName: 'parser',
        file: undefined,
        outfile: undefined,
        inputPath: undefined,
        inputFilename: undefined,
        lexfile: undefined,
        warn_cb: undefined,  // function(msg) | true (= use Jison.Print) | false (= throw Exception)

        parseParams: undefined,
        parserErrorsAreRecoverable: false,
        lexerErrorsAreRecoverable: false,
        ranges: undefined,
        showSource: false,
        reportStats: false,
        exportAST: false,               // output grammar in JSON / JSON5 format (CLI version of JISON only); this will be a copy of `grammar`
        prettyCfg: true,                // use `prettier` (or not) to (re)format the generated parser code.

        // internal analysis flags which MAY be forced by special %options
        // to override default jison behaviour for a given grammar.
        //
        // Do note that some analysis options CANNOT be overridden directly
        // as that would allow the user to produce GUARANTEED DEFECTIVE PARSERS
        // when they utilize this advanced behaviour modification power.
        //
        //    actionsAreAllDefault,
        actionsUseLocationAssignment: false,
        actionsUseLocationTracking: false,
        actionsUseParseError: false,
        actionsUseValueAssignment: false,
        actionsUseValueTracking: false,
        actionsUseYYCLEARIN: false,
        actionsUseYYERROK: false,
        actionsUseYYERROR: false,
        actionsUseYYLENG: false,
        actionsUseYYLINENO: false,
        actionsUseYYLOC: false,
        actionsUseYYRECOVERING: false,
        actionsUseYYRULELENGTH: false,
        actionsUseYYMERGELOCATIONINFO: false,
        actionsUseYYSSTACK: false,
        actionsUseYYSTACK: false,
        actionsUseYYSTACKPOINTER: false,
        actionsUseYYTEXT: false,
        hasErrorRecovery: false,
        hasErrorReporting: false
    };

    Jison$1.defaultJisonOptions = defaultJisonOptions;



    // Merge sets of options.
    //
    // Convert alternative jison option names to their base option.
    //
    // The *last* option set which overrides the default wins, where 'override' is
    // defined as specifying a not-undefined value which is not equal to the
    // default value.
    //
    // When the FIRST argument is STRING "NODEFAULT", then we MUST NOT mix the
    // default values avialable in Jison.defaultJisonOptions.
    //
    // Return a fresh set of options.
    /** @public */
    function mkStdOptions$1(...args) {
        let h = Object.prototype.hasOwnProperty;

        let opts = {};
        //let args = Array.prototype.concat.apply([], args);
        // clone defaults, so we do not modify those constants?
        if (args[0] !== 'NODEFAULT') {
            args.unshift(Jison$1.defaultJisonOptions);
        } else {
            args.shift();
        }

        for (let i = 0, len = args.length; i < len; i++) {
            let o = args[i];
            if (!o) continue;

            // clone input (while camel-casing the options), so we do not modify those either.
            let o2 = {};

            for (let p in o) {
                if (typeof o[p] !== 'undefined' && h.call(o, p)) {
                    o2[mkIdentifier$4(p)] = o[p];
                }
            }

            // now clean them options up:
            if (typeof o2.main !== 'undefined') {
                o2.noMain = !o2.main;
            }

            if (typeof o2.noDefaultAction !== 'undefined') {
                throw new Error('option "no-default-action" has been OBSOLETED. Use "default-action-mode=[for-value,for-location]" instead (see \'jison --help\' for usage description).');
            }
            if (typeof o2.defaultAction !== 'undefined') {
                throw new Error('option "default-action" has been OBSOLETED. Use "default-action-mode=[for-value,for-location]" instead (see \'jison --help\' for usage description).');
            }
            if (typeof o2.hasDefaultResolve !== 'undefined') {
                o2.noDefaultResolve = !o2.hasDefaultResolve;
            }
            switch (typeof o2.defaultActionMode) {
            case 'undefined':
                break;

            case 'object':
                if (typeof o2.defaultActionMode.slice === 'function') {
                    // make a copy of `defaultActionMode` to ensure the default source cannot be mutated through this `opts` instance:
                    o2.defaultActionMode = o2.defaultActionMode.slice(0);
                    break;
                }
                // fall through
            case 'string':
                let a = String(o2.defaultActionMode).split(',').map(function (m) {
                    return m.trim();
                });
                if (a.length === 1) {
                    a[1] = a[0];
                }
                o2.defaultActionMode = a;
                break;

            default:
                throw new Error('option "default-action-mode" must be a STRING or 2-element ARRAY value, when specified (see \'jison --help\' for usage description).');
            }

            if (typeof o2.hasTryCatch !== 'undefined') {
                o2.noTryCatch = !o2.hasTryCatch;
            }
            if (typeof o2.parserType !== 'undefined') {
                o2.type = o2.parserType;
            }
            if (typeof o2.moduleType !== 'undefined') {
                switch (o2.moduleType) {
                case 'js':
                case 'amd':
                case 'es':
                case 'commonjs':
                    break;

                // aliases a la `rollup` c.s.:
                case 'cjs':
                    o2.moduleType = 'commonjs';
                    break;

                case 'iife':
                    o2.moduleType = 'js';
                    break;

                case 'umd':
                    o2.moduleType = 'amd';
                    break;

                default:
                    throw new Error('unsupported moduleType: ' + dquote(opt.moduleType));
                }
            }

            if (o2.errorRecoveryTokenDiscardCount != null) {
                if (typeof o2.errorRecoveryTokenDiscardCount !== 'number') {
                    throw new Error('options.errorRecoveryTokenDiscardCount should be a number or undefined; instead it has type: ' + typeof o2.errorRecoveryTokenDiscardCount);
                }
            }

            delete o2.parserType;
            delete o2.main;
            delete o2.hasDefaultResolve;
            delete o2.hasTryCatch;
            delete o2.noDefaultAction;

            // special check for `moduleName` to ensure we detect the 'default' moduleName entering from the CLI
            // NOT overriding the moduleName set in the grammar definition file via an `%options` entry:
            if (o2.moduleName === o2.defaultModuleName) {
                delete o2.moduleName;
            }

            // now see if we have an overriding option here:
            for (let p in o2) {
                if (h.call(o2, p)) {
                    if (typeof o2[p] !== 'undefined') {
                        opts[p] = o2[p];
                    }
                }
            }
        }

        return opts;
    }

    // set up export/output attributes of the `options` object instance
    function prepExportStructures$1(options) {
        // set up the 'option' `exportAllTables` as a hash object for returning
        // all generated tables to the caller
        let exportDest = options.exportAllTables;
        if (!exportDest || typeof exportDest !== 'object') {
            exportDest = {
                enabled: !!exportDest
            };
        } else if (typeof exportDest.enabled !== 'boolean') {
            exportDest.enabled = true;
        }
        options.exportAllTables = exportDest;

        // set up the 'option' `exportSourceCode` as a hash object for returning
        // all generated source code chunks to the caller
        let exportSourceCode = options.exportSourceCode;
        if (!exportSourceCode || typeof exportSourceCode !== 'object') {
            exportSourceCode = {
                enabled: !!exportSourceCode
            };
        } else if (typeof exportSourceCode.enabled !== 'boolean') {
            exportSourceCode.enabled = true;
        }
        options.exportSourceCode = exportSourceCode;
    }

    // Autodetect if the input grammar and optional lexer spec is in JSON or JISON
    // format when the `options.json` flag is `true`.
    //
    // Produce the JSON parse result when these are JSON formatted already as that
    // would save us the trouble of doing this again, anywhere else in the JISON
    // compiler/generator.
    //
    // Otherwise return the *parsed* grammar and optional lexer specs as they have
    // been processed through EBNFParser and LEXParser respectively.
    function autodetectAndConvertToJSONformat$1(grammar, optionalLexerSection, options) {
        let chk_g = null;
        let chk_l = null;
        let ex1, err;

        if (typeof grammar === 'string') {
            if (options.json) {
                try {
                    chk_g = JSON5__default['default'].parse(grammar);

                    // When JSON5-based parsing of the grammar succeeds, this implies the grammar is specified in `JSON mode`
                    // *OR* there's a JSON/JSON5 format error in the input:
                } catch (e) {
                    ex1 = e;
                }
            }
            if (!chk_g) {
                try {
                    chk_g = ebnfParser.parse(grammar);
                } catch (e) {
                    if (options.json) {
                        // When both JSON5 and JISON input modes barf a hairball, assume the most important
                        // error is the JISON one (show that one first!), while it MAY be a JSON5 format
                        // error that triggered it (show that one last!).
                        //
                        // Also check for common JISON errors which are obviously never triggered by any
                        // odd JSON5 input format error: when we encounter such an error here, we don't
                        // confuse matters and forget about the JSON5 fail as it's irrelevant:
                        const commonErrors = [
                            /does not compile/,
                            /you did not correctly separate trailing code/,
                            /You did not specify/,
                            /You cannot specify/,
                            /must be qualified/,
                            /%start/,
                            /%token/,
                            /%import/,
                            /%include/,
                            /%options/,
                            /%parse-params/,
                            /%parser-type/,
                            /%epsilon/,
                            /definition list error/,
                            /token list error/,
                            /declaration error/,
                            /should be followed/,
                            /should be separated/,
                            /an error in one or more of your lexer regex rules/,
                            /an error in your lexer epilogue/,
                            /unsupported definition type/
                        ];
                        let cmnerr = commonErrors.filter(function check(re) {
                            return e.message.match(re);
                        });
                        if (cmnerr.length > 0) {
                            err = e;
                        } else {
                            err = new Error('Could not parse jison grammar in JSON AUTODETECT mode:\nin JISON Mode we get Error: ' + e.message + '\nwhile JSON5 Mode produces Error: ' + ex1.message);
                            err.secondary_exception = e;
                            err.stack = ex1.stack;
                        }
                    } else {
                        err = new Error('Could not parse jison grammar\nError: ' + e.message);
                        err.stack = e.stack;
                    }
                    throw err;
                }
            }

            // Save time! Don't reparse the entire grammar *again* inside the code generators when that's not necessary:
            // if (chk_g) {
            //   grammar = chk_g;
            // }
        } else {
            chk_g = grammar;
        }

        // Now the same treatment for the lexer:
        if (chk_g && optionalLexerSection) {
            if (chk_g.lex) {
                throw new Error('Cannot invoke with both a lexer section in the grammar input and a separate lexer input at the same time!');
            }

            if (typeof optionalLexerSection === 'string') {
                if (options.json) {
                    try {
                        chk_l = JSON5__default['default'].parse(optionalLexerSection);

                        // When JSON5-based parsing of the lexer spec succeeds, this implies the lexer spec is specified in `JSON mode`
                        // *OR* there's a JSON/JSON5 format error in the input:
                    } catch (e) {
                        ex1 = e;
                    }
                }
                if (!chk_l) {
                    // // WARNING: the lexer may receive options specified in the **grammar spec file**,
                    // //          hence we should mix the options to ensure the lexParser always
                    // //          receives the full set!
                    // //
                    // // make sure all options are 'standardized' before we go and mix them together:
                    // options = mkStdOptions(grammar.options, options);
                    try {
                        chk_l = lexParser.parse(optionalLexerSection);
                    } catch (e) {
                        if (options.json) {
                            err = new Error('Could not parse lexer spec in JSON AUTODETECT mode\nError: ' + ex1.message + ' (' + e.message + ')');
                            err.secondary_exception = e;
                            err.stack = ex1.stack;
                        } else {
                            err = new Error('Could not parse lexer spec\nError: ' + e.message);
                            err.stack = e.stack;
                        }
                        throw err;
                    }
                }
            } else {
                chk_l = optionalLexerSection;
            }

            // Save time! Don't reparse the entire lexer spec *again* inside the code generators when that's not necessary:
            if (chk_l) {
                chk_g.lex = chk_l;
            }
        }

        return chk_g;
    }

    Jison$1.rmCommonWS = rmCommonWS$5;
    Jison$1.mkStdOptions = mkStdOptions$1;
    Jison$1.camelCase = helpers.camelCase;
    Jison$1.mkIdentifier = mkIdentifier$4;
    Jison$1.autodetectAndConvertToJSONformat = autodetectAndConvertToJSONformat$1;

    // detect print
    if (typeof console !== 'undefined' && console.log) {
        // wrap console.log to prevent 'Illegal Invocation' exceptions when Jison.print() is used, e.g.
        // in the web tryout pages where this code is employed.
        Jison$1.print = function console_log(/* ... */) {
            let args = Array.prototype.slice.call(arguments, 0);
            args.unshift('');           // prevent `%.` printf-style expansions; see https://nodejs.org/api/console.html#console_console_log_data_args
            console.log.apply(console, args);
        };
    } else if (typeof puts !== 'undefined') {
        Jison$1.print = function puts_print() {
            puts([].join.call(arguments, ' '));
        };
    } else if (typeof print !== 'undefined') {
        Jison$1.print = print;
    } else {
        Jison$1.print = function no_op_print() {};
    }

    // Also export other APIs: the JISON module should act as a 'facade' for the others,
    // so applications using the JISON compiler itself can rely on it providing everything
    // in a guaranteed compatible version as it allows userland code to use the precise
    // same APIs as JISON will be using itself:
    Jison$1.Lexer = RegExpLexer;
    Jison$1.ebnfParser = ebnfParser;
    Jison$1.lexParser = lexParser;
    Jison$1.codeExec = code_exec$1;
    Jison$1.XRegExp = XRegExp__default['default'];
    Jison$1.recast = recast__default['default'];
    Jison$1.astUtils = astUtils__default['default'];
    //Jison.prettier = prettier;
    //Jison.codeShift = codeshift;
    Jison$1.JSON5 = JSON5__default['default'];
    Jison$1.prettyPrint = grammarPrinter;


    // iterator utility
    function each(obj, func) {
        if (typeof obj.forEach === 'function') {
            obj.forEach(func);
        } else {
            let p;
            for (p in obj) {
                if (obj.hasOwnProperty(p)) {
                    func.call(obj, obj[p], p, obj);
                }
            }
        }
    }

    // This was Set.union() but it's not about *Set* at all: it is purely *Array* oriented!
    function union(a, b) {
        assert__default['default'](Array.isArray(a));
        assert__default['default'](Array.isArray(b));
        // Naive indexOf()-based scanning delivers a faster union()
        // (which takes the brunt of the load for large grammars):
        // for examples/jscore this drops 13.2 seconds down to
        // 8.9 seconds total time spent in the generator!
        //
        // The idea there was that the FIRST/FOLLOW sets are generally
        // quite small; bad cases could run this up to > 128 entries
        // to scan through, but overall the FIRST and FOLLOW sets will
        // be a few tens of entries at best, and thus it was expected
        // that a naive scan would be faster than hash-object creation
        // and O(1) checking that hash... Turns out I was right.
        //
        // The 'arbitrary' threshold of 52 entries in the array to check
        // against is probably at or near the worst-case FIRST/FOLLOW set
        // site for this jscore grammar as the naive scan consistently
        // outperformed the old smarter hash-object code for smaller
        // thresholds (10, 20, 32, 42!)
        let k, len;

        if (a.length > 52) {
            let ar = {};
            for (k = 0, len = a.length; k < len; k++) {
                ar[a[k]] = true;
            }
            for (k = 0, len = b.length; k < len; k++) {
                if (!ar[b[k]]) {
                    a.push(b[k]);
                }
            }
        } else {
            let bn = [];
            for (k = 0, len = b.length; k < len; k++) {
                if (a.indexOf(b[k]) < 0) {
                    bn.push(b[k]);
                }
            }
            a = a.concat(bn);
        }
        return a;
    }

    let Nonterminal = typal.construct({
        constructor: function Nonterminal(symbol) {
            this.symbol = symbol;
            this.productions = new Set$1();
            this.first = [];
            this.follows = [];
            this.nullable = false;
        },
        toString: function Nonterminal_toString() {
            let str = this.symbol;
            let attr_str = [];

            if (this.nullable) {
                attr_str.push('nullable');
            }

            if (attr_str.length) {
                str += '        [' + attr_str.join(' ') + ']';
            }
            str += '\n  Firsts:  [' + this.first.join(']  [') + ']';
            str += '\n  Follows: [' + this.follows.join(']  [') + ']';
            str += '\n  Productions:\n    ' + this.productions.join('\n    ');

            return str;
        }
    });

    let Production = typal.construct({
        constructor: function Production(symbol, handle, id, handle_aliases, handle_action) {
            this.symbol = symbol;
            this.handle = handle;
            this.nullable = false;
            this.id = id;
            this.aliases = handle_aliases;
            this.action = handle_action;
            this.first = [];
            this.follows = [];
            this.precedence = 0;
            this.reachable = false;
        },
        toString: function Production_toString() {
            let str = this.symbol;

            let attr_str = [];

            if (this.nullable) {
                attr_str.push('~');
            }
            if (this.precedence) {
                attr_str.push('@' + this.precedence);
            }
            if (!this.reachable) {
                attr_str.push('*RIP*');
            }

            if (attr_str.length) {
                str += '[' + attr_str.join(' ') + ']';
            }
            str += ' -> ' + this.handle.join(' ');

            return str;
        },
        describe: function Production_describe() {
            let str = this.symbol;

            let attr_str = [];

            if (this.nullable) {
                attr_str.push('nullable');
            }
            if (this.precedence) {
                attr_str.push('precedence: ' + this.precedence);
            }

            if (attr_str.length) {
                str += '        [' + attr_str.join(' ') + ']';
            }
            str += '\n  Firsts: [' + this.first.join(']  [') + ']';
            str += '\n  -->  ' + this.handle.join(' ');

            return str;
        }
    });



    let generator = typal.beget();

    // `optionalLexerSection` is an optional {String} argument, specifying the lexer rules.
    // May only be specified when the specified `grammar` also is a yet-unparsed
    // {String} defining the grammar.
    //
    // Hence these invocations are legal:
    //
    // - `Generator("String")`
    //   --> `String` contains entire grammar, including
    //   optional `%lex` lexer rules section
    //
    //
    // - `Generator("String-1", "String-2")`
    //   --> The `String-1` string contains grammar, *excluding* `%lex` lexer rules section,
    //   while the `String-2` string contains the `%lex` lexer rules section
    //
    //
    // - `Generator("String", {Options})`
    //   --> `String` contains entire grammar, including
    //   optional `%lex` lexer rules section
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // - `Generator("String", NULL, {Options})`
    //   --> `String` contains entire grammar, including
    //   optional `%lex` lexer rules section
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // - `Generator("String-1", "String-2", {Options})`
    //   --> The `String-1` string contains grammar, *excluding* `%lex` lexer rules section,
    //   while the `String-2` string contains the `%lex` lexer rules section
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // - `Generator({Grammar})`
    //   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
    //   including optional `%lex` lexer rules section in its `.lex` member.
    //
    //
    // - `Generator({Grammar}, {Options})`
    //   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
    //   including optional `%lex` lexer rules section in its `.lex` member.
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // - `Generator({Grammar}, NULL, {Options})`
    //   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
    //   including optional `%lex` lexer rules section in its `.lex` member.
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // - `Generator({Grammar}, "String-2")`
    //   --> The `Grammar` object contains grammar, *excluding* `%lex` lexer rules section,
    //   while the `String-2` string contains the `%lex` lexer rules section
    //
    //
    // - `Generator({Grammar}, "String-2", {Options})`
    //   --> The `Grammar` object contains grammar, *excluding* `%lex` lexer rules section,
    //   while the `String-2` string contains the `%lex` lexer rules section
    //
    //   The `Options` object specifies the desired jison options' settings.
    //
    //
    // Any other arguments / arguments' types sequence is illegal.
    //
    generator.constructor = function Jison_Generator(grammar, optionalLexerSection, options) {
        // pick the correct argument for the `options` for this call:
        if (!options && optionalLexerSection && typeof optionalLexerSection !== 'string') {
            options = optionalLexerSection;
            optionalLexerSection = null;
        }
        // and standardize it:
        let preliminary_options = mkStdOptions$1(options);

        grammar = autodetectAndConvertToJSONformat$1(grammar, optionalLexerSection, preliminary_options);

        // make sure all options are 'standardized' before we go and mix them together
        //
        // WARNING:
        // make sure to mix together the **original options sets** as it's last-come-last-serve
        // in `mkStdOptions` and you don't want the mixed in defaults carried in `preliminary_options`
        // to percolate into the final options set as if those we overrides coming in from
        // the API (via the `options` parameter above)!
        //
        // Anyway, API/CLI options **override** options coming in from the grammar spec.
        //
        options = mkStdOptions$1(grammar.options, options);

        prepExportStructures$1(options);

        this.terms = {};
        this.operators = {};
        this.productions = [];
        this.conflicts = 0;
        this.new_conflicts_found_this_round = 0;
        this.conflicting_states = [];
        this.resolutions = [];
        this.conflict_productions_LU = {};
        this.conflict_states_LU = {};
        this.conflict_fixing_round = false;
        this.parseParams = grammar.parseParams;
        this.yy = {}; // accessed as yy free variable in the parser/lexer actions

        // also export the grammar itself *and* the cleaned-up generator options:
        this.options = options;
        this.grammar = grammar;

        this.DEBUG = !!options.debug;

        // // propagate %parse-params into the lexer!
        // if (grammar.lex) {
        //     if (!grammar.lex.options) {
        //         grammar.lex.options = {};
        //     }
        //     if (this.parseParams) {
        //         grammar.lex.options.parseParams = this.parseParams;
        //     }
        // }

        // calculate the input path; if none is specified, it's the present working directory
        let inpath = options.file || options.outfile || './dummy';
        inpath = path__default['default'].normalize(inpath);
        options.inputPath = path__default['default'].dirname(inpath);
        options.inputFilename = path__default['default'].basename(inpath);

        // source included in semantic action execution scope
        if (grammar.actionInclude) {
            if (typeof grammar.actionInclude === 'function') {
                // Also cope with Arrow Functions (and inline those as well?).
                // See also https://github.com/zaach/jison-lex/issues/23
                grammar.actionInclude = helpers.printFunctionSourceCodeContainer(grammar.actionInclude).code;
            }
            this.actionInclude = grammar.actionInclude;
        }
        this.moduleInclude = grammar.moduleInclude || '';
        this.moduleInit = grammar.moduleInit || [];
        assert__default['default'](Array.isArray(this.moduleInit));

        this.DEBUG = !!this.options.debug;
        this.enableDebugLogs = !!options.enableDebugLogs;
        this.numExpectedConflictStates = options.numExpectedConflictStates || 0;

        if (this.DEBUG) {
            this.mix(generatorDebug); // mixin debug methods

            Jison$1.print('Grammar::OPTIONS:\n', this.options);
        }

        this.processGrammar(grammar);

        if (grammar.lex) {
            let lexer_options = {
                // include the knowledge about which parser/lexer
                // features will actually be *used* by the environment:
                //
                // (this stuff comes straight from the jison Optimization Analysis.)
                //
                parseActionsAreAllDefault: this.actionsAreAllDefault,
                parseActionsUseYYLENG: this.actionsUseYYLENG,
                parseActionsUseYYLINENO: this.actionsUseYYLINENO,
                parseActionsUseYYTEXT: this.actionsUseYYTEXT,
                parseActionsUseYYLOC: this.actionsUseYYLOC,
                parseActionsUseParseError: this.actionsUseParseError,
                parseActionsUseYYERROR: this.actionsUseYYERROR,
                parseActionsUseYYRECOVERING: this.actionsUseYYRECOVERING,
                parseActionsUseYYERROK: this.actionsUseYYERROK,
                parseActionsUseYYCLEARIN: this.actionsUseYYCLEARIN,
                parseActionsUseValueTracking: this.actionsUseValueTracking,
                parseActionsUseValueAssignment: this.actionsUseValueAssignment,
                parseActionsUseLocationTracking: this.actionsUseLocationTracking,
                parseActionsUseLocationAssignment: this.actionsUseLocationAssignment,
                parseActionsUseYYSTACK: this.actionsUseYYSTACK,
                parseActionsUseYYSSTACK: this.actionsUseYYSSTACK,
                parseActionsUseYYSTACKPOINTER: this.actionsUseYYSTACKPOINTER,
                parseActionsUseYYRULELENGTH: this.actionsUseYYRULELENGTH,
                parseActionsUseYYMERGELOCATIONINFO: this.actionsUseYYMERGELOCATIONINFO,
                parserHasErrorRecovery: this.hasErrorRecovery,
                parserHasErrorReporting: this.hasErrorReporting,

                // and re-use any useful options:
                moduleType: this.options.moduleType,
                debug: this.options.debug,
                enableDebugLogs: this.options.enableDebugLogs,
                json: this.options.json,
                main: false,
                dumpSourceCodeOnFailure: this.options.dumpSourceCodeOnFailure,
                throwErrorOnCompileFailure: this.options.throwErrorOnCompileFailure,
                moduleName: 'lexer',        // this.options.moduleName + '_Lexer',
                file: this.options.file,
                outfile: this.options.outfile,
                inputPath: this.options.inputPath,
                inputFilename: this.options.inputFilename,       // or should we feed it `this.options.lexfile` instead?
                warn_cb: this.options.warn_cb,
                //parseParams: this.options.parseParams,
                xregexp: this.options.xregexp,
                //parserErrorsAreRecoverable: this.options.parserErrorsAreRecoverable,
                lexerErrorsAreRecoverable: this.options.lexerErrorsAreRecoverable,
                flex: this.options.flex,
                backtrack_lexer: this.options.backtrack_lexer,
                ranges: this.options.ranges,
                caseInsensitive: this.options.caseInsensitive,
                showSource: this.options.showSource,
                exportSourceCode: this.options.exportSourceCode,
                exportAST: this.options.exportAST,
                prettyCfg: this.options.prettyCfg,
                pre_lex: this.options.pre_lex,
                post_lex: this.options.post_lex
            };

            this.lexer = new RegExpLexer(grammar.lex, null, this.terminals_, lexer_options);
        }
    };

    generator.processGrammar = function processGrammarDef(grammar) {
        let bnf = grammar.bnf;
        let tokens = grammar.tokens;
        let nonterminals = this.nonterminals = {};
        let productions = this.productions;

        if (!grammar.bnf && grammar.ebnf) {
            bnf = grammar.bnf = ebnfParser.transform(grammar.ebnf);
        }
        if (tokens) {
            if (typeof tokens === 'string') {
                tokens = tokens.trim().split(' ');
            } else {
                tokens = tokens.slice(0);
            }
        }

        // did the grammar user also provide a predefined set of symbols to be (re)used with this grammar?
        // (This is used when you want to generate multiple lexers and parsers which share a common symbol set
        // so as to make the parsers and lexers mutually interchangeable.)
        let predefined_symbols = null;
        if (grammar.imports) {
            let symbols_import = grammar.imports.find(function (el, idx) {
                if (el.name === 'symbols') {
                    return el;
                }
                return false;
            });
            if (symbols_import) {
                let filepath = path__default['default'].resolve(symbols_import.path);

                let source = fs__default['default'].readFileSync(filepath, 'utf8');
                // It's either a JSON file or a JISON generated output file:
                //
                //     symbols_: {
                //       "symbol": ID, ...
                //     },
                try {
                    predefined_symbols = JSON5__default['default'].parse(source);
                } catch (ex) {
                    try {
                        let m = /[\r\n]\s*symbols_:\s*(\{[\s\S]*?\}),\s*[\r\n]/.exec(source);
                        if (m && m[1]) {
                            source = m[1];
                            predefined_symbols = JSON5__default['default'].parse(source);
                        }
                    } catch (ex) {
                        throw new Error('Error: `%import symbols <path>` must point to either a JSON file containing a symbol table (hash table) or a previously generated JISON JavaScript file, which contains such a symbol table. Error message: ' + ex.message);
                    }
                }

                if (!predefined_symbols || typeof predefined_symbols !== 'object') {
                    throw new Error('Error: `%import symbols <path>` must point to either a JSON file containing a symbol table (hash table) or a previously generated JISON JavaScript file, which contains such a symbol table.');
                }

                // Make sure all predefined symbols are unique and *numeric* and do not include predefined tokens JISON already defines to a fixed ID on its own:
                delete predefined_symbols.$accept;
                delete predefined_symbols.$end;
                delete predefined_symbols.error;
                delete predefined_symbols.$eof;
                delete predefined_symbols.EOF;

                let symdef_uniq_check = {};
                // Only these symbols are allowed to have the values 1 or 2:
                symdef_uniq_check[1] = 'EOF';
                symdef_uniq_check[2] = 'error';
                Object.keys(predefined_symbols).forEach(function cvt_symbol_id_to_numeric(sym) {
                    let v = predefined_symbols[sym];

                    // Symbol value may be defined as boolean TRUE, in which case we let JISON pick the value for us:
                    if (v === true) return;

                    // Symbol value may be defined as a one-character string:
                    if (typeof v !== 'number') {
                        if (typeof v !== 'string' || v.length !== 1) {
                            throw new Error("Error: `%import symbols <path>`: symbol table contains invalid entry at key '" + sym + "': a non-numeric symbol ID value must be a single-character string.");
                        }
                        v = v.charCodeAt(0);
                    }
                    v |= 0;
                    if (!v || v < 0) {
                        throw new Error("Error: `%import symbols <path>`: symbol table contains invalid entry at key '" + sym + "': a symbol ID value must be an integer value, 3 or greater.");
                    }
                    if (symdef_uniq_check[v]) {
                        if (symdef_uniq_check[v] !== sym) {
                            throw new Error("Error: `%import symbols <path>`: symbol table contains duplicate ID values for keys '" + sym + "' and '" + symdef_uniq_check[v] + "'");
                        }
                    }
                    symdef_uniq_check[v] = sym;
                    predefined_symbols[sym] = v;
                });
            }
        }

        let symbols = this.symbols = [];

        // calculate precedence of operators
        let operators = this.operators = processOperators(grammar.operators);

        // build productions from CFG and calculate the symbol sets (terminals and nonterminals) and their name-to-ID mappings
        this.buildProductions(bnf, productions, nonterminals, symbols, operators, predefined_symbols, grammar.extra_tokens);
        if (tokens) {
            let termset = this.terminals.filter(function (t) {
                switch (t) {
                case 'EOF':
                case 'error':
                case '$eof':
                case '$end':
                    return false;

                default:
                    return true;
                }
            });
            let diffset = termset.filter(function (t) {
                return tokens.indexOf(t) === -1;
            });
            diffset = diffset.concat(tokens.filter(function (t) {
                return termset.indexOf(t) === -1;
            }));

            if (termset.length !== tokens.length) {
                this.trace('\nWarning: declared tokens differ from terminals set found in rules.');
                this.trace('difference: ', diffset);
                this.trace('Terminals:  ', termset);
                this.trace('Tokens:     ', tokens);
            }
        }

        // augment the grammar
        this.augmentGrammar(grammar);

        // detect unused productions and flag them
        this.signalUnusedProductions();

        // build production action code chunks (originally done in `buildProductions` as a side-effect)
        this.buildProductionActions();
    };

    generator.augmentGrammar = function augmentGrammar(grammar) {
        if (this.productions.length === 0) {
            throw new Error('Grammar error: must have at least one rule.');
        }
        // use specified start symbol, or default to first user defined production
        this.startSymbol = grammar.start || grammar.startSymbol || this.productions[0].symbol;
        if (!this.nonterminals[this.startSymbol]) {
            throw new Error('Grammar error: startSymbol must be a non-terminal found in your grammar.');
        }
        //this.EOF = '$end';       // moved to generator.buildProductions()

        // Augment the grammar:
        //
        // Add the top-most accept rule (and implicit, default, action):
        //
        //     $accept: <startSymbol> $end
        //                  %{ $$ = $1; @$ = @1; %}
        //
        // which, combined with the new parse kernel's `$accept` state behaviour will produce the
        // `$$` value output of the <startSymbol> rule as the parse result, IFF that result is
        // *not* `undefined`. (See also the parser kernel code.)
        //
        // In code:
        //
        //                  %{
        //                      @$ = @1;
        //                      if (typeof $1 !== 'undefined')
        //                          return $1;
        //                      else
        //                          return true;           // the default parse result if the rule actions don't produce anything
        //                  %}
        //
        let acceptProduction = new Production('$accept', [ this.startSymbol, '$end' ], 0);
        this.productions.unshift(acceptProduction);

        // prepend parser tokens       // moved to generator.buildProductions()
        //this.symbols.unshift('$accept', this.EOF);
        //this.symbols_.$accept = 0;
        //this.symbols_[this.EOF] = 1;
        //this.terminals.unshift(this.EOF);

        //this.nonterminals.$accept = new Nonterminal('$accept');

        this.nonterminals.$accept.productions.push(acceptProduction);

        // add follow $ to start symbol
        this.nonterminals[this.startSymbol].follows.push(this.EOF);
    };

    // Mark unused productions
    generator.signalUnusedProductions = function () {
        let mark = {};

        let productions = this.productions;
        let nonterminals = this.nonterminals;

        for (let i = 0, len = nonterminals.length; i < len; i++) {
            let nt = nonterminals[i];
            assert__default['default'](nt.symbol);
            mark[nt.symbol] = false;
        }

        // scan & mark all visited productions
        function traverseGrammar(nt) {
            assert__default['default'](nt);
            assert__default['default'](nt.symbol);
            mark[nt.symbol] = true;

            let prods = nt.productions;
            assert__default['default'](prods);
            prods.forEach(function (p) {
                assert__default['default'](p.symbol === nt.symbol);
                assert__default['default'](p.handle);
                let rhs = p.handle;

                for (let j = 0, len = rhs.length; j < len; j++) {
                    let sym = rhs[j];
                    assert__default['default'](!sym ? !nonterminals[sym] : true);
                    if (nonterminals[sym] && !mark[sym]) {
                        traverseGrammar(nonterminals[sym]);
                    }
                }
            });
        }

        traverseGrammar(nonterminals['$accept' /* this.startSymbol */]);

        // now any production which is not yet marked is *unused*:
        for (let sym in mark) {
            let nt = nonterminals[sym];
            assert__default['default'](nt);
            let prods = nt.productions;
            assert__default['default'](prods);
            let in_use = mark[sym];
            prods.forEach(function (p) {
                assert__default['default'](p);
                if (in_use) {
                    p.reachable = true;
                } else {
                    p.reachable = false;
                }
            });

            if (!in_use) {
                // and kill the unused nonterminals:
                delete this.nonterminals[sym];
            }
        }

        this.unused_productions = productions.filter(function (p) {
            return !p.reachable;
        });

        // and kill the unused productions:
        this.productions = productions.filter(function (p) {
            return p.reachable;
        });
    };

    // set precedence and associativity of operators
    function processOperators(ops) {
        if (!ops) return {};
        let operators = {};
        for (let i = 0, k, prec; (prec = ops[i]); i++) {
            for (k = 1; k < prec.length; k++) {
                operators[prec[k]] = {
                    precedence: i + 1,
                    assoc: prec[0]
                };
            }
        }
        return operators;
    }

    // Detect the indentation of the given sourcecode chunk and shift the chunk to be indented the given number of spaces.
    //
    // Note that the first line doesn't count as the chunk is very probably trimmed!
    function reindentCodeBlock(action, indent_level) {
        let width = 0;
        let lines = action
        .trim()
        .split('\n')
        // measure the indent:
        .map(function checkIndentation(line, idx) {
            if (idx === 1) {
                // first line didn't matter: reset width to help us find the block indent level:
                width = Infinity;
            }
            if (line.trim() === '') return '';

            // take out any TABs: turn them into spaces (4 per TAB)
            line = line
            .replace(/^[ \t]+/, function expandTabs(s) {
                return s.replace(/\t/g, '    ');
            });

            let m = /^[ ]+/.exec(line);
            if (m) {
                width = Math.min(m[0].length, width);
            }

            return line;
        })
        // remove/adjust the indent:
        .map(function checkIndentation(line, idx) {
            line = line
            .replace(/^[ ]*/, function adjustIndent(s) {
                let l = Math.max(s.length - width, 0) + indent_level;
                let shift = (new Array(l + 1)).join(' ');
                return shift;
            });
            return line;
        });

        return lines.join('\n');
    }


    generator.buildProductions = function buildProductions(bnf, productions, nonterminals, symbols, operators, predefined_symbols, descriptions) {
        let self = this;
        let prods, symId;
        let productions_ = [];
        let symbols_ = {};
        let descriptions_ = {};
        let usedSymbolIds = [/* $accept = 0 */ true, /* $end = 1 */ true, /* error = 2 */ true ];
        let usedSymbolIdsLowIndex = 3;

        // set up the required symbols `$accept` and `$end` (a.k.a. EOF) and make sure they occupy the expected slots:
        this.EOF = '$end';

        symbols_.$accept = 0;
        symbols_[this.EOF] = 1;
        symbols_.$eof = 1;               // `$eof` is a synonym of `$end` for bison compatibility; this is the only place where two symbol names may map to a single symbol ID number!
        symbols_.EOF = 1;                // `EOF` is a synonym of `$end` for bison compatibility; this is the only place where two symbol names may map to a single symbol ID number!
        symbols[0] = '$accept';
        symbols[1] = this.EOF;

        nonterminals.$accept = new Nonterminal('$accept');

        // always add the error symbol; will be third symbol, or "2": ($accept, $end, error)
        symbols_.error = 2;
        symbols[2] = 'error';

        if (predefined_symbols) {
            for (let symbol in predefined_symbols) {
                symId = predefined_symbols[symbol];
                if (symId === true) {
                    // add symbol to queue which must be assigned a value by JISON; after all the other predefined symbols have been processed.
                    continue;
                }

                // skip $accept, $end and error:
                if (symId <= 2) continue;

                // has this ID already been taken? If not, pick this ID, otherwise throw a tantrum.
                if (!usedSymbolIds[symId]) {
                    usedSymbolIds[symId] = true;
                    symbols_[symbol] = symId;
                    symbols[symId] = symbol;
                } else {
                    throw new Error('Error: Predefined symbol (imported via `%import symbols`) "' + symbol + '" has an ID ' + symId + ' which is already in use by symbol "' + symbols[symId] + '"');
                }
            }

            // preferably assign readable ASCII-range token IDs to tokens added from the predefined list
            // but only when maximum table compression isn't demanded:
            usedSymbolIdsLowIndex = ((this.options.compressTables | 0) < 2 ? 32 : 3);
            for (let symbol in predefined_symbols) {
                symId = predefined_symbols[symbol];
                addSymbol(symbol);
            }

            // reset ID low water mark: nonterminals etc. can be assigned any number, preferably a small/low one!
            usedSymbolIdsLowIndex = 3;
        }

        if (descriptions) {
            this.trace('descriptions obtained from grammar: ', descriptions);
            descriptions.forEach(function (tokdef) {
                // fields: id, type, value, description
                if (tokdef.description && tokdef.id) {
                    descriptions_[tokdef.id] = tokdef.description;
                }
            });
        }


        let hasErrorRecovery = false; // has error recovery

        // Produce the next available unique symbolID:
        function getNextSymbolId() {
            for (let i = usedSymbolIdsLowIndex; ; i++) {
                if (!usedSymbolIds[i]) {
                    usedSymbolIds[i] = true;
                    usedSymbolIdsLowIndex = i + 1;
                    return i;
                }
            }
        }

        function addSymbol(s) {
            if (s && !symbols_[s]) {
                let i;

                // assign the Unicode codepoint index to single-character symbols,
                // but only when maximum table compression isn't demanded:
                if (s.length === 1 && (self.options.compressTables | 0) < 2) {
                    i = s.charCodeAt(0);
                    // has this ID already been taken? If not, pick this ID.
                    if (i < 128 /* only allow this within the ASCII range */ && !usedSymbolIds[i]) {
                        usedSymbolIds[i] = true;
                    } else {
                        i = getNextSymbolId();
                    }
                } else {
                    // otherwise simply obtain the next available ID number as usual.
                    i = getNextSymbolId();
                }
                symbols_[s] = i;
                symbols[i] = s;
            }
            return symbols_[s] || false;
        }

        // `this` is options object with `maxTokenLength` option to guide us which literal tokens we want to process:
        function collectLiteralTokensInProduction(handle) {
            let rhs;

            try {
                if (devDebug) ;

                let maxlen = this.maxTokenLength || Infinity;

                if (handle.constructor === Array) {
                    rhs = (typeof handle[0] === 'string') ?
                        splitStringIntoSymbols(handle[0]) :
                        handle[0].slice(0);

                    for (let i = 0; i < rhs.length; i++) {
                        let sym = rhs[i];
                        // check for aliased names, e.g., id[alias] and strip them
                        let rhs_i = sym.match(new XRegExp__default['default'](`\\[${ID_REGEX_BASE$3}\\]$`));
                        if (rhs_i) {
                            sym = sym.substr(0, sym.length - rhs_i[0].length);
                        }

                        if (!bnf[sym] && sym.length <= maxlen) {
                            addSymbol(sym);
                        }
                    }
                } else {
                    // no action -> don't care about aliases; strip them.
                    handle = handle.replace(new XRegExp__default['default'](`\\[${ID_REGEX_BASE$3}\\]`, 'g'), '');
                    rhs = splitStringIntoSymbols(handle);
                    for (let i = 0; i < rhs.length; i++) {
                        let sym = rhs[i];
                        if (!bnf[sym] && sym.length <= maxlen) {
                            addSymbol(sym);
                        }
                    }
                }
            } catch (ex) {
                console.error(ex, '\ncollectLiteralTokensInProduction: ', this.symbol, ':', JSON.stringify(handle, null, 2), ' @ options: ', this, { rhs });
                throw ex;
            }
        }

        // Before we go process the grammar for real, we collect the 'literal' non-terminals and add them to the symbol table
        // before all others: this way these tokens have the maximum chance to get assigned their ASCII value as symbol ID,
        // which helps debugging/diagnosis of generated grammars.
        // (This is why previously we had set `usedSymbolIdsLowIndex` to 127 instead of 3!)

        let prodsLUT = {};
        for (let symbol in bnf) {
            if (!bnf.hasOwnProperty(symbol)) continue;

            if (typeof bnf[symbol] === 'string') {
                prods = bnf[symbol].split(/\s*\|\s*/g);
            } else {
                prods = bnf[symbol].slice(0);
            }

            prodsLUT[symbol] = prods;
        }

        // First we collect all single-character literal tokens:
        for (let symbol in prodsLUT) {
            if (!prodsLUT.hasOwnProperty(symbol)) continue;

            prods = prodsLUT[symbol];
            prods.forEach(collectLiteralTokensInProduction, {
                maxTokenLength: 1,
                symbol
            });
        }
        // Next we collect all other literal tokens:
        for (let symbol in prodsLUT) {
            if (!prodsLUT.hasOwnProperty(symbol)) continue;

            prods = prodsLUT[symbol];
            prods.forEach(collectLiteralTokensInProduction, {
                maxTokenLength: Infinity,
                symbol
            });
        }

        // and now go and process the entire grammar:
        // first collect all nonterminals in a symbol table, then build the productions
        // for each of those: nonterminals should all have IDs assigned before they
        // should be processed as part of a *production* rule, where these MAY be
        // referenced:
        for (let symbol in bnf) {
            if (!bnf.hasOwnProperty(symbol)) continue;

            addSymbol(symbol);
            nonterminals[symbol] = new Nonterminal(symbol);
        }

        // now that we have collected all nonterminals in our symbol table, it's finally
        // time to process the productions:
        for (let symbol in prodsLUT) {
            if (!prodsLUT.hasOwnProperty(symbol)) continue;

            prods = prodsLUT[symbol];
            prods.forEach(buildProduction, { symbol });
        }

        let terms = [];
        let terms_ = {};
        each(symbols_, function (id, sym) {
            // `$eof` and `EOF` are synonyms of `$end` (`$eof` is for bison compatibility);
            // this is the only place where two symbol names may map to a single symbol ID number
            // and we do not want `$eof`/`EOF` to show up in the symbol tables of generated parsers
            // as we use `$end` for that one!
            if (!nonterminals[sym] && sym !== '$eof') {
                terms.push(sym);
                terms_[id] = sym;
            }
        });

        this.hasErrorRecovery = hasErrorRecovery;
        // fix error recovery related options now that we know whether we actually have any recovery
        // rules at all:
        if (!this.hasErrorRecovery) {
            let chk_er_opt = function check_error_recovery_option(opt, label) {
                if (self.options[opt]) {
                    self.options[opt] = false;
                    self.warn('The grammar does not have any error recovery rules, so using the ' + label + ' is rather useless.');
                }
            };

            chk_er_opt('parserErrorsAreRecoverable', 'parser-errors-are-recoverable feature/option');

            // Hmmmm... why would lexer errors need to be NON-recoverable when there's no ERROR rules in the GRAMMAR?!
            chk_er_opt('lexerErrorsAreRecoverable', 'lexer-errors-are-recoverable feature/option');

            chk_er_opt('parseActionsUseYYRECOVERING', "YYRECOVERING macro/API in grammar rules' action code");
            chk_er_opt('parseActionsUseYYERROK', "yyerrok() function/API in grammar rules' action code");
            chk_er_opt('parseActionsUseYYCLEARIN', "yyclearin() function/API in grammar rules' action code");
        }

        this.terminals = terms;
        this.terminals_ = terms_;
        this.symbols_ = symbols_;
        this.symbolIds = symbols;
        this.descriptions_ = descriptions_;

        this.productions_ = productions_;
        assert__default['default'](this.productions === productions);


        // Cope with literal symbols in the string, including *significant whitespace* tokens
        // as used in a rule like this: `rule: A ' ' B;` which should produce 3 tokens for the
        // rhs: ['A', ' ', 'B']
        function splitStringIntoSymbols(rhs) {
            // when there's no literal tokens in there, we can fast-track this baby:
            rhs = rhs.trim();
            let pos1 = rhs.indexOf("'");
            let pos2 = rhs.indexOf('"');
            if (pos1 < 0 && pos2 < 0) {
                return rhs.split(' ');
            }
            // else:
            //
            // rhs has at least one literal: we will need to parse the rhs into tokens
            // with a little more effort now.
            let tokens = [];
            while (pos1 >= 0 || pos2 >= 0) {
                let pos = pos1;
                let marker = "'";
                if (pos < 0) {
                    assert__default['default'](pos2 >= 0);
                    pos = pos2;
                    marker = '"';
                } else if (pos >= 0 && pos2 >= 0 && pos2 < pos) {
                    pos = pos2;
                    marker = '"';
                }
                let ls = rhs.substr(0, pos).trim();
                if (ls.length > 0) {
                    tokens.push.apply(tokens, ls.split(' '));
                }
                rhs = rhs.substr(pos + 1);
                // now find the matching end marker.
                //
                // Edge case: token MAY include the ESCAPED MARKER... or other escapes!
                // Hence we need to skip over ALL escapes inside the token!
                let pos3 = rhs.indexOf('\\');
                pos = rhs.indexOf(marker);
                ls = '';
                while (pos3 >= 0 && pos3 < pos) {
                    ls += rhs.substr(0, pos3 + 2);  // chop off entire escape (2 chars) and keep as part of next token
                    rhs = rhs.substr(pos3 + 2);
                    pos3 = rhs.indexOf('\\');
                    pos = rhs.indexOf(marker);
                }
                if (pos < 0) {
                    throw new Error('internal error parsing literal token(s) in grammar rule');
                }
                ls += rhs.substr(0, pos);
                // check for aliased literals, e.g., `'>'[gt]` and keep it and the alias together
                rhs = rhs.substr(pos + 1);
                let alias = rhs.match(new XRegExp__default['default'](`^\\[${ID_REGEX_BASE$3}\\]`));
                if (alias) {
                    ls += alias[0];
                    rhs = rhs.substr(alias[0].length);
                }
                tokens.push(ls);

                rhs = rhs.trim();

                pos1 = rhs.indexOf("'");
                pos2 = rhs.indexOf('"');
            }
            // Now, outside the loop, we're left with the remainder of the rhs, which does NOT
            // contain any literal tokens.
            if (rhs.length > 0) {
                tokens.push.apply(tokens, rhs.split(' '));
            }
            return tokens;
        }

        // options object { symbol } is `this` for this functon/callback:
        function buildProduction(handle) {
            let rhs;
            let precedence_override = null;
            let aliased = [];
            let action = null;

            if (handle.constructor === Array) {
                rhs = (typeof handle[0] === 'string') ?
                    splitStringIntoSymbols(handle[0]) :
                    handle[0].slice(0);

                for (let i = 0; i < rhs.length; i++) {
                    // check for aliased names, e.g., id[alias] and strip them
                    let rhs_i = rhs[i].match(new XRegExp__default['default'](`\\[${ID_REGEX_BASE$3}\\]$`));
                    if (rhs_i) {
                        rhs[i] = rhs[i].substr(0, rhs[i].length - rhs_i[0].length);
                        rhs_i = rhs_i[0].substr(1, rhs_i[0].length - 2);
                        aliased[i] = rhs_i;
                    } else {
                        aliased[i] = rhs[i];
                    }

                    if (rhs[i] === 'error') {
                        hasErrorRecovery = true;
                    }
                    assert__default['default'](bnf[rhs[i]] ? symbols_[rhs[i]] : true, 'all nonterminals must already exist in the symbol table');
                    assert__default['default'](rhs[i] ? symbols_[rhs[i]] : true, 'all symbols (terminals and nonterminals) must already exist in the symbol table');
                    //addSymbol(rhs[i]);
                }

                assert__default['default'](handle.length === 3 ? typeof handle[1] === 'string' : true);
                if (typeof handle[1] === 'string') {
                    // semantic action specified
                    action = handle[1];

                    // precedence specified also
                    if (handle[2] && operators[handle[2].prec]) {
                        precedence_override = {
                            symbol: handle[2].prec,
                            spec: operators[handle[2].prec]
                        };
                    }
                } else {
                    // only precedence specified
                    if (operators[handle[1].prec]) {
                        precedence_override = {
                            symbol: handle[1].prec,
                            spec: operators[handle[1].prec]
                        };
                    }
                }
            } else {
                // no action -> don't care about aliases; strip them.
                handle = handle.replace(new XRegExp__default['default'](`\\[${ID_REGEX_BASE$3}\\]`, 'g'), '');
                rhs = splitStringIntoSymbols(handle);
                for (let i = 0; i < rhs.length; i++) {
                    if (rhs[i] === 'error') {
                        hasErrorRecovery = true;
                    }
                    assert__default['default'](bnf[rhs[i]] ? symbols_[rhs[i]] : true, 'all nonterminals must already exist in the symbol table');
                    assert__default['default'](rhs[i] ? symbols_[rhs[i]] : true, 'all symbols (terminals and nonterminals) must already exist in the symbol table');
                    //addSymbol(rhs[i]);
                }
            }

            let r = new Production(this.symbol, rhs, productions.length + 1, aliased, action);

            // set precedence
            assert__default['default'](r.precedence === 0);
            if (precedence_override) {
                r.precedence = precedence_override.spec.precedence;
            } else {
                let prec_symbols = [];
                let winning_symbol;

                for (let i = r.handle.length - 1; i >= 0; i--) {
                    if (!(r.handle[i] in nonterminals) && r.handle[i] in operators) {
                        let old_prec = r.precedence;
                        let new_prec = operators[r.handle[i]].precedence;
                        if (old_prec !== 0 && old_prec !== new_prec) {
                            prec_symbols.push(r.handle[i]);
                            // Jison.print('precedence set twice: ', old_prec, new_prec, r.handle[i], this.symbol, handle[0]);
                            if (new_prec < old_prec) {
                                winning_symbol = r.handle[i];
                            } else {
                                // keep previously set precedence:
                                new_prec = old_prec;
                            }
                        } else if (old_prec === 0) {
                            prec_symbols.push(r.handle[i]);
                            winning_symbol = r.handle[i];
                            // Jison.print('precedence set first time: ', old_prec, r.handle[i], this.symbol, handle[0]);
                        }
                        r.precedence = new_prec;
                    }
                }

                if (prec_symbols.length > 1) {
                    if (self.DEBUG || 1) {
                        self.warn('Ambiguous rule precedence in grammar: picking the (highest) precedence from operator "' + winning_symbol + '" for rule "' + this.symbol + ': ' + r.handle.join(' ') + '" which contains multiple operators with different precedences: {' + prec_symbols.join(', ') + '}');
                    }
                }
            }

            productions.push(r);
            productions_.push([ symbols_[r.symbol], r.handle[0] === '' ? 0 : r.handle.length ]);
            nonterminals[this.symbol].productions.push(r);
        }
    };


    // Preprocess the action code block before we perform any `$n`, `@n` ,`##n` or `#n` expansions:
    // Any comment blocks in there should be kept intact (and not cause trouble either as those comments MAY
    // contain `$`, `@`, `##` or `#` prefixed bits which might look like references but aren't!)
    //
    // Also do NOT replace any $x, @x, ##x or #x macros inside any strings!
    //
    // Note:
    // We also replace '/*' comment markers which may (or may not) be lurking inside other comments.
    function preprocessActionCode(s) {
        function replace_markers(cmt) {
            cmt = cmt
            .replace(/##/g, '\x01\x89')
            .replace(/#/g, '\x01\x81')
            .replace(/\$/g, '\x01\x82')
            .replace(/@/g, '\x01\x83')
            .replace(/\/\*/g, '\x01\x85')
            .replace(/\/\//g, '\x01\x86')
            .replace(/\'/g, '\x01\x87')
            .replace(/\"/g, '\x01\x88')
            // and also whiteout any other macros we're about to expand in there:
            .replace(/\bYYABORT\b/g, '\x01\x94')
            .replace(/\bYYACCEPT\b/g, '\x01\x95')
            .replace(/\byyvstack\b/g, '\x01\x96')
            .replace(/\byylstack\b/g, '\x01\x97')
            .replace(/\byyerror\b/g, '\x01\x98')
            .replace(/\bYYRECOVERING\b/g, '\x01\x99')
            .replace(/\byyerrok\b/g, '\x01\x9A')
            .replace(/\byyclearin\b/g, '\x01\x9B')
            .replace(/\byysp\b/g, '\x01\x9C')
            .replace(/\byy([a-zA-Z]+)\b/g, '\x01\x9D__$1');   // `yyxxx`: all `yy`-prefixed (camelCased) identifiers are RESERVED USE for jison.

            return cmt;
        }

        s = s
        // do not trim any NEWLINES in the action block:
        .replace(/^\s+/, '')
        .replace(/\s+$/, '')
        // unify CR/LF combo's:
        .replace(/\r\n|\r/g, '\n')
        // replace any '$', '@' and '#' in any C++-style comment line to prevent
        // them from being expanded as if they were part of the action code proper:
        .replace(/^\s*\/\/.+$/mg, replace_markers)
        // also process any //-comments trailing a line of code:
        // (we need to ensure these are real and not a bit of string,
        // which leaves those comments that are very hard to correctly
        // recognize with a simple regex, e.g. '// this isn't a #666 location ref!':
        // we accept that we don't actually *parse* the action block and let these
        // slip through... :-( )
        //
        // WARNING: without that `\n` inside the regex `[...]` set, the set *will*
        // match a NEWLINE and thus *possibly* gobble TWO lines for the price of ONE,
        // when the first line is an *empty* comment line, i.e. nothing trailing
        // the `//` in there and thus the `[^'"]` regex matching the terminating NL *before*
        // the `$` in the regex can get at it. Cave canem therefor!       |8-(
        .replace(/\/\/[^'"\n]+$/mg, replace_markers)
        // now MARK all the not-too-tricky-to-recognize /*...*/ comment blocks and process those!
        // (Here again we accept that we don't actually *parse* the action code and
        // permit to let some of these slip, i.e. comment blocks which trail
        // a line of code and contain string delimiter(s). :-( )
        .replace(/^([^'"\n]*?)\/\*/mg, '$1\x01\x84')                            // comment starts the line, guaranteed not to be inside a string
        .replace(/\/\*([^'"\n]*)$/mg, '\x01\x84$1')                             // comment does not contain any string sentinel in its first line
        .replace(/\/\*([^\/]*?\*\/[^'"\n]*)$/mg, '\x01\x84$1')                  // comment end marker near end of line and since the end is definitely not inside a string, there's bound to be comment start as well
        // and find their END marker: first '*/' found wins!
        // (The `[\s\S]` regex expression is a hack to ensure NEWLINES are matched
        // by that set as well, i.e. this way we can easily cross line boundaries
        // while searching for he end of the multiline comment we're trying to
        // dig out by regex matching. Also note that we employ non-aggressive
        // matching to ensure the regex matcher will find the FIRST occurrence of
        // `*/` and mark that as the end of the regex match!)
        .replace(/\x01\x84[\s\S]*?\*\//g, replace_markers)
        // Now that we have processed all comments in the code, it's time
        // to tackle the strings in the code: any strings must be kept intact
        // as well. Regrettably, there's regexes which may carry quotes,
        // e.g. `/'/`, and escapes of quotes inside strings, e.g. `'\''`,
        // which makes this a non-trivial task. This is when we reconsider whether
        // we should run this stuff through Esprima and deal with that AST
        // verbosity instead...? For now, we accept that regexes can screw
        // us up, but we can handle strings of any kind, by first taking
        // out all explicit `\\` non-escaping characters:
        .replace(/\\\\/g, '\x01\x90')
        // and then we take out all escaped quotes:
        .replace(/\\\'/g, '\x01\x91')
        .replace(/\\\"/g, '\x01\x92')
        // and to top it off, we also take out any more-or-less basic regexes:
        .replace(/\\\//g, '\x01\x93')

        // WARNING: Without that prefix check this would also catch
        // `6/7 + $$ + 8/9` as if `/7 + $$ + 8/` would be a regex   :-(
        // but we need this one to ensure any quotes hiding inside
        // any regex in there are caught and marked, e.g. `/'/g`.
        // Besides, this regex prefix is constructed to prevent
        // the regex matching a `//....` comment line either!
        .replace(/[^_a-zA-Z0-9\$\)\/][\s\n\r]*\/[^\n\/\*][^\n\/]*\//g, replace_markers);

        // ... which leaves us with plain strings of both persuasions to cover
        // next: we MUST do both at the same time, though or we'll be caught
        // with our pants down in constructs like
        // `'"' + $$ + '"'` vs. `"'" + $$ + "'"`

        let dqpos, sqpos, ccmtpos, cppcmtpos;
        let first = -1;
        for (let c = 0; ; c++) {
            first++;
            dqpos = s.indexOf('"', first);
            sqpos = s.indexOf("'", first);
            // also look for remaining comments which contain quotes of any kind,
            // as those will not have been caught by the previous global regexes:
            ccmtpos = s.indexOf('/*', first);
            cppcmtpos = s.indexOf('//', first);
            first = s.length;
            first = Math.min((dqpos >= 0 ? dqpos : first), (sqpos >= 0 ? sqpos : first), (ccmtpos >= 0 ? ccmtpos : first), (cppcmtpos >= 0 ? cppcmtpos : first));
            // now it matters which one came up first:
            if (dqpos === first) {
                s = s
                .replace(/"[^"\n]*"/, replace_markers);
            } else if (sqpos === first) {
                s = s
                .replace(/'[^'\n]*'/, replace_markers);
            } else if (ccmtpos === first) {
                s = s
                .replace(/\/\*[\s\S]*?\*\//, replace_markers);
            } else if (cppcmtpos === first) {
                s = s
                .replace(/\/\/[^\n]*$/m, replace_markers);
            } else {
                break;
            }
        }
        // Presto!
        return s;
    }

    // Postprocess the action code block after we perform any `$n`, `@n`, `##n` or `#n` expansions:
    // revert the preprocessing!
    function postprocessActionCode(s) {
        s = s
        // multiline comment start markers:
        .replace(/\x01\x84/g, '/*')
        .replace(/\x01\x85/g, '/*')
        .replace(/\x01\x86/g, '//')
        // revert markers:
        .replace(/\x01\x81/g, '#')
        .replace(/\x01\x82/g, '$')
        .replace(/\x01\x83/g, '@')
        // and revert the string and regex markers:
        .replace(/\x01\x87/g, "'")
        .replace(/\x01\x88/g, '\"')
        .replace(/\x01\x89/g, '##')
        .replace(/\x01\x90/g, '\\\\')
        .replace(/\x01\x91/g, "\\'")
        .replace(/\x01\x92/g, '\\\"')
        .replace(/\x01\x93/g, '\\\/')
        .replace(/\x01\x94/g, 'YYABORT')
        .replace(/\x01\x95/g, 'YYACCEPT')
        .replace(/\x01\x96/g, 'yyvstack')
        .replace(/\x01\x97/g, 'yylstack')
        .replace(/\x01\x98/g, 'yyerror')
        .replace(/\x01\x99/g, 'YYRECOVERING')
        .replace(/\x01\x9A/g, 'yyerrok')
        .replace(/\x01\x9B/g, 'yyclearin')
        .replace(/\x01\x9C/g, 'yysp')
        .replace(/\x01\x9D__/g, 'yy');

        // And a final, minimal, fixup for the semicolon-lovers -- like me! ;-)
        //
        // Make sure the last statement is properly semicolon-terminated 99.9% of the time:
        s = s
        .replace(/[\s\r\n]+$/, '')          // trim trailing whitespace and empty lines
        .replace(/([^\;}])$/, '$1;');       // append a semicolon to the last statement if it doesn't end with one (or a closing brace, e.g. a function definition)

        return s;
    }

    // Strip off any insignificant whitespace from the user code to ensure that
    // otherwise identical actions are indeed matched up into a single actionGroup:
    function mkHashIndex(s) {
        return s.trim()
        .replace(/\s+$/mg, '')          // strip any trailing whitespace for each line of action code
        .replace(/^\s+/mg, '');         // ditto for leading whitespace for each line: we don't care about more or less clean indenting practices in the user code
    }

    function analyzeFeatureUsage(sourcecode, feature, threshold) {
        let found = sourcecode.match(feature);
        return !!(found && found.length > threshold);
    }


    function mkParserFeatureHash(self) {
        assert__default['default'](self.options.exportAllTables);   // check that this function isn't called too early in the process or the hash will be bogus
        assert__default['default'](self.options.exportSourceCode);
        let h = [
            self.actionsAreAllDefault,
            self.actionsUseLocationAssignment,
            self.actionsUseLocationTracking,
            self.actionsUseParseError,
            self.actionsUseValueAssignment,
            self.actionsUseValueTracking,
            self.actionsUseYYCLEARIN,
            self.actionsUseYYERROK,
            self.actionsUseYYERROR,
            self.actionsUseYYLENG,
            self.actionsUseYYLINENO,
            self.actionsUseYYLOC,
            self.actionsUseYYRECOVERING,
            self.actionsUseYYRULELENGTH,
            self.actionsUseYYMERGELOCATIONINFO,
            self.actionsUseYYSSTACK,
            self.actionsUseYYSTACK,
            self.actionsUseYYSTACKPOINTER,
            self.actionsUseYYTEXT,
            self.hasErrorRecovery,
            self.hasErrorReporting,
            self.onDemandLookahead,
            self.options.compressTables,
            self.options.debug,
            self.options.errorRecoveryTokenDiscardCount,
            self.options.exportAllTables.enabled,
            self.options.exportSourceCode.enabled,
            self.options.hasPartialLrUpgradeOnConflict,
            self.options.lexerErrorsAreRecoverable,
            self.options.moduleType,
            self.options.defaultActionMode,
            self.options.testCompileActionCode,
            self.options.noDefaultResolve,
            self.options.noMain,
            self.options.moduleMain,
            self.options.moduleMainImports,
            self.options.noTryCatch,
            self.options.numExpectedConflictStates,
            self.options.outputDebugTables,
            self.options.parserErrorsAreRecoverable,
            self.options.tokenStack,
            self.options.type,
            self.options.moduleName,
            self.options.parseParams,
            self.options.ranges,
            self.options.prettyCfg,
            '======================================',
            self.performAction,
            '======================================'
        ];
        return JSON.stringify(h);
    }

    generator.buildProductionActions = function buildProductionActions() {
        /*
            this.terminals = terms;
            this.terminals_ = terms_;
            this.symbols_ = symbols_;
            this.descriptions_ = descriptions_;

            this.productions_ = productions_;
            assert(this.productions === productions);
        */
        let productions = this.productions;
        let nonterminals = this.nonterminals;
        let symbols = this.symbols;
        let operators = this.operators;
        let self = this;

        // As a SIDE EFFECT of this call, we also fixup
        // the other code chunks specified in the grammar file:
        //
        // Replace direct symbol references, e.g. #NUMBER# when there's a `%token NUMBER` for your grammar.
        // We allow these tokens to be referenced anywhere in your code as #TOKEN#.
        let moduleInclude = preprocessActionCode(this.moduleInclude)
            .replace(new XRegExp__default['default'](`#(${ID_REGEX_BASE$3})#`, 'g'), function (_, sym) {
                return provideSymbolAsSourcecode(sym);
            });
        // and COPY the `moduleInit` array, after preprocessing the individual COPIES:
        let moduleInit = this.moduleInit.map(function (chunk) {
            assert__default['default'](chunk.qualifier);
            assert__default['default'](typeof chunk.include === 'string');
            return {
                qualifier: chunk.qualifier,
                include: preprocessActionCode(chunk.include)
                    .replace(new XRegExp__default['default'](`#(${ID_REGEX_BASE$3})#`, 'g'), function (_, sym) {
                        return provideSymbolAsSourcecode(sym);
                    })
            };
        });
        assert__default['default'](Array.isArray(moduleInit));

        // We potentially need multiple (2+) rounds to produce the correct actions
        // as userland action code determines whether the default actions should
        // include location tracking or not:
        let gen_level = 0;
        let prev_gen_hash = 'n';
        let gen_hash = 'y';
        this.performAction = null;
        while (gen_hash !== prev_gen_hash) {
            let preludeCode = preprocessActionCode(this.actionInclude || '');
            let actions = [ `
          /* this == yyval */

          // the JS engine itself can go and remove these statements when \`yy\` turns out to be unused in any action code!
          let yy = this.yy;
          let yyparser = yy.parser;
          let yylexer = yy.lexer;

          ${preludeCode}

          switch (yystate) {`
            ];
            let actionGroups = {};          // used to combine identical actions into single instances: no use duplicating action code needlessly
            let actionGroupValue = {};      // stores the unaltered, expanded, user-defined action code for each action group.
            let stateHasAction = [];        // marks which state IDs have an action, either user-specified or default.

            // and now go and process the entire grammar:
            productions.forEach(buildProductionAction, { actionGroups, actionGroupValue, stateHasAction });

            for (let hash in actionGroups) {
                actions.push([].concat.apply([], actionGroups[hash]).join('\n') + '\n\n' + actionGroupValue[hash] + '\n    break;\n');
            }

            // add the special error recovery reduction action:
            if (this.hasErrorRecovery) {
                let userland_err_recov_redux_code = '';

                actions.push(`case YY_ERROR_RECOVERY_COMBINE_ID:       // === NO_ACTION[1] :: ensures that anyone (but us) using this new state will fail dramatically!
                // error recovery reduction action (action generated by jison,
                // using the user-specified \`%code error_recovery_reduction\` %{...%}
                // code chunk below.

                ${userland_err_recov_redux_code}
                break;
            `);
            }

            // check if all IDs have an action now:
            let missingActions = [];
            for (let idx = 0, len = stateHasAction.length; idx < len; idx++) {
                if (!stateHasAction[idx]) {
                    missingActions.push(idx);
                }
            }
            this.missingActions = missingActions;
            if (missingActions.length) {
                if ( this.DEBUG) {
                    this.warn('WARNING: missing actions for states: ', missingActions);
                }

                actions.push(`default:
                // default action for all unlisted resolve states: ${missingActions.join(', ')}

                // When we hit this entry, it's always a non-recoverable issue as this is a severe internal parser state failure:
                function __b0rk_on_internal_failure(str) {
                    let hash = yyparser.constructParseErrorInfo(str, null, null, false);

                    return yyparser.parseError(str, hash, yyparser.JisonParserError);
                }

                return __b0rk_on_internal_failure("internal parser failure: resolving unlisted state: " + yystate);`
                );
            }
            actions.push('}');

            let parameters = 'yytext, yyleng, yylineno, yyloc, yystate /* action[1] */, yysp, yyrulelength, yyvstack, yylstack, yystack, yysstack';

            this.performAction = [].concat(
                'function parser__PerformAction(' + parameters + ') {',
                actions,
                '}'
            ).join('\n')
            .replace(/\bYYABORT\b/g, 'return false')
            .replace(/\bYYACCEPT\b/g, 'return true')

            // Replace direct symbol references, e.g. #NUMBER# when there's a `%token NUMBER` for your grammar.
            // We allow these tokens to be referenced anywhere in your code as #TOKEN#.
            .replace(new XRegExp__default['default'](`#(${ID_REGEX_BASE$3})#`, 'g'), function (_, sym) {
                return provideSymbolAsSourcecode(sym);
            });

            this.performAction = this.performAction
            .replace(/\byyerror\b/g, 'yyparser.yyError')
            .replace(/\bYYRECOVERING\b(?:\s*\(\s*\))?/g, 'yyparser.yyRecovering()')
            .replace(/\byyerrok\b(?:\s*\(\s*\))?/g, 'yyparser.yyErrOk()')
            .replace(/\byyclearin\b(?:\s*\(\s*\))?/g, 'yyparser.yyClearIn()');

            this.actionsUseYYLENG = this.actionsUseYYLENG || analyzeFeatureUsage(this.performAction, /\byyleng\b/g, 1);
            this.actionsUseYYLINENO = this.actionsUseYYLINENO || analyzeFeatureUsage(this.performAction, /\byylineno\b/g, 1);
            this.actionsUseYYTEXT = this.actionsUseYYTEXT || analyzeFeatureUsage(this.performAction, /\byytext\b/g, 1);
            this.actionsUseYYLOC = this.actionsUseYYLOC || analyzeFeatureUsage(this.performAction, /\byyloc\b/g, 1);
            this.actionsUseParseError = this.actionsUseParseError || analyzeFeatureUsage(this.performAction, /\.parseError\b/g, 0);
            this.actionsUseYYERROR = this.actionsUseYYERROR || analyzeFeatureUsage(this.performAction, /\.yyError\b/g, 0);
            this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || analyzeFeatureUsage(this.performAction, /\.yyRecovering\b/g, 0);
            this.actionsUseYYERROK = this.actionsUseYYERROK || analyzeFeatureUsage(this.performAction, /\.yyErrOk\b/g, 0);
            this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || analyzeFeatureUsage(this.performAction, /\.yyClearIn\b/g, 0);
            // At this point in time, we have already expanded `$name`, `$$` and `$n` to its `$$[n]` index expression.
            //
            // Also note we cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
            // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
            // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
            // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
            this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(this.performAction, /\byyvstack\b/g, 1);
            // Ditto for the specific case where we are assigning a value to `$$`, i.e. `this.$`:
            this.actionsUseValueAssignment = this.actionsUseValueAssignment || analyzeFeatureUsage(this.performAction, /\bthis\.\$[^\w]/g, 0);
            // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
            this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(this.performAction, /\byylstack\b/g, 1);
            // Ditto for the specific case where we are assigning a value to `@$`, i.e. `this._$`:
            this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || analyzeFeatureUsage(this.performAction, /\bthis\._\$[^\w]/g, 0);
            // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
            // the need to use yystack! Hence yystack is only there for very special use action code.)
            this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(this.performAction, /\byystack\b/g, 1);
            // Ditto for yysstack...
            this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(this.performAction, /\byysstack\b/g, 1);
            this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(this.performAction, /\byysp\b/g, 1);
            this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || analyzeFeatureUsage(this.performAction, /\byyrulelength\b/g, 1);
            this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(this.performAction, /\.yyMergeLocationInfo\b/g, 1);

            // ------------------------------------------------------------------------------------
            // And Check if any of these features occur in the other user-defined chunks of code
            // that will end up as part of the parser at large:
            //
            // ---
            //
            // It does NOT matter that other user code accesses lexer-specific items; this analysis is
            // abut accessing PARSER INTERNALS, hence we have commented out the items which cannot ever
            // reach those variables from here.
            //
            //
            // ### NOTE ###
            //
            // We DO NOT care if some very obscure piece of code transfers a `this` (= yyval) reference from
            // and action code chunk to an outside function: if you are *that* devious, we also reckon you
            // are very well aware of what you are doing and quite capable of 'forcing' these feature
            // flags via the `%options` route. ;-))
            //
            // HOWVER, writing a custom `parseError` handler in there is considered rather more mundane,
            // so we reckon you have found a way to grab yyvstack et al from the error hash in that
            // wicked `parseError` callback of yours! ;-))
            //
            //   (Do note that `constructParseErrorInfo()` **intentionally** DOES NOT include the internal
            //    `yyval` in the produced error info chunk! Meanwhile, `yyvstack` is known under a different
            //    name inside the error info object and that is, as far as we are concerned, the only
            //    sensible way to get access to the internal parse stacks *outside* `performAction()`!
            //    ... Just because we like our copy-pasta, we wave our hands and check for both incantations...)
            //

            //this.actionsUseYYLENG = this.actionsUseYYLENG || analyzeFeatureUsage(moduleInclude, /\byyleng\b/g, 0);
            //this.actionsUseYYLINENO = this.actionsUseYYLINENO || analyzeFeatureUsage(moduleInclude, /\byylineno\b/g, 0);
            //this.actionsUseYYTEXT = this.actionsUseYYTEXT || analyzeFeatureUsage(moduleInclude, /\byytext\b/g, 0);
            //this.actionsUseYYLOC = this.actionsUseYYLOC || analyzeFeatureUsage(moduleInclude, /\byyloc\b/g, 0);
            this.actionsUseParseError = this.actionsUseParseError || analyzeFeatureUsage(moduleInclude, /\.parseError\b/g, 0);
            this.actionsUseYYERROR = this.actionsUseYYERROR || analyzeFeatureUsage(moduleInclude, /\.yyError\b/g, 0);
            this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || analyzeFeatureUsage(moduleInclude, /\.yyRecovering\b/g, 0);
            this.actionsUseYYERROK = this.actionsUseYYERROK || analyzeFeatureUsage(moduleInclude, /\.yyErrOk\b/g, 0);
            this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || analyzeFeatureUsage(moduleInclude, /\.yyClearIn\b/g, 0);
            // We cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
            // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
            // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
            // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
            this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\byyvstack\b/g, 0);
            this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\.value_stack\b/g, 0);
            // Ditto for the specific case where we are assigning a value to `$$`, i.e. `this.$`:
            //this.actionsUseValueAssignment = this.actionsUseValueAssignment || analyzeFeatureUsage(moduleInclude, /\bthis\.\$[^\w]/g, 0);
            // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
            this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\byylstack\b/g, 0);
            this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\.location_stack\b/g, 0);
            // Ditto for the specific case where we are assigning a value to `@$`, i.e. `this._$`:
            //this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || analyzeFeatureUsage(moduleInclude, /\bthis\._\$[^\w]/g, 0);
            // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
            // the need to use yystack! Hence yystack is only there for very special use action code.)
            this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\byystack\b/g, 0);
            this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\.symbol_stack\b/g, 0);
            // Ditto for yysstack...
            this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\byysstack\b/g, 0);
            this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\.state_stack\b/g, 0);
            this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\byysp\b/g, 0);
            this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\.stack_pointer\b/g, 0);
            //this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || analyzeFeatureUsage(moduleInclude, /\byyrulelength\b/g, 0);
            this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(moduleInclude, /\.yyMergeLocationInfo\b/g, 0);

            moduleInit.forEach(function (chunk) {
                assert__default['default'](chunk.qualifier);
                assert__default['default'](typeof chunk.include === 'string');
                let moduleInclude = chunk.include;

                //self.actionsUseYYLENG = self.actionsUseYYLENG || analyzeFeatureUsage(moduleInclude, /\byyleng\b/g, 0);
                //self.actionsUseYYLINENO = self.actionsUseYYLINENO || analyzeFeatureUsage(moduleInclude, /\byylineno\b/g, 0);
                //self.actionsUseYYTEXT = self.actionsUseYYTEXT || analyzeFeatureUsage(moduleInclude, /\byytext\b/g, 0);
                //self.actionsUseYYLOC = self.actionsUseYYLOC || analyzeFeatureUsage(moduleInclude, /\byyloc\b/g, 0);
                self.actionsUseParseError = self.actionsUseParseError || analyzeFeatureUsage(moduleInclude, /\.parseError\b/g, 0);
                self.actionsUseYYERROR = self.actionsUseYYERROR || analyzeFeatureUsage(moduleInclude, /\.yyError\b/g, 0);
                self.actionsUseYYRECOVERING = self.actionsUseYYRECOVERING || analyzeFeatureUsage(moduleInclude, /\.yyRecovering\b/g, 0);
                self.actionsUseYYERROK = self.actionsUseYYERROK || analyzeFeatureUsage(moduleInclude, /\.yyErrOk\b/g, 0);
                self.actionsUseYYCLEARIN = self.actionsUseYYCLEARIN || analyzeFeatureUsage(moduleInclude, /\.yyClearIn\b/g, 0);
                // We cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
                // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
                // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
                // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
                self.actionsUseValueTracking = self.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\byyvstack\b/g, 0);
                self.actionsUseValueTracking = self.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\.value_stack\b/g, 0);
                // Ditto for the specific case where we are assigning a value to `$$`, i.e. `self.$`:
                //self.actionsUseValueAssignment = self.actionsUseValueAssignment || analyzeFeatureUsage(moduleInclude, /\bself\.\$[^\w]/g, 0);
                // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
                self.actionsUseLocationTracking = self.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\byylstack\b/g, 0);
                self.actionsUseLocationTracking = self.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\.location_stack\b/g, 0);
                // Ditto for the specific case where we are assigning a value to `@$`, i.e. `self._$`:
                //self.actionsUseLocationAssignment = self.actionsUseLocationAssignment || analyzeFeatureUsage(moduleInclude, /\bself\._\$[^\w]/g, 0);
                // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
                // the need to use yystack! Hence yystack is only there for very special use action code.)
                self.actionsUseYYSTACK = self.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\byystack\b/g, 0);
                self.actionsUseYYSTACK = self.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\.symbol_stack\b/g, 0);
                // Ditto for yysstack...
                self.actionsUseYYSSTACK = self.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\byysstack\b/g, 0);
                self.actionsUseYYSSTACK = self.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\.state_stack\b/g, 0);
                self.actionsUseYYSTACKPOINTER = self.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\byysp\b/g, 0);
                self.actionsUseYYSTACKPOINTER = self.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\.stack_pointer\b/g, 0);
                //self.actionsUseYYRULELENGTH = self.actionsUseYYRULELENGTH || analyzeFeatureUsage(moduleInclude, /\byyrulelength\b/g, 0);
                self.actionsUseYYMERGELOCATIONINFO = self.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(moduleInclude, /\.yyMergeLocationInfo\b/g, 0);
            });

            // ------------------------------------------------------------------------------------
            // Mix in user overrides via CLI or %options:
            this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || this.options.actionsUseLocationAssignment;
            this.actionsUseLocationTracking = this.actionsUseLocationTracking || this.options.actionsUseLocationTracking;
            this.actionsUseParseError = this.actionsUseParseError || this.options.actionsUseParseError;
            this.actionsUseValueAssignment = this.actionsUseValueAssignment || this.options.actionsUseValueAssignment;
            this.actionsUseValueTracking = this.actionsUseValueTracking || this.options.actionsUseValueTracking;
            this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || this.options.actionsUseYYCLEARIN;
            this.actionsUseYYERROK = this.actionsUseYYERROK || this.options.actionsUseYYERROK;
            this.actionsUseYYERROR = this.actionsUseYYERROR || this.options.actionsUseYYERROR;
            this.actionsUseYYLENG = this.actionsUseYYLENG || this.options.actionsUseYYLENG;
            this.actionsUseYYLINENO = this.actionsUseYYLINENO || this.options.actionsUseYYLINENO;
            this.actionsUseYYLOC = this.actionsUseYYLOC || this.options.actionsUseYYLOC;
            this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || this.options.actionsUseYYRECOVERING;
            this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || this.options.actionsUseYYRULELENGTH;
            this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || this.options.actionsUseYYMERGELOCATIONINFO;
            this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || this.options.actionsUseYYSSTACK;
            this.actionsUseYYSTACK = this.actionsUseYYSTACK || this.options.actionsUseYYSTACK;
            this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || this.options.actionsUseYYSTACKPOINTER;
            this.actionsUseYYTEXT = this.actionsUseYYTEXT || this.options.actionsUseYYTEXT;
            this.hasErrorRecovery = this.hasErrorRecovery || this.options.hasErrorRecovery;
            this.hasErrorReporting = this.hasErrorReporting || this.options.hasErrorReporting;

            // ------------------------------------------------------------------------------------
            // Now combine fature flags which are related:
            switch (self.options.defaultActionMode[0]) {
            default:
                this.actionsUseValueTracking = true;
                this.actionsUseValueAssignment = true;
                break;

            case 'none':    // <-- this one injects "$$ = undefined;", which doesn't count as 'non-trivial code' on its own.
            case 'skip':    // <-- this one injects *nothing*
                break;
            }
            this.actionsUseValueTracking = this.actionsUseValueTracking || this.actionsUseYYLENG || this.actionsUseYYTEXT || this.actionsUseValueAssignment;

            switch (self.options.defaultActionMode[1]) {
            default:
                break;

            case 'none':    // <-- this one injects "$$ = undefined;", which doesn't count as 'non-trivial code' on its own.
            case 'skip':    // <-- this one injects *nothing*
                break;
            }
            this.actionsUseLocationTracking = this.actionsUseLocationTracking || this.actionsUseYYLINENO || this.actionsUseYYLOC || this.actionsUseLocationAssignment || this.actionsUseYYMERGELOCATIONINFO;

            this.hasErrorReporting = this.hasErrorReporting || this.actionsUseParseError || this.actionsUseYYERROR;
            // --------------------- done! --------------------------------------------------------

            // Now that we've completed all macro expansions, it's time to execute
            // the recovery code, i.e. the postprocess:
            this.performAction = postprocessActionCode(this.performAction);

            // Now check if we produced an *EMPTY* `parser__PerformAction()`.
            // If so, we can discard the entire function!
            this.actionsAreAllDefault = false; // TODO

            gen_level++;
            prev_gen_hash = gen_hash;
            gen_hash = null;

            // create check hash of the new generated code:
            let new_hash = mkParserFeatureHash(this);

            if ( this.DEBUG) {
                Jison$1.print('Optimization analysis:\n', {
                    cycle: gen_level,
                    SAME: prev_gen_hash === new_hash,
                    actionsAreAllDefault: this.actionsAreAllDefault,
                    actionsUseYYLENG: this.actionsUseYYLENG,
                    actionsUseYYLINENO: this.actionsUseYYLINENO,
                    actionsUseYYTEXT: this.actionsUseYYTEXT,
                    actionsUseYYLOC: this.actionsUseYYLOC,
                    actionsUseParseError: this.actionsUseParseError,
                    actionsUseYYERROR: this.actionsUseYYERROR,
                    actionsUseYYRECOVERING: this.actionsUseYYRECOVERING,
                    actionsUseYYERROK: this.actionsUseYYERROK,
                    actionsUseYYCLEARIN: this.actionsUseYYCLEARIN,
                    actionsUseValueTracking: this.actionsUseValueTracking,
                    actionsUseValueAssignment: this.actionsUseValueAssignment,
                    actionsUseLocationTracking: this.actionsUseLocationTracking,
                    actionsUseLocationAssignment: this.actionsUseLocationAssignment,
                    actionsUseYYSTACK: this.actionsUseYYSTACK,
                    actionsUseYYSSTACK: this.actionsUseYYSSTACK,
                    actionsUseYYSTACKPOINTER: this.actionsUseYYSTACKPOINTER,
                    actionsUseYYRULELENGTH: this.actionsUseYYRULELENGTH,
                    actionsUseYYMERGELOCATIONINFO: this.actionsUseYYMERGELOCATIONINFO,
                    hasErrorRecovery: this.hasErrorRecovery,
                    hasErrorReporting: this.hasErrorReporting,
                    defaultActionMode: this.options.defaultActionMode,
                    testCompileActionCode: this.options.testCompileActionCode,
                    noTryCatch: this.options.noTryCatch
                });
            }

            gen_hash = new_hash;
        }

        // And before we leave, as a SIDE EFFECT of this call, we also fixup
        // the other code chunks specified in the grammar file.
        this.moduleInclude = postprocessActionCode(moduleInclude);
        this.moduleInit = moduleInit.map(function (chunk) {
            assert__default['default'](chunk.qualifier);
            assert__default['default'](typeof chunk.include === 'string');
            chunk.include = postprocessActionCode(chunk.include);
            return chunk;
        });
        assert__default['default'](Array.isArray(this.moduleInit));

        // add helper methods to `this.moduleInit` for later use by our code generator:
        moduleInit = this.moduleInit;
        moduleInit.__consumedInitCodeSlots__ = [];

        moduleInit.getInitCodeSection = function getInitCodeSection(section) {
            let rv = [];
            for (let i = 0, len = this.length; i < len; i++) {
                let m = this[i];
                if (m.qualifier === section) {
                    if (m.include.trim()) {
                        rv.push(m.include);
                    }
                    this.__consumedInitCodeSlots__[i] = true;
                }
            }
            return rv;
        };

        moduleInit.getRemainingInitCodeSections = function getRemainingInitCodeSections() {
            let rv = [];
            for (let i = 0, len = this.length; i < len; i++) {
                let m = this[i];
                if (!this.__consumedInitCodeSlots__[i]) {
                    rv.push(rmCommonWS$5`

                    // START code section "${m.qualifier}"
                    ${m.include}
                    // END code section "${m.qualifier}"

                `);
                    this.__consumedInitCodeSlots__[i] = true;
                }
            }
            return rv;
        };


        // make sure a comment does not contain any embedded '*/' end-of-comment marker
        // as that would break the generated code
        function postprocessComment(str) {
            if (Array.isArray(str)) {
                str = str.map(function (_) {
                    return (_ === '' || _ == null) ? 'ε' : _;
                }).join(' ');
            }
            if (str === '') {
                str = 'ε';
            }
            str = str.replace(/\*\//g, '*\\/');         // destroy any inner `*/` comment terminator sequence.
            return str;
        }

        function getSymbolId(s) {
            if (s && !self.symbols_[s]) {
                throw new Error('Your action code is trying to reference non-existing symbol "' + s + '"');
            }
            return self.symbols_[s] || 0;
        }

        function provideSymbolAsSourcecode(sym) {
            let ss = String(sym);
            return ' /* ' + postprocessComment(ss) + ' */ ' + getSymbolId(sym);
        }

        // helper: convert index string/number to proper JS add/subtract expression
        function indexToJsExpr(n, len, rule4msg) {
            let v = parseInt(n, 10);
            // the usual situation: `$3`; MUST reference an rhs[] element or it will be considered an ERROR:
            if (v > 0) {
                if (v > len) {
                    throw new Error(`invalid token reference "\$${v}" in action code for rule: "${rule4msg}"`);
                }
                v = len - v;
                if (v) {
                    return ` - ${v}`;
                }
                // do not generate code for superfluous `- 0` JS expression:
                return '';
            }
            // the VERY UNusual situation: `$-1`: referencing *parent* rules' values
            if (v < 0) {
                return ` - ${len - v}`;
            }
            // decode error?
            if (v !== 0) {
                throw new Error(`invalid token reference "\$${v}" in action code for rule: "${rule4msg}"`);
            }
            // the slightly unusual situation: `$0` (instead of `$$`)
            v = len;
            if (v) {
                return ` - ${v}`;
            }
            // do not generate code for superfluous `- 0` JS expression:
            return '';
        }

        // options object { actionGroups, actionGroupValue, stateHasAction } is `this` for this function/callback:
        function buildProductionAction(handle) {

            let aliased = handle.aliases;

            let rhs = handle.handle;
            let named_token_re = new XRegExp__default['default'](`^${ID_REGEX_BASE$3}$`);

            // semantic action specified
            let label = [
                'case ', handle.id, ':',
                '\n    /*! Production::    ', postprocessComment(handle.symbol), ' : '
            ].concat(postprocessComment(rhs.map(function (sym) {
                // check if the symbol is a literal terminal, and if it is, quote it:
                if (sym && !self.nonterminals[sym] && !named_token_re.test(sym) && sym !== self.EOF) {
                    return '"' + sym.replace(/["]/g, '\\"') + '"';
                } else if (!sym) {
                    sym = '%epsilon';
                }
                return sym;
            })), ' */').join('');
            let action = preprocessActionCode(handle.action || '');
            let rule4msg = handle.symbol + ': ' + rhs.join(' ');

            assert__default['default'](typeof handle.id === 'number');
            assert__default['default'](handle.id >= 0);
            this.stateHasAction[handle.id] = true;

            // before anything else, replace direct symbol references, e.g. #NUMBER# when there's a %token NUMBER for your grammar.
            // This is done to prevent incorrect expansions where tokens are used in rules as RHS elements: we allow these to
            // be referenced as both #TOKEN# and #TOKEN where the first is a literal token/symbol reference (unrelated to its use
            // in the rule) and the latter is a reference to the token/symbol being used in the rule.
            //
            // Here we expand those direct token/symbol references: #TOKEN#
            action = action
                .replace(new XRegExp__default['default'](`#(${ID_REGEX_BASE$3})#`, 'g'), function (_, sym) {
                    return provideSymbolAsSourcecode(sym);
                });

            // replace named semantic values ($nonterminal)
            if (action.match(new XRegExp__default['default'](`(?:[$@#]|##)${ID_REGEX_BASE$3}`))) {
                let count = {};
                let names = {};
                let donotalias = {};

                // When the rule is fitted with aliases it doesn't mean that the action code MUST use those:
                // we therefor allow access to both the original (non)terminal and the alias.
                //
                // Also note that each (non)terminal can also be uniquely addressed by [$@]<nonterminal><N>
                // where N is a number representing the number of this particular occurrence of the given
                // (non)terminal.
                //
                // For example, given this (intentionally contrived) production:
                //     elem[alias] elem[another_alias] another_elem[alias] elem[alias] another_elem[another_alias]
                // all the items can be accessed as:
                //     $1 $2 $3 $4 $5
                //     $elem1 $elem2 $another_elem1 $elem3 $another_elem2
                //     $elem $elem2 $another_elem $elem3 $another_elem2
                //     $alias1 $another_alias1 $alias2 $alias3 $another_alias2
                //     $alias $another_alias $alias2 $alias3 $another_alias2
                // where each line above is equivalent to the top-most line. Note the numbers postfixed to
                // both (non)terminal identifiers and aliases alike and also note alias2 === another_elem1:
                // the postfix numbering is independent.
                //
                // WARNING: this feature is disabled for a term when there already exists an
                //          (human-defined) *alias* for this term *or* when the numbered auto-alias already
                //          exists because the user has used it as an alias for another term, e.g.
                //
                //             e: WORD[e1] '=' e '+' e;
                //
                //          would *not* produce the `e1` and `e2` aliases, as `e1` is already defined
                //          as an explicit alias: adding auto-alias `e1` would then break the system,
                //          while `e2` would be ambiguous from the human perspective as he *might* then
                //          expect `e2` and `e3`.
                let addName = function addName(s, i) {
                    let base = s.replace(/[0-9]+$/, '');
                    let dna = donotalias[base];

                    if (names[s]) {
                        count[s]++;
                        if (!dna) {
                            names[s + count[s]] = i + 1;
                            count[s + count[s]] = 1;
                        }
                    } else {
                        names[s] = i + 1;
                        count[s] = 1;
                        if (!dna) {
                            names[s + count[s]] = i + 1;
                            count[s + count[s]] = 1;
                        }
                    }
                };

                // register the alias/rule name when the real one ends with a number, e.g. `rule5` as
                // *blocking* the auto-aliasing process for the term of the same base, e.g. `rule`.
                // This will catch the `WORD[e1]` example above too, via `e1` --> `donotalias['e']`
                let markBasename = function markBasename(s) {
                    if (/[0-9]$/.test(s)) {
                        s = s.replace(/[0-9]+$/, '');
                        donotalias[s] = true;
                    }
                };

                for (let i = 0; i < rhs.length; i++) {
                    // mark both regular and aliased names, e.g., `id[alias1]` and `id1`
                    let rhs_i = aliased[i];
                    markBasename(rhs_i);
                    if (rhs_i !== rhs[i]) {
                        markBasename(rhs[i]);
                    }
                }

                for (let i = 0; i < rhs.length; i++) {
                    // check for aliased names, e.g., id[alias]
                    let rhs_i = aliased[i];
                    addName(rhs_i, i);
                    if (rhs_i !== rhs[i]) {
                        addName(rhs[i], i);
                    }
                }
                action = action.replace(
                    new XRegExp__default['default'](`([$@#]|##)(${ID_REGEX_BASE$3})`, 'g'), function (str, mrkr, pl) {
                        if (names[pl] && count[pl] !== 1) {
                            throw new Error(`The action block references the ambiguous named alias or term reference "${pl}" which is mentioned ${count[pl]} times in production "${handle.handle}", implicit and explicit aliases included.` +
                                '\nYou should either provide unambiguous = uniquely named aliases for these terms or use numeric index references (e.g. `$3`) as a stop-gap in your action code.');
                        }
                        return names[pl] ? mrkr + names[pl] : str;
                    });
            }
            action = action
                // replace references to `$$` with `this.$`, `@$` with `this._$` and `#$` with the token ID of the current rule
                .replace(/\$\$/g, 'this.$')
                .replace(/@\$/g, 'this._$')
                .replace(/#\$/g, function (_) {
                    return provideSymbolAsSourcecode(handle.symbol);
                })
                // replace semantic value references ($n) with stack value (stack[n])
                .replace(/\$(-?\d+)\b/g, function (_, n) {
                    return 'yyvstack[yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ']';
                })
                // same as above for location references (@n)
                .replace(/@(-?\d+)\b/g, function (_, n) {
                    return 'yylstack[yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ']';
                })
                // same as above for positional value references (##n): these represent stack indexes
                .replace(/##(-?\d+)\b/g, function (_, n) {
                    return '(yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ')';
                })
                .replace(/##\$/g, function (_) {
                    return 'yysp';
                })
                // same as above for token ID references (#n)
                .replace(/#(-?\d+)\b/g, function (_, n) {
                    let i = parseInt(n, 10) - 1;
                    if (!rhs[i]) {
                        throw new Error(`invalid token location reference in action code for rule: "${rule4msg}" - location reference: "${_}"`);
                    }
                    return provideSymbolAsSourcecode(rhs[i]);
                });

            // Now that the user action (if any) has been expanded to valid JavaScript code
            // (we're SOL and very probably looking at bugs in the user-written action code
            // if it is NOT VALID by now!) we can perform code analysis to see which,
            // if any, default actions have to be injected in the code snippet.
            //
            // The rules of the game are:
            // - when there's *use* of `$$` or `@$` *before* they are assigned a value,
            //   the corresponding default action is required.
            // - when there's *nothing* about (no use of, no assignment to) `$$` or `@$`
            //   then the corresponding default action should be injected IFF the
            //   code analysis flags have been set, i.e. only inject the default action
            //   when we already *know* that other parts of the parser state machine
            //   (other rules' actions!) *are* using these.
            //   We DO NOT include "flow analysis" so we cannot determine if
            //   *this particular* rule's values will be accessed; iff location tracking
            //   is used at all, we inject it everywhere. Ditto for value tracking.
            // - value tracking (`$$` et al) is considered *independently* from location
            //   tracking (`@$` et al): the one or the other may need the default
            //   actions for more-or-less sensible (or at least *deterministic*!) results
            //   and consequently should get them, indenpent of whether the user-written
            //   action code fuly addresses the other.
            //
            //   Generally, user actions concern themselves with assigning a value to `$$`,
            //   while not addressing `@$`: in that case, the location tracking default
            //   action `@$ = ...` will be injected in that action snippet.
            //
            //   Also note that, in order to prevent obscure failures due to analysis
            //   false positives, all default actions are injected *before* the user-written
            //   action code.
            //
            // Technical Note
            //
            // We perform the action code analysis *after* jison variable expansions are done
            // because we want the analysis to be *independent* of how the user wrote
            // the action code: if some Smart Alec decides to code `this.$` instead of
            // `$$` it SHOULD NOT confuse the code analysis here!

            let uses_$$ = analyzeFeatureUsage(action, /\bthis\.\$[^\w]/g, 0);   // use includes assignment, not just read accesses!

            // the next check is very rough; we need the AST of the code to do better than this.
            function analyzeFeatureAssignmentBeforeUse(source, assignment_re, access_re) {
                // first match agains the assignment regex: it MUST have a closure
                // to catch all code that came before this first assignment.
                //
                // If no assignment can be found at all, we're probably looking at access-only
                // OR weird constructs we don't yet understand, in which case we play it safe.
                let prelude = source;
                let m = source.match(assignment_re);
                if (m) {
                    // check the closure exists in the regex: m[1] is filled with its content:
                    assert__default['default'](m[1] != null);
                    prelude = m[1];
                }
                // now check if there's any mention of the feature before its first
                // assignment.
                //
                // We MAY get thwarted by complex action code such as this:
                //
                //     function closure_func(a) {
                //       $$ = a;
                //     }
                //
                //     if ($term1) {
                //       print($$);         // actually this is use before assignment, but we won't recognize it as such!
                //     } else {
                //       closure_func($term2);
                //       print('alt');
                //     }
                //
                // but for now we ignore the complexity of the situation and move on.
                m = prelude.match(access_re);
                if (m) {
                    return true;       // access before assignment
                }
                return false;          // assignment before access (or no usage and assignments at all!)
            }

            let uses_$$_before_assignment = uses_$$ && analyzeFeatureAssignmentBeforeUse(action, /^([^]*?)\bthis\.\$\s*=[^=>]/, /\bthis\.\$[^\w]/g);

            // ditto for location tracking, but only iff we use it at all:
            let uses_$loc = false;
            let uses_$loc_before_assignment = false;

            if (self.actionsUseLocationTracking) {
                uses_$loc = analyzeFeatureUsage(action, /\bthis\._\$[^\w]/g, 0);
                uses_$loc_before_assignment = uses_$loc && analyzeFeatureAssignmentBeforeUse(action, /^([^]*?)\bthis\._\$\s*=[^=>]/, /\bthis\._\$[^\w]/g);
            }

            let inject_default_value_action = (uses_$$_before_assignment || (self.actionsUseValueTracking && !uses_$$));
            let inject_default_loc_action = (uses_$loc_before_assignment || (self.actionsUseLocationTracking && !uses_$loc));

            let default_action = [];

            // Note:
            //
            // when the option defaultActionMode="none,none" has been set, we still strive to produce
            // a deterministic output, hence we take the swiftest route towards producing
            // a deterministic rule result: we assign it the value `undefined`:
            //
            //     $$ = undefined;
            //     $@ = undefined;
            //
            let vmode = !inject_default_value_action ? 'skip' : self.options.defaultActionMode[0];
            let lmode = !inject_default_loc_action ? 'skip' : self.options.defaultActionMode[1];

            // check if there's no user action specified. Insert default action if it isn't.

            // first determine the actual number of terms in the production:
            let rhs_reduced_length = rhs.length;
            let real_rhs_length = rhs.length;

            // strip away EOF terms at the end of the rule, ditto for epsilon terms:
            while (rhs_reduced_length) {
                switch (rhs[rhs_reduced_length - 1]) {
                case '$end':
                    rhs_reduced_length--;
                    continue;

                case '':                // %epsilon
                    rhs_reduced_length--;
                    continue;
                }
                break;
            }

            // then we can choose what to do, depending on the number of terms in the production.
            //
            // There are a few reasons *why* one would choose to inject the default action:
            //
            // 1. there's use (read access) before assignment (write).
            // 2. there's no use nor any assignment, but the rest of the parser *does* use rule values.
            //    (In which case we would need flow analysis to determine if our default action would
            //    really matter, but absent that, we just inject the default action everywhere and
            //    we can be certain the other action code chunks will work as expected, though
            //    the parser may be a bit sub-optimal due to possibly unused default actions being
            //    executed in some states.)
            //
            // Ditto for location tracking default actions...
            //
            switch (rhs_reduced_length) {
            case 0:
                switch (vmode) {
                case 'classic':
                    // $$ = $1;   <-- but that would cause nondeterministic behaviour, so
                    //                we fall back to the default here!
                case 'ast':
                case 'none':
                    default_action.push('this.$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
                }

                switch (lmode) {
                case 'classic':
                case 'ast':
                case 'merge':
                    // an empty production has no location as there are no terms parsed.
                    // ergo: we produce a zero-width location which points at the tail
                    // end of the previous content:
                    // @$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
                    default_action.push('this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);');
                    break;

                case 'none':
                    // @$ = undefined;
                    default_action.push('this._$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
                }
                break;

            case 1:
                switch (vmode) {
                case 'classic':
                    // $$ = $1;
                    //
                    // WARNING: be careful with the ACCEPT rule as that one's production has
                    // rhs_reduced_length === 1 **BUT** has real_rhs_length === 2 as we have discarded
                    // the `$end` term at the end!
                    // Here we need to account for that magick though!
                    default_action.push('this.$ = yyvstack[yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + '];');
                    break;

                case 'ast':
                    // bundle all production terms in an array:
                    //   $$ = yyvstack.slice(yysp - ${rhs_reduced_length - 1}, yysp + 1);
                    // As we're looking at a production which has one(1) useful term, we can simply
                    // reference-copy that one intom a fresh array, instead of `slice()`-ing it out
                    // of the vstack.
                    //   $$ = [$1];
                    //
                    // WARNING/NOTE: as above, and ditto BTW for rule productions which end with
                    // `EOF` as a last term: as we now construct an entire AST, we DO NOT include
                    // those 'values' here!
                    default_action.push('this.$ = [yyvstack[yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + ']];');
                    break;

                case 'none':
                    default_action.push('this.$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
                }

                switch (lmode) {
                case 'classic':
                case 'ast':
                case 'merge':
                    // merge all production terms' locations into a single range:
                    // as we have a production length of 1 only, we can simply ref-copy @1:
                    // @$ = @1;
                    //
                    // WARNING: same as above for the value copying: we may have discarded an `EOF` or `$end` term!
                    default_action.push('this._$ = yylstack[yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + '];');
                    break;

                case 'none':
                    // @$ = undefined;
                    default_action.push('this._$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
                }
                break;

            default:
                switch (vmode) {
                case 'classic':
                    // $$ = $1;
                    default_action.push('this.$ = yyvstack[yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + '];');
                    break;

                case 'ast':
                    // bundle all production terms in an array:
                    // $$ = yyvstack.slice(yysp - ${rhs_reduced_length - 1}, yysp + 1);
                    //
                    // WARNING: as with the situation further above where rhs_reduced_length === 1 after we
                    // have got rid of a possible `EOF` or `$end` at the end of the production,
                    // we again have to account for our trickery earlier and compensate the
                    // action above: again we DO NOT include the value of the EOF/$end token in the
                    // resulting array 'AST', hence our `slice()` end index may vary by one(1):
                    let end_offset = 1 - real_rhs_length + rhs_reduced_length;
                    default_action.push('this.$ = yyvstack.slice(yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + ', yysp' + /* CANNOT USE indexToJsExpr(rhs_reduced_length + 1, real_rhs_length, rule4msg) HERE! */ (end_offset === 0 ? '' : ' + ' + end_offset) + ');');
                    break;

                case 'none':
                    default_action.push('this.$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
                }

                switch (lmode) {
                case 'classic':
                case 'ast':
                case 'merge':
                    // merge all production terms' locations into a single range:
                    // @$ = yyparser.yyMergeLocationInfo(yysp - ${rhs_reduced_length - 1}, yysp);
                    default_action.push('this._$ = yyparser.yyMergeLocationInfo(yysp' + indexToJsExpr(1, real_rhs_length, rule4msg) + ', yysp);');
                    break;

                case 'none':
                    // @$ = undefined;
                    default_action.push('this._$ = undefined;');
                    break;

                case 'skip':
                    // nothing to inject
                    break;

                default:
                    throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
                }
                break;
            }

            // comment/mark the default action chunk, if any, so we can simply observe
            // what is user code and what is generated by us in the final product:
            if (default_action.length > 0) {
                let flags = [
                    rhs_reduced_length + '/' + real_rhs_length,
                    self.actionsUseValueTracking ? 'VT' : '-',
                    self.actionsUseValueAssignment ? 'VA' : '-',
                    uses_$$ ? 'VU' : '-',
                    uses_$$_before_assignment ? 'VUbA' : '-',
                    self.actionsUseLocationTracking ? 'LT' : '-',
                    self.actionsUseLocationAssignment ? 'LA' : '-',
                    uses_$loc ? 'LU' : '-',
                    uses_$loc_before_assignment ? 'LUbA' : '-'
                ].join(',');

                default_action.unshift(`// default action (generated by JISON mode ${self.options.defaultActionMode[0]}/${self.options.defaultActionMode[1]} :: ${flags}):`);
                default_action.push(`// END of default action (generated by JISON mode ${self.options.defaultActionMode[0]}/${self.options.defaultActionMode[1]} :: ${flags})`);

                if (action.trim() !== '') {
                    // If action includes the keyword `let` or `const`, then it's ES6 code
                    // which must be scoped to prevent collisions with other action code chunks
                    // in the same large generated switch/case statement:
                    if (/\blet\b/.test(action) || /\bconst\b/.test(action)) {
                        action = '{\n' + action + '\n}';
                    }
                    default_action.push('\n', action);
                }
                action = default_action.join('\n');
            }

            action = reindentCodeBlock(action, 4);

            let actionHash = mkHashIndex(action);

            // Delay running the postprocess (restore) process until we've done ALL macro expansions:
            //action = postprocessActionCode(action);

            if (actionHash in this.actionGroups) {
                this.actionGroups[actionHash].push(label);
            } else {
                this.actionGroups[actionHash] = [ label ];
                this.actionGroupValue[actionHash] = action;
            }
        }
    };



    generator.createParser = function createParser() {
        throw new Error('Calling abstract method.');
    };

    generator.createLexer = function createLexer() {
        throw new Error('Calling abstract method.');
    };

    // no-op. implemented in debug mixin
    generator.trace = (new Function('', 'function no_op_trace() { }\nreturn no_op_trace;'))();
    //generator.trace.name = 'no_op_trace';

    generator.warn = function warn() {
        let args = Array.prototype.slice.call(arguments, 0);
        Jison$1.print.call(null, args.join(''));
    };

    generator.error = function error(msg) {
        throw new Error(msg);
    };

    // Report a few things about the grammar:
    //
    // - unused rules
    // - stats:
    //   + production count     (-> parser table size indicator)
    //   + state count          (-> parser table size indicator)
    //
    generator.reportGrammarInformation = function reportGrammarInformation() {
        if (this.unused_productions.length) {
            this.warn('\nUnused productions in your grammar:\n  ' + this.unused_productions.join('\n  ') + '\n\n');
        }

        if (!this.options.reportStats) {
            return;
        }

        // nonterminals = this.nonterminals,
        // operators = this.operators,
        // this.table
        // this.states
        // this.defaultActions
        // this.productions,
        // this.terms = {};
        // this.operators = {};
        // this.productions = [];
        // this.conflicts = 0;
        // this.new_conflicts_found_this_round = 0;
        // this.conflicting_states = [];
        // this.resolutions = [];
        // this.options = options;
        // this.parseParams = grammar.parseParams;
        // exportDest.parseTable = this.table;
        // exportDest.defaultParseActions = this.defaultActions;
        // exportDest.parseProductions = this.productions_;

        // TODO: the next bit of code is LR type specific: refactor into a
        //       LR specific mixin class later on, so that we can have another
        //       implementation/report for LL and PEG type grammars.

        let rows = 0, cols = 0;
        let colmarks = {};
        let i, j, len;

        for (i = 0, len = this.table.length; i < len; i++) {
            rows++;
            for (j in this.table[i]) {
                if (!colmarks[j]) {
                    colmarks[j] = true;
                    cols++;
                }
            }
        }
        let defrows = 0;
        let rowmarks = {};
        for (j in this.defaultActions) {
            if (!rowmarks[j]) {
                rowmarks[j] = true;
                defrows++;
            }
        }

        let ntc = 0;
        for (let nt in this.nonterminals) {
            ntc++;
        }

        this.warn('Number of productions in parser:........ ' + this.productions_.length);
        this.warn('Number of non-terminals in grammar:..... ' + ntc);
        this.warn('Number of states:....................... ' + this.states.size());
        this.warn('Number of rows (states) in table:....... ' + this.table.length);
        this.warn('Number of rows in table:................ ' + rows);
        this.warn('Number of columns in table:............. ' + cols);
        this.warn('Number of defaulted rows in table:...... ' + defrows);
        this.warn('Number of unresolvable conflicts:....... ' + this.conflicts);
        this.warn('\n');
    };


    // --- START of debugTraceSrc chunk ---
    const debugTraceSrc = `
function debug_trace() {
    if (typeof Jison !== 'undefined' && Jison.print) {
        Jison.print.apply(null, arguments);
    } else if (typeof print !== 'undefined') {
        print.apply(null, arguments);
    } else if (typeof console !== 'undefined' && console.log) {
        let args = Array.prototype.slice.call(arguments, 0);
        args.unshift('');           // prevent \`%.\` printf-style expansions; see https://nodejs.org/api/console.html#console_console_log_data_args
        console.log.apply(null, args);
    }
}
`;
    // --- END of debugTraceSrc chunk ---

    // Generator debug mixin

    const generatorDebug = {
        trace: (new Function('', debugTraceSrc + `
        return debug_trace;`))(),
        beforeprocessGrammar: function () {
            this.trace('Processing grammar.');
        },
        afteraugmentGrammar: function () {
            let trace = this.trace;
            trace('\nSymbols:\n');
            each(this.symbols, function (sym, i) {
                trace(sym + '(' + i + ')');
            });
            trace('\n');
        }
    };



    /*
     * Mixin for common behaviors of lookahead parsers
     */
    let lookaheadMixin = {};

    lookaheadMixin.computeLookaheads = function computeLookaheads() {
        if (this.DEBUG) {
            this.mix(lookaheadDebug); // mixin debug methods
        }

        this.computeLookaheads = function () {};
        this.nullableSets();
        this.firstSets();
        this.followSets();
    };

    lookaheadMixin.displayFollowSets = function displayFollowSets() {
        let self = this;
        let symfollowdbg = {};
        this.productions.forEach(function Follow_prod_forEach_debugOut(production, k) {
            let key = [ 'prod-', k, ':  ', production.symbol, ' := ', production.handle.join(' ') ].join('');
            let flw = '[' + self.nonterminals[production.symbol].follows.join(']  [') + ']';
            if (!symfollowdbg[flw]) {
                symfollowdbg[flw] = {};
            }
            if (!symfollowdbg[flw][key]) {
                symfollowdbg[flw][key] = 1;
            } else {
                assert__default['default'](0);
                symfollowdbg[flw][key]++;
            }
        });
        for (let l in symfollowdbg) {
            let lst = [];
            for (let k in symfollowdbg[l]) {
                lst.push(k);
            }
            self.trace('Symbol/Follows:\n   ', lst.join('\n    '), ' -->\n        ', l);
        }
    };

    // calculate follow sets based on first and nullable
    lookaheadMixin.followSets = function followSets() {
        let productions = this.productions;
        let nonterminals = this.nonterminals;
        let self = this;
        let cont = true;

        // loop until no further changes have been made
        while (cont) {
            cont = false;

            productions.forEach(function Follow_prod_forEach(production, k) {

                // q is used in Simple LALR algorithm determine follows in context
                let q;
                let ctx = !!self.go_;

                for (let i = 0, t; (t = production.handle[i]); ++i) {
                    if (!nonterminals[t]) continue;

                    // for Simple LALR algorithm, self.go_ checks if
                    if (ctx) {
                        q = self.go_(production.symbol, production.handle.slice(0, i));
                    }
                    let bool = (!ctx || q === self.nterms_[t]);
                    let set;

                    if (i === production.handle.length - 1 && bool) {
                        set = nonterminals[production.symbol].follows;
                    } else {
                        let part = production.handle.slice(i + 1);

                        set = self.first(part);
                        if (self.nullable(part) && bool) {
                            assert__default['default'](nonterminals[production.symbol].follows);
                            set.push.apply(set, nonterminals[production.symbol].follows);
                        }
                    }
                    let follows = nonterminals[t].follows;
                    let oldcount = follows.length;
                    follows = union(follows, set);
                    if (oldcount !== follows.length) {
                        cont = true;
                    }
                    nonterminals[t].follows = follows;
                }
            });
        }

        if ( this.DEBUG) {
            this.displayFollowSets();
        }
    };

    // return the FIRST set of a symbol or series of symbols
    lookaheadMixin.first = function first(symbol) {
        // epsilon
        if (symbol === '') {
            return [];
        // RHS
        } else if (symbol instanceof Array) {
            let firsts = [];
            for (let i = 0, t; (t = symbol[i]); ++i) {
                if (!this.nonterminals[t]) {
                    if (firsts.indexOf(t) === -1) {
                        firsts.push(t);
                    }
                } else {
                    firsts = union(firsts, this.nonterminals[t].first);
                }
                if (!this.nullable(t)) { break; }
            }
            return firsts;
        // terminal
        } else if (!this.nonterminals[symbol]) {
            return [ symbol ];
        // nonterminal
        }
        return this.nonterminals[symbol].first;

    };

    // fixed-point calculation of FIRST sets
    lookaheadMixin.firstSets = function firstSets() {
        let productions = this.productions;
        let nonterminals = this.nonterminals;
        let self = this;
        let cont = true;

        // loop until no further changes have been made
        while (cont) {
            cont = false;

            productions.forEach(function FirstSets_forEach(production, k) {
                let firsts = self.first(production.handle);
                if (firsts.length !== production.first.length) {
                    production.first = firsts;
                    cont = true;
                }
            });

            for (let symbol in nonterminals) {
                let firsts = [];
                nonterminals[symbol].productions.forEach(function FirstSets_forEachNonTerm(production) {
                    firsts = union(firsts, production.first);
                });
                if (firsts.length !== nonterminals[symbol].first.length) {
                    nonterminals[symbol].first = firsts;
                    cont = true;
                }
            }
        }
    };

    // fixed-point calculation of NULLABLE
    lookaheadMixin.nullableSets = function nullableSets() {
        let nonterminals = this.nonterminals;
        let self = this;
        let cont = true;

        // loop until no further changes have been made
        while (cont) {
            cont = false;

            // check if each production is nullable
            this.productions.forEach(function isEachProductionNullable(production, k) {
                if (!production.nullable) {
                    let i = 0;
                    let n = 0;
                    for (let t; (t = production.handle[i]); ++i) {
                        if (self.nullable(t)) n++;
                    }
                    if (n === i) { // production is nullable if all tokens are nullable
                        production.nullable = cont = true;
                    }
                }
            });

            // check if each symbol is nullable
            for (let symbol in nonterminals) {
                if (!this.nullable(symbol)) {
                    for (let i = 0, production; (production = nonterminals[symbol].productions.item(i)); i++) {
                        if (production.nullable) {
                            nonterminals[symbol].nullable = cont = true;
                        }
                    }
                }
            }
        }
    };

    // check if a token or series of tokens is nullable
    lookaheadMixin.nullable = function nullable(symbol) {
        // epsilon
        if (symbol === '') {
            return true;
        // RHS
        } else if (symbol instanceof Array) {
            for (let i = 0, t; (t = symbol[i]); ++i) {
                if (!this.nullable(t)) {
                    return false;
                }
            }
            return true;
        // terminal
        } else if (!this.nonterminals[symbol]) {
            return false;
        // nonterminal
        }
        return this.nonterminals[symbol].nullable;

    };


    // lookahead debug mixin
    const lookaheadDebug = {
        beforenullableSets: function () {
            this.trace('Computing Nullable sets.');
        },
        beforefirstSets: function () {
            this.trace('Computing First sets.');
        },
        beforefollowSets: function () {
            this.trace('Computing Follow sets.');
        },
        afterfollowSets: function () {
            let trace = this.trace;
            trace('\nNonterminals:\n');
            each(this.nonterminals, function (nt, t) {
                trace(nt.toString(), '\n');
            });
            trace('\n');
        }
    };

    /*
     * Mixin for common LR parser behavior
     */
    let lrGeneratorMixin = {};


    // LR state machine actions:
    const NONASSOC = 0;
    const SHIFT = 1; // shift
    const REDUCE = 2; // reduce
    const ACCEPT = 3; // accept


    lrGeneratorMixin.buildTable = function buildTable() {
        if (this.DEBUG) {
            this.mix(lrGeneratorDebug); // mixin debug methods
        }

        this.states = this.canonicalCollection();

        if ( this.DEBUG) {
            Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER canonicalCollection:');
            this.displayFollowSets();
            Jison$1.print('\n');
        }

        this.table = this.parseTable(this.states);

        if ( this.DEBUG) {
            Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable:');
            this.displayFollowSets();
            Jison$1.print('\n');
        }

        this.defaultActions = findDefaults(this.table, this.hasErrorRecovery);
        cleanupTable(this.table);

        traceStates(this.trace, this.states, 'at the end of LR::buildTable(), after cleanupTable()');
    };

    lrGeneratorMixin.Item = typal.construct({
        constructor: function Item(production, dotPosition, followSet, predecessor) {
            this.production = production;
            this.dotPosition = dotPosition || 0;
            this.follows = followSet || [];
            this.predecessor = predecessor;
            this.id = production.id + '#' + this.dotPosition;
            this.markedSymbol = this.production.handle[this.dotPosition];
        },
        remainingHandle: function () {
            return this.production.handle.slice(this.dotPosition + 1);
        },
        eq: function (e) {
            return e.id === this.id;
        },
        handleToString: function () {
            let handle = this.production.handle.slice(0);
            handle[this.dotPosition] = '.' + (handle[this.dotPosition] || '');
            return handle.join(' ');
        },
        toString: function () {
            let temp = this.production.handle.slice(0);
            temp[this.dotPosition] = '.' + (temp[this.dotPosition] || '');
            let s = this.production.symbol + ' -> ' + temp.join(' ');
            let padlen = Math.max(4, 40 - s.length);
            let pad = new Array(padlen);
            if (this.follows.length) {
                s += pad.join(' ') + '#lookaheads= [' + this.follows.join(']  [') + ']';
                pad = new Array(2);
            }
            if (this.reductions && this.reductions.length) {
                s += pad.join(' ') + '#reductions= [' + this.reductions.join(']  [') + ']';
                pad = new Array(2);
            }
            return s;
        }
    });

    lrGeneratorMixin.ItemSet = Set$1.prototype.construct({
        afterconstructor: function () {
            this.reductions = [];
            this.goes = {};
            this.edges = {};
            this.shifts = false;
            this.inadequate = false;
            this.hash_ = {};
            for (let i = this._items.length - 1; i >= 0; i--) {
                this.hash_[this._items[i].id] = true; //i;
            }
        },
        concat: function concat(set) {
            let a = set._items || set;
            for (let i = a.length - 1; i >= 0; i--) {
                this.hash_[a[i].id] = true;
            }
            this._items.push.apply(this._items, a);
            return this;
        },
        push: function (item) {
            this.hash_[item.id] = true;
            return this._items.push(item);
        },
        contains: function (item) {
            return this.hash_[item.id];
        },
        valueOf: function toValue() {
            let v = this._items.map(function (a) { return a.id; }).sort().join('|');
            this.valueOf = function valueOf_inner() { return v; };
            return v;
        }
    });

    lrGeneratorMixin.closureOperation = function closureOperation(itemSet) {
        let closureSet = new this.ItemSet();
        let self = this;

        let set = itemSet;
        let itemQueue;
        let syms = {};

        do {
            itemQueue = new Set$1();
            closureSet = closureSet.concat(set);
            set.forEach(function CO_set_forEach(item) {
                let symbol = item.markedSymbol;

                // if token is a non-terminal, recursively add closures
                if (symbol && self.nonterminals[symbol]) {
                    if (!syms[symbol]) {
                        self.nonterminals[symbol].productions.forEach(function CO_nt_forEach(production) {
                            let newItem = new self.Item(production, 0);
                            if (!closureSet.contains(newItem)) {
                                itemQueue.push(newItem);
                            }
                        });
                        syms[symbol] = true;
                    }
                } else if (!symbol) {
                    // reduction
                    closureSet.reductions.push(item);
                    closureSet.inadequate = (closureSet.reductions.length > 1 || closureSet.shifts);
                } else {
                    // shift
                    closureSet.shifts = true;
                    closureSet.inadequate = closureSet.reductions.length > 0;
                }
            });

            set = itemQueue;
        } while (!itemQueue.isEmpty());

        return closureSet;
    };

    lrGeneratorMixin.gotoOperation = function gotoOperation(itemSet, symbol) {
        let gotoSet = new this.ItemSet();
        let self = this;

        itemSet.forEach(function goto_forEach(item, n) {
            if (item.markedSymbol === symbol) {
                gotoSet.push(new self.Item(item.production, item.dotPosition + 1, item.follows, n));
            }
        });

        return gotoSet;
    };

    /*
     * Create unique set of item sets
     */
    lrGeneratorMixin.canonicalCollection = function canonicalCollection() {
        let item1 = new this.Item(this.productions[0], 0, [ this.EOF ]);
        let firstStateNoClosure = new this.ItemSet(item1);
        let firstState = this.closureOperation(firstStateNoClosure);
        let states = new Set$1(firstState);
        let marked = 0;
        let self = this;
        let itemSet;
        let markedSymbols;

        states.has = {};
        states.has[firstStateNoClosure.valueOf()] = 0;

        while (marked !== states.size()) {
            itemSet = states.item(marked);
            markedSymbols = {};
            itemSet.forEach(function CC_itemSet_forEach(item) {
                if (item.markedSymbol && !markedSymbols[item.markedSymbol] && item.markedSymbol !== self.EOF) {
                    markedSymbols[item.markedSymbol] = true;
                    self.canonicalCollectionInsert(item.markedSymbol, itemSet, states, marked);
                }
            });
            marked++;
        }

        return states;
    };

    // Pushes a unique state into the queue. Some parsing algorithms may perform additional operations
    lrGeneratorMixin.canonicalCollectionInsert = function canonicalCollectionInsert(symbol, itemSet, states, stateNum) {
        let g = this.gotoOperation(itemSet, symbol);
        let state = states.has[g.valueOf()];

        if (typeof state !== 'undefined') {
            itemSet.edges[symbol] = state;       // store goto transition for table
            states.item(state).predecessors[symbol].push(stateNum);
        } else {
            // add g to queue if not empty or duplicate
            if (!g.isEmpty()) {
                states.has[g.valueOf()] = states.size();
                g = this.closureOperation(g);
                if (!g.predecessors) {
                    g.predecessors = {};
                }
                itemSet.edges[symbol] = states.size();  // store goto transition for table
                states.push(g);
                g.predecessors[symbol] = [ stateNum ];
            }
        }
    };

    lrGeneratorMixin.parseTable = function lrParseTable(itemSets) {
        let states = [];
        let nonterminals = this.nonterminals;
        let operators = this.operators;
        let conflictedStates = {}; // set of [state, token] tuples
        let self = this;

        // for each item set
        itemSets.forEach(function parseTableItem(itemSet, k) {
            k = +k;
            let state = states[k] = {};
            let action, stackSymbol;

            // set shift and goto actions
            for (stackSymbol in itemSet.edges) {
                itemSet.forEach(function findShiftAndGotoActions(item, j) {
                    // find shift and goto actions
                    if (item.markedSymbol === stackSymbol) {
                        let gotoState = itemSet.edges[stackSymbol];
                        assert__default['default'](gotoState);
                        if (nonterminals[stackSymbol]) {
                            // store state to go to after a reduce
                            state[self.symbols_[stackSymbol]] = gotoState;
                        } else {
                            state[self.symbols_[stackSymbol]] = [ SHIFT, gotoState ];
                        }
                    }
                });
            }

            // set accept action
            itemSet.forEach(function setAcceptAction(item, j) {
                if (item.markedSymbol === self.EOF) {
                    // accept
                    state[self.symbols_[self.EOF]] = [ ACCEPT ];
                }
            });

            let allterms = self.lookAheads ? false : self.terminals;

            // set reductions and resolve potential conflicts
            itemSet.reductions.forEach(function calcReduction(item, j) {
                // if parser uses lookahead, only enumerate those terminals
                let terminals = allterms || self.lookAheads(itemSet, item);

                terminals.forEach(function (stackSymbol) {
                    action = state[self.symbols_[stackSymbol]];
                    let op = operators[stackSymbol];

                    // Reading a terminal and current position is at the end of a production, try to reduce
                    if (action) {
                        let sol = resolveConflict(item.production, op, [ REDUCE, item.production.id ], action[0] instanceof Array ? action[0] : action);
                        self.resolutions.push([ k, stackSymbol, sol ]);
                        if (sol.bydefault) {
                            self.conflicts++;

                            if (self.conflict_fixing_round && self.options.hasPartialLrUpgradeOnConflict) {
                                // have we encountered a *new* conflict, compared to previous rounds?
                                if (!self.conflict_productions_LU[item.production.id]) {
                                    self.new_conflicts_found_this_round++;
                                    // and we RESET the `conflict_fixing_round` flag to signal that
                                    // this round needs another one to attempt a *complete* fix
                                    // of the grammar.
                                    //
                                    // This little act also conveniently helps to manage the
                                    // *finity* of the big parsetable production loop, which
                                    // wraps around all this work (and more).
                                    self.conflict_fixing_round = false;
                                    if (self.enableDebugLogs) {
                                        self.warn('RESET conflict fixing: we need another round to see us through...');
                                    }
                                }
                            }
                            if (!self.conflict_fixing_round && self.options.hasPartialLrUpgradeOnConflict) {
                                self.conflict_productions_LU[item.production.id] = true;
                                self.conflict_states_LU[k] = true;
                            }

                            if (self.enableDebugLogs) {
                                self.warn('Conflict in grammar: multiple actions possible when lookahead token is ', stackSymbol, ' in state ', k, '\n- ', printAction(sol.r, self), '\n- ', printAction(sol.s, self), '\n  (', sol.msg, ')');
                            }
                            conflictedStates[k] = {
                                reduction: item,
                                symbol: stackSymbol,
                                resolution: sol,
                                state: k
                            };

                            if (self.options.noDefaultResolve) {
                                if (!(action[0] instanceof Array)) {
                                    action = [ action ];
                                }
                                action.push(sol.r);
                            }
                        } else {
                            action = sol.action;
                        }
                    } else {
                        action = [ REDUCE, item.production.id ];
                    }
                    if (action && action.length) {
                        state[self.symbols_[stackSymbol]] = action;
                    } else if (action === NONASSOC) {
                        state[self.symbols_[stackSymbol]] = NONASSOC;
                        // ^- Can't delete this node right away as it will influence
                        // `findDefaults()` decision-making process adversely when this state is
                        // not visible at that time. Hence we defer cleanup to the function
                        // `cleanupTable()` which will be invoked at the very end: the NONASSOC
                        // transition signals a transition into an ERROR state and we don't care
                        // for the explicit zero(0) to be present in our table as anything
                        // 'falsey' as an action code will be considered an error state in
                        // the parser and not having these zeroes around keeps the table small(er).
                    }
                });
            });
        });

        self.conflicting_states = conflictedStates;

        if (self.conflicts > 0) {
            if (self.numExpectedConflictStates !== self.conflicts || self.enableDebugLogs) {
                self.warn('\nStates with conflicts:');
                each(conflictedStates, function report_conflict_state(val, state) {
                    self.warn('\nState ' + state, '    (' + val.symbol + ' @ ' + val.reduction.production.symbol + ' -> ' + val.reduction.handleToString() + ')\n');
                    self.warn('  ', itemSets.item(state).join('\n  '));
                });
                self.warn('\n');
            }
        }

        return states;
    };

    // find states with only one action: a reduction.
    //
    // Note: only the state columns for EOF/ERROR/terminals are relevant here as those
    // columns are the only ones ever visited by the table lookup code at the top
    // of the loop in the parse kernel as the `symbol` index used there cannot ever
    // contain a *nonterminal* value!
    //
    // The nonterminals are recognizable in the table by having numeric entries, rather
    // than 1-or-2-element array values, as they only store a GOTO state.
    //
    // ---
    //
    // Another 'default' is when all listed terminals all point to the exact same reduce state;
    // only this time we are careful about the TERROR symbol as a state carrying that one
    // is an explicitly encoded error recovery rule and should remain as-is.
    function findDefaults(states, hasErrorRecovery) {
        let defaults = {};
        states.forEach(function (state, k) {
            let act;
            let i = 0;
            let gotos = {};

            for (let sym in state) {
                assert__default['default']({}.hasOwnProperty.call(state, sym));    // it this isn't true, the last part of this function won't work!
                // keep state rows where there's an error recovery state:
                if (sym === 2 /* TERROR */) {
                    return;
                }
                let st = state[sym];
                if (typeof st !== 'number') {
                    if (st[0] !== REDUCE) {
                        // not a reduce action: forget about this row!
                        return;
                    }
                    let go = st[1];
                    if (!gotos[go]) {
                        gotos[go] = true;
                        i++;
                        act = sym;
                    }
                } else if (st === NONASSOC) {
                    // forget about this row: it's a state where we should kick up an error
                    // because you're trying to get associativity going where there is none!
                    return;
                }
            }

            if (i === 1) {
                // only one action in state and it's a reduction; hence we only need to store the new (goto production) state:
                defaults[k] = state[act][1];

                // ... and nuke the entry/entries in the parse table to save space in the generated output: we won't be needing
                // it any more! But make sure we keep the slots for the nonterminal symbols, so only nuke the *terminal* entries!
                //
                // Aber Oh-ho! The table[] entries themselves *are* used: they are needed by
                // the error recovery code to decide, when SHIFTING, if the ERROR token would
                // improve (fix) matters when it is treated as an *inserted* token.  This code
                // is therefor not executed then!
                //
                // ... hence we only nuke these table entries (as that makes for a smaller table --> smaller parser file)
                // when there's no error recovery code included in the generated parser:
                if (!hasErrorRecovery) {
                    for (let sym in state) {
                        let st = state[sym];
                        if (typeof st !== 'number') {
                            delete state[sym];
                        }
                    }
                }
            }
        });

        return defaults;
    }

    // Remove all NONASSOC state transitions from the generated table now that we don't need them any longer
    function cleanupTable(table) {
        table.forEach(function (state, k) {
            for (let symbol in state) {
                if (state[symbol] === NONASSOC) {
                    delete state[symbol];
                }
            }
        });
    }

    // resolves shift-reduce and reduce-reduce conflicts
    function resolveConflict(production, op, reduce, shift) {
        let sln = {
            production: production,
            operator: op,
            r: reduce,
            s: shift,

            msg: null,
            action: null,
            bydefault: false
        };

        if (shift[0] === REDUCE) {
            sln.msg = 'Resolved R/R conflict: use first production declared in grammar.';
            sln.action = shift[1] < reduce[1] ? shift : reduce;
            if (shift[1] !== reduce[1]) sln.bydefault = true;
            return sln;
        }

        if (production.precedence === 0 || !op) {
            sln.msg = 'Resolved S/R conflict: shift by default.';
            sln.bydefault = true;
            sln.action = shift;
        } else if (production.precedence < op.precedence) {
            sln.msg = 'Resolved S/R conflict: shift for higher precedent operator.';
            sln.action = shift;
        } else if (production.precedence === op.precedence) {
            if (op.assoc === 'right') {
                sln.msg = 'Resolved S/R conflict: shift for right associative operator.';
                sln.action = shift;
            } else if (op.assoc === 'left') {
                sln.msg = 'Resolved S/R conflict: reduce for left associative operator.';
                sln.action = reduce;
            } else if (op.assoc === 'nonassoc') {
                sln.msg = 'Resolved S/R conflict: no action for non-associative operator.';
                sln.action = NONASSOC;
            }
        } else {
            sln.msg = 'Resolved conflict: reduce for higher precedent production.';
            sln.action = reduce;
        }

        return sln;
    }

    /*
     * Mixin for common LR/LL/*any* parser behavior
     */
    let generatorMixin = {};

    // internal helper function:
    generatorMixin.__prepareOptions = function parser___prepare_Options(opt) {
        opt = mkStdOptions$1(this.options, opt);

        prepExportStructures$1(opt);

        this.options = opt;
        this.DEBUG = !!opt.debug;

        // check for illegal identifier
        if (!opt.moduleName || !opt.moduleName.match(/^[a-zA-Z_$][a-zA-Z0-9_$\.]*?[a-zA-Z0-9_$]$/)) {
            if (opt.moduleName) {
                let msg = 'WARNING: The specified moduleName "' + opt.moduleName + '" is illegal (only characters [a-zA-Z0-9_$] and "." dot are accepted); using the default moduleName "parser" instead.';
                if (typeof opt.warn_cb === 'function') {
                    opt.warn_cb(msg);
                } else if (opt.warn_cb) {
                    Jison$1.print(msg);
                } else {
                    // do not treat as warning; barf hairball instead so that this oddity gets noticed right away!
                    throw new Error(msg);
                }
            }
            opt.moduleName = opt.defaultModuleName;
        }
        return opt;
    };

    generatorMixin.generateGenericHeaderComment = function generateGenericHeaderComment() {
        let out = `
/* parser generated by jison ${version$2} */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" \`yy\` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               \`cleanupAfterParse()\` will clean up and reset \`quoteName()\` to reference this function
 *               at the end of the \`parse()\`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack),
 *
 *               The function parameters and \`this\` have the following value/meaning:
 *               - \`this\`    : reference to the \`yyval\` internal object, which has members (\`$\` and \`_$\`)
 *                             to store/reference the rule value \`$$\` and location info \`@$\`.
 *
 *                 One important thing to note about \`this\` a.k.a. \`yyval\`: every *reduce* action gets
 *                 to see the same object via the \`this\` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use \`yyval\` a.k.a. \`this\` for storing you own semi-permanent data.
 *
 *                 \`this.yy\` is a direct reference to the \`yy\` shared state object.
 *
 *                 \`%parse-param\`-specified additional \`parse()\` arguments have been added to this \`yy\`
 *                 object at \`parse()\` start and are therefore available to the action code via the
 *                 same named \`yy.xxxx\` attributes (where \`xxxx\` represents a identifier name from
 *                 the \%parse-param\` list.
 *
 *               - \`yytext\`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, \`yytext\` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - \`yyleng\`  : ditto as \`yytext\`, only now for the lexer.yyleng value.
 *
 *               - \`yylineno\`: ditto as \`yytext\`, only now for the lexer.yylineno value.
 *
 *               - \`yyloc\`   : ditto as \`yytext\`, only now for the lexer.yylloc lexer token location info.
 *
 *                               WARNING: since jison 0.4.18-186 this entry may be NULL/UNDEFINED instead
 *                               of an empty object when no suitable location info can be provided.
 *
 *               - \`yystate\` : the current parser state number, used internally for dispatching and
 *                               executing the action code chunk matching the rule currently being reduced.
 *
 *               - \`yysp\`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. \`##$ === ##0 === yysp\`, while \`##1\` is the stack index for all things
 *                 related to the first rule term, just like you have \`$1\`, \`@1\` and \`#1\`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - \`yyrulelength\`: the current rule's term count, i.e. the number of entries occupied on the stack.
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *               - \`yyvstack\`: reference to the parser value stack. Also accessed via the \`$1\` etc.
 *                             constructs.
 *
 *               - \`yylstack\`: reference to the parser token location stack. Also accessed via
 *                             the \`@1\` etc. constructs.
 *
 *                             WARNING: since jison 0.4.18-186 this array MAY contain slots which are
 *                             UNDEFINED rather than an empty (location) object, when the lexer/parser
 *                             action code did not provide a suitable location info object when such a
 *                             slot was filled!
 *
 *               - \`yystack\` : reference to the parser token id stack. Also accessed via the
 *                             \`#1\` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any \`#n\` reference to
 *                 its numeric token id value, hence that code wouldn't need the \`yystack\` but *you* might
 *                 want access this array for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - \`yysstack\`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in \`yystate\`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - \`...\`     : the extra arguments you specified in the \`%parse-param\` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - \`state\`  --> hash table
 *               - \`symbol\` --> action (number or array)
 *
 *                 If the \`action\` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO \`state\`
 *
 *                 If the \`action\` is a number, it is the GOTO \`state\`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into \`parseError()\`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   let infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   let retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic \`parseError\` handler provided by JISON.
 *               \`cleanupAfterParse()\` will clean up and reset \`parseError()\` to reference this function
 *               at the end of the \`parse()\`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given \`input\` and return the parsed value (or \`true\` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional \`args...\` parameters as per \`%parse-param\` spec of this grammar:
 *               these extra \`args...\` are added verbatim to the \`yy\` object reference as member variables.
 *
 *               WARNING:
 *               Parser's additional \`args...\` parameters (via \`%parse-param\`) MAY conflict with
 *               any attributes already added to \`yy\` by the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *               The lexer MAY add its own set of additional parameters (via the \`%parse-param\` line in
 *               the lexer section of the grammar spec): these will be inserted in the \`yy\` shared state
 *               object and any collision with those will be reported by the lexer via a thrown exception.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               This helper API is invoked at the end of the \`parse()\` call, unless an exception was thrown
 *               and \`%options no-try-catch\` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the \`post_parse\` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    yyMergeLocationInfo: function(first_index, last_index, first_yylloc, last_yylloc, dont_look_back),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               This helper API can be invoked to calculate a spanning \`yylloc\` location info object.
 *
 *               Note: %epsilon rules MAY specify no \`first_index\` and \`first_yylloc\`, in which case
 *               this function will attempt to obtain a suitable location marker by inspecting the location stack
 *               backwards.
 *
 *               For more info see the documentation comment further below, immediately above this function's
 *               implementation.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" \`yy\` once
 *                             received via a call to the \`.setInput(input, yy)\` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The \`parseError\` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the \`collect_expected_token_set()\`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal \`$$\` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" \`yy\`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while \`this\` will reference the current parser instance.
 *
 * When \`parseError\` is invoked by the lexer, \`this\` will still reference the related *parser*
 * instance, while these additional \`hash\` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When \`parseError\` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, \`this\` will still reference the related *parser*
 * instance, while these additional \`hash\` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the \`expected\` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the \`.yy\` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy)
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last \`%%\`.
 *  Parser.post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last \`%%\`. When it does not return any value,
 *                 the parser will return the original \`retval\`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy)
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of \`lex()\`) but immediately after the invocation of
 *                 \`parser.pre_parse()\`).
 *      post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 \`retval\` contains the return value to be produced by \`Parser.parse()\`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 \`retval\`.
 *                 This function is invoked immediately before \`parser.post_parse()\`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default \`parseError\` function.
 *      quoteName: function(name),
 *                 optional: overrides the default \`quoteName\` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 \`this\` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token \`token\`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original \`token\`.
 *                 \`this\` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: \`true\` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: \`true\` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: \`true\` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: \`true\` ==> lexer rule regexes are "extended regex format" requiring the
 *                 \`XRegExp\` library. When this \`%option\` has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */
`;

        return out;
    };

    generatorMixin.generate = function parser_generate(opt) {
        opt = this.__prepareOptions(opt);

        let code = '';

        switch (opt.moduleType) {
        case 'js':
            code = this.generateModule(opt);
            break;
        case 'amd':
            code = this.generateAMDModule(opt);
            break;
        case 'es':
            code = this.generateESModule(opt);
            break;
        case 'commonjs':
            code = this.generateCommonJSModule(opt);
            break;
        default:
            throw new Error('unsupported moduleType: ' + opt.moduleType);
        }

        return code;
    };


    generatorMixin.generateAMDModule = function generateAMDModule(opt) {
        opt = this.__prepareOptions(opt);

        let module = this.generateModule_();
        let out = [
            this.generateGenericHeaderComment(),
            '',
            'define(function (require) {',
            module.initCode,
            module.commonCode,
            '',
            'let parser = ' + module.moduleCode,
            module.modulePostlude
        ];
        if (this.lexer && this.lexer.generateModule) {
            let lexSrc = this.lexer.generateModule();
            opt.exportSourceCode.lexer = lexSrc;
            out.push(lexSrc);
            out.push('parser.lexer = lexer;');
        }
        out.push('', module.moduleInclude, '', 'return parser;');
        out.push('});');

        let src = out.join('\n') + '\n';
        opt.exportSourceCode.all = src;
        return src;
    };

    lrGeneratorMixin.generateESModule = function generateESModule(opt) {
        opt = this.__prepareOptions(opt);

        let module = this.generateModule_();
        let out = [
            this.generateGenericHeaderComment(),
            '',
            module.initCode,
            module.commonCode,
            '',
            'let parser = ' + module.moduleCode,
            module.modulePostlude
        ];
        if (this.lexer && this.lexer.generateModule) {
            let lexSrc = this.lexer.generateModule();
            opt.exportSourceCode.lexer = lexSrc;
            out.push(this.lexer.generateModule());
            out.push('parser.lexer = lexer;');
        }
        out.push('', module.moduleInclude, '');

        let exportMain = '';
        let invokeMain = '';
        if (!opt.noMain) {
            let moduleNameAsCode = String(opt.moduleMain || commonJsMain);
            let moduleImportsAsCode = String(opt.moduleMainImports || commonJsMainImports);

            out.push(rmCommonWS$5`

            ${moduleImportsAsCode}

            let yymain = ${moduleNameAsCode.trim()};

            function yyExecMain() {
              yymain(process.argv.slice(1));
            }
        `);
            exportMain = 'main: yyExecMain,';
            invokeMain = rmCommonWS$5`
            // IFF this is the main module executed by NodeJS,
            // then run 'main()' immediately:
            if (typeof module !== 'undefined' && require.main === module) {
              yyExecMain();
            }
        `;
        }
        out.push(rmCommonWS$5`
        function Parser() {
            this.yy = {};
        }
        Parser.prototype = parser;
        parser.Parser = Parser;

        function yyparse() {
            return parser.parse.apply(parser, arguments);
        }

        ${invokeMain}

        export default {
            parser,
            Parser,
            parse: yyparse,
            ${exportMain}
        };
    `);

        let src = out.join('\n') + '\n';
        opt.exportSourceCode.all = src;
        return src;
    };

    generatorMixin.generateCommonJSModule = function generateCommonJSModule(opt) {
        opt = this.__prepareOptions(opt);

        let moduleName = opt.moduleName;
        let main = '';
        if (!opt.noMain) {
            let moduleNameAsCode = String(opt.moduleMain || commonJsMain);
            let moduleImportsAsCode = String(opt.moduleMainImports || commonJsMainImports);

            main = rmCommonWS$5`

            ${moduleImportsAsCode}

            exports.main = ${moduleNameAsCode.trim()};

            // IFF this is the main module executed by NodeJS,
            // then run 'main()' immediately:
            if (typeof module !== 'undefined' && require.main === module) {
              exports.main(process.argv.slice(1));
            }
        `;
        }
        let out = this.generateModule(opt) +
            rmCommonWS$5`


        if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
          exports.parser = ${moduleName};
          exports.Parser = ${moduleName}.Parser;
          exports.parse = function () {
            return ${moduleName}.parse.apply(${moduleName}, arguments);
          };
          ${main}
        }
        `;

        opt.exportSourceCode.all = out;
        return out;
    };

    generatorMixin.generateModule = function generateModule(opt) {
        opt = this.__prepareOptions(opt);

        let moduleName = opt.moduleName;
        let out = this.generateGenericHeaderComment();

        let self = this;
        function _generateNamespace(namespaces, previousNamespace, callback) {
            let subModuleName = namespaces.shift();
            if (subModuleName != null) {
                let moduleName = previousNamespace == null ? subModuleName : previousNamespace + '.' + subModuleName;
                if (namespaces.length > 0) {
                    return '(function (' + subModuleName + ') {\n'
                        + _generateNamespace(namespaces, subModuleName, callback)
                        + '\n})(' + subModuleName + (previousNamespace == null ? '' : ' = ' + moduleName) + ' || (' + moduleName + ' = {}));\n';
                }
                return callback(moduleName);
            }
            return '';
        }

        let sourceCodeDef = self.generateModuleExpr();

        out += `
        ${sourceCodeDef.init}
    `;

        out += _generateNamespace(moduleName.split('.'), null, function _generateNamespace_cb(moduleName) {
            let name = (moduleName.match(/\./) ? moduleName : 'let ' + moduleName);
            return `
            ${name} = ${sourceCodeDef.src}
        `;
        });

        opt.exportSourceCode.all = out;
        return out;
    };


    generatorMixin.generateModuleExpr = function generateModuleExpr() {
        let opt = this.__prepareOptions();
        let module = this.generateModule_();

        let out = [
            '(function () {',
            module.commonCode,
            '',
            'let parser = ' + module.moduleCode,
            module.modulePostlude
        ];
        if (this.lexer && this.lexer.generateModule) {
            let lexSrc = this.lexer.generateModule();
            opt.exportSourceCode.lexer = lexSrc;
            out.push(lexSrc);
            out.push('parser.lexer = lexer;');
        }
        out = out.concat([ '',
            module.moduleInclude,
            '',
            'function Parser() {',
            '  this.yy = {};',
            '}',
            'Parser.prototype = parser;',
            'parser.Parser = Parser;',
            '',
            'return new Parser();',
            '})();'
        ]);

        let src = out.join('\n') + '\n';
        opt.exportSourceCode.all = src;

        return {
            src,
            init: module.initCode
        };
    };

    function removeUnusedKernelFeatures(parseFn, info) {
        let actionFn = info.performAction;

        if (info.actionsAreAllDefault) {
            // in this case, there's no need to call the parseAction function at all:
            // it is functionally empty anyway.
            actionFn = '';

            // remove:
            //
            //     r = this.performAction.call(yyval, ...);
            //
            //     if (typeof r !== 'undefined') {
            //         retval = r;
            //         break;
            //     }
            //

            parseFn = parseFn
            .replace(/\s+r = this\.performAction\.call[^)]+\)\;/g, '')
            .replace(/\s+if \(typeof r !== 'undefined'\) \{[^}]+\}/g, '');
        }

        if (!info.actionsUseYYTEXT) {

            // kill the passing of the local variable as a parameter,
            // its use in an assignment and its declaration:
            parseFn = parseFn
            .replace(/, yytext\b/g, '')
            .replace(/^.*?\bvar yytext\b.*?$/gm, '')
            .replace(/^.*[^.]\byytext = .+$/gm, '')
            .replace(/^.+ = yytext\b.+$/gm, '');
        }

        if (!info.actionsUseYYLENG) {
            actionFn = actionFn
            .replace(/, yyleng\b/g, '');

            // remove:
            //
            //     if (typeof lexer.yyleng === 'undefined') {
            //       lexer.yyleng = 0;
            //     }
            //     let yyleng;
            //     ...

            parseFn = parseFn
            .replace(/, yyleng\b/g, '')
            .replace(/^.*?\bvar yyleng\b.*?$/gm, '')
            .replace(/\s+if\b.*?\.yyleng\b.*?\{[^}]+\}/g, '\n')
            .replace(/^.*?\byyleng = .+$/gm, '')
            .replace(/^.*?\byyleng\b.*?=.*?\byyleng\b.*?$/gm, '');
        }

        if (!info.actionsUseYYLINENO) {
            // The error handling code inside the kernel still uses this one, but only straight off the lexer
            // so we can kill the local var and its usage at least:
            actionFn = actionFn
            .replace(/, yylineno\b/g, '');

            // remove:
            //
            //     let yylineno;
            //     ...

            parseFn = parseFn
            .replace(/\bvar yylineno\b.*?$/gm, '')
            .replace(/, yylineno\b/g, '')
            .replace(/^.*?\byylineno\b.*?=.*?\byylineno\b.*?$/gm, '');
        }

        if (!info.actionsUseYYSTACK) {
            actionFn = actionFn
            .replace(/, yystack\b/g, '');

            parseFn = parseFn
            .replace(/, stack\b/g, '');
        }

        if (!info.actionsUseYYSSTACK) {
            actionFn = actionFn
            .replace(/, yysstack\b/g, '');

            parseFn = parseFn
            .replace(/, sstack\b/g, '');
        }

        if (!info.actionsUseYYRULELENGTH) {
            actionFn = actionFn
            .replace(/, yyrulelength\b/g, '');

            parseFn = parseFn
            .replace(/, yyrulelen\b/g, '');
        }

        if (!info.actionsUseYYSTACKPOINTER) {
            actionFn = actionFn
            .replace(/, yysp\b/g, '');

            parseFn = parseFn
            .replace(/, sp - 1\b/g, '');
        }

        if (!info.actionsUseYYMERGELOCATIONINFO) {
            // remove the entire function plus all leading comment:
            parseFn = parseFn
            .replace(/\n.*?merge yylloc info into a new yylloc instance[^]*?\bthis\.yyMergeLocationInfo\b[^]*?\};[^]*?\n/g, (new Array(134)).join('\n'))
            // also remove its invocation in the error recovery code:
            .replace(/\n.*?\bthis\.yyMergeLocationInfo\b[^\n]+\n/g, '\n');
        }

        if (!info.actionsUseLocationTracking) {
            actionFn = actionFn
            .replace(/\byyloc, (.*?), yylstack\b/g, '$1');

            // remove:
            //
            //    let yyloc = lexer.yylloc;
            //    lstack[sp] = yyloc;
            //    ...
            //        lstack[sp] = copy_yylloc(lexer.yylloc);
            //    ...

            parseFn = parseFn
            .replace(/\byyloc, (.*?), lstack\b/g, '$1')
            .replace(/\s+yyval\._\$\s*=\s*.+$/gm, '\n')
            .replace(/^.*?\blstack\b.*$/gm, '')
            .replace(/^.*?\byyloc\b.*?$/gm, '')
            .replace(/^.*?\byylloc\b.*?$/gm, '')
            .replace(/^\s*_\$:\s+undefined\s*$/gm, '')
            .replace(/\s+function\s+copy_yylloc\b[^]*?return\s+rv[^}]+\}/g, '')
            .replace(/^.*?\bcopy_yylloc\b.*?$/gm, '')
            .replace(/^.*?\blocation_stack\b.*?$/gm, '')
            ;
        }

        if (!info.actionsUseValueTracking) {
            actionFn = actionFn
            .replace(/, yyvstack\b/g, '');

            parseFn = parseFn
            .replace(/, vstack\b/g, '');

            // also nuke all `yyval`-related code as we know, when this set of
            // features is set, that the grammar doesn't produce any value:
            // we are looking at a *matcher*, rather than a *parser*!
            //
            // remove
            //
            //     // Return the `$accept` rule's `$$` result, if available.
            //     // ...
            //     sp--;
            //     if (typeof vstack[sp] !== 'undefined') {
            //         retval = vstack[sp];
            //     }
            //
            // and
            //
            //     if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
            //         retval = vstack[sp];
            //     }
            //
            // but keep the yyval declaration as either location tracking MAY
            // still be employed by the grammar OR the grammar uses advanced
            // code which uses `yyval` as a run-time store which carries data
            // across multiple reduction calls to `performAction`, as per
            // the suggestion in the document comment for the grammar:
            //
            // >
            // > One important thing to note about `this` a.k.a. `yyval`: ...
            // >
            parseFn = parseFn
            .replace(/\s+\/\/ Return the \`\$accept\` rule's \`\$\$\` result[\s\S]+?if \((?:sp\b.*?)?typeof vstack\[sp\] !== 'undefined'\)[^\}]+\}[^\n]*\n/g, '\n\n\n\n\n\n');

            // kill all vstack entries which would be copied into the
            // error recovery `value_stack`:
            //
            //     recoveringErrorInfo.value_stack[esp] = ...
            //
            //     if (errStr) {
            //         recoveringErrorInfo.value_stack[esp] = {
            //             ...
            //         };
            //         ...
            //     } else {
            //         recoveringErrorInfo.value_stack[esp] = {
            //             ...
            //         };
            //     }
            //
            //     rv.value_stack = ...
            //
            parseFn = parseFn
            .replace(/[^\n]+if \(errStr\) \{\s*\n.*?\.value_stack\b[^]*?\};[^]*?\} else \{\s*\n.*?\.value_stack\b[^]*?\};[^}]*\}[^\n]*\n/g, '\n\n\n\n\n\n\n\n\n\n\n\n')
            .replace(/[^\n]+\.value_stack\b[^n]*\n/g, '\n');

            // kill *all* value tracking when there's also no *implicit* `$$ = ...` action any more:

            // remove all lines using `vstack[xyz...]` ...
            parseFn = parseFn
            .replace(/^.*?\bvstack\b.*$/gm, '');

            // When there's no `performAction()` call at all, then
            // the `yyval` declaration can safely be discarded as well.
            if (info.actionsAreAllDefault) {
                // remove
                //
                //     let yyval = {
                //         $: true,
                //         _$: undefined,
                //         yy: sharedState_yy
                //     };
                parseFn = parseFn
                .replace(/\s+let yyval =[\s\S]+?\};[^\n]*\n/g, '\n\n\n\n\n\n');
            }
        }

        if (!info.DEBUG) {
            // When 'debug mode' hasn't been turned on during parser generation,
            // then we don't allow it at all: this gives us faster production parsers.
            //
            // When you want debug output at parse run-time, then you MUST produce a parser
            // with either the
            //     %debug
            // option set or by invoking JISON with the debug flag `-t`.

            // remove:
            //
            //     let yydebug = false;
            //     ... and delete yydebug function definition ...
            //     ...
            //     if (yydebug) yydebug(...);
            //     ...
            //     if (yydebug) {
            //         yydebug(...);
            //     }
            //
            // and
            //
            //     // disable debugging at run-time ANYWAY when you've *explicitly* set "yy.yydebug = false":
            //     if (sharedState_yy.yydebug === false) {
            //         yydebug = undefined;
            //     }


            parseFn = parseFn
            .replace(/\s+let yydebug = [\s\S]+?self\.trace[\s\S]+?};[^}]+}/g, '\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n')
            // strip multi-line `if (debug) { yydebug(..., {...}); }` statements
            // also strip simple yet possibly multi-line `if (debug) yydebug('...');` statements
            .replace(/\n\s+if\s+\(yydebug\)\s+\{[\r\n]+\s+yydebug\([^]+?}\);[\s\r\n]+}\s*/g, '\n\n\n\n\n\n\n\n\n')
            .replace(/\n\s+if\s+\(yydebug\)\s+yydebug\([^]+?['}]\);[^\r\n]*?/g, '\n\n\n\n\n\n\n\n\n')
            // strip single-line `yydebug(...);` statements
            .replace(/^.*?\byydebug\b[^;]+?\);[^\r\n]*?$/gm, '')
            // strip `if (sharedState_yy.yydebug) {...}` chunk
            .replace(/\n\s+\/\/\s*disable\s*debugging.*?[\r\n]+\s+if\s+\(sharedState_yy\.yydebug[^]+?\}/g, '\n\n\n\n');
        }

        if (!info.actionsUseYYERROK && !info.actionsUseYYRECOVERING && !info.actionsUseYYCLEARIN && !info.actionsUseYYERROR) {
            /*
             * Kill long multi-line comment about yyerror + YYRECOVERING + yyerrok + yyclearin before this code:
             *
             *       if (this.yyError) {
             *           ...
             */
            parseFn = parseFn
            .replace(/\s+\/\/.*setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions[^\0]+?\n\s+if \(/g, '\n\n\n\n\n  if (');
        }

        if (!info.actionsUseYYERROR) {
            /*
             * Kill this code:
             *
             *       if (this.yyError) {
             *           this.yyError = function yyError(str) {
             *               ...
             *           };
             *       }
             */
            parseFn = parseFn
            .replace(/\s+if \(this\.yyError\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
        }

        if (!info.actionsUseYYRECOVERING) {
            /*
             * Kill this code:
             *
             *       if (this.yyRecovering) {
             *           this.yyRecovering = function yyRecovering() {
             *               return recovering;
             *           };
             *       }
             */
            parseFn = parseFn
            .replace(/\s+if \(this\.yyRecovering\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
        }

        if (!info.actionsUseYYERROK) {
            /*
             * Kill this code:
             *
             *       if (this.yyErrOk) {
             *           this.yyErrOk = function yyErrOk() {
             *               recovering = 0;
             *           };
             *       }
             */
            parseFn = parseFn
            .replace(/\s+if \(this\.yyErrOk\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
        }

        if (!info.actionsUseYYCLEARIN) {
            parseFn = parseFn
            .replace(/\s+if \(this\.yyClearIn\) \{[^\0]+?[^{]\};\n\s+\}\n/g, '\n\n\n\n\n\n');
        }

        if (info.options.noTryCatch) {
            /*
             * Kill this code:
             *
             *     try {
             *         this.__reentrant_call_depth++;
             *         ... keep all this stuff ...
             *     } catch (ex) {
             *         ... remove this stuff ...
             *     } finally {
             *         retval = this.cleanupAfterParse(retval, true, true);       // <-- keep this line
             *     } // /finally
             *
             * and also remove any re-entrant parse() call support:
             *
             *     ... __reentrant_call_depth ...
             */
            parseFn = parseFn
            .replace(/\s+try \{([\s\r\n]+this\.__reentrant_call_depth[\s\S]+?)\} catch \(ex\) \{[\s\S]+?\} finally \{([^]+?)\}\s+\/\/\s+\/finally/, function replace_noTryCatch(m, p1, p2) {
                p1 = p1.replace(/^ {8}/mg, '    ');
                p2 = p2.replace(/^ {8}/mg, '    ');
                return '\n' + p1 + '\n    // ... AND FINALLY ...\n' + p2;
            })
            .replace(/^[^\n]+\b__reentrant_call_depth\b[^\n]+$/gm, '\n');
        }

        if (!info.actionsUseYYTEXT) {
            // See the comment for the same section near the start of this function:
            //
            // Wait with this bit of cleanup until the very end to help keep the
            // other cleanup/optimization options below that much simpler to code:
            actionFn = actionFn
            .replace(/\(\byytext\b(,\s*)?/g, '(');
        }


        // When we're done feature stripping, we can clean up any lingering
        // internals, which would otherwise go unused:
        if (!analyzeFeatureUsage(parseFn, /\bshallowCopyErrorInfo\b/g, 1)) {
            // Remove:
            //
            //     // clone some parts of the (possibly enhanced!) errorInfo object
            //     // to give them some persistence.
            //     this.shallowCopyErrorInfo = function ...(p) {
            //         ...
            //         return rv;
            //     }
            //
            parseFn = parseFn
            .replace(/\n[^\n]*?clone some parts of the[^\n]*?errorInfo object[^]*?\bshallowCopyErrorInfo\b[^]*?return rv;[^}]*\};[^\n]*/g, '\n\n\n\n\n\n\n\n\n\n\n');
        }
        if (!analyzeFeatureUsage(parseFn, /\bshallow_copy\b/g, 1)) {
            // Remove:
            //
            //     // shallow clone objects, straight copy of simple `src` values
            //     // ...
            //     function shallow_copy(...) {
            //         ...
            //         return src;
            //     }
            //
            parseFn = parseFn
            .replace(/\n[^\n]*?shallow clone objects, straight copy[^]*?\bshallow_copy\b[^]*?return src;[^}]*\}[^\n]*/g, '\n\n\n\n\n\n');
        }


        info.performAction = actionFn;

        return parseFn;
    }

    // Fill in the optional, extra parse parameters (`%parse-param ...`)
    // in the generated parser.
    //
    // See for important context:
    //
    //     https://github.com/zaach/jison/pull/332
    function expandParseArguments(parseFn, self) {
        let arglist = self.parseParams;

        if (!arglist || arglist.length === 0) {
            parseFn = parseFn.replace(/, parseParams\b/g, '');
            parseFn = parseFn.replace(/\bparseParams\b/g, '');
            parseFn = parseFn.replace(/,\s*[\r\n]+\s*parseParamsAsMembers\b/g, '');
        } else {
            parseFn = parseFn.replace(/, parseParams\b/g, ', ' + arglist.join(', '));
            parseFn = parseFn.replace(/\bparseParams\b/g, arglist.join(', '));
            parseFn = parseFn.replace(/,\s*[\r\n]+(\s*)parseParamsAsMembers\b/g, function parseParamsReplF(m, ws) {
                let s = ',';

                // determine longest name of the bunch (for formatting the generated code)
                let max_k_len = 0;
                for (let i = 0, len = arglist.length; i < len; i++) {
                    let k = arglist[i];
                    max_k_len = Math.max(max_k_len, k.length);
                }
                let wsi2 = (new Array(max_k_len + 1)).join(' ');

                // generate the member assignment list for the `sharedState_yy` object which will store the `parseParams` for everyone to access
                for (let i = 0, len = arglist.length; i < len; i++) {
                    let k = arglist[i];
                    s += '\n' + ws + k + ': ' + k + (i < len - 1 ? ',' + wsi2.substr(0, max_k_len - k.length - 1) : wsi2.substr(0, max_k_len - k.length)) + '  // parseParams::' + k;
                }
                return s;
            });
        }
        return parseFn;
    }


    function expandConstantsInGeneratedCode(src, self) {
        // expand the error recovery 'combine rule' action constant in the generated code
        src = src
        .replace(/\bYY_ERROR_RECOVERY_COMBINE_ID\b/g, '' + self.table.length)
        // the next 'constant' has explicit `\n` newlines included for protection:
        // it should only occur in *one* place in the *entire* code stream.
        .replace(/\nYY_REMAINING_INIT_CODE_SECTIONS_GO_HERE\n/g, self.moduleInit.getRemainingInitCodeSections().join('\n'));

        return src;
    }


    function pickOneOfTwoCodeAlternatives(parseFn, pick_A_not_B, A_start_marker, B_start_marker, end_marker) {
        // Notes:
        // 1) we use the special /[^\0]*/ regex set as that one will also munch newlines, etc.
        //    while the obvious /.*/ does not as '.' doesn't eat the newlines.
        return parseFn.replace(new RegExp('(' + A_start_marker + '[^\\n]*\\n)([^\\0]*?)(' + B_start_marker + '[^\\n]*\\n)([^\\0]*?)(' + end_marker + '[^\\n]*\\n)', 'g'), function pick_code_alt(str, mA, cA, mB, cB, mE) {
            if (pick_A_not_B) {
                return cA;
            }
            return cB;
        });
    }

    function addOrRemoveTokenStack(fn, wantTokenStack) {
        let parseFn = fn;
        // We don't use the Esprima+Escodegen toolchain as those loose the code comments easily;
        // instead we just chop the code using labels as sentinels for our chopping-it-up regexes:
        //
        // if (wantTokenStack) {
        //     try {
        //         let ast = esprima.parse(parseFn);
        //         let stackAst = esprima.parse(String(tokenStackLex)).body[0];
        //         stackAst.id.name = 'lex';
        //
        //         let labeled = JSONSelect.match(':has(:root > .label > .name:val("_token_stack"))', ast);
        //
        //         labeled[0].body = stackAst;
        //
        //         return escodegen.generate(ast);
        //     } catch (e) {
        //         return parseFn;
        //     }
        // } else {
        //     // remove the line:
        //     // let tstack = []; // token stack
        //     parseFn = parseFn.replace(/tstack = .*$/m, '');
        //     return parseFn;
        // }
        parseFn = pickOneOfTwoCodeAlternatives(parseFn, !wantTokenStack, '//_lexer_without_token_stack:', '//_lexer_with_token_stack:', '//_lexer_with_token_stack_end:');
        // and some post-coital touch-ups:
        if (wantTokenStack) {
            // And rename the `tokenStackLex` function to become the new `lex`:
            return parseFn.replace(/\btokenStackLex\b/g, 'lex');
        }
        // Also nuke the support declaration statement:
        //     let tstack = [];
        return parseFn.replace(/^.*?\btstack\b.*$/gm, '');

    }

    // returns parse function with/without error recovery code
    function pickErrorHandlingChunk(fn, hasErrorRecovery) {
        let parseFn = fn;

        // We don't use the Esprima+Escodegen toolchain as those loose the code comments easily;
        // instead we just chop the code using labels as sentinels for our chopping-it-up regexes:
        // try {
        //     let ast = esprima.parse(parseFn);

        //     let labeled = JSONSelect.match(':has(:root > .label > .name:val("' +
        //         (!hasErrorRecovery ? '_handle_error_with_recovery' : '_handle_error_no_recovery') +
        //         '"))', ast);
        //     Jison.print('labeled: ', labeled);
        //     assert(labeled[0].body.type === 'IfStatement');
        //     labeled[0].body.type = 'DebuggerStatement';
        //     Jison.print('patched::labeled: ', labeled);

        //     return escodegen.generate(ast);
        // } catch (e) {
        //     return parseFn;
        // }
        parseFn = pickOneOfTwoCodeAlternatives(parseFn, hasErrorRecovery, '//_handle_error_with_recovery:', '//_handle_error_no_recovery:', '//_handle_error_end_of_section:');
        // and some post-coital touch-ups:
        if (!hasErrorRecovery) {
            // Also nuke the support declaration statement:
            //          let recovering = 0;
            // and the recovery support statements:
            //          if (recovering > 0) {
            //              recovering--;
            //          }
            // and these yydebug particles:
            //          , recovering: recovering
            //          ASSERT(recovering === 0);
            parseFn = parseFn
            .replace(/^\s*let recovering.*$/gm, '')
            .replace(/, recovering: recovering/g, '')
            .replace(/^.*?recovering =.*$/gm, '')
            .replace(/^\s+recovering[,]?\s*$/gm, '')
            .replace(/[ \t]*if \(recovering[^\)]+\) \{[^\0]+?\}\n/g, '\n\n\n\n\n')
            // And nuke the preErrorSymbol code as it is unused when there's no error recovery
            //        if (!preErrorSymbol) {
            //            ... keep this chunk ...
            //        } else {
            //            ... KILL this chunk ...
            //        }
            .replace(/\s+if[^a-z]+preErrorSymbol.*?\{\s*\/\/[^\n]+([\s\S]+?)\} else \{[\s\S]+?\}\n\s+\}\n/g, '\n$1\n\n\n\n')
            .replace(/^\s+(?:let )?preErrorSymbol = .*$/gm, '')
            .replace(/^.*?\bpreErrorSymbol =.*$/gm, '')
            // And nuke the support declaration statement:
            //         let lastEofErrorStateDepth = 0;
            .replace(/^\s*let lastEofErrorStateDepth.*$/gm, '');
        }
        return parseFn;
    }

    // Generates the code of the parser module, which consists of two parts:
    // - module.commonCode: initialization code that should be placed before the module
    // - module.moduleCode: code that creates the module object
    lrGeneratorMixin.generateModule_ = function generateModule_() {
        let parseFn = String(parser$4.parse);
        parseFn = pickErrorHandlingChunk(parseFn, this.hasErrorRecovery);

        parseFn = addOrRemoveTokenStack(parseFn, this.options.tokenStack);

        parseFn = removeUnusedKernelFeatures(parseFn, this);

        parseFn = expandParseArguments(parseFn, this);

        let errorClassCode = this.generateErrorClass();

        let exportDest = this.options.exportAllTables;
        assert__default['default'](exportDest);

        // store the parse tables:
        exportDest.parseTable = this.table;
        exportDest.defaultParseActions = this.defaultActions;
        exportDest.parseProductions = this.productions_;

        let tableCode;
        switch (this.options.compressTables | 0) {
        case 0: // no compression
            tableCode = this.generateTableCode0(this.table, this.defaultActions, this.productions_);
            break;

        default:
        case 1: // default: vanilla JISON table compression = run-length encoding
            tableCode = this.generateTableCode1(this.table, this.defaultActions, this.productions_);
            break;

        case 2: // column-mode compression
            // this compression method corrupts the table when this option is turned on (and one or more conflicts occur)
            if (this.options.noDefaultResolve && this.conflicts > 0) {
                tableCode = this.generateTableCode1(this.table, this.defaultActions, this.productions_);
            } else {
                tableCode = this.generateTableCode2(this.table, this.defaultActions, this.productions_);
            }
            break;
        }

        // Generate the initialization code

        let initCode = [].concat(
            this.moduleInit.getInitCodeSection('imports'),
            this.moduleInit.getInitCodeSection('init')
        );

        let commonCode = [].concat(
            this.moduleInit.getInitCodeSection('required'),
            errorClassCode.commonCode,
            errorClassCode.moduleCode,
            [ '\nYY_REMAINING_INIT_CODE_SECTIONS_GO_HERE\n' ],
            tableCode.commonCode
        );


        // sort hash table by key to produce a nicer output:
        function produceSymbolTable(tbl) {
            let a = Object.keys(tbl);
            a.sort();
            let nt = {};
            for (let i = 0, len = a.length; i < len; i++) {
                let k = a[i];
                // `$eof` and `EOF` are synonyms of `$end` (`$eof` is for bison compatibility);
                // this is the only place where two symbol names may map to a single symbol ID number
                // and we do not want `$eof`/`EOF` to show up in the symbol tables of generated parsers
                // as we use `$end` for that one!
                if (k !== '$eof') {
                    nt[k] = tbl[k];
                }
            }
            return nt;
        }

        // swap key and value and then sort hash table by key to produce a nicer output:
        function produceTerminalTable(tbl) {
            let a = Object.keys(tbl);
            let nt = {};
            for (let i = 0, len = a.length; i < len; i++) {
                let k = a[i];
                let v = tbl[k];
                nt[v] = +k;  // convert numeric key back to number type; all terminals have numeric keys
            }
            return produceSymbolTable(nt);
        }

        function produceProductionsForDebugging(options, symbols, base) {
            function get_orig_symbol(s) {
                let a = s.split(':');
                if (a.length === 1 || a[0] === '') {
                    return {
                        state: -1,
                        symbol: s
                    };
                }
                let state = a[0];
                a.shift();
                return {
                    state: +state,
                    symbol: a.join(':')
                };
            }
            function get_orig_symbol_set(arr) {
                let rv = {};
                for (let i = 0, len = arr.length; i < len; i++) {
                    let item = arr[i];
                    let symbol = get_orig_symbol(item);
                    rv[symbol.symbol] = symbol.state;
                }
                return Object.keys(rv);
            }

            let tbl = this.nonterminals;
            let sym = this.symbols_ || symbols;

            if (!options.outputDebugTables && !options.exportAllTables.enabled) {
                return undefined;
            }

            let prods = {
                ids: {},
                states: {},
                rules: {},
                nonterminals: {},
                symbols: {},
                first: {},
                follows: {}
            };

            let self = this;
            this.productions.forEach(function Follow_prod_forEach_genDebugTable(production, k) {
                let nonterm = production.symbol;
                prods.states[k] = nonterm;
                prods.ids[nonterm] = sym[nonterm];

                let lst = prods.rules[nonterm] || {};
                lst[k] = gen_lalr_states_production(production, k, false, k, true);
                prods.rules[nonterm] = lst;
            });

            function gen_nonterminal(nt) {
                let l = nt.productions._items;
                let lst = l.map(function (p, i) {
                    return gen_lalr_states_production(p, i, false, false, false);
                });
                let rv = {
                    symbol: nt.symbol,
                    productions: lst,
                    first: nt.first,
                    base_first: get_orig_symbol_set(nt.first),
                    follows: nt.follows,
                    base_follows: get_orig_symbol_set(nt.follows),
                    nullable: nt.nullable
                };

                // clean up structure: ditch superfluous elements:
                if (rv.base_first.join(' ') === rv.first.join(' ')) {
                    delete rv.base_first;
                }
                if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                    delete rv.base_follows;
                }

                return rv;
            }

            for (let key in tbl) {
                prods.nonterminals[key] = gen_nonterminal(tbl[key]);
            }

            if (this.nterms_) {
                prods.nterms_ = this.nterms_;
            }

            function gen_lalr_states_production(production, index, dotPosition, state, patch_base) {
                let nonterm = production.symbol;
                let hlen = production.handle.length;
                let rulestr = production.handle.map(function (t, idx) {
                    if (!t) {
                        t = '%epsilon';
                    }

                    if (dotPosition === idx) {
                        t = '⬤' + t;
                    }
                    return t;
                }).join(' ');
                if (dotPosition === hlen) {
                    rulestr += ' ⬤';
                }

                let base_rulestr = production.handle.map(function (t) {
                    if (!t) {
                        t = '%epsilon';
                    }
                    t = get_orig_symbol(t).symbol;
                    return t;
                }).join(' ');

                let rv = {
                    symbol: nonterm,
                    base_symbol: get_orig_symbol(nonterm).symbol,
                    handle: rulestr,
                    base_handle: base_rulestr,
                    nullable: production.nullable,
                    id: production.id,
                    index: index,
                    state: (state !== false ? state : -1),
                    base_state: -1,
                    first: production.first,
                    base_first: get_orig_symbol_set(production.first),
                    follows: production.follows,
                    base_follows: get_orig_symbol_set(production.follows),
                    precedence: production.precedence,
                    reachable: production.reachable
                };

                // Determine state for given production, if it's not a production that's listed as part of a state:
                let lst = prods.rules[nonterm];
                let chk = rv.symbol + ' : ' + rv.handle;
                for (let idx in lst) {
                    idx = +idx;
                    let p = lst[idx];
                    if (p) {
                        if (p.symbol + ' : ' + p.handle === chk) {
                            assert__default['default'](rv.state === -1);
                            rv.state = idx;
                            break;
                        }
                    }
                }

                // Try to reference base productions from newg child productions and vice versa:
                chk = rv.base_symbol + ' : ' + rv.base_handle;
                if (base && base.rules) {
                    let pr = base.rules[rv.base_symbol];
                    for (let idx in pr) {
                        let bprod = pr[idx];
                        if (bprod.symbol + ' : ' + bprod.handle === chk) {
                            assert__default['default'](rv.base_state === -1);
                            rv.base_state = bprod.state;
                            if (patch_base) {
                                bprod.newg_states = (bprod.newg_states || []);
                                bprod.newg_states.push(rv.index);
                            }
                            break;
                        }
                    }
                }

                // clean up structure: ditch superfluous elements:
                if (rv.base_symbol === rv.symbol) {
                    delete rv.base_symbol;
                }
                if (rv.base_handle === rv.handle) {
                    delete rv.base_handle;
                }
                if (rv.base_first.join(' ') === rv.first.join(' ')) {
                    delete rv.base_first;
                }
                if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                    delete rv.base_follows;
                }
                if (rv.base_state === -1) {
                    delete rv.base_state;
                }
                return rv;
            }

            if (this.states) {
                prods.lalr_states = [];
                let these_states = this.states;
                these_states.forEach(function traverse_states(state, i) {
                    //assert(state.inadequate ? these_states.inadequate : true);
                    state.forEach(function traverse_state(item, j) {
                        // is this a REDUCE state?
                        let nterm_first = self.nonterminals[item.production.symbol].first;
                        let rv = {
                            state: i,
                            item_index: j,
                            is_reduce_state: (item.dotPosition === item.production.handle.length),
                            dot_position: item.dotPosition,
                            state_inadequate: state.inadequate ? true : undefined,
                            item_inadequate: item.inadequate ? true : undefined,
                            production: gen_lalr_states_production(item.production, j, item.dotPosition, i, true),
                            follows: item.follows,
                            base_follows: get_orig_symbol_set(item.follows),
                            nterm_first: nterm_first,
                            base_nterm_first: get_orig_symbol_set(nterm_first),
                            prod_first: item.production.first,
                            base_prod_first: get_orig_symbol_set(item.production.first)
                        };

                        // clean up structure: ditch superfluous elements:
                        if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                            delete rv.base_follows;
                        }
                        if (rv.base_nterm_first.join(' ') === rv.nterm_first.join(' ')) {
                            delete rv.base_nterm_first;
                        }
                        if (rv.base_prod_first.join(' ') === rv.prod_first.join(' ')) {
                            delete rv.base_prod_first;
                        }

                        prods.lalr_states.push(rv);
                    });
                });
            }

            let nt = tbl;
            for (let sbn in nt) {
                let orig_symbol = get_orig_symbol(sbn);
                let item = nt[sbn];
                let firsts = item.first;
                let follows = item.follows;
                if (!prods.symbols[orig_symbol.symbol]) {
                    prods.symbols[orig_symbol.symbol] = orig_symbol.state;
                }
                if (!prods.first[orig_symbol.symbol]) {
                    prods.first[orig_symbol.symbol] = firsts;
                } else {
                    prods.first[orig_symbol.symbol] = prods.first[orig_symbol.symbol].concat(firsts);
                }
                if (!prods.follows[orig_symbol.symbol]) {
                    prods.follows[orig_symbol.symbol] = follows;
                } else {
                    prods.follows[orig_symbol.symbol] = prods.follows[orig_symbol.symbol].concat(follows);
                }
            }
            for (let sbn in prods.first) {
                prods.first[sbn] = get_orig_symbol_set(prods.first[sbn]);
            }
            for (let sbn in prods.follows) {
                prods.follows[sbn] = get_orig_symbol_set(prods.follows[sbn]);
            }

            if (this.newg) {
                prods.newg = produceProductionsForDebugging.call(this.newg, options, sym, prods);
            }
            return prods;
        }

        function produceTerminalDescriptions(tbl, sym) {
            let rv = {};
            let count = 0;
            for (let k in tbl) {
                let descr = tbl[k];
                let id = sym[k];
                if (id && descr && descr !== id) {
                    rv[id] = descr;
                    count++;
                }
            }
            return (count ? rv : undefined);
        }

        function produceOptions(opts) {
            let obj = {};
            let do_not_pass = {
                type: 0,                   // CLI: --parserType option
                debug: !opts.debug,     // do not include this item when it is FALSE as there's no debug tracing built into the generated grammar anyway!
                enableDebugLogs: 1,
                numExpectedConflictStates: 1,
                dumpSourceCodeOnFailure: 1,
                throwErrorOnCompileFailure: 1,
                json: 1,
                _: 1,
                noMain: 1,
                moduleMain: 1,
                moduleMainImports: 1,
                noDefaultResolve: 1,
                defaultActionMode: 1,
                testCompileActionCode: 1,
                noTryCatch: 1,
                hasPartialLrUpgradeOnConflict: 0,
                compressTables: 1,
                outputDebugTables: 1,
                reportStats: 1,
                file: 1,
                outfile: 1,
                inputPath: 1,
                inputFilename: 1,
                lexfile: 1,
                defaultModuleName: 1,
                moduleName: 1,
                moduleType: 1,
                exportAllTables: 1,
                exportSourceCode: 1,
                tokenStack: 0,
                parserErrorsAreRecoverable: 0,
                lexerErrorsAreRecoverable: 1,
                showSource: 1,
                exportAST: 1,
                prettyCfg: 1,

                errorRecoveryTokenDiscardCount: 0,

                warn_cb: 0,  // function(msg) | true (= use Jison.Print) | false (= throw Exception)

                parseParams: 1,
                ranges: 0
            };
            for (let k in opts) {
                if (!do_not_pass[k] && opts[k] != null && opts[k] !== false) {
                    // make sure numeric values are encoded as numeric, the rest as boolean/string.
                    if (typeof opts[k] === 'string') {
                        let f = parseFloat(opts[k]);
                        if (f == opts[k]) {
                            obj[k] = f;
                            continue;
                        }
                    }
                    obj[k] = opts[k];
                }
            }

            // And now some options which should receive some special processing:
            if (!obj.hasPartialLrUpgradeOnConflict) {
                // only list this option when it's actually TRUE:
                delete obj.hasPartialLrUpgradeOnConflict;
            }

            let pre = obj.pre_parse;
            let post = obj.post_parse;
            // since JSON cannot encode functions, we'll have to do it manually at run-time, i.e. later on:
            if (pre) {
                obj.pre_parse = true;
            }
            if (post) {
                obj.post_parse = true;
            }

            let js = JSON.stringify(obj, null, 2);

            js = js.replace(new XRegExp__default['default'](`  "(${ID_REGEX_BASE$3})": `, 'g'), '  $1: ');
            js = js.replace(/^( +)pre_parse: true(,)?$/gm, function (m, ls, tc) {
                return ls + 'pre_parse: ' + String(pre) + (tc || '');
            });
            js = js.replace(/^( +)post_parse: true(,)?$/gm, function (m, ls, tc) {
                return ls + 'post_parse: ' + String(post) + (tc || '');
            });
            return js;
        }


        // Generate the module creation code
        let termDescrs = produceTerminalDescriptions(this.descriptions_, this.symbols_);
        exportDest.terminalDescriptions = termDescrs;
        let descrLst = JSON.stringify(termDescrs, null, 2);
        if (descrLst) {
            descrLst = descrLst.replace(/"([0-9]+)":/g, '$1:');
        }

        let rules4Dbg = produceProductionsForDebugging.call(this, this.options);
        exportDest.parseRules = rules4Dbg;
        let rulesLst = ((this.options.outputDebugTables || this.options.exportAllTables.enabled) ? JSON.stringify(rules4Dbg, null, 2) : undefined);
        if (rulesLst) {
            rulesLst = rulesLst.replace(/"([0-9]+)":/g, '$1:').replace(/^(\s+)"([a-z_][a-z_0-9]*)":/gmi, '$1$2:');
        }

        let symbolTable = produceSymbolTable(this.symbols_);
        exportDest.symbolTable = symbolTable;

        // produce a hash lookup table from the terminal set
        exportDest.terminalTable = produceTerminalTable(this.terminals_);

        let moduleCode = `{
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   default action mode: ............. ${JSON.stringify(this.options.defaultActionMode)}
    //   test-compile action mode: ........ ${JSON.stringify(this.options.testCompileActionCode)}
    //   try..catch: ...................... ${!this.options.noTryCatch}
    //   default resolve on conflict: ..... ${!this.options.noDefaultResolve}
    //   on-demand look-ahead: ............ ${this.onDemandLookahead}
    //   error recovery token skip maximum: ${this.options.errorRecoveryTokenDiscardCount}
    //   yyerror in parse actions is: ..... ${this.options.parserErrorsAreRecoverable ? 'recoverable' : 'NOT recoverable'},
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. ${this.options.lexerErrorsAreRecoverable ? 'recoverable' : 'NOT recoverable'},
    //   debug grammar/output: ............ ${this.options.debug}
    //   has partial LR conflict upgrade:   ${this.options.hasPartialLrUpgradeOnConflict}
    //   rudimentary token-stack support:   ${this.options.tokenStack}
    //   parser table compression mode: ... ${this.options.compressTables}
    //   export debug tables: ............. ${this.options.outputDebugTables}
    //   export *all* tables: ............. ${this.options.exportAllTables.enabled}
    //   module type: ..................... ${this.options.moduleType}
    //   parser engine type: .............. ${this.options.type}
    //   output main() in the module: ..... ${this.options.noMain}
    //   has user-specified main(): ....... ${!!this.options.moduleMain}
    //   has user-specified require()/import modules for main():
    //   .................................. ${!!this.options.moduleMainImports}
    //   number of expected conflicts: .... ${this.options.numExpectedConflictStates}
    //
    //
    // Parser Analysis flags:
    //
    //   no significant actions (parser is a language matcher only):
    //   .................................. ${this.actionsAreAllDefault}
    //   uses yyleng: ..................... ${this.actionsUseYYLENG}
    //   uses yylineno: ................... ${this.actionsUseYYLINENO}
    //   uses yytext: ..................... ${this.actionsUseYYTEXT}
    //   uses yylloc: ..................... ${this.actionsUseYYLOC}
    //   uses ParseError API: ............. ${this.actionsUseParseError}
    //   uses YYERROR: .................... ${this.actionsUseYYERROR}
    //   uses YYRECOVERING: ............... ${this.actionsUseYYRECOVERING}
    //   uses YYERROK: .................... ${this.actionsUseYYERROK}
    //   uses YYCLEARIN: .................. ${this.actionsUseYYCLEARIN}
    //   tracks rule values: .............. ${this.actionsUseValueTracking}
    //   assigns rule values: ............. ${this.actionsUseValueAssignment}
    //   uses location tracking: .......... ${this.actionsUseLocationTracking}
    //   assigns location: ................ ${this.actionsUseLocationAssignment}
    //   uses yystack: .................... ${this.actionsUseYYSTACK}
    //   uses yysstack: ................... ${this.actionsUseYYSSTACK}
    //   uses yysp: ....................... ${this.actionsUseYYSTACKPOINTER}
    //   uses yyrulelength: ............... ${this.actionsUseYYRULELENGTH}
    //   uses yyMergeLocationInfo API: .... ${this.actionsUseYYMERGELOCATIONINFO}
    //   has error recovery: .............. ${this.hasErrorRecovery}
    //   has error reporting: ............. ${this.hasErrorReporting}
    //
    // --------- END OF REPORT -----------

`;
        moduleCode += [
            'trace: ' + String(this.trace || parser$4.trace),
            'JisonParserError: JisonParserError',
            'yy: {}',
            'options: ' + produceOptions(this.options),
            'symbols_: ' + JSON.stringify(symbolTable, null, 2),
            'terminals_: ' + JSON.stringify(this.terminals_, null, 2).replace(/"([0-9]+)":/g, '$1:')
        ].concat(
            rulesLst ?
                'nonterminals_: ' + rulesLst :
                []
        ).concat(
            descrLst ?
                'terminal_descriptions_: ' + descrLst :
                []
        ).concat([
            define_parser_APIs_1.trim(),
            'productions_: ' + tableCode.productionsCode
        ]).concat(
            String(this.performAction).trim() !== '' ?
                'performAction: ' + String(this.performAction) :
                []
        ).concat([
            'table: ' + tableCode.tableCode,
            'defaultActions: ' + tableCode.defaultActionsCode,
            'parseError: ' + String(this.parseError || parseErrorSourceCode).trim(),
            'parse: ' + parseFn.trim()
        ]).concat(
            this.actionsUseYYERROR ?
                'yyError: 1' :
                []
        ).concat(
            this.actionsUseYYRECOVERING ?
                'yyRecovering: 1' :
                []
        ).concat(
            this.actionsUseYYERROK ?
                'yyErrOk: 1' :
                []
        ).concat(
            this.actionsUseYYCLEARIN ?
                'yyClearIn: 1' :
                []
        ).join(',\n');
        moduleCode += '\n};';

        const exportSourceCode = this.options.exportSourceCode;
        assert__default['default'](exportSourceCode);
        exportSourceCode.parserChunks = {
            initCode: expandConstantsInGeneratedCode(initCode.join('\n'), this),
            commonCode: expandConstantsInGeneratedCode(commonCode.join('\n'), this),
            moduleCode: expandConstantsInGeneratedCode(moduleCode, this),
            modulePostlude: [
                'parser.originalParseError = parser.parseError;',
                'parser.originalQuoteName = parser.quoteName;'
            ].join('\n'),
            moduleInclude: expandConstantsInGeneratedCode(this.moduleInclude, this)
        };
        return exportSourceCode.parserChunks;
    };

    lrGeneratorMixin.generateErrorClass = function () {
        // --- START parser error class ---
        const prelude = `
// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    let stacktrace;
    if (hash && hash.exception instanceof Error) {
        let ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError.prototype, Error.prototype);
} else {
    JisonParserError.prototype = Object.create(Error.prototype);
}
JisonParserError.prototype.constructor = JisonParserError;
JisonParserError.prototype.name = 'JisonParserError';
`;
        // --- END parser error class ---

        return {
            commonCode: '',
            moduleCode: prelude
        };
    };

    // Generate code that represents the specified parser table
    lrGeneratorMixin.generateTableCode0 = function (table, defaultActions, productions) {
        let tableCode = JSON.stringify(table, null, 2);
        let defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
        let productionsCode = JSON.stringify(productions, null, 2);

        // Don't surround numerical property name numbers in quotes
        tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');

        let prelude = [];

        // Return the variable initialization code and the table code
        return {
            commonCode: prelude.join('\n'),
            tableCode: tableCode,
            defaultActionsCode: defaultActionsCode,
            productionsCode: productionsCode
        };
    };

    // Function that extends an object with the given value for all given keys
    // e.g., x([1, 3, 4], [6, 7], { x: 1, y: 2 }) = { 1: [6, 7]; 3: [6, 7], 4: [6, 7], x: 1, y: 2 }
    let compressor1ObjectCode = `
function x(k, v, o) {
  o = o || {};
  for (let l = k.length; l--; ) {
    o[k[l]] = v;
  }
  return o;
}
`;

    // Generate code that represents the specified parser table
    lrGeneratorMixin.generateTableCode1 = function (table, defaultActions, productions) {
        let tableCode = JSON.stringify(table, null, 2);
        let defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
        let productionsCode = JSON.stringify(productions, null, 2);
        let usesCompressor = false;

        // Don't surround numerical property name numbers in quotes
        tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');

        // Replace objects with several identical values by function calls
        // e.g., { 1: [6, 7]; 3: [6, 7], 4: [6, 7], 5: 8 } = x([1, 3, 4], [6, 7], { 5: 8 })
        tableCode = tableCode.replace(/\{[\s\r\n]*\d+:[^\}]+,[\s\r\n]*\d+:[^\}]+\}/g, function (object) {
            // Find the value that occurs with the highest number of keys
            let frequentValue;
            let keys = {};
            let maxKeyCount = 0;
            let keyValue;
            let keyValues = [];
            let keyValueMatcher = /(\d+):[\s\r\n]*([^:\}]+)(?=,[\s\r\n]*\d+:|\})/g;

            while ((keyValue = keyValueMatcher.exec(object))) {
                // For each value, store the keys where that value occurs
                let key = keyValue[1];
                let value = keyValue[2].trim();
                let keyCount = 1;

                if (!(value in keys)) {
                    keys[value] = [ key ];
                } else {
                    keyCount = keys[value].push(key);
                }
                // Remember this value if it is the most frequent one
                if (keyCount > maxKeyCount) {
                    maxKeyCount = keyCount;
                    frequentValue = value;
                }
            }
            // Construct the object with a function call if the most frequent value occurs multiple times
            if (maxKeyCount > 1) {
                // Collect all non-frequent values into a remainder object
                for (let value in keys) {
                    if (value !== frequentValue) {
                        for (let k = keys[value], i = 0, l = k.length; i < l; i++) {
                            keyValues.push(k[i] + ':' + value);
                        }
                    }
                }
                keyValues = keyValues.length ? ', {' + keyValues.join(',') + '}' : '';
                // Create the function call `x(keys, value, remainder)`
                object = 'x([' + keys[frequentValue].join(',') + '], ' + frequentValue + keyValues + ')';
                usesCompressor = true;
            }
            return object;
        });

        // Count occurrences of number lists
        let list;
        let lists = {};
        let listMatcher = /\[[0-9,]+\]/g;
        let frequentLists = [];

        while ((list = listMatcher.exec(tableCode))) {
            lists[list] = (lists[list] || 0) + 1;
        }

        // Replace frequently occurring number lists with variables
        tableCode = tableCode.replace(listMatcher, function (list) {
            let listId = lists[list];
            // If listId is a number, it represents the list's occurrence frequency
            if (typeof listId === 'number') {
                // If the list does not occur frequently, represent it by the list
                if (listId === 1) {
                    lists[list] = listId = list;
                // If the list occurs frequently, represent it by a newly assigned variable
                } else {
                    lists[list] = listId = 'u[' + frequentLists.length + ']';
                    frequentLists.push(list);
                }
            }
            return listId;
        });

        let prelude = [];

        // Only include the expander function when it's actually used
        // (tiny grammars don't have much state duplication, so this shaves off
        // another couple bytes off the generated output)
        if (usesCompressor) {
            prelude.push(compressor1ObjectCode);
            prelude.push('');
        }

        if (frequentLists.length > 0) {
            prelude.push('let u = [\n    ' + frequentLists.join(',\n    ') + '\n];');
            prelude.push('');
        }

        // Return the variable initialization code and the table code
        return {
            commonCode: prelude.join('\n'),
            tableCode: tableCode,
            defaultActionsCode: defaultActionsCode,
            productionsCode: productionsCode
        };
    };

    // Generate code that represents the specified parser table
    lrGeneratorMixin.generateTableCode2 = function (table, defaultActions, productions) {
        if (this.options.noDefaultResolve && this.conflicts > 0) {
            throw new Error("Table Compression mode 2 corrupts the table when the 'noDefaultResolve' option is turned on and one or more conflicts occur. Please use a different compression mode and/or disable this option.");
        }

        let tableCode = JSON.stringify(table, null, 2);
        let defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
        let productionsCode = JSON.stringify(productions, null, 2);

        // We know a couple of things about the parse table:
        //
        // - The first level is an array with continuous indexes
        // - Each entry of the array is an object which contains a series of numeric states as a hash table
        // - Each 'hash table' entry is either a state number or a 2-element array
        //
        // So we can start by encoding the table 'vertically', i.e. by column rather than by row,
        // and then provide a bit of code to transform that series of arrays to the real parse table
        // at run time.
        // We can encode the columns by encoding the array-or-number aspect as a separate column,
        // while encoding the size of each hash table in yet another column: number of entries per state.
        // Then thanks to that length info, plus the 'is this hash-table entry going to be a number or an array' flag column,
        // we can transform those back to what we need at run-time.
        //
        // Meanwhile, we can inspect each of the columns and see if we can compress them.
        //
        // Of course the flags array is compressible as it's only 1 bit per entry, but there's sure to
        // be more compression goodies to be had in there, such as run-length encoding and maybe
        // delta-encoding of the hashtable indexes themselves.
        //
        //

        // Don't surround numerical property name numbers in quotes
        tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');


        function reportColumnsForCompression(def_arr) {
            let report = [];

            let len = 0;
            for (let key in def_arr) {
                len = Math.max(len, def_arr[key].length);
            }

            let col_width = 6;
            let col_delta_width = 4;

            function clip(val, width) {
                let s = '        ' + val;
                s = s.substr(s.length - width);
                return s;
            }

            let track_prev4delta = {};
            let line = [];
            line.push('║');
            for (let c in def_arr) {
                let key = clip(c, col_width);
                let delta = clip('∆', col_delta_width);
                line.push(key);
                line.push('┊');
                line.push(delta);
                line.push('║');

                track_prev4delta[c] = 10000000;
            }
            report.push(line.join(''));

            for (let i = 0; i < len; i++) {
                line = [];
                line.push('║');

                for (let c in def_arr) {
                    let val, delta_val;
                    let tbl = def_arr[c];
                    if (tbl.length > i) {
                        val = tbl[i] || 0;

                        delta_val = val - track_prev4delta[c];
                        // negative deltas are jumps: don't treat those as delta but as absolute value, sign-flipped:
                        if (delta_val < 0) {
                            delta_val = -val - 1;  // so that absolute 0 becomes -1, so it can be recognized from delta=0 ('no change')
                        }
                        track_prev4delta[c] = val;
                    } else {
                        val = '.';
                        delta_val = '.';
                    }

                    let key = clip(val, col_width);
                    let delta = clip(delta_val, col_delta_width);
                    line.push(key);
                    line.push('┊');
                    line.push(delta);
                    line.push('║');
                }
                report.push(line.join(''));
            }

            return '\n\n\n// ------------------------------\n\n\n// ' + report.join('\n// ') + '\n\n\n// ------------------\n\n\n';
        }


        // table is array of 1/2-len arrays:
        function analyzeTableForCompression(table) {
            // column: productions' row length
            let len_col = [];
            // column: productions' shift size / action column
            let pop_col = [];
            // column: rule number for each slot ('rule'):
            let rule_col = [];

            let i;
            let row_count = table.length;
            for (i = 0; i < row_count; i++) {
                let prod = table[i];

                len_col.push(prod.length);
                assert__default['default'](prod.length <= 2);
                assert__default['default'](prod.length > 0);
                // and the special knowledge about the productions[] table:
                assert__default['default'](prod.length === 2);
                pop_col.push(prod[0]);
                rule_col.push(prod[1]);
            }

            let def_arr = {
                len: len_col,
                pop: pop_col,
                rule: rule_col
            };
            return def_arr;
        }




        // table is hash of 1/2-len arrays:
        function analyzeSetForCompression(table) {
            // column: row index
            let idx_col = [];
            // column: REDUCE productions' goto column
            let goto_col = [];

            let i;
            for (i in table) {
                i = +i;
                let prod = table[i];
                idx_col.push(i);

                // and the special knowledge about the defaultActions[] table:
                assert__default['default'](typeof prod === 'number');
                goto_col.push(prod);
            }

            let def_arr = {
                idx: idx_col,
                goto: goto_col
            };
            return def_arr;
        }



        function analyzeGotoTableForCompression(table) {
            // column: number of symbol hash entries per state slot ('length'):
            let len_col = [];
            // column: symbol hash entry key for each slot ('symbol'):
            let symbol_col = [];
            // column: symbol hash entry value type: number (0) or array (array.length) ('type'):
            let type_col = [];
            // column: symbol hash entry value if single GOTO state number ('state'):
            let state_col = [];
            // column: symbol hash entry mode value if array slot type (reduce/shift/accept):
            let mode_col = [];
            // column: symbol hash entry goto state value if array slot type:
            let goto_col = [];
            // // column: merged: state_col + goto_col:
            // let next_col = [];

            let row_count = table.length;
            for (let state = 0; state < row_count; state++) {
                let hashtable = table[state];
                let count = 0;
                for (let symbol in hashtable) {
                    symbol = +symbol;
                    symbol_col.push(symbol);

                    let slot = hashtable[symbol];
                    if (slot && slot.length) {
                        // array type slot:
                        assert__default['default'](slot.length === 2 || slot.length === 1);
                        assert__default['default'](slot.length === 1 ? slot[0] === 3 /* $accept */ : true);
                        type_col.push(slot.length);
                        if (slot.length > 1) {
                            mode_col.push(slot[0]);
                            goto_col.push(slot[1]);
                            //next_col.push(slot[1]);
                        }
                    } else if (slot) {
                        // number type slot:
                        type_col.push(0);
                        state_col.push(slot);
                        //next_col.push(slot);
                    } else {
                        assert__default['default'](0);
                        type_col.push(666);
                        state_col.push((typeof slot) + state + '/' + symbol);
                        //next_col.push((typeof slot) + state + '/' + symbol);
                    }
                    count++;
                }
                len_col.push(count);
            }

            let def_arr = {
                len: len_col,
                symbol: symbol_col,
                type: type_col,
                state: state_col,
                mode: mode_col,
                goto: goto_col
                //'next': next_col,
            };
            return def_arr;
        }


        let has_compressed_a_table = false;


        function generateColumn(name, col) {
            let rv = [];

            for (let i = 0, len = col.length; i < len; i++) {
                // try basic run-length encoding first:
                let v = col[i];
                let j;

                for (j = i + 1; j < len; j++) {
                    if (col[j] !== v) {
                        break;
                    }
                }
                let runlength = j - i;

                // try stepped run-length encoding next:
                let delta = col[i + 1] - v;
                let steplength = 0;

                // we don't want to replicate the runlength result, so only look for a match
                // when delta !== 0:
                if (delta !== 0) {
                    for (j = i + 2; j < len; j++) {
                        if (col[j] - col[j - 1] !== delta) {
                            break;
                        }
                    }
                    steplength = j - i;
                }

                // try to match the pattern in history:
                let best_pos = 0;
                let best_len = 0;
                let upper_bound = i - 2;
                for (j = 0; j < upper_bound; j++) {
                    let l;
                    for (l = 0; col[j + l] === col[i + l]; l++) {
                        // No need to check for:
                        //    if (j + l === i) break;
                        // because we know how the c() helper function will regenerate
                        // this pattern: it is perfectly fine to overlap on itself: we always
                        // have an offset of relative -1 or more, so we can encode runlength
                        // patterns as duplicates this way too:
                        //   [4, c(0, 7)]   (note the written offset is 0!)
                        // will output an sequence of 7+1 '4' values: one '4' and then 7 more.
                        //
                        // Encoding such a pattern as direct runlength `s(4, 8)` is cheaper
                        // though. Hence we loop until `i - 2`: we want to find ABABABAB...
                        // patterns, but no AAAAAA... patterns here.
                    }

                    // We want the nearest offset for the longest pattern:
                    if (l >= best_len) {
                        best_len = l;
                        best_pos = i - j;
                    }
                }

                // weight our options now:
                let gain = [
                    runlength - 2,
                    steplength - 3,
                    best_len - 2
                ];
                let optimum_gain = Math.max.apply(null, gain);
                if (optimum_gain <= 0) {
                    rv.push(v);
                } else if (optimum_gain === gain[0]) {
                    rv.push('s', '[' + v + ', ' + runlength + ']');
                    i += runlength - 1;
                } else if (optimum_gain === gain[1]) {
                    rv.push('s', '[' + v + ', ' + steplength + ', ' + delta + ']');
                    i += steplength - 1;
                } else if (optimum_gain === gain[2]) {
                    rv.push('c', '[' + best_pos + ', ' + best_len + ']');
                    i += best_len - 1;
                } else {
                    rv.push(v);
                    //assert(0);      // should never get here!
                }

                if (optimum_gain > 0) {
                    has_compressed_a_table = true;
                }
            }

            let code = [
                '  ', name, ': ',
                'u([',
                '\n  ',
                rv.join(',\n  '),                // JSON.stringify(col, null, 2),
                '\n',
                '])'
            ].join('');
            return code;
        }


        function generateCompressedTable(def_arr) {
            let code = [
                'bp({',
                generateColumn('pop', def_arr.pop) + ',',
                generateColumn('rule', def_arr.rule),
                '})'
            ].join('\n');
            return code;
        }


        function generateCompressedSet(def_arr) {
            let code = [
                'bda({',
                generateColumn('idx', def_arr.idx) + ',',
                generateColumn('goto', def_arr.goto),
                '})'
            ].join('\n');
            return code;
        }


        function generateCompressedGotoTable(def_arr) {
            let code = [
                'bt({',
                generateColumn('len', def_arr.len) + ',',
                generateColumn('symbol', def_arr.symbol) + ',',
                generateColumn('type', def_arr.type) + ',',
                generateColumn('state', def_arr.state) + ',',
                generateColumn('mode', def_arr.mode) + ',',
                generateColumn('goto', def_arr.goto),
                '})'
            ].join('\n');
            return code;
        }


        let tableDef = analyzeGotoTableForCompression(table);
        let defaultActionsDef = analyzeSetForCompression(defaultActions);
        let productionsDef = analyzeTableForCompression(productions);


        const bp_code_container = `
        // helper: reconstruct the productions[] table
        function bp(s) {
            let rv = [];
            let p = s.pop;
            let r = s.rule;
            for (let i = 0, l = p.length; i < l; i++) {
                rv.push([
                    p[i],
                    r[i]
                ]);
            }
            return rv;
        }
    `;

        const bda_code_container = `
        // helper: reconstruct the defaultActions[] table
        function bda(s) {
            let rv = {};
            let d = s.idx;
            let g = s.goto;
            for (let i = 0, l = d.length; i < l; i++) {
                let j = d[i];
                rv[j] = g[i];
            }
            return rv;
        }
    `;

        const bt_code_container = `
        // helper: reconstruct the 'goto' table
        function bt(s) {
            let rv = [];
            let d = s.len;
            let y = s.symbol;
            let t = s.type;
            let a = s.state;
            let m = s.mode;
            let g = s.goto;
            for (let i = 0, l = d.length; i < l; i++) {
                let n = d[i];
                let q = {};
                for (let j = 0; j < n; j++) {
                    let z = y.shift();
                    switch (t.shift()) {
                    case 2:
                        q[z] = [
                            m.shift(),
                            g.shift()
                        ];
                        break;

                    case 0:
                        q[z] = a.shift();
                        break;

                    default:
                        // type === 1: accept
                        q[z] = [
                            3
                        ];
                    }
                }
                rv.push(q);
            }
            return rv;
        }
    `;

        const c_s_u_code_container = `
        // helper: runlength encoding with increment step: code, length: step (default step = 0)
        // \`this\` references an array
        function s(c, l, a) {
            a = a || 0;
            for (let i = 0; i < l; i++) {
                this.push(c);
                c += a;
            }
        }

        // helper: duplicate sequence from *relative* offset and length.
        // \`this\` references an array
        function c(i, l) {
            i = this.length - i;
            for (l += i; i < l; i++) {
                this.push(this[i]);
            }
        }

        // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
        function u(a) {
            let rv = [];
            for (let i = 0, l = a.length; i < l; i++) {
                let e = a[i];
                // Is this entry a helper function?
                if (typeof e === 'function') {
                    i++;
                    e.apply(rv, a[i]);
                } else {
                    rv.push(e);
                }
            }
            return rv;
        }
    `;

        has_compressed_a_table = false;
        let tc = generateCompressedGotoTable(tableDef);
        let compressGotoTable = has_compressed_a_table;

        has_compressed_a_table = false;
        let dac = generateCompressedSet(defaultActionsDef);
        let compressDefaultActions = has_compressed_a_table;

        has_compressed_a_table = false;
        let pc = generateCompressedTable(productionsDef);
        let compressProductions = has_compressed_a_table;

        let compressAnything = (compressProductions || compressDefaultActions || compressGotoTable);

        tableCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(tableDef) : '') + (compressGotoTable ? tc : tableCode);
        defaultActionsCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(defaultActionsDef) : '') + (compressDefaultActions ? dac : defaultActionsCode);
        productionsCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(productionsDef) : '') + (compressProductions ? pc : productionsCode);


        let prelude = [
            '',
            compressProductions ? bp_code_container : '',
            '',
            compressDefaultActions ? bda_code_container : '',
            '',
            compressGotoTable ? bt_code_container : '',
            '',
            c_s_u_code_container
        ];
        if (!compressAnything) {
            prelude = [];
        }

        // Return the variable initialization code and the table code
        return {
            commonCode: prelude.join('\n'),
            tableCode: tableCode,
            defaultActionsCode: defaultActionsCode,
            productionsCode: productionsCode
        };
    };

    // --- START of commonJsMain chunk ---
    //
    // default main method for generated commonjs modules
    const commonJsMain = `
function __jison_default_main__(args) {
    // When the parser comes with its own \`main\` function, then use that one:
    if (typeof exports.parser.main === 'function') {
        return exports.parser.main(args);
    }

    if (!args[1]) {
        console.log('Usage:', path.basename(args[0]) + ' FILE');
        process.exit(1);
    }
    const source = fs.readFileSync(path.normalize(args[1]), 'utf8');
    const dst = exports.parser.parse(source);
    console.log('parser output:\\n\\n', {
        type: typeof dst,
        value: dst
    });
    try {
        console.log('\\n\\nor as JSON:\\n', JSON.stringify(dst, null, 2));
    } catch (e) { /* ignore crashes; output MAY not be serializable! We are a generic bit of code, after all... */ }
        let rv = 0;
        if (typeof dst === 'number' || typeof dst === 'boolean') {
            rv = dst;
    }
    return dst;
}
`;
    // --- END of commonJsMain chunk ---

    const commonJsMainImports = `
const fs = require('fs');
const path = require('path');
`;

    // debug mixin for LR parser generators

    function printAction(a, gen) {
        let s = a[0] === SHIFT ? 'shift token (then go to state ' + a[1] + ')' :
            a[0] === REDUCE ? 'reduce by rule: ' + gen.productions[a[1]] :
                a[0] === ACCEPT ? 'accept' : 'UNDEFINED ACTION: ' + a[0];

        return s;
    }

    function traceStates(trace, states, title) {
        trace('\nItem sets -- ' + title + '\n------');

        states.forEach(function (state, i) {
            trace('\nitem set', i, '\n' + state.join('\n'), '\ntransitions -> ', JSON.stringify(state.edges));
        });
        trace('\n');
    }

    const lrGeneratorDebug = {
        beforeparseTable: function () {
            this.trace('Building parse table.');
        },
        afterparseTable: function () {
            let trace = this.trace;
            let self = this;
            if (this.conflicts > 0) {
                trace('\nConflicts:\n');
                this.resolutions.forEach(function (r, i) {
                    if (r[2].bydefault) {
                        trace('Conflict at state: ', r[0], ', token: ', r[1], '\n  ', printAction(r[2].r, self), '\n  ', printAction(r[2].s, self));
                    }
                });
                trace('\n' + this.conflicts + ' Conflict(s) found in grammar.');
            }
            trace('Done.\n');
        },
        aftercanonicalCollection: function (states /* as produced by `this.canonicalCollection()` */) {
            traceStates(this.trace, states, 'as produced by LR::canonicalCollection()');
        }
    };

    const parser$4 = typal.beget();

    generatorMixin.createParser = function createParser() {
        let sourceCodeDef = this.generateModuleExpr();

        // produce a chunk of sourcecode that's suitable for evaluation through `eval()`:
        let sourcecode = rmCommonWS$5`
        ${sourceCodeDef.init}

        let yy__parser = ${sourceCodeDef.src};

        // produce the generated parser function/class as the last value
        // in this chunk of code so that we can be sure to produce *that*
        // one as the 'return value' of the \`eval()\` call we'll submit
        // this code to.
        //
        // See also: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval

        yy__parser;
    `;
        let p = code_exec$1(sourcecode, function generated_code_exec_wrapper_jison(sourcecode) {
            //console.log("===============================PARSER TEST CODE\n", sourcecode, "\n=====================END====================\n");
            chkBugger$3(sourcecode);
            let rv = eval(sourcecode);
            return rv;
        }, mkStdOptions$1(this.options, {
            dumpSourceCodeOnFailure: this.DEBUG,
            throwErrorOnCompileFailure: true
        }), 'parser');
        assert__default['default'](typeof p === 'object');
        assert__default['default'](typeof p.parse === 'function');
        assert__default['default'](typeof p.parser === 'undefined');
        assert__default['default'](typeof p.Parser === 'function');
        assert__default['default'](typeof p.yy === 'object');
        assert__default['default'](typeof p.EOF === 'number');
        assert__default['default'](typeof p.TERROR === 'number');
        // assert(typeof p.trace === 'function');
        assert__default['default'](typeof p.JisonParserError === 'function');
        assert__default['default'](typeof p.quoteName === 'function');
        assert__default['default'](typeof p.originalQuoteName === 'function');
        assert__default['default'](typeof p.describeSymbol === 'function');
        assert__default['default'](typeof p.symbols_ === 'object');
        assert__default['default'](typeof p.terminals_ === 'object');
        // assert(typeof p.nonterminals === 'undefined');
        // assert(typeof p.terminal_descriptions_ === 'undefined');
        // assert(typeof p.productions_ === 'object');
        assert__default['default'](typeof p.performAction === 'function');
        assert__default['default'](typeof p.table === 'object');
        // assert(typeof p.defaultActions === 'object');
        assert__default['default'](typeof p.parseError === 'function');
        // assert(typeof p.yyError === 'undefined');
        // assert(typeof p.yyRecovering === 'undefined');
        // assert(typeof p.yyErrOk === 'undefined');
        // assert(typeof p.yyClearIn === 'undefined');
        assert__default['default'](typeof p.constructParseErrorInfo === 'object');
        assert__default['default'](typeof p.originalParseError === 'function');
        assert__default['default'](typeof p.options === 'object');
        assert__default['default'](typeof p.cleanupAfterParse === 'object');
        assert__default['default'](typeof p.yyMergeLocationInfo === 'object');
        assert__default['default'](typeof p.lexer === 'object' || typeof p.lexer === 'undefined');

        // for debugging
        p.productions = this.productions;
        p.unused_productions = this.unused_productions;
        p.conflicts = this.conflicts;
        if (p.conflicts && this.options.hasPartialLrUpgradeOnConflict) {
            p.conflicts_have_been_fixed = this.conflict_fixing_round;
            p.conflict_productions_LU = this.conflict_productions_LU;
            p.conflict_states_LU = this.conflict_states_LU;
        }
        p.sourceCode = sourceCodeDef;

        let self = this;
        function bind(method) {
            return function () {
                self.lexer = p.lexer;
                return method.apply(self, arguments);
            };
        }

        // backwards compatibility
        p.lexer = this.lexer;
        p.generate = bind(this.generate);
        p.generateAMDModule = bind(this.generateAMDModule);
        p.generateModule = bind(this.generateModule);
        p.generateCommonJSModule = bind(this.generateCommonJSModule);

        this.reportGrammarInformation();

        return p;
    };

    parser$4.trace = generator.trace;
    parser$4.warn = generator.warn;
    parser$4.error = generator.error;

    // --- START parser Error class chunk ---
    const parseErrorSourceCode = `
function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable) {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
}
`;
    // --- END of parseErrorSourceCode chunk ---

    chkBugger$3(parseErrorSourceCode);
    parser$4.parseError = lrGeneratorMixin.parseError = eval(parseErrorSourceCode + '\n\nparseError;');

    generatorMixin.createLexer = function createLexer(lexerSpec, input, tokens, options) {
        // TODO: construct options from generator options:
        // lexer_options = ...
        let lexer = new RegExpLexer(lexerSpec, input, tokens, options);

        return lexer;
    };


    // --- START parser API def chunk ---
    //
    // One chunk so we can easily stringify the APIs defined here to code *with comments*
    // in the generated code:
    const define_parser_APIs_1 = `
    TERROR: 2,
    EOF: 1,

    // internals: defined here so the object *structure* doesn't get modified by parse() et al,
    // thus helping JIT compilers like Chrome V8.
    originalQuoteName: null,
    originalParseError: null,
    cleanupAfterParse: null,
    constructParseErrorInfo: null,
    yyMergeLocationInfo: null,
    copy_yytext: null,
    copy_yylloc: null,

    __reentrant_call_depth: 0,      // INTERNAL USE ONLY
    __error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
    __error_recovery_infos: [],     // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

    // APIs which will be set up depending on user action code analysis:
    //yyRecovering: 0,
    //yyErrOk: 0,
    //yyClearIn: 0,

    // Helper APIs
    // -----------

    // Helper function which can be overridden by user code later on: put suitable quotes around
    // literal IDs in a description string.
    quoteName: function parser_quoteName(id_str) {
        return '"' + id_str + '"';
    },

    // Return the name of the given symbol (terminal or non-terminal) as a string, when available.
    //
    // Return NULL when the symbol is unknown to the parser.
    getSymbolName: function parser_getSymbolName(symbol) {
        if (this.terminals_[symbol]) {
            return this.terminals_[symbol];
        }

        // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
        //
        // An example of this may be where a rule's action code contains a call like this:
        //
        //      parser.getSymbolName(#$)
        //
        // to obtain a human-readable name of the current grammar rule.
        const s = this.symbols_;
        for (let key in s) {
            if (s[key] === symbol) {
                return key;
            }
        }
        return null;
    },

    // Return a more-or-less human-readable description of the given symbol, when available,
    // or the symbol itself, serving as its own 'description' for lack of something better to serve up.
    //
    // Return NULL when the symbol is unknown to the parser.
    describeSymbol: function parser_describeSymbol(symbol) {
        if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
            return this.terminal_descriptions_[symbol];
        } else if (symbol === this.EOF) {
            return 'end of input';
        }

        let id = this.getSymbolName(symbol);
        if (id) {
            return this.quoteName(id);
        }
        return null;
    },

    // Produce a (more or less) human-readable list of expected tokens at the point of failure.
    //
    // The produced list may contain token or token set descriptions instead of the tokens
    // themselves to help turning this output into something that easier to read by humans
    // unless \`do_not_describe\` parameter is set, in which case a list of the raw, *numeric*,
    // expected terminals and nonterminals is produced.
    //
    // The returned list (array) will not contain any duplicate entries.
    collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
        const TERROR = this.TERROR;
        let tokenset = [];
        let check = {};

        // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
        // If so, use that one instead of the less palatable token set.
        if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
            return [
                this.state_descriptions_[state]
            ];
        }
        for (let p in this.table[state]) {
            p = +p;
            if (p !== TERROR) {
                let d = do_not_describe ? p : this.describeSymbol(p);
                if (d && !check[d]) {
                    tokenset.push(d);
                    check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
                }
            }
        }
        return tokenset;
    }
`;
    // --- END of define_parser_APIs_1 chunk ---

    const api_set = (new Function('', 'return { ' + define_parser_APIs_1 + ' };'))();
    for (let api in api_set) {
        parser$4[api] = api_set[api];
    }


    // --- START parser kernel ---
    parser$4.parse = `
function parse(input, parseParams) {
    let self = this;
    let stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
    let sstack = new Array(128);        // state stack: stores states (column storage)
    let tstack = [];                    // token stack (only used when \`%options token_stack\` support has been enabled)
    let vstack = new Array(128);        // semantic value stack
    let lstack = new Array(128);        // location stack
    let table = this.table;
    let sp = 0;                         // 'stack pointer': index into the stacks
    let yyloc;
    let yytext;
    let yylineno;
    let yyleng;

    let symbol = 0;
    let preErrorSymbol = 0;
    let lastEofErrorStateDepth = Infinity;
    let recoveringErrorInfo = null;
    let recovering = 0;                 // (only used when the grammar contains error recovery rules)
    const TERROR = this.TERROR;
    const EOF = this.EOF;
    const ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    const NO_ACTION = [ 0, YY_ERROR_RECOVERY_COMBINE_ID /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

    let lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    let sharedState_yy = {
        parseError: undefined,
        quoteName: undefined,
        lexer: undefined,
        parser: undefined,
        pre_parse: undefined,
        post_parse: undefined,
        pre_lex: undefined,
        post_lex: undefined,
        parseParamsAsMembers      // WARNING: must be written this way for the code expanders to work correctly!
    };

    const ASSERT = (
        typeof assert !== 'function' ?
            function JisonAssert(cond, msg) {
                if (!cond) {
                    throw new Error('assertion failed: ' + (msg || '***'));
                }
            } :
            assert
    );

    this.yyGetSharedState = function yyGetSharedState() {
        return sharedState_yy;
    };

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
        return recoveringErrorInfo;
    };

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    // shallow clone objects & arrays, straight copy of simple \`src\` values
    // e.g. \`lexer.yytext\` MAY be a complex value object,
    // rather than a simple string/value.
    //
    // https://jsperf.com/new-array-vs-splice-vs-slice/72
    // https://jsperf.com/instanceof-vs-typeof/20
    // benchmark:: http://127.0.0.1:8080/example/jsperf/#testfile=test0020-typeof-instanceof-isArray.json5
    // benchmark:: http://127.0.0.1:8080/example/jsperf/?333#testfile=test0021-shallow-clones.json5
    //
    function shallow_copy(src) {
        if (src && typeof src === 'object') {
            // non-Object-type objects, e.g. RegExp, Date, etc., can usually be shallow cloned
            // using their constructor:
            if (src.constructor !== Object) {
                if (Array.isArray(src)) {
                    return src.slice();
                }
                let dst = new src.constructor(src);

                // and make sure all custom attributes are added to the clone:
                shallow_copy_noclobber(dst, src);
                return dst;
            }
            // native objects must be cloned a different way:
            {
                //return Object.assign({}, src);
                let dst = {};
                shallow_copy_noclobber(dst, src);
                return dst;
            }
        }
        return src;
    }
    // add elements from \`src\` to \`dst\` when:
    // - either the element does not yet exist in \`src\`
    // - or exists in \`src\` but is NULL or UNDEFINED there, while its value is non-NULL in \`dst\`
    function shallow_copy_noclobber(dst, src) {
        const chk = Object.prototype.hasOwnProperty;
        for (let k in src) {
            if (!(k in dst)) {
                if (chk.call(src, k)) {
                    dst[k] = src[k];
                }
            } else if (src[k] != null && dst[k] == null && chk.call(src, k)) {
                dst[k] = src[k];
            }
        }
    }
    function copy_yylloc_native(loc) {
        let rv = shallow_copy(loc);
        // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
        if (rv) {
            rv.range = rv.range.slice();
        }
        return rv;
    }

    // copy state
    shallow_copy_noclobber(sharedState_yy, this.yy);

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;

    // allow userland code to override the yytext and yylloc copy/clone functions:
    this.copy_yytext = this.options.copy_yytext || sharedState_yy.copy_yytext || shallow_copy;
    this.copy_yylloc = this.options.copy_yylloc || sharedState_yy.copy_yylloc || copy_yylloc_native;

    let yydebug = false;
    if (this.options.debug) {
        yydebug = function yydebug_impl(msg, obj) {
            let ref_list;
            let ref_names;

            function deepClone(from, sub) {
                if (sub == null) {
                    ref_list = [];
                    ref_names = [];
                    sub = 'root';
                }
                if (typeof from === 'function') return '[Function]';
                if (from == null || typeof from !== 'object') return from;
                if (from.constructor !== Object && from.constructor !== Array) {
                    return from;
                }

                let i = ref_list.indexOf(from);
                if (i >= 0) {
                    return '[Circular/Xref:' + ref_names[i] + ']';   // circular or cross reference
                }
                ref_list.push(from);
                ref_names.push(sub);

                let to = new from.constructor();
                for (let name in from) {
                    if (name === 'parser') continue;
                    if (name === 'lexer') continue;
                    to[name] = deepClone(from[name], name);
                }
                return to;
            }

            obj = obj || {};
            if (obj.symbol) {
                obj.local_yytext = yytext;
                obj.lexer_yytext = lexer.yytext;
                obj.lexer_yylloc = lexer.yylloc;
                obj.lexer_yyllineno = lexer.yyllineno;
            }

            // warning: here we fetch from closure (stack et al)
            obj.symbol_stack = stack;
            obj.state_stack = sstack;
            obj.value_stack = vstack;
            obj.location_stack = lstack;
            obj.stack_pointer = sp;

            // ready the object for printing:
            obj = deepClone(obj);

            // wrap try/catch in a function to help the V8 JIT compiler...
            function yydebug_cvt(obj) {
                let js;
                try {
                    let re1;
                    if (typeof XRegExp === 'undefined') {
                        re1 = / {2}\\"([a-z_][a-z_0-9. ]*)\\": /ig;
                    } else {
                        re1 = new XRegExp('  \\"([\\\\p{Alphabetic}_][\\\\p{Alphabetic}\\\\p{Number}_. ]*)\\": ', 'g');
                    }
                    js = JSON.stringify(obj, null, 2)
                    .replace(re1, '  $1: ')
                    .replace(/[\\n\\s]+/g, ' ')
                    // shorten yylloc object dumps too:
                    .replace(/\\{ first_line: (\\d+), first_column: (\\d+), last_line: (\\d+), last_column: (\\d+)/g, '{L/C: ($1,$2)..($3,$4)');
                } catch (ex) {
                    js = String(obj);
                }
                return js;
            }

            self.trace(msg, yydebug_cvt(obj), '\\n');
        };
    }

    // disable debugging at run-time ANYWAY when you've *explicitly* set "yy.yydebug = false":
    if (sharedState_yy.yydebug === false) {
        yydebug = undefined;
    }

    // *Always* setup \`yyError\`, \`YYRECOVERING\`, \`yyErrOk\` and \`yyClearIn\` functions as it is paramount
    // to have *their* closure match ours -- if we only set them up once,
    // any subsequent \`parse()\` runs will fail in very obscure ways when
    // these functions are invoked in the user action code block(s) as
    // their closure will still refer to the \`parse()\` instance which set
    // them up. Hence we MUST set them up at the start of every \`parse()\` run!
    if (this.yyError) {
        this.yyError = function yyError(str /*, ...args */) {
            if (yydebug) {
                yydebug('yyerror: ', {
                    message: str,
                    args: arguments,
                    symbol, state, newState, recovering, action
                });
            }

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

            let error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
            let expected = this.collect_expected_token_set(state);
            let hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
            // append to the old one?
            if (recoveringErrorInfo) {
                let esp = recoveringErrorInfo.info_stack_pointer;

                recoveringErrorInfo.symbol_stack[esp] = symbol;
                let v = this.shallowCopyErrorInfo(hash);
                v.yyError = true;
                v.errorRuleDepth = error_rule_depth;
                v.recovering = recovering;
                // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                recoveringErrorInfo.value_stack[esp] = v;
                recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                ++esp;
                recoveringErrorInfo.info_stack_pointer = esp;
            } else {
                recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                recoveringErrorInfo.yyError = true;
                recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                recoveringErrorInfo.recovering = recovering;
            }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules

            let expected = this.collect_expected_token_set(state);
            let hash = this.constructParseErrorInfo(str, null, expected, false);

//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

            // Add any extra args to the hash under the name \`extra_error_attributes\`:
            let args = Array.prototype.slice.call(arguments, 1);
            if (args.length) {
                hash.extra_error_attributes = args;
            }

            return this.parseError(str, hash, this.JisonParserError);
        };
    }

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    if (this.yyRecovering) {
        this.yyRecovering = function yyRecovering() {
            if (yydebug) yydebug('yyrecovering: ', { symbol, state, newState, recovering, action });
            return recovering;
        };
    }

    if (this.yyErrOk) {
        this.yyErrOk = function yyErrOk() {
            if (yydebug) yydebug('yyerrok: ', { symbol, state, newState, recovering, action });
            recovering = 0;

            // DO NOT reset/cleanup \`recoveringErrorInfo\` yet: userland code
            // MAY invoke this API before the error is actually fully
            // recovered, in which case the parser recovery code won't be able
            // to append the skipped tokens to this info object.
            //
            // The rest of the kernel code is safe enough that it won't inadvertedly
            // re-use an old \`recoveringErrorInfo\` chunk so we'ld better wait
            // with destruction/cleanup until the end of the parse or until another
            // fresh parse error rears its ugly head...
            //
            // if (recoveringErrorInfo && typeof recoveringErrorInfo.destroy === 'function') {
            //     recoveringErrorInfo.destroy();
            //     recoveringErrorInfo = undefined;
            // }
        };
    }

    if (this.yyClearIn) {
        this.yyClearIn = function yyClearIn() {
            if (yydebug) yydebug('yyclearin: ', { symbol, newState, recovering, action, preErrorSymbol });
            if (symbol === TERROR) {
                symbol = 0;
                yytext = null;
                yyleng = 0;
                yyloc = undefined;
            }
            preErrorSymbol = 0;
        };
    }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    // Does the shared state override the default \`parseError\` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default \`quoteName\` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = function quoteNameAlt(id_str) {
            return sharedState_yy.quoteName.call(this, id_str);
        };
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the \`%options no-try-catch\` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a \`finally { ... }\` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your \`sharedState\`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        let rv;

        if (invoke_post_methods) {
            let hash;

            if (sharedState_yy.post_parse || this.post_parse) {
                // create an error hash info instance: we re-use this API in a **non-error situation**
                // as this one delivers all parser internals ready for access by userland code.
                hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
            }

            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }

            // cleanup:
            if (hash && hash.destroy) {
                hash.destroy();
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;
        lstack.length = 0;
        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (let i = this.__error_infos.length - 1; i >= 0; i--) {
                let el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

            for (let i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                let el = this.__error_recovery_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_recovery_infos.length = 0;

            // \`recoveringErrorInfo\` is also part of the \`__error_recovery_infos\` array,
            // hence has been destroyed already: no need to do that *twice*.
            if (recoveringErrorInfo) {
                recoveringErrorInfo = undefined;
            }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

        }

        return resultValue;
    };

    // merge yylloc info into a new yylloc instance.
    //
    // \`first_index\` and \`last_index\` MAY be UNDEFINED/NULL or these are indexes into the \`lstack[]\` location stack array.
    //
    // \`first_yylloc\` and \`last_yylloc\` MAY be UNDEFINED/NULL or explicit (custom or regular) \`yylloc\` instances, in which
    // case these override the corresponding first/last indexes.
    //
    // \`dont_look_back\` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
    // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
    // yylloc info.
    //
    // Note: epsilon rule's yylloc situation is detected by passing both \`first_index\` and \`first_yylloc\` as UNDEFINED/NULL.
    this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
        let i1 = first_index | 0;
        let i2 = last_index | 0;
        let l1 = first_yylloc;
        let l2 = last_yylloc;
        let rv;

        // rules:
        // - first/last yylloc entries override first/last indexes

        if (!l1) {
            if (first_index != null) {
                for (let i = i1; i <= i2; i++) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
        }

        if (!l2) {
            if (last_index != null) {
                for (let i = i2; i >= i1; i--) {
                    l2 = lstack[i];
                    if (l2) {
                        break;
                    }
                }
            }
        }

        // - detect if an epsilon rule is being processed and act accordingly:
        if (!l1 && first_index == null) {
            // epsilon rule span merger. With optional look-ahead in l2.
            if (!dont_look_back) {
                for (let i = (i1 || sp) - 1; i >= 0; i--) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
            if (!l1) {
                if (!l2) {
                    // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                    // without look-ahead and no preceding terms and/or \`dont_look_back\` set:
                    // in that case we ca do nothing but return NULL/UNDEFINED:
                    return null;
                }
                // shallow-copy L2: after all, we MAY be looking
                // at unconventional yylloc info objects...
                rv = this.copy_yylloc(l2);
                return rv;
            }
            // shallow-copy L1, then adjust first col/row 1 column past the end.
            rv = this.copy_yylloc(l1);
            rv.first_line = rv.last_line;
            rv.first_column = rv.last_column;
            rv.range[0] = rv.range[1];

            if (l2) {
                // shallow-mixin L2, then adjust last col/row accordingly.
                shallow_copy_noclobber(rv, l2);
                rv.last_line = l2.last_line;
                rv.last_column = l2.last_column;
                rv.range[1] = l2.range[1];
            }
            return rv;
        }

        if (!l1) {
            l1 = l2;
            l2 = null;
        }
        if (!l1) {
            return null;
        }

        // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
        // at unconventional yylloc info objects...
        rv = this.copy_yylloc(l1);

        if (l2) {
            shallow_copy_noclobber(rv, l2);
            rv.last_line = l2.last_line;
            rv.last_column = l2.last_column;
            rv.range[1] = l2.range[1];
        }

        return rv;
    };

    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your \`lexer\`, \`sharedState\`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        const pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: this.copy_yytext(lexer.yytext),
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,
            loc: this.copy_yylloc(lexer.yylloc),
            expected,
            recoverable,
            state,
            action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,
            location_stack: lstack,
            stack_pointer: sp,
            yy: sharedState_yy,
            lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                const rec = !!this.recoverable;
                for (let key in this) {
                    if (this[key] && this.hasOwnProperty(key) && typeof this[key] === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };

    // clone some parts of the (possibly enhanced!) errorInfo object
    // to give them some persistence.
    this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
        let rv = shallow_copy(p);

        // remove the large parts which can only cause cyclic references
        // and are otherwise available from the parser kernel anyway.
        delete rv.sharedState_yy;
        delete rv.parser;
        delete rv.lexer;

        // lexer.yytext MAY be a complex value object, rather than a simple string/value:
        rv.value = this.copy_yytext(rv.value);

        // yylloc info:
        rv.loc = this.copy_yylloc(rv.loc);

        // the 'expected' set won't be modified, so no need to clone it:
        //rv.expected = rv.expected.slice();

        // symbol stack is a simple array:
        rv.symbol_stack = rv.symbol_stack.slice();
        // ditto for state stack:
        rv.state_stack = rv.state_stack.slice();
        // clone the yylloc's in the location stack?:
        rv.location_stack = rv.location_stack.map(this.copy_yylloc);
        // and the value stack may carry both simple and complex values:
        // shallow-copy the latter.
        rv.value_stack = rv.value_stack.map(this.copy_yytext);

        // and we don't bother with the sharedState_yy reference:
        //delete rv.yy;

        // now we prepare for tracking the COMBINE actions
        // in the error recovery code path:
        //
        // as we want to keep the maximum error info context, we
        // *scan* the state stack to find the first *empty* slot.
        // This position will surely be AT OR ABOVE the current
        // stack pointer, but we want to keep the 'used but discarded'
        // part of the parse stacks *intact* as those slots carry
        // error context that may be useful when you want to produce
        // very detailed error diagnostic reports.
        //
        // ### Purpose of each stack pointer:
        //
        // - stack_pointer: points at the top of the parse stack
        //                  **as it existed at the time of the error
        //                  occurrence, i.e. at the time the stack
        //                  snapshot was taken and copied into the
        //                  errorInfo object.**
        // - base_pointer:  the bottom of the **empty part** of the
        //                  stack, i.e. **the start of the rest of
        //                  the stack space /above/ the existing
        //                  parse stack. This section will be filled
        //                  by the error recovery process as it
        //                  travels the parse state machine to
        //                  arrive at the resolving error recovery rule.**
        // - info_stack_pointer:
        //                  this stack pointer points to the **top of
        //                  the error recovery tracking stack space**, i.e.
        //                  this stack pointer takes up the role of
        //                  the \`stack_pointer\` for the error recovery
        //                  process. Any mutations in the **parse stack**
        //                  are **copy-appended** to this part of the
        //                  stack space, keeping the bottom part of the
        //                  stack (the 'snapshot' part where the parse
        //                  state at the time of error occurrence was kept)
        //                  intact.
        // - root_failure_pointer:
        //                  copy of the \`stack_pointer\`...
        //
        {
            let i;
            for (i = rv.stack_pointer; rv.state_stack[i] != null; i++) {
                // empty
            }
            rv.base_pointer = i;
            rv.info_stack_pointer = i;
        }

        rv.root_failure_pointer = rv.stack_pointer;

        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_recovery_infos.push(rv);

        return rv;
    };

    function getNonTerminalFromCode(symbol) {
        let tokenName = self.getSymbolName(symbol);
        if (!tokenName) {
            tokenName = symbol;
        }
        return tokenName;
    }

//_lexer_without_token_stack:

    function stdLex() {
        let token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
            let tokenName = self.getSymbolName(token || EOF);
            if (!tokenName) {
                tokenName = token;
            }

            Jison.lexDebugger.push({
                tokenName,
                tokenText: lexer.match,
                tokenValue: lexer.yytext
            });
        }

        return token || EOF;
    }

    function fastLex() {
        let token = lexer.fastLex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
            let tokenName = self.getSymbolName(token || EOF);
            if (!tokenName) {
                tokenName = token;
            }

            Jison.lexDebugger.push({
                tokenName,
                tokenText: lexer.match,
                tokenValue: lexer.yytext
            });
        }

        return token || EOF;
    }

    let lex = stdLex;

//_lexer_with_token_stack:

    // lex function that supports token stacks
    function tokenStackLex() {
        let token;
        token = tstack.pop() || lexer.lex() || EOF;
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            if (token instanceof Array) {
                // tokenstack CANNOT be nested, i.e. an 'array'-type token
                // now means the \`tstack\` is empty as this array of tokens
                // could only have originated from the \`lexer.lex()\`
                // call:
                tstack = token;
                token = tstack.pop();
            }
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }
        }

        if (typeof Jison !== 'undefined' && Jison.lexDebugger) {
            let tokenName = self.getSymbolName(token || EOF);
            if (!tokenName) {
                tokenName = token;
            }

            Jison.lexDebugger.push({
                tokenName,
                tokenText: lexer.match,
                tokenValue: lexer.yytext
            });
        }

        return token || EOF;
    }

//_lexer_with_token_stack_end:

    let state, action, r, t;
    let yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    let p;
    let yyrulelen;
    let this_production;
    let newState;
    let retval = false;

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    // Return the rule stack depth where the nearest error rule can be found.
    // Return -1 when no error recovery rule was found.
    function locateNearestErrorRecoveryRule(state) {
        let stack_probe = sp - 1;
        let depth = 0;

        // try to recover from error
        while (stack_probe >= 0) {
            // check for error recovery rule in this state
            if (yydebug) {
                yydebug('locateNearestErrorRecoveryRule #test#: ', {
                    symbol, state, depth,
                    stackidx: sp - 1 - depth,
                    lastidx: lastEofErrorStateDepth
                });
            }
            const t = (table[state] && table[state][TERROR]) || NO_ACTION;
            if (t[0]) {
                // We need to make sure we're not cycling forever:
                // once we hit EOF, even when we \`yyerrok()\` an error, we must
                // prevent the core from running forever,
                // e.g. when parent rules are still expecting certain input to
                // follow after this, for example when you handle an error inside a set
                // of braces which are matched by a parent rule in your grammar.
                //
                // Hence we require that every error handling/recovery attempt
                // *after we've hit EOF* has a diminishing state stack: this means
                // we will ultimately have unwound the state stack entirely and thus
                // terminate the parse in a controlled fashion even when we have
                // very complex error/recovery code interplay in the core + user
                // action code blocks:
                if (yydebug) {
                    yydebug('locateNearestErrorRecoveryRule #found#: ', {
                        symbol, state, depth,
                        stackidx: sp - 1 - depth,
                        lastidx: lastEofErrorStateDepth
                    });
                }
                if (symbol === EOF) {
                    if (lastEofErrorStateDepth > sp - 1 - depth) {
                        lastEofErrorStateDepth = sp - 1 - depth;
                    } else {
                        if (yydebug) {
                            yydebug('locateNearestErrorRecoveryRule #skip#: ', {
                                symbol, state, depth,
                                stackidx: sp - 1 - depth,
                                lastidx: lastEofErrorStateDepth
                            });
                        }
                        --stack_probe; // popStack(1): [symbol, action]
                        state = sstack[stack_probe];
                        ++depth;
                        continue;
                    }
                }
                return depth;
            }
            if (state === 0 /* $accept rule */ || stack_probe < 1) {
                if (yydebug) {
                    yydebug('locateNearestErrorRecoveryRule #end=NIL#: ', {
                        symbol, state, depth,
                        stackidx: sp - 1 - depth,
                        lastidx: lastEofErrorStateDepth
                    });
                }
                return -1; // No suitable error recovery rule available.
            }
            --stack_probe; // popStack(1): [symbol, action]
            state = sstack[stack_probe];
            ++depth;
        }
        if (yydebug) {
            yydebug('locateNearestErrorRecoveryRule #EMPTY#: ', {
                symbol, state, depth,
                stackidx: sp - 1 - depth,
                lastidx: lastEofErrorStateDepth
            });
        }
        return -1; // No suitable error recovery rule available.
    }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    try {
        this.__reentrant_call_depth++;

        lexer.setInput(input, sharedState_yy);

        // NOTE: we *assume* no lexer pre/post handlers are set up *after*
        // this initial \`setInput()\` call: hence we can now check and decide
        // whether we'll go with the standard, slower, lex() API or the
        // \`fast_lex()\` one:
        if (typeof lexer.canIUse === 'function') {
            let lexerInfo = lexer.canIUse();
            if (lexerInfo.fastLex && typeof fastLex === 'function') {
                lex = fastLex;
            }
        }

        yyloc = this.copy_yylloc(lexer.yylloc);
        lstack[sp] = yyloc;
        vstack[sp] = null;
        sstack[sp] = 0;
        stack[sp] = 0;
        ++sp;

        yytext = lexer.yytext;
        yylineno = lexer.yylineno;
        yyleng = lexer.yyleng;

        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single \`==\` condition below covers both these \`===\` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];

                if (yydebug) {
                    yydebug('after FETCH/LEX: ', {
                        symbol,
                        symbolID: this.terminals_ && this.terminals_[symbol],
                        state, newState, recovering, action
                    });
                }

//_handle_error_with_recovery:                // run this code when the grammar includes error recovery rules

                // handle parse error
                if (!action) {
                    // first see if there's any chance at hitting an error recovery rule:
                    let error_rule_depth = locateNearestErrorRecoveryRule(state);
                    let errStr = null;
                    let errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    let expected = this.collect_expected_token_set(state);

                    if (!recovering) {
                        // Report error
                        errStr = 'Parse error';
                        if (typeof lexer.yylineno === 'number') {
                            errStr += ' on line ' + (lexer.yylineno + 1);
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += ':\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                        } else {
                            errStr += ': ';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                        // DO NOT cleanup the old one before we start the new error info track:
                        // the old one will *linger* on the error stack and stay alive until we
                        // invoke the parser's cleanup API!
                        recoveringErrorInfo = this.shallowCopyErrorInfo(p);

                        if (yydebug) {
                            yydebug('error recovery rule detected: ', {
                                error_rule_depth,
                                error: p.errStr,
                                error_hash: p
                            });
                        }

                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                            break;
                        }

                        // Protect against overly blunt userland \`parseError\` code which *sets*
                        // the \`recoverable\` flag without properly checking first:
                        // we always terminate the parse when there's no recovery rule available anyhow!
                        if (!p.recoverable || error_rule_depth < 0) {
                            break;
                        } else {
                            // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                        }
                    }

                    if (yydebug) {
                        yydebug('after ERROR DETECT: ', {
                            error_rule_depth,
                            error: p.errStr,
                            error_hash: p
                        });
                    }

                    let esp = recoveringErrorInfo.info_stack_pointer;

                    // just recovered from another error
                    if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                        // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                        yyleng = lexer.yyleng;
                        yytext = this.copy_yytext(lexer.yytext);
                        yylineno = lexer.yylineno;
                        yyloc = this.copy_yylloc(lexer.yylloc);

                        // SHIFT current lookahead and grab another
                        recoveringErrorInfo.symbol_stack[esp] = symbol;
                        recoveringErrorInfo.value_stack[esp] = yytext;
                        recoveringErrorInfo.location_stack[esp] = yyloc;
                        recoveringErrorInfo.state_stack[esp] = newState; // push state
                        ++esp;

                        preErrorSymbol = 0;
                        symbol = lex();

                        if (yydebug) {
                            yydebug('after ERROR RECOVERY-3: ', {
                                symbol,
                                symbolID: this.terminals_ && this.terminals_[symbol]
                            });
                        }
                    }

                    // try to recover from error
                    if (error_rule_depth < 0) {
                        ASSERT(recovering > 0, 'Line 1048');
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                        // while we are still busy recovering from another error:
                        let po = this.__error_infos[this.__error_infos.length - 1];

                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                        } else {
                            errStr = 'Parsing halted while starting to recover from another error';
                        }

                        if (po) {
                            errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                        } else {
                            errStr += ': ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, false);
                        if (po) {
                            p.extra_error_attributes = po;
                        }

                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }

                    preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                    symbol = TERROR;            // insert generic error symbol as new lookahead

                    const EXTRA_STACK_SAMPLE_DEPTH = 3;

                    // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                    recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                    if (errStr) {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: this.copy_yytext(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            errStr,
                            errSymbolDescr,
                            expectedStr: expected,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                        if (yydebug) {
                            yydebug('Error recovery process: pushed error info item on the info stack: ', {
                                item: vstack[sp],
                                sp, esp, vstack, stack, sstack,
                                combineState: NO_ACTION[1]
                            });
                        }
                    } else {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: this.copy_yytext(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                    }
                    recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    yyval.$ = recoveringErrorInfo;
                    yyval._$ = undefined;

                    yyrulelen = error_rule_depth;

                    let combineState = NO_ACTION[1];

                    if (yydebug) {
                        yydebug('Error recovery process: performAction: COMBINE: ', {
                            yyval, yytext, sp,
                            pop_size: yyrulelen,
                            vstack, stack, sstack,
                            combineState
                        });
                    }
                    r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, combineState, sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                    if (typeof r !== 'undefined') {
                        retval = r;
                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // and move the top entries + discarded part of the parse stacks onto the error info stack:
                    for (let idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                        recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                        recoveringErrorInfo.value_stack[esp] = vstack[idx];
                        recoveringErrorInfo.location_stack[esp] = lstack[idx];
                        recoveringErrorInfo.state_stack[esp] = sstack[idx];
                    }

                    recoveringErrorInfo.symbol_stack[esp] = TERROR;
                    recoveringErrorInfo.value_stack[esp] = this.copy_yytext(yyval.$);
                    recoveringErrorInfo.location_stack[esp] = this.copy_yylloc(yyval._$);

                    // goto new state = table[STATE][NONTERMINAL]
                    newState = sstack[sp - 1];

                    if (this.defaultActions[newState]) {
                        recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                    } else {
                        t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                        recoveringErrorInfo.state_stack[esp] = t[1];
                    }

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    // allow N (default: 3) real symbols to be shifted before reporting a new error
                    recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;

                    if (yydebug) yydebug('after ERROR POP: ', { error_rule_depth, symbol, preErrorSymbol });

                    // Now duplicate the standard parse machine here, at least its initial
                    // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                    // as we wish to push something special then!
                    //
                    // Run the state machine in this copy of the parser state machine
                    // until we *either* consume the error symbol (and its related information)
                    // *or* we run into another error while recovering from this one
                    // *or* we execute a \`reduce\` action which outputs a final parse
                    // result (yes, that MAY happen!).
                    //
                    // We stay in this secondary parse loop until we have completed
                    // the *error recovery phase* as the main parse loop (further below)
                    // is optimized for regular parse operation and DOES NOT cope with
                    // error recovery *at all*.
                    //
                    // We call the secondary parse loop just below the "slow parse loop",
                    // while the main parse loop, which is an almost-duplicate of this one,
                    // yet optimized for regular parse operation, is called the "fast
                    // parse loop".
                    //
                    // Compare this to \`bison\` & (vanilla) \`jison\`, both of which have
                    // only a single parse loop, which handles everything. Our goal is
                    // to eke out every drop of performance in the main parse loop...

                    ASSERT(recoveringErrorInfo, 'Line 1204');
                    ASSERT(symbol === TERROR, 'Line 1205');
                    ASSERT(!action, 'Line 1206');
                    let errorSymbolFromParser = true;
                    for (;;) {
                        // retrieve state number from top of stack
                        state = newState;               // sstack[sp - 1];

                        // use default actions if available
                        if (this.defaultActions[state]) {
                            action = 2;
                            newState = this.defaultActions[state];
                        } else {
                            // The single \`==\` condition below covers both these \`===\` comparisons in a single
                            // operation:
                            //
                            //     if (symbol === null || typeof symbol === 'undefined') ...
                            if (!symbol) {
                                symbol = lex();
                                // **Warning: Edge Case**: the *lexer* may produce
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided \`yyvalue\`
                                // and \`yylloc\`:
                                errorSymbolFromParser = false;
                            }
                            // read action for current state and first input
                            t = (table[state] && table[state][symbol]) || NO_ACTION;
                            newState = t[1];
                            action = t[0];

                            if (yydebug) {
                                yydebug('after FETCH/LEX: ', {
                                    symbol,
                                    symbolID: this.terminals_ && this.terminals_[symbol],
                                    state, newState, recovering, action
                                });
                            }

                            // encountered another parse error? If so, break out to main loop
                            // and take it from there!
                            if (!action) {
                                if (yydebug) yydebug('**NESTED ERROR DETECTED** while still recovering from previous error');

                                ASSERT(recoveringErrorInfo, 'Line 1248');

                                // Prep state variables so that upon breaking out of
                                // this "slow parse loop" and hitting the \`continue;\`
                                // statement in the outer "fast parse loop" we redo
                                // the exact same state table lookup as the one above
                                // so that the outer=main loop will also correctly
                                // detect the 'parse error' state (\`!action\`) we have
                                // just encountered above.
                                newState = state;
                                break;
                            }
                        }

                        if (yydebug) {
                            yydebug('::: SLOW ERROR RECOVERY PHASE CYCLE action: ' +
                            (action === 1 ?
                                'shift token ' + symbol + ' (then go to state ' + newState + ')' :
                                action === 2 ?
                                    'reduce by rule: ' + newState + (function __print_rule(nt, state) {
                                        if (!nt || !nt.states || !nt.rules) {
                                            return '';
                                        }
                                        let rulename = nt.states[state];
                                        let rulespec = nt.rules[rulename][state];
                                        return ' (' + rulespec.symbol + ' := ' + rulespec.handle + ')';
                                    })(this.nonterminals_, newState) :
                                    action === 3 ?
                                        'accept' :
                                        '???unexpected???'
                            ), {
                                action, newState, recovering, symbol
                            });
                        }

                        switch (action) {
                        // catch misc. parse failures:
                        default:
                            // this shouldn't happen, unless resolve defaults are off
                            //
                            // SILENTLY SIGNAL that the outer "fast parse loop" should
                            // take care of this internal error condition:
                            // prevent useless code duplication now/here.
                            break;

                        // shift:
                        case 1:
                            stack[sp] = symbol;
                            // ### Note/Warning ###
                            //
                            // The *lexer* may also produce TERROR tokens on its own,
                            // so we specifically test for the TERROR we did set up
                            // in the error recovery logic further above!
                            if (symbol === TERROR && errorSymbolFromParser) {
                                // Push a special value onto the stack when we're
                                // shifting the \`error\` symbol that is related to the
                                // error we're recovering from.
                                ASSERT(recoveringErrorInfo, 'Line 1305');
                                vstack[sp] = recoveringErrorInfo;
                                lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                            } else {
                                ASSERT(symbol !== 0, 'Line 1309');
                                ASSERT(preErrorSymbol === 0, 'Line 1310');
                                vstack[sp] = lexer.yytext;
                                lstack[sp] = this.copy_yylloc(lexer.yylloc);
                            }
                            sstack[sp] = newState; // push state

                            ++sp;

                            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                let tokenName = this.getSymbolName(symbol || EOF);
                                if (!tokenName) {
                                    tokenName = symbol;
                                }

                                Jison.parserDebugger.push({
                                    action: 'shift',
                                    text: lexer.yytext,
                                    terminal: tokenName,
                                    terminal_id: symbol
                                });
                            }

                            symbol = 0;
                            // **Warning: Edge Case**: the *lexer* may have produced
                            // TERROR tokens of its own volition: *those* TERROR
                            // tokens should be treated like *regular tokens*
                            // i.e. tokens which have a lexer-provided \`yyvalue\`
                            // and \`yylloc\`:
                            errorSymbolFromParser = false;
                            if (!preErrorSymbol) { // normal execution / no error
                                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                                yyleng = lexer.yyleng;
                                yytext = lexer.yytext;
                                yylineno = lexer.yylineno;
                                yyloc = this.copy_yylloc(lexer.yylloc);

                                if (recovering > 0) {
                                    recovering--;
                                    if (yydebug) yydebug('... SHIFT:error rule matching: ', { recovering, symbol });
                                }
                            } else {
                                // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                ASSERT(recovering > 0, 'Line 1352');
                                symbol = preErrorSymbol;
                                preErrorSymbol = 0;
                                if (yydebug) yydebug('... SHIFT:error recovery: ', { recovering, symbol });
                                // read action for current state and first input
                                t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                if (!t[0] || symbol === TERROR) {
                                    // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                    // (simple) stuff might have been missing before the token which caused the error we're
                                    // recovering from now...
                                    //
                                    // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                    // recovery, for then this we would we idling (cycling) on the error forever.
                                    // Yes, this does not take into account the possibility that the *lexer* may have
                                    // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!
                                    if (yydebug) yydebug('... SHIFT:error recovery: re-application of old symbol doesn\\'t work: instead, we\\'re moving forward now. ', { recovering, symbol });
                                    symbol = 0;
                                }
                            }

                            // once we have pushed the special ERROR token value,
                            // we REMAIN in this inner, "slow parse loop" until
                            // the entire error recovery phase has completed.
                            //
                            // ### Note About Edge Case ###
                            //
                            // Userland action code MAY already have 'reset' the
                            // error recovery phase marker \`recovering\` to ZERO(0)
                            // while the error symbol hasn't been shifted onto
                            // the stack yet. Hence we only exit this "slow parse loop"
                            // when *both* conditions are met!
                            ASSERT(preErrorSymbol === 0, 'Line 1383');
                            if (recovering === 0) {
                                break;
                            }
                            continue;

                        // reduce:
                        case 2:
                            this_production = this.productions_[newState - 1];  // \`this.productions_[]\` is zero-based indexed while states start from 1 upwards...
                            yyrulelen = this_production[1];

                            if (yydebug) {
                                yydebug('~~~ REDUCE: ', {
                                    pop_size: yyrulelen,
                                    newState, recovering, symbol
                                });
                            }

                            r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, newState, sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                                let debuggableProductions = [];
                                for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                                    let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                                    debuggableProductions.push(debuggableProduction);
                                }

                                // find the current nonterminal name (- nolan)
                                let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                                let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                                Jison.parserDebugger.push({
                                    action: 'reduce',
                                    nonterminal: currentNonterminal,
                                    nonterminal_id: currentNonterminalCode,
                                    prereduce: prereduceValue,
                                    result: r,
                                    productions: debuggableProductions,
                                    text: yyval.$
                                });
                            }

                            if (typeof r !== 'undefined') {
                                // signal end of error recovery loop AND end of outer parse loop
                                action = 3;
                                retval = r;

                                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                    Jison.parserDebugger.push({
                                        action: 'accept',
                                        text: retval
                                    });
                                    console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                                }

                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up \`retval\` parser return value.
                                break;
                            }

                            // pop off stack
                            sp -= yyrulelen;

                            // don't overwrite the \`symbol\` variable: use a local var to speed things up:
                            {
                                let ntsymbol = this_production[0];    // push nonterminal (reduce)
                                stack[sp] = ntsymbol;
                                vstack[sp] = yyval.$;
                                lstack[sp] = yyval._$;
                                // goto new state = table[STATE][NONTERMINAL]
                                newState = table[sstack[sp - 1]][ntsymbol];
                                sstack[sp] = newState;
                                ++sp;
                                if (yydebug) yydebug('REDUCED: ', { newState, recovering, symbol });
                            }
                            continue;

                        // accept:
                        case 3:
                            retval = true;
                            // Return the \`$accept\` rule's \`$$\` result, if available.
                            //
                            // Also note that JISON always adds this top-most \`$accept\` rule (with implicit,
                            // default, action):
                            //
                            //     $accept: <startSymbol> $end
                            //                  %{ $$ = $1; @$ = @1; %}
                            //
                            // which, combined with the parse kernel's \`$accept\` state behaviour coded below,
                            // will produce the \`$$\` value output of the <startSymbol> rule as the parse result,
                            // IFF that result is *not* \`undefined\`. (See also the parser kernel code.)
                            //
                            // In code:
                            //
                            //                  %{
                            //                      @$ = @1;            // if location tracking support is included
                            //                      if (typeof $1 !== 'undefined')
                            //                          return $1;
                            //                      else
                            //                          return true;           // the default parse result if the rule actions don't produce anything
                            //                  %}
                            sp--;
                            if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                retval = vstack[sp];
                            }

                            if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                                Jison.parserDebugger.push({
                                    action: 'accept',
                                    text: retval
                                });
                                console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                            }

                            sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up \`retval\` parser return value.
                            break;
                        }

                        // break out of loop: we accept or fail with error
                        break;
                    }

                    // should we also break out of the regular/outer parse loop,
                    // i.e. did the parser already produce a parse result in here?!
                    // *or* did we hit an unsupported parse state, to be handled
                    // in the \`switch/default\` code further below?
                    ASSERT(action !== 2, 'Line 1509');
                    if (!action || action === 1) {
                        continue;
                    }
                }

//_handle_error_no_recovery:                  // run this code when the grammar does not include any error recovery rules

                // handle parse error
                if (!action) {
                    let errStr;
                    let errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    let expected = this.collect_expected_token_set(state);

                    // Report error
                    errStr = 'Parse error';
                    if (typeof lexer.yylineno === 'number') {
                        errStr += ' on line ' + (lexer.yylineno + 1);
                    }

                    if (typeof lexer.showPosition === 'function') {
                        errStr += ':\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                    } else {
                        errStr += ': ';
                    }
                    if (expected.length) {
                        errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                    } else {
                        errStr += 'Unexpected ' + errSymbolDescr;
                    }
                    // we cannot recover from the error!
                    p = this.constructParseErrorInfo(errStr, null, expected, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }

//_handle_error_end_of_section:                  // this concludes the error recovery / no error recovery code section choice above

            }

            if (yydebug) {
                yydebug('::: MAIN CYCLE action: ' +
                (action === 1 ?
                    'shift token ' + symbol + ' (then go to state ' + newState + ')' :
                    action === 2 ?
                        'reduce by rule: ' + newState + (function __print_rule(nt, state) {
                            if (!nt || !nt.states || !nt.rules) {
                                return '';
                            }
                            let rulename = nt.states[state];
                            let rulespec = nt.rules[rulename][state];
                            return ' (' + rulespec.symbol + ' := ' + rulespec.handle + ')';
                        })(this.nonterminals_, newState) :
                        action === 3 ?
                            'accept' :
                            '???unexpected???'
                ), {
                    action, newState, recovering, symbol
                });
            }

            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                r = this.parseError(p.errStr, p, this.JisonParserError);
                if (typeof r !== 'undefined') {
                    retval = r;
                }
                break;

            // shift:
            case 1:
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;
                lstack[sp] = this.copy_yylloc(lexer.yylloc);
                sstack[sp] = newState; // push state

                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                    let tokenName = this.getSymbolName(symbol || EOF);
                    if (!tokenName) {
                        tokenName = symbol;
                    }

                    Jison.parserDebugger.push({
                        action: 'shift',
                        text: lexer.yytext,
                        terminal: tokenName,
                        terminal_id: symbol
                    });
                }

                ++sp;

                symbol = 0;

                ASSERT(preErrorSymbol === 0, 'Line 1619');         // normal execution / no error
                ASSERT(recovering === 0, 'Line 1620');             // normal execution / no error

                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                yyleng = lexer.yyleng;
                yytext = lexer.yytext;
                yylineno = lexer.yylineno;
                yyloc = this.copy_yylloc(lexer.yylloc);
                continue;

            // reduce:
            case 2:
                ASSERT(preErrorSymbol === 0, 'Line 1631');         // normal execution / no error
                ASSERT(recovering === 0, 'Line 1632');             // normal execution / no error

                this_production = this.productions_[newState - 1];  // \`this.productions_[]\` is zero-based indexed while states start from 1 upwards...
                yyrulelen = this_production[1];

                if (yydebug) {
                    yydebug('~~~ REDUCE: ', {
                        pop_size: yyrulelen,
                        newState, recovering, symbol
                    });
                }

                r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, newState, sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                    let prereduceValue = vstack.slice(sp - yyrulelen, sp);
                    let debuggableProductions = [];
                    for (let debugIdx = yyrulelen - 1; debugIdx >= 0; debugIdx--) {
                        let debuggableProduction = getNonTerminalFromCode(stack[sp - debugIdx]);
                        debuggableProductions.push(debuggableProduction);
                    }

                    // find the current nonterminal name (- nolan)
                    let currentNonterminalCode = this_production[0];     // WARNING: nolan's original code takes this one instead:   this.productions_[newState][0];
                    let currentNonterminal = getNonTerminalFromCode(currentNonterminalCode);

                    Jison.parserDebugger.push({
                        action: 'reduce',
                        nonterminal: currentNonterminal,
                        nonterminal_id: currentNonterminalCode,
                        prereduce: prereduceValue,
                        result: r,
                        productions: debuggableProductions,
                        text: yyval.$
                    });
                }

                if (typeof r !== 'undefined') {
                    retval = r;

                    if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                        Jison.parserDebugger.push({
                            action: 'accept',
                            text: retval
                        });
                        console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                    }

                    break;
                }

                // pop off stack
                sp -= yyrulelen;

                // don't overwrite the \`symbol\` variable: use a local var to speed things up:
                {
                    let ntsymbol = this_production[0];    // push nonterminal (reduce)
                    stack[sp] = ntsymbol;
                    vstack[sp] = yyval.$;
                    lstack[sp] = yyval._$;
                    // goto new state = table[STATE][NONTERMINAL]
                    newState = table[sstack[sp - 1]][ntsymbol];
                    sstack[sp] = newState;
                    ++sp;
                    if (yydebug) yydebug('REDUCED: ', { newState, recovering, symbol });
                }
                continue;

            // accept:
            case 3:
                if (sp !== -2) {
                    retval = true;
                    // Return the \`$accept\` rule's \`$$\` result, if available.
                    //
                    // Also note that JISON always adds this top-most \`$accept\` rule (with implicit,
                    // default, action):
                    //
                    //     $accept: <startSymbol> $end
                    //                  %{ $$ = $1; @$ = @1; %}
                    //
                    // which, combined with the parse kernel's \`$accept\` state behaviour coded below,
                    // will produce the \`$$\` value output of the <startSymbol> rule as the parse result,
                    // IFF that result is *not* \`undefined\`. (See also the parser kernel code.)
                    //
                    // In code:
                    //
                    //                  %{
                    //                      @$ = @1;            // if location tracking support is included
                    //                      if (typeof $1 !== 'undefined')
                    //                          return $1;
                    //                      else
                    //                          return true;           // the default parse result if the rule actions don't produce anything
                    //                  %}
                    sp--;
                    if (typeof vstack[sp] !== 'undefined') {
                        retval = vstack[sp];
                    }
                }

                if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
                    Jison.parserDebugger.push({
                        action: 'accept',
                        text: retval
                    });
                    console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
                }

                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        } else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }

        p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
        retval = false;
        r = this.parseError(p.errStr, p, this.JisonParserError);
        if (typeof r !== 'undefined') {
            retval = r;
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;

        if (typeof Jison !== 'undefined' && Jison.parserDebugger) {
            Jison.parserDebugger.push({
                action: 'return',
                text: retval
            });
            console.log(Jison.parserDebugger[Jison.parserDebugger.length - 1]);
        }
    }   // /finally

    return retval;
}
`;
    // --- END parser kernel ---


    /*
     * LR(0) Parser
     */

    const lr0 = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
        type: 'LR(0)',
        afterconstructor: function lr0_afterconstructor() {
            this.buildTable();
        }
    });

    const LR0Generator = Jison$1.LR0Generator = lr0.construct();

    /*
     * Simple LALR(1)
     */

    const lalr = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
        type: 'LALR(1)',

        afterconstructor: function lalr_afterconstructor() {
            let self = this;

            if (this.DEBUG) {
                this.mix(lrGeneratorDebug, lalrGeneratorDebug); // mixin debug methods
            }

            for (let round = 1; /* infinite loop if it weren't for the `break`s at the end */ ; round++) {
                this.states = this.canonicalCollection();

                if (this.DEBUG || devDebug) {
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER canonicalCollection:');
                    this.displayFollowSets();
                    Jison$1.print('\n');
                }

                this.terms_ = {};

                let newg = this.newg = typal.beget(lookaheadMixin, {
                    oldg: this,
                    trace: this.trace,
                    nterms_: {},
                    DEBUG: false,
                    go_: function (productionSymbol, productionHandle) {
                        let stateNum = productionSymbol.split(':')[0]; // grab state #
                        assert__default['default'](stateNum == +stateNum);
                        stateNum = +stateNum;
                        productionHandle = productionHandle.map(function (rhsElem) {
                            return rhsElem.slice(rhsElem.indexOf(':') + 1);
                        });
                        return this.oldg.go(stateNum, productionHandle, productionSymbol);
                    }
                });
                newg.nonterminals = {};
                newg.productions = [];

                //this.inadequateStates = [];

                // if true, only lookaheads in inadequate states are computed (faster, larger table)
                // if false, lookaheads for all reductions will be computed (slower, smaller table)
                //
                // WARNING: using this has a negative effect on your error reports:
                //          a lot of 'expected' symbols are reported which are not in the real FOLLOW set,
                //          resulting in 'illogical' error messages!
                this.onDemandLookahead = !!this.options.onDemandLookahead;
                if ( this.DEBUG) Jison$1.print('LALR: using on-demand look-ahead: ', (this.onDemandLookahead ? 'yes' : 'no'));

                this.buildNewGrammar();

                if ( this.DEBUG) {
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER buildNewGrammar: NEW GRAMMAR');
                    newg.displayFollowSets();
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER buildNewGrammar: ORIGINAL GRAMMAR');
                    this.displayFollowSets();
                }

                newg.computeLookaheads();

                // backprop `nullable` value for each nonterminal and production back to original grammar:
                each(newg.nonterminals, function (newg_nt, t) {
                    // extract original symbol:
                    let sym;
                    let a = newg_nt.symbol.split(':');
                    if (a.length === 1 || a[0] === '') {
                        sym = newg_nt.symbol;
                    } else {
                        a.shift();
                        sym = a.join(':');
                    }
                    if (self.nonterminals[sym] && newg_nt.nullable) {
                        self.nonterminals[sym].nullable = true;
                    }
                });

                if ( this.DEBUG) {
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads: NEW GRAMMAR');
                    newg.displayFollowSets();
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads: ORIGINAL GRAMMAR');
                    this.displayFollowSets();
                }

                this.unionLookaheads();

                if ( this.DEBUG) {
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER unionLookaheads: NEW GRAMMAR');
                    newg.displayFollowSets();
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER unionLookaheads: ORIGINAL GRAMMAR');
                    this.displayFollowSets();
                }

                this.table = this.parseTable(this.states);

                if ( this.DEBUG) {
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable: NEW GRAMMAR');
                    newg.displayFollowSets();
                    Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable: ORIGINAL GRAMMAR');
                    this.displayFollowSets();
                }

                // When some productions are flagged as conflicting, we redo the G' generation and consequent union-ing of the productions
                // in the `.goes[]` arrays.
                //
                // Also quit when we're at the end of the conflict resolution round (which is round #2)
                if (this.conflicts === 0 || this.conflict_fixing_round || !this.options.hasPartialLrUpgradeOnConflict) {
                    break;
                }

                {
                    Jison$1.print('\n'
                        + '----------------------------------- NOTICE -------------------------------\n'
                        + 'Attempting to resolve the unresolved conflicts in partial LR mode...\n\n'
                        + 'When no conflicts are reported in the next round below, your grammar is\n'
                        + 'accepted as mixed LR/LALR and should work as expected.\n'
                        + '--------------------------------------------------------------------------\n\n');
                }

                this.conflict_fixing_round = true;

                // and reset the conflict trackers, which we do not use to attempt to fix the conflict in round #2:
                this.conflicts = 0;
                this.new_conflicts_found_this_round = 0;
                this.conflicting_states = [];
                this.resolutions = [];
            }

            this.defaultActions = findDefaults(this.table, this.hasErrorRecovery);
            cleanupTable(this.table);

            traceStates(this.trace, this.states, 'at the end of the LALR constructor, after cleanupTable() and findDefaults()');
        },

        lookAheads: function LALR_lookaheads(state, item) {
            return (this.onDemandLookahead && !state.inadequate) ? this.terminals : item.follows;
        },

        go: function LALR_go(stateNum, productionHandle, productionSymbol) {
            assert__default['default'](typeof stateNum === 'number');
            let endStateNum = stateNum;
            for (let i = 0; i < productionHandle.length; i++) {
                endStateNum = this.states.item(endStateNum).edges[productionHandle[i]] || endStateNum;
            }
            return endStateNum;
        },

        goPath: function LALR_goPath(stateNum, productionHandle, productionSymbol) {
            assert__default['default'](typeof stateNum === 'number');
            let endStateNum = stateNum,
                    t,
                    path = [];
            for (let i = 0; i < productionHandle.length; i++) {
                t = productionHandle[i] ? endStateNum + ':' + productionHandle[i] /* + ':' + productionSymbol */ : '';
                if (t) {
                    this.newg.nterms_[t] = endStateNum;
                }
                path.push(t);
                endStateNum = this.states.item(endStateNum).edges[productionHandle[i]] || endStateNum;
                assert__default['default'](t ? typeof this.terms_[t] === 'undefined' || this.terms_[t] === productionHandle[i] : true);
                this.terms_[t] = productionHandle[i];
            }
            return {
                path: path,
                endState: endStateNum
            };
        },

        // every disjoint reduction of a nonterminal becomes a production in G'
        buildNewGrammar: function LALR_buildNewGrammar() {
            let self = this,
                    newg = this.newg;

            this.states.forEach(function (state, i) {
                i = +i;
                state.forEach(function LALR_buildNewHandle(item) {
                    if (item.dotPosition === 0) {
                        // new symbols are a combination of state and transition symbol
                        let symbol = i + ':' + item.production.symbol;
                        assert__default['default'](typeof self.terms_[symbol] === 'undefined' || self.terms_[symbol] === item.production.symbol);
                        self.terms_[symbol] = item.production.symbol;
                        newg.nterms_[symbol] = i;
                        if (!newg.nonterminals[symbol]) {
                            newg.nonterminals[symbol] = new Nonterminal(symbol);
                        }
                        let pathInfo = self.goPath(i, item.production.handle, item.production.symbol);
                        let p = new Production(symbol, pathInfo.path, newg.productions.length);
                        newg.productions.push(p);
                        newg.nonterminals[symbol].productions.push(p);

                        // store the transition that gets 'backed up to' after reduction on path
                        let handle = item.production.handle.join(' ');
                        if (self.conflict_fixing_round && self.conflict_states_LU[i]) ;
                        if (self.conflict_fixing_round && self.conflict_productions_LU[item.production.id]) {
                            handle += ':P' + item.production.id;
                        }

                        let goes = self.states.item(pathInfo.endState).goes;
                        if (!goes[handle]) {
                            goes[handle] = [];
                        }
                        goes[handle].push(symbol);
                    }
                });
                // if (state.inadequate) {
                //     self.inadequateStates.push(i);
                // }
            });
        },

        unionLookaheads: function LALR_unionLookaheads() {
            let self = this,
                    newg = this.newg;
            // let states = !!this.onDemandLookahead ? this.inadequateStates : this.states;

            let these_states = this.states;
            these_states.forEach(function union_states_forEach(state, i) {
                i = +i;
                //assert(state.inadequate ? these_states.inadequate : true);
                let treat_me = (self.onDemandLookahead ? these_states.inadequate || state.inadequate : true);
                if (state.reductions.length && treat_me) {
                    state.reductions.forEach(function union_reduction_forEach(item) {
                        let follows = {};
                        for (let k = 0; k < item.follows.length; k++) {
                            follows[item.follows[k]] = true;
                        }
                        let handle = item.production.handle.join(' ');
                        if (self.conflict_fixing_round && self.conflict_states_LU[i]) ;
                        if (self.conflict_fixing_round && self.conflict_productions_LU[item.production.id]) {
                            handle += ':P' + item.production.id;
                        }
                        if (!state.goes[handle]) {
                            state.goes[handle] = [];
                        }

                        state.goes[handle].forEach(function reduction_goes_forEach(symbol) {
                            newg.nonterminals[symbol].follows.forEach(function goes_follows_forEach(symbol) {
                                let terminal = self.terms_[symbol];
                                if (!follows[terminal]) {
                                    follows[terminal] = true;

                                    item.follows.push(terminal);
                                }
                            });
                        });
                    });
                }
            });
        }
    });

    const LALRGenerator = Jison$1.LALRGenerator = lalr.construct();

    // LALR generator debug mixin

    const lalrGeneratorDebug = {
        beforebuildNewGrammar: function () {
            this.trace(this.states.size() + ' states.');
            this.trace('Building lookahead grammar.');
        },
        beforeunionLookaheads: function () {
            this.trace('Computing lookaheads.');
        },
        afterbuildNewGrammar: function () {
            traceStates(this.trace, this.states, 'after LALR::buildNewGrammar()');
        },
        afterunionLookaheads: function () {
            traceStates(this.trace, this.states, 'after LALR::unionLookaheads()');
        },
        aftercomputeLookaheads: function () {
            traceStates(this.trace, this.states, 'after LALR::computeLookaheads()');
        },
        aftercanonicalCollection: function (states /* as produced by `this.canonicalCollection()` */) {
            traceStates(this.trace, states, 'as produced by LALR::canonicalCollection()');
        }
    };

    /*
     * Lookahead parser definitions
     *
     * Define base type
     */
    const lrLookaheadGenerator = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
        afterconstructor: function lr_aftercontructor() {
            this.computeLookaheads();

            if ( this.DEBUG) {
                Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads:');
                this.displayFollowSets();
                Jison$1.print('\n');
            }

            this.buildTable();
        }
    });

    /*
     * SLR Parser
     */
    const SLRGenerator = Jison$1.SLRGenerator = lrLookaheadGenerator.construct({
        type: 'SLR(1)',

        lookAheads: function SLR_lookAhead(state, item) {
            return this.nonterminals[item.production.symbol].follows;
        }
    });


    /*
     * LR(1) Parser
     */
    const lr1 = lrLookaheadGenerator.beget({
        type: 'Canonical LR(1)',

        lookAheads: function LR_lookAheads(state, item) {
            return item.follows;
        },

        Item: lrGeneratorMixin.Item.prototype.construct({
            afterconstructor: function () {
                this.id = this.production.id + '#' + this.dotPosition + '#' + this.follows.sort().join(',');
            },
            eq: function (e) {
                return e.id === this.id;
            }
        }),

        closureOperation: function LR_ClosureOperation(itemSet) {
            let closureSet = new this.ItemSet();
            let self = this;

            let set = itemSet;

            do {
                let itemQueue = new Set$1();
                closureSet = closureSet.concat(set);
                set.forEach(function LR_AddItemToClosureSets(item) {
                    let symbol = item.markedSymbol;

                    // if token is a nonterminal, recursively add closures
                    if (symbol && self.nonterminals[symbol]) {
                        let r = item.remainingHandle();
                        let b = self.first(r);
                        if (b.length === 0 || item.production.nullable || self.nullable(r)) {
                            b = b.concat(item.follows);
                        }
                        self.nonterminals[symbol].productions.forEach(function (production) {
                            let newItem = new self.Item(production, 0, b);
                            if (!closureSet.contains(newItem) && !itemQueue.contains(newItem)) {
                                itemQueue.push(newItem);
                            }
                        });
                    } else if (!symbol) {
                        // reduction
                        closureSet.reductions.push(item);
                    }
                });

                set = itemQueue;
            } while (!set.isEmpty());

            return closureSet;
        }
    });

    const LR1Generator = Jison$1.LR1Generator = lr1.construct();

    /*
     * LL Parser
     */
    const ll = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
        type: 'LL(1)',

        afterconstructor: function ll_aftercontructor() {
            this.computeLookaheads();

            if ( this.DEBUG) {
                Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads:');
                this.displayFollowSets();
            }

            this.table = this.parseTable(this.productions);

            if ( this.DEBUG) {
                Jison$1.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable:');
                this.displayFollowSets();
            }

            this.defaultActions = {}; // findDefaults(this.table, this.hasErrorRecovery);
            //cleanupTable(this.table);
        },

        parseTable: function ll_ParseTable(productions) {
            let table = {};
            let symbols_ = this.symbols_;
            let self = this;

            productions.forEach(function (production, i) {
                let row = table[production.symbol] || {};
                let tokens = production.first;
                if (self.nullable(production.handle)) {
                    tokens = union(tokens, self.nonterminals[production.symbol].follows);
                }
                tokens.forEach(function (token) {
                    if (row[token]) {
                        row[token].push(i);
                        self.conflicts++;
                    } else {
                        row[token] = [ i ];
                    }
                });
                table[production.symbol] = row;
                production.first = tokens;
            });

            return table;
        }
    });

    const LLGenerator = Jison$1.LLGenerator = ll.construct();

    Jison$1.Generator = function Jison_Generator(grammar, optionalLexerSection, options) {
        // pick the correct argument for the `options` for this call:
        if (!options && optionalLexerSection && typeof optionalLexerSection !== 'string') {
            options = optionalLexerSection;
            optionalLexerSection = null;
        }
        // and standardize it:
        let preliminary_options = mkStdOptions$1(options);

        // Provisionally parse the grammar, really only to obtain the *options.type*
        // specified within the grammar, if specified (via `%parser-type`).
        //
        // Meanwhile, we *auto-detect* if the input is in JSON or JISON format
        // and parse the specs, so we don't have to, nor should we have to, do
        // *that* activity again in the specific generators below: they all
        // share a common grammar+lexer spec format (JSON/JSON5/JISON) which will
        // be parsed by `autodetectAndConvertToJSONformat()` right now!
        grammar = autodetectAndConvertToJSONformat$1(grammar, optionalLexerSection, preliminary_options);

        // make sure all options are 'standardized' before we go and mix them together
        //
        // WARNING:
        // make sure to mix together the **original options sets** as it's last-come-last-serve
        // in `mkStdOptions` and you don't want the mixed in defaults carried in `preliminary_options`
        // to percolate into the final options set as if those we overrides coming in from
        // the API (via the `options` parameter above)!
        //
        // Anyway, API/CLI options **override** options coming in from the grammar spec.
        //
        options = mkStdOptions$1('NODEFAULT', grammar.options, options);
        switch (options.type || Jison$1.defaultJisonOptions.type) {
        case 'lr0':
            options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
            return new LR0Generator(grammar, null, options);
        case 'slr':
            options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
            return new SLRGenerator(grammar, null, options);
        case 'lr':
        case 'lr1':
            options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
            return new LR1Generator(grammar, null, options);
        case 'll':
        case 'll1':
            options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
            return new LLGenerator(grammar, null, options);
        case 'lalr1':
        case 'lalr':
        case '':
            return new LALRGenerator(grammar, null, options);
        default:
            throw new Error('Unsupported parser type: ' + options.type);
        }
    };

    function Parser$3(g, l, options) {
        let gen = Jison$1.Generator(g, l, options);
        return gen.createParser();
    }

    Jison$1.Parser = Parser$3;

    // exports for unit/system testing purposes:
    Jison$1.TestExports = {
        lookaheadMixin, generatorMixin, lrGeneratorMixin,
        lalr,
        lr0,
        lr1,
        ll,
        parser: parser$4,
        pickErrorHandlingChunk,
        addOrRemoveTokenStack,
        removeUnusedKernelFeatures,
        expandParseArguments
    };

    return Jison$1;

})));
